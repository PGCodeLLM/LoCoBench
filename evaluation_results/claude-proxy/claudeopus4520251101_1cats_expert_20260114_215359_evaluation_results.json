{
  "metadata": {
    "evaluation_timestamp": "2026-01-14T21:53:59.091936",
    "framework_version": "1.0.0",
    "config_file": "default",
    "total_models": 1,
    "total_scenarios": 25,
    "unique_scenarios": 25,
    "models_evaluated": [
      "claude-opus-4-5-20251101"
    ],
    "evaluation_scope": {
      "category_distribution": {
        "feature_implementation": 25
      },
      "difficulty_distribution": {
        "expert": 25
      },
      "unique_scenario_ids": [
        "python_mobile_game_medium_096_feature_implementation_expert_01",
        "python_system_monitoring_medium_061_feature_implementation_expert_01",
        "python_system_automation_medium_098_feature_implementation_expert_01",
        "python_api_rest_easy_078_feature_implementation_expert_01",
        "python_game_simulation_medium_033_feature_implementation_expert_01",
        "python_data_streaming_hard_013_feature_implementation_expert_01",
        "python_ml_nlp_easy_017_feature_implementation_expert_01",
        "python_system_automation_hard_062_feature_implementation_expert_01",
        "python_fintech_payment_expert_029_feature_implementation_expert_01",
        "python_ml_nlp_easy_089_feature_implementation_expert_01",
        "python_game_engine_expert_032_feature_implementation_expert_01",
        "python_system_monitoring_hard_097_feature_implementation_expert_01",
        "python_desktop_productivity_easy_091_feature_implementation_expert_01",
        "python_mobile_game_hard_060_feature_implementation_expert_01",
        "python_data_streaming_expert_085_feature_implementation_expert_01",
        "python_web_cms_hard_074_feature_implementation_expert_01",
        "python_data_warehouse_easy_084_feature_implementation_expert_01",
        "python_fintech_trading_hard_030_feature_implementation_expert_01",
        "python_api_graphql_easy_043_feature_implementation_expert_01",
        "python_web_blog_easy_004_feature_implementation_expert_01",
        "python_api_gateway_hard_009_feature_implementation_expert_01",
        "python_web_social_easy_073_feature_implementation_expert_01",
        "python_ml_training_hard_015_feature_implementation_expert_01",
        "python_blockchain_nft_medium_035_feature_implementation_expert_01",
        "python_data_lake_hard_014_feature_implementation_expert_01"
      ]
    },
    "system_info": {
      "total_evaluation_time": 4266.313661575317,
      "avg_parsing_success_rate": 1.0
    }
  },
  "configuration": {
    "api_settings": {
      "max_requests_per_minute": 600,
      "default_models": {
        "openai": "claude-opus-4-5-20251101",
        "google": "gemini-2.5-pro"
      }
    },
    "evaluation_weights": {
      "architectural_coherence": 0.125,
      "dependency_traversal": 0.125,
      "cross_file_reasoning": 0.125,
      "system_thinking": 0.125,
      "robustness": 0.125,
      "comprehensiveness": 0.125,
      "innovation": 0.125,
      "solution_elegance": 0.125,
      "information_coverage": 0.5,
      "multi_session_memory": 0.5
    },
    "benchmark_settings": {
      "total_instances": 8000,
      "min_information_coverage": 0.2
    }
  },
  "analysis": {
    "model_comparison": {},
    "performance_ranking": [
      [
        "claude-opus-4-5-20251101",
        2.9389788376843735
      ]
    ],
    "category_performance": {
      "claude-opus-4-5-20251101": {
        "feature_implementation": {
          "count": 25,
          "avg_total_score": 2.9389788376843735,
          "avg_software_engineering": 0.5304707946924899,
          "avg_functional_correctness": 0.4723482746436039,
          "avg_code_quality": 0.7846041025641024,
          "avg_longcontext_utilization": 0.7698214675397697
        }
      }
    }
  },
  "summaries": {
    "claude-opus-4-5-20251101": {
      "model_name": "claude-opus-4-5-20251101",
      "total_scenarios": 25,
      "completed_scenarios": 25,
      "failed_scenarios": 0,
      "avg_software_engineering_score": 0.5304707946924899,
      "avg_functional_correctness_score": 0.4723482746436039,
      "avg_code_quality_score": 0.7846041025641024,
      "avg_longcontext_utilization_score": 0.7698214675397697,
      "avg_total_score": 2.9389788376843735,
      "avg_generation_time": 170.6525464630127,
      "total_evaluation_time": 4266.313661575317,
      "parsing_success_rate": 1.0,
      "category_results": {
        "feature_implementation": {
          "count": 25,
          "avg_total_score": 2.9389788376843735,
          "avg_software_engineering": 0.5304707946924899,
          "avg_functional_correctness": 0.4723482746436039,
          "avg_code_quality": 0.7846041025641024,
          "avg_longcontext_utilization": 0.7698214675397697
        }
      },
      "difficulty_results": {
        "expert": {
          "count": 25,
          "avg_total_score": 2.9389788376843735,
          "avg_software_engineering": 0.5304707946924899,
          "avg_functional_correctness": 0.4723482746436039,
          "avg_code_quality": 0.7846041025641024,
          "avg_longcontext_utilization": 0.7698214675397697
        }
      }
    }
  },
  "detailed_results": {
    "claude-opus-4-5-20251101": [
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_game_simulation_medium_033_feature_implementation_expert_01",
        "scenario_title": "Implement Programmable Force Fields",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.4910993182490914,
        "functional_correctness_score": 0.35524200229135455,
        "code_quality_score": 0.8099999999999998,
        "longcontext_utilization_score": 0.8286609299516907,
        "total_score": 2.73939210491106,
        "generation_time": 220.02771925926208,
        "code_files_generated": 7,
        "total_lines_generated": 2009,
        "parsing_success": true,
        "solution_code": {
          "physage_academy/src/physage_academy/engine/scene.py": "\"\"\"Scene management for PhySage Academy.\"\"\"\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Any, Optional\nimport uuid\n\n\n@dataclass\nclass Vec2d:\n    \"\"\"Simple 2D vector class.\"\"\"\n    x: float = 0.0\n    y: float = 0.0\n    \n    def __add__(self, other: 'Vec2d') -> 'Vec2d':\n        return Vec2d(self.x + other.x, self.y + other.y)\n    \n    def __sub__(self, other: 'Vec2d') -> 'Vec2d':\n        return Vec2d(self.x - other.x, self.y - other.y)\n    \n    def __mul__(self, scalar: float) -> 'Vec2d':\n        return Vec2d(self.x * scalar, self.y * scalar)\n    \n    def __rmul__(self, scalar: float) -> 'Vec2d':\n        return self.__mul__(scalar)\n    \n    @property\n    def length_sq(self) -> float:\n        \"\"\"Return squared length of vector.\"\"\"\n        return self.x * self.x + self.y * self.y\n    \n    @property\n    def length(self) -> float:\n        \"\"\"Return length of vector.\"\"\"\n        import math\n        return math.sqrt(self.length_sq)\n    \n    def normalized(self) -> 'Vec2d':\n        \"\"\"Return normalized vector.\"\"\"\n        l = self.length\n        if l == 0:\n            return Vec2d(0, 0)\n        return Vec2d(self.x / l, self.y / l)\n    \n    def distance_to(self, other: 'Vec2d') -> float:\n        \"\"\"Return distance to another vector.\"\"\"\n        return (self - other).length\n\n\n@dataclass\nclass PhysicsBody:\n    \"\"\"Represents a physics body in the scene.\"\"\"\n    id: str\n    position: Vec2d\n    velocity: Vec2d = field(default_factory=lambda: Vec2d(0, 0))\n    mass: float = 1.0\n    is_static: bool = False\n    shape_type: str = \"circle\"\n    radius: float = 10.0\n    width: float = 20.0\n    height: float = 20.0\n    restitution: float = 0.5\n    friction: float = 0.3\n    \n    def apply_force(self, force: Vec2d) -> None:\n        \"\"\"Apply a force to this body.\"\"\"\n        if not self.is_static and self.mass > 0:\n            acceleration = Vec2d(force.x / self.mass, force.y / self.mass)\n            self.velocity = self.velocity + acceleration\n\n\n@dataclass\nclass ForceField:\n    \"\"\"Represents a programmable force field in the scene.\"\"\"\n    id: str\n    position: Vec2d\n    radius: float\n    script_path: str\n    enabled: bool = True\n    \n    def contains(self, point: Vec2d) -> bool:\n        \"\"\"Check if a point is within the force field radius.\"\"\"\n        return self.position.distance_to(point) <= self.radius\n\n\n@dataclass\nclass SceneObject:\n    \"\"\"Represents a generic scene object.\"\"\"\n    id: str\n    name: str\n    position: Vec2d\n    rotation: float = 0.0\n    scale: Vec2d = field(default_factory=lambda: Vec2d(1.0, 1.0))\n    visible: bool = True\n    layer: int = 0\n    tags: List[str] = field(default_factory=list)\n    properties: Dict[str, Any] = field(default_factory=dict)\n    physics_body: Optional[PhysicsBody] = None\n\n\nclass Scene:\n    \"\"\"Manages all objects and entities in a scene.\"\"\"\n    \n    def __init__(self, name: str = \"Untitled Scene\"):\n        self.name = name\n        self.id = str(uuid.uuid4())\n        self._objects: Dict[str, SceneObject] = {}\n        self._physics_bodies: Dict[str, PhysicsBody] = {}\n        self._force_fields: Dict[str, ForceField] = {}\n        self._layers: Dict[int, List[str]] = {}\n        self.gravity = Vec2d(0, 9.8)\n        self.bounds = (800, 600)\n    \n    def add_object(self, obj: SceneObject) -> None:\n        \"\"\"Add a scene object.\"\"\"\n        self._objects[obj.id] = obj\n        if obj.layer not in self._layers:\n            self._layers[obj.layer] = []\n        self._layers[obj.layer].append(obj.id)\n        \n        if obj.physics_body:\n            self._physics_bodies[obj.physics_body.id] = obj.physics_body\n    \n    def remove_object(self, object_id: str) -> Optional[SceneObject]:\n        \"\"\"Remove a scene object by ID.\"\"\"\n        if object_id in self._objects:\n            obj = self._objects.pop(object_id)\n            if obj.layer in self._layers and object_id in self._layers[obj.layer]:\n                self._layers[obj.layer].remove(object_id)\n            if obj.physics_body and obj.physics_body.id in self._physics_bodies:\n                del self._physics_bodies[obj.physics_body.id]\n            return obj\n        return None\n    \n    def get_object(self, object_id: str) -> Optional[SceneObject]:\n        \"\"\"Get a scene object by ID.\"\"\"\n        return self._objects.get(object_id)\n    \n    def get_all_objects(self) -> List[SceneObject]:\n        \"\"\"Get all scene objects.\"\"\"\n        return list(self._objects.values())\n    \n    def add_physics_body(self, body: PhysicsBody) -> None:\n        \"\"\"Add a physics body directly.\"\"\"\n        self._physics_bodies[body.id] = body\n    \n    def remove_physics_body(self, body_id: str) -> Optional[PhysicsBody]:\n        \"\"\"Remove a physics body by ID.\"\"\"\n        return self._physics_bodies.pop(body_id, None)\n    \n    def get_physics_body(self, body_id: str) -> Optional[PhysicsBody]:\n        \"\"\"Get a physics body by ID.\"\"\"\n        return self._physics_bodies.get(body_id)\n    \n    def get_all_physics_bodies(self) -> List[PhysicsBody]:\n        \"\"\"Get all physics bodies.\"\"\"\n        return list(self._physics_bodies.values())\n    \n    def get_dynamic_bodies(self) -> List[PhysicsBody]:\n        \"\"\"Get all dynamic (non-static) physics bodies.\"\"\"\n        return [b for b in self._physics_bodies.values() if not b.is_static]\n    \n    def add_force_field(self, force_field: ForceField) -> None:\n        \"\"\"Add a force field to the scene.\"\"\"\n        self._force_fields[force_field.id] = force_field\n    \n    def remove_force_field(self, field_id: str) -> Optional[ForceField]:\n        \"\"\"Remove a force field by ID.\"\"\"\n        return self._force_fields.pop(field_id, None)\n    \n    def get_force_field(self, field_id: str) -> Optional[ForceField]:\n        \"\"\"Get a force field by ID.\"\"\"\n        return self._force_fields.get(field_id)\n    \n    def get_all_force_fields(self) -> List[ForceField]:\n        \"\"\"Get all force fields.\"\"\"\n        return list(self._force_fields.values())\n    \n    def clear(self) -> None:\n        \"\"\"Clear all objects from the scene.\"\"\"\n        self._objects.clear()\n        self._physics_bodies.clear()\n        self._force_fields.clear()\n        self._layers.clear()\n    \n    def find_objects_by_tag(self, tag: str) -> List[SceneObject]:\n        \"\"\"Find all objects with a specific tag.\"\"\"\n        return [obj for obj in self._objects.values() if tag in obj.tags]\n    \n    def find_objects_in_layer(self, layer: int) -> List[SceneObject]:\n        \"\"\"Find all objects in a specific layer.\"\"\"\n        if layer not in self._layers:\n            return []\n        return [self._objects[oid] for oid in self._layers[layer] if oid in self._objects]\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Serialize scene to dictionary.\"\"\"\n        return {\n            \"name\": self.name,\n            \"id\": self.id,\n            \"gravity\": {\"x\": self.gravity.x, \"y\": self.gravity.y},\n            \"bounds\": self.bounds,\n            \"objects\": [self._serialize_object(obj) for obj in self._objects.values()],\n            \"force_fields\": [self._serialize_force_field(ff) for ff in self._force_fields.values()]\n        }\n    \n    def _serialize_object(self, obj: SceneObject) -> Dict[str, Any]:\n        \"\"\"Serialize a scene object.\"\"\"\n        data = {\n            \"id\": obj.id,\n            \"name\": obj.name,\n            \"position\": {\"x\": obj.position.x, \"y\": obj.position.y},\n            \"rotation\": obj.rotation,\n            \"scale\": {\"x\": obj.scale.x, \"y\": obj.scale.y},\n            \"visible\": obj.visible,\n            \"layer\": obj.layer,\n            \"tags\": obj.tags,\n            \"properties\": obj.properties\n        }\n        if obj.physics_body:\n            data[\"physics_body\"] = self._serialize_physics_body(obj.physics_body)\n        return data\n    \n    def _serialize_physics_body(self, body: PhysicsBody) -> Dict[str, Any]:\n        \"\"\"Serialize a physics body.\"\"\"\n        return {\n            \"id\": body.id,\n            \"position\": {\"x\": body.position.x, \"y\": body.position.y},\n            \"velocity\": {\"x\": body.velocity.x, \"y\": body.velocity.y},\n            \"mass\": body.mass,\n            \"is_static\": body.is_static,\n            \"shape_type\": body.shape_type,\n            \"radius\": body.radius,\n            \"width\": body.width,\n            \"height\": body.height,\n            \"restitution\": body.restitution,\n            \"friction\": body.friction\n        }\n    \n    def _serialize_force_field(self, ff: ForceField) -> Dict[str, Any]:\n        \"\"\"Serialize a force field.\"\"\"\n        return {\n            \"id\": ff.id,\n            \"position\": {\"x\": ff.position.x, \"y\": ff.position.y},\n            \"radius\": ff.radius,\n            \"script_path\": ff.script_path,\n            \"enabled\": ff.enabled\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Scene':\n        \"\"\"Deserialize scene from dictionary.\"\"\"\n        scene = cls(name=data.get(\"name\", \"Untitled Scene\"))\n        scene.id = data.get(\"id\", str(uuid.uuid4()))\n        \n        if \"gravity\" in data:\n            scene.gravity = Vec2d(data[\"gravity\"][\"x\"], data[\"gravity\"][\"y\"])\n        if \"bounds\" in data:\n            scene.bounds = tuple(data[\"bounds\"])\n        \n        for obj_data in data.get(\"objects\", []):\n            scene.add_object(cls._deserialize_object(obj_data))\n        \n        for ff_data in data.get(\"force_fields\", []):\n            scene.add_force_field(cls._deserialize_force_field(ff_data))\n        \n        return scene\n    \n    @classmethod\n    def _deserialize_object(cls, data: Dict[str, Any]) -> SceneObject:\n        \"\"\"Deserialize a scene object.\"\"\"\n        physics_body = None\n        if \"physics_body\" in data:\n            physics_body = cls._deserialize_physics_body(data[\"physics_body\"])\n        \n        return SceneObject(\n            id=data[\"id\"],\n            name=data[\"name\"],\n            position=Vec2d(data[\"position\"][\"x\"], data[\"position\"][\"y\"]),\n            rotation=data.get(\"rotation\", 0.0),\n            scale=Vec2d(data.get(\"scale\", {}).get(\"x\", 1.0), data.get(\"scale\", {}).get(\"y\", 1.0)),\n            visible=data.get(\"visible\", True),\n            layer=data.get(\"layer\", 0),\n            tags=data.get(\"tags\", []),\n            properties=data.get(\"properties\", {}),\n            physics_body=physics_body\n        )\n    \n    @classmethod\n    def _deserialize_physics_body(cls, data: Dict[str, Any]) -> PhysicsBody:\n        \"\"\"Deserialize a physics body.\"\"\"\n        return PhysicsBody(\n            id=data[\"id\"],\n            position=Vec2d(data[\"position\"][\"x\"], data[\"position\"][\"y\"]),\n            velocity=Vec2d(data.get(\"velocity\", {}).get(\"x\", 0), data.get(\"velocity\", {}).get(\"y\", 0)),\n            mass=data.get(\"mass\", 1.0),\n            is_static=data.get(\"is_static\", False),\n            shape_type=data.get(\"shape_type\", \"circle\"),\n            radius=data.get(\"radius\", 10.0),\n            width=data.get(\"width\", 20.0),\n            height=data.get(\"height\", 20.0),\n            restitution=data.get(\"restitution\", 0.5),\n            friction=data.get(\"friction\", 0.3)\n        )\n    \n    @classmethod\n    def _deserialize_force_field(cls, data: Dict[str, Any]) -> ForceField:\n        \"\"\"Deserialize a force field.\"\"\"\n        return ForceField(\n            id=data[\"id\"],\n            position=Vec2d(data[\"position\"][\"x\"], data[\"position\"][\"y\"]),\n            radius=data[\"radius\"],\n            script_path=data[\"script_path\"],\n            enabled=data.get(\"enabled\", True)\n        )\n",
          "physage_academy/src/physage_academy/editor/commands.py": "\"\"\"Command pattern implementation for editor operations.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\nfrom dataclasses import dataclass\nimport uuid\n\nfrom physage_academy.engine.scene import Scene, SceneObject, PhysicsBody, ForceField, Vec2d\n\n\nclass Command(ABC):\n    \"\"\"Abstract base class for all commands.\"\"\"\n    \n    @abstractmethod\n    def execute(self) -> Any:\n        \"\"\"Execute the command.\"\"\"\n        pass\n    \n    @abstractmethod\n    def undo(self) -> None:\n        \"\"\"Undo the command.\"\"\"\n        pass\n    \n    @abstractmethod\n    def redo(self) -> None:\n        \"\"\"Redo the command.\"\"\"\n        pass\n\n\nclass CommandHistory:\n    \"\"\"Manages command history for undo/redo functionality.\"\"\"\n    \n    def __init__(self, max_history: int = 100):\n        self._history: List[Command] = []\n        self._redo_stack: List[Command] = []\n        self._max_history = max_history\n    \n    def execute(self, command: Command) -> Any:\n        \"\"\"Execute a command and add it to history.\"\"\"\n        result = command.execute()\n        self._history.append(command)\n        self._redo_stack.clear()\n        \n        if len(self._history) > self._max_history:\n            self._history.pop(0)\n        \n        return result\n    \n    def undo(self) -> bool:\n        \"\"\"Undo the last command.\"\"\"\n        if not self._history:\n            return False\n        \n        command = self._history.pop()\n        command.undo()\n        self._redo_stack.append(command)\n        return True\n    \n    def redo(self) -> bool:\n        \"\"\"Redo the last undone command.\"\"\"\n        if not self._redo_stack:\n            return False\n        \n        command = self._redo_stack.pop()\n        command.redo()\n        self._history.append(command)\n        return True\n    \n    def can_undo(self) -> bool:\n        \"\"\"Check if undo is available.\"\"\"\n        return len(self._history) > 0\n    \n    def can_redo(self) -> bool:\n        \"\"\"Check if redo is available.\"\"\"\n        return len(self._redo_stack) > 0\n    \n    def clear(self) -> None:\n        \"\"\"Clear all history.\"\"\"\n        self._history.clear()\n        self._redo_stack.clear()\n\n\nclass CreateObjectCommand(Command):\n    \"\"\"Command to create a new scene object.\"\"\"\n    \n    def __init__(self, scene: Scene, name: str, position: Vec2d, **kwargs):\n        self._scene = scene\n        self._name = name\n        self._position = position\n        self._kwargs = kwargs\n        self._object_id: Optional[str] = None\n        self._created_object: Optional[SceneObject] = None\n    \n    def execute(self) -> SceneObject:\n        \"\"\"Create and add the object to the scene.\"\"\"\n        self._object_id = str(uuid.uuid4())\n        self._created_object = SceneObject(\n            id=self._object_id,\n            name=self._name,\n            position=self._position,\n            **self._kwargs\n        )\n        self._scene.add_object(self._created_object)\n        return self._created_object\n    \n    def undo(self) -> None:\n        \"\"\"Remove the created object.\"\"\"\n        if self._object_id:\n            self._scene.remove_object(self._object_id)\n    \n    def redo(self) -> None:\n        \"\"\"Re-add the object.\"\"\"\n        if self._created_object:\n            self._scene.add_object(self._created_object)\n\n\nclass DeleteObjectCommand(Command):\n    \"\"\"Command to delete a scene object.\"\"\"\n    \n    def __init__(self, scene: Scene, object_id: str):\n        self._scene = scene\n        self._object_id = object_id\n        self._deleted_object: Optional[SceneObject] = None\n    \n    def execute(self) -> bool:\n        \"\"\"Delete the object from the scene.\"\"\"\n        self._deleted_object = self._scene.remove_object(self._object_id)\n        return self._deleted_object is not None\n    \n    def undo(self) -> None:\n        \"\"\"Restore the deleted object.\"\"\"\n        if self._deleted_object:\n            self._scene.add_object(self._deleted_object)\n    \n    def redo(self) -> None:\n        \"\"\"Re-delete the object.\"\"\"\n        self._scene.remove_object(self._object_id)\n\n\nclass MoveObjectCommand(Command):\n    \"\"\"Command to move a scene object.\"\"\"\n    \n    def __init__(self, scene: Scene, object_id: str, new_position: Vec2d):\n        self._scene = scene\n        self._object_id = object_id\n        self._new_position = new_position\n        self._old_position: Optional[Vec2d] = None\n    \n    def execute(self) -> bool:\n        \"\"\"Move the object to the new position.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj:\n            self._old_position = Vec2d(obj.position.x, obj.position.y)\n            obj.position = self._new_position\n            if obj.physics_body:\n                obj.physics_body.position = self._new_position\n            return True\n        return False\n    \n    def undo(self) -> None:\n        \"\"\"Move the object back to its original position.\"\"\"\n        if self._old_position:\n            obj = self._scene.get_object(self._object_id)\n            if obj:\n                obj.position = self._old_position\n                if obj.physics_body:\n                    obj.physics_body.position = self._old_position\n    \n    def redo(self) -> None:\n        \"\"\"Re-apply the move.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj:\n            obj.position = self._new_position\n            if obj.physics_body:\n                obj.physics_body.position = self._new_position\n\n\nclass CreatePhysicsBodyCommand(Command):\n    \"\"\"Command to create a physics body.\"\"\"\n    \n    def __init__(self, scene: Scene, position: Vec2d, mass: float = 1.0,\n                 is_static: bool = False, shape_type: str = \"circle\", **kwargs):\n        self._scene = scene\n        self._position = position\n        self._mass = mass\n        self._is_static = is_static\n        self._shape_type = shape_type\n        self._kwargs = kwargs\n        self._body_id: Optional[str] = None\n        self._created_body: Optional[PhysicsBody] = None\n    \n    def execute(self) -> PhysicsBody:\n        \"\"\"Create and add the physics body.\"\"\"\n        self._body_id = str(uuid.uuid4())\n        self._created_body = PhysicsBody(\n            id=self._body_id,\n            position=self._position,\n            mass=self._mass,\n            is_static=self._is_static,\n            shape_type=self._shape_type,\n            **self._kwargs\n        )\n        self._scene.add_physics_body(self._created_body)\n        return self._created_body\n    \n    def undo(self) -> None:\n        \"\"\"Remove the created physics body.\"\"\"\n        if self._body_id:\n            self._scene.remove_physics_body(self._body_id)\n    \n    def redo(self) -> None:\n        \"\"\"Re-add the physics body.\"\"\"\n        if self._created_body:\n            self._scene.add_physics_body(self._created_body)\n\n\nclass CreateForceFieldCommand(Command):\n    \"\"\"Command to create a programmable force field.\"\"\"\n    \n    def __init__(self, scene: Scene, position: Vec2d, radius: float, script_path: str):\n        self._scene = scene\n        self._position = position\n        self._radius = radius\n        self._script_path = script_path\n        self._field_id: Optional[str] = None\n        self._created_field: Optional[ForceField] = None\n    \n    def execute(self) -> ForceField:\n        \"\"\"Create and add the force field to the scene.\"\"\"\n        self._field_id = str(uuid.uuid4())\n        self._created_field = ForceField(\n            id=self._field_id,\n            position=self._position,\n            radius=self._radius,\n            script_path=self._script_path,\n            enabled=True\n        )\n        self._scene.add_force_field(self._created_field)\n        return self._created_field\n    \n    def undo(self) -> None:\n        \"\"\"Remove the created force field.\"\"\"\n        if self._field_id:\n            self._scene.remove_force_field(self._field_id)\n    \n    def redo(self) -> None:\n        \"\"\"Re-add the force field.\"\"\"\n        if self._created_field:\n            self._scene.add_force_field(self._created_field)\n\n\nclass DeleteForceFieldCommand(Command):\n    \"\"\"Command to delete a force field.\"\"\"\n    \n    def __init__(self, scene: Scene, field_id: str):\n        self._scene = scene\n        self._field_id = field_id\n        self._deleted_field: Optional[ForceField] = None\n    \n    def execute(self) -> bool:\n        \"\"\"Delete the force field from the scene.\"\"\"\n        self._deleted_field = self._scene.remove_force_field(self._field_id)\n        return self._deleted_field is not None\n    \n    def undo(self) -> None:\n        \"\"\"Restore the deleted force field.\"\"\"\n        if self._deleted_field:\n            self._scene.add_force_field(self._deleted_field)\n    \n    def redo(self) -> None:\n        \"\"\"Re-delete the force field.\"\"\"\n        self._scene.remove_force_field(self._field_id)\n\n\nclass ModifyPropertyCommand(Command):\n    \"\"\"Command to modify an object's property.\"\"\"\n    \n    def __init__(self, scene: Scene, object_id: str, property_name: str, new_value: Any):\n        self._scene = scene\n        self._object_id = object_id\n        self._property_name = property_name\n        self._new_value = new_value\n        self._old_value: Any = None\n    \n    def execute(self) -> bool:\n        \"\"\"Modify the property.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj and hasattr(obj, self._property_name):\n            self._old_value = getattr(obj, self._property_name)\n            setattr(obj, self._property_name, self._new_value)\n            return True\n        return False\n    \n    def undo(self) -> None:\n        \"\"\"Restore the old property value.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj and self._old_value is not None:\n            setattr(obj, self._property_name, self._old_value)\n    \n    def redo(self) -> None:\n        \"\"\"Re-apply the property change.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj:\n            setattr(obj, self._property_name, self._new_value)\n\n\nclass BatchCommand(Command):\n    \"\"\"Command that executes multiple commands as a single unit.\"\"\"\n    \n    def __init__(self, commands: List[Command]):\n        self._commands = commands\n        self._executed = False\n    \n    def execute(self) -> List[Any]:\n        \"\"\"Execute all commands.\"\"\"\n        results = []\n        for cmd in self._commands:\n            results.append(cmd.execute())\n        self._executed = True\n        return results\n    \n    def undo(self) -> None:\n        \"\"\"Undo all commands in reverse order.\"\"\"\n        for cmd in reversed(self._commands):\n            cmd.undo()\n        self._executed = False\n    \n    def redo(self) -> None:\n        \"\"\"Redo all commands.\"\"\"\n        for cmd in self._commands:\n            cmd.redo()\n        self._executed = True\n",
          "physage_academy/src/physage_academy/editor/service.py": "\"\"\"Editor service for PhySage Academy.\"\"\"\nfrom typing import Any, Dict, List, Optional, Tuple\nimport json\nimport os\n\nfrom physage_academy.engine.scene import Scene, SceneObject, PhysicsBody, ForceField, Vec2d\nfrom physage_academy.editor.commands import (\n    Command,\n    CommandHistory,\n    CreateObjectCommand,\n    DeleteObjectCommand,\n    MoveObjectCommand,\n    CreatePhysicsBodyCommand,\n    CreateForceFieldCommand,\n    DeleteForceFieldCommand,\n    ModifyPropertyCommand,\n    BatchCommand\n)\n\n\nclass EditorService:\n    \"\"\"Main editor service that provides high-level editing operations.\"\"\"\n    \n    def __init__(self):\n        self._scene: Optional[Scene] = None\n        self._command_history = CommandHistory()\n        self._selection: List[str] = []\n        self._clipboard: List[SceneObject] = []\n        self._grid_size = 16\n        self._snap_to_grid = False\n        self._is_modified = False\n        self._current_file_path: Optional[str] = None\n    \n    @property\n    def scene(self) -> Optional[Scene]:\n        \"\"\"Get the current scene.\"\"\"\n        return self._scene\n    \n    @property\n    def is_modified(self) -> bool:\n        \"\"\"Check if the scene has unsaved changes.\"\"\"\n        return self._is_modified\n    \n    def new_scene(self, name: str = \"Untitled Scene\") -> Scene:\n        \"\"\"Create a new empty scene.\"\"\"\n        self._scene = Scene(name=name)\n        self._command_history.clear()\n        self._selection.clear()\n        self._is_modified = False\n        self._current_file_path = None\n        return self._scene\n    \n    def load_scene(self, file_path: str) -> Scene:\n        \"\"\"Load a scene from a file.\"\"\"\n        with open(file_path, 'r') as f:\n            data = json.load(f)\n        \n        self._scene = Scene.from_dict(data)\n        self._command_history.clear()\n        self._selection.clear()\n        self._is_modified = False\n        self._current_file_path = file_path\n        return self._scene\n    \n    def save_scene(self, file_path: Optional[str] = None) -> bool:\n        \"\"\"Save the current scene to a file.\"\"\"\n        if not self._scene:\n            return False\n        \n        path = file_path or self._current_file_path\n        if not path:\n            return False\n        \n        with open(path, 'w') as f:\n            json.dump(self._scene.to_dict(), f, indent=2)\n        \n        self._is_modified = False\n        self._current_file_path = path\n        return True\n    \n    def create_object(self, name: str, x: float, y: float, **kwargs) -> Optional[SceneObject]:\n        \"\"\"Create a new scene object.\"\"\"\n        if not self._scene:\n            return None\n        \n        position = self._apply_grid_snap(Vec2d(x, y))\n        command = CreateObjectCommand(self._scene, name, position, **kwargs)\n        obj = self._command_history.execute(command)\n        self._is_modified = True\n        return obj\n    \n    def delete_object(self, object_id: str) -> bool:\n        \"\"\"Delete a scene object.\"\"\"\n        if not self._scene:\n            return False\n        \n        command = DeleteObjectCommand(self._scene, object_id)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n            if object_id in self._selection:\n                self._selection.remove(object_id)\n        return result\n    \n    def move_object(self, object_id: str, x: float, y: float) -> bool:\n        \"\"\"Move a scene object to a new position.\"\"\"\n        if not self._scene:\n            return False\n        \n        new_position = self._apply_grid_snap(Vec2d(x, y))\n        command = MoveObjectCommand(self._scene, object_id, new_position)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n        return result\n    \n    def create_physics_body(self, x: float, y: float, mass: float = 1.0,\n                           is_static: bool = False, shape_type: str = \"circle\",\n                           **kwargs) -> Optional[PhysicsBody]:\n        \"\"\"Create a new physics body.\"\"\"\n        if not self._scene:\n            return None\n        \n        position = self._apply_grid_snap(Vec2d(x, y))\n        command = CreatePhysicsBodyCommand(\n            self._scene, position, mass, is_static, shape_type, **kwargs\n        )\n        body = self._command_history.execute(command)\n        self._is_modified = True\n        return body\n    \n    def create_force_field(self, x: float, y: float, radius: float,\n                          script_path: str) -> Optional[ForceField]:\n        \"\"\"Create a new programmable force field.\n        \n        Args:\n            x: X position of the force field center\n            y: Y position of the force field center\n            radius: Radius of effect for the force field\n            script_path: Path to the Python script defining the force behavior\n        \n        Returns:\n            The created ForceField object, or None if no scene is loaded\n        \"\"\"\n        if not self._scene:\n            return None\n        \n        position = self._apply_grid_snap(Vec2d(x, y))\n        command = CreateForceFieldCommand(self._scene, position, radius, script_path)\n        field = self._command_history.execute(command)\n        self._is_modified = True\n        return field\n    \n    def delete_force_field(self, field_id: str) -> bool:\n        \"\"\"Delete a force field.\"\"\"\n        if not self._scene:\n            return False\n        \n        command = DeleteForceFieldCommand(self._scene, field_id)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n        return result\n    \n    def modify_property(self, object_id: str, property_name: str, value: Any) -> bool:\n        \"\"\"Modify a property of a scene object.\"\"\"\n        if not self._scene:\n            return False\n        \n        command = ModifyPropertyCommand(self._scene, object_id, property_name, value)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n        return result\n    \n    def undo(self) -> bool:\n        \"\"\"Undo the last command.\"\"\"\n        result = self._command_history.undo()\n        if result:\n            self._is_modified = True\n        return result\n    \n    def redo(self) -> bool:\n        \"\"\"Redo the last undone command.\"\"\"\n        result = self._command_history.redo()\n        if result:\n            self._is_modified = True\n        return result\n    \n    def can_undo(self) -> bool:\n        \"\"\"Check if undo is available.\"\"\"\n        return self._command_history.can_undo()\n    \n    def can_redo(self) -> bool:\n        \"\"\"Check if redo is available.\"\"\"\n        return self._command_history.can_redo()\n    \n    def select(self, object_id: str, add_to_selection: bool = False) -> None:\n        \"\"\"Select an object.\"\"\"\n        if not add_to_selection:\n            self._selection.clear()\n        if object_id not in self._selection:\n            self._selection.append(object_id)\n    \n    def deselect(self, object_id: str) -> None:\n        \"\"\"Deselect an object.\"\"\"\n        if object_id in self._selection:\n            self._selection.remove(object_id)\n    \n    def clear_selection(self) -> None:\n        \"\"\"Clear all selections.\"\"\"\n        self._selection.clear()\n    \n    def get_selection(self) -> List[str]:\n        \"\"\"Get the current selection.\"\"\"\n        return self._selection.copy()\n    \n    def set_grid_size(self, size: int) -> None:\n        \"\"\"Set the grid size for snapping.\"\"\"\n        self._grid_size = max(1, size)\n    \n    def set_snap_to_grid(self, enabled: bool) -> None:\n        \"\"\"Enable or disable snap to grid.\"\"\"\n        self._snap_to_grid = enabled\n    \n    def _apply_grid_snap(self, position: Vec2d) -> Vec2d:\n        \"\"\"Apply grid snapping to a position if enabled.\"\"\"\n        if not self._snap_to_grid:\n            return position\n        \n        return Vec2d(\n            round(position.x / self._grid_size) * self._grid_size,\n            round(position.y / self._grid_size) * self._grid_size\n        )\n    \n    def get_object_at(self, x: float, y: float) -> Optional[SceneObject]:\n        \"\"\"Get the topmost object at a screen position.\"\"\"\n        if not self._scene:\n            return None\n        \n        point = Vec2d(x, y)\n        for obj in reversed(self._scene.get_all_objects()):\n            if self._point_in_object(point, obj):\n                return obj\n        return None\n    \n    def _point_in_object(self, point: Vec2d, obj: SceneObject) -> bool:\n        \"\"\"Check if a point is inside an object's bounds.\"\"\"\n        if obj.physics_body:\n            body = obj.physics_body\n            if body.shape_type == \"circle\":\n                return point.distance_to(obj.position) <= body.radius\n            else:\n                half_w = body.width / 2\n                half_h = body.height / 2\n                return (abs(point.x - obj.position.x) <= half_w and\n                        abs(point.y - obj.position.y) <= half_h)\n        return point.distance_to(obj.position) <= 20\n    \n    def duplicate_selection(self) -> List[SceneObject]:\n        \"\"\"Duplicate all selected objects.\"\"\"\n        if not self._scene:\n            return []\n        \n        duplicates = []\n        commands = []\n        \n        for obj_id in self._selection:\n            obj = self._scene.get_object(obj_id)\n            if obj:\n                offset = Vec2d(20, 20)\n                new_pos = obj.position + offset\n                cmd = CreateObjectCommand(\n                    self._scene,\n                    f\"{obj.name} (copy)\",\n                    new_pos,\n                    rotation=obj.rotation,\n                    scale=obj.scale,\n                    visible=obj.visible,\n                    layer=obj.layer,\n                    tags=obj.tags.copy(),\n                    properties=obj.properties.copy()\n                )\n                commands.append(cmd)\n        \n        if commands:\n            batch = BatchCommand(commands)\n            duplicates = self._command_history.execute(batch)\n            self._is_modified = True\n        \n        return duplicates\n",
          "physage_academy/src/physage_academy/scripting/engine.py": "\"\"\"Scripting engine for PhySage Academy.\"\"\"\nfrom typing import Any, Dict, Optional, Callable, Tuple\nimport os\nimport sys\nimport traceback\nfrom pathlib import Path\n\n\nclass ScriptContext:\n    \"\"\"Context object passed to scripts during execution.\"\"\"\n    \n    def __init__(self, variables: Dict[str, Any] = None):\n        self._variables = variables or {}\n    \n    def get(self, name: str, default: Any = None) -> Any:\n        \"\"\"Get a variable from the context.\"\"\"\n        return self._variables.get(name, default)\n    \n    def set(self, name: str, value: Any) -> None:\n        \"\"\"Set a variable in the context.\"\"\"\n        self._variables[name] = value\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert context to dictionary.\"\"\"\n        return self._variables.copy()\n\n\nclass ScriptResult:\n    \"\"\"Result of script execution.\"\"\"\n    \n    def __init__(self, success: bool, return_value: Any = None, error: str = None):\n        self.success = success\n        self.return_value = return_value\n        self.error = error\n\n\nclass ScriptingEngine:\n    \"\"\"Engine for executing user scripts safely.\"\"\"\n    \n    def __init__(self):\n        self._scripts: Dict[str, str] = {}\n        self._compiled_scripts: Dict[str, Any] = {}\n        self._global_context = ScriptContext()\n        self._script_callbacks: Dict[str, Callable] = {}\n        self._allowed_imports = {\n            'math', 'random', 'time', 'collections', 'itertools', 'functools'\n        }\n        self._script_cache: Dict[str, str] = {}\n    \n    def load_script(self, script_path: str) -> bool:\n        \"\"\"Load a script from a file.\"\"\"\n        try:\n            path = Path(script_path)\n            if not path.exists():\n                return False\n            \n            with open(path, 'r') as f:\n                script_content = f.read()\n            \n            self._scripts[script_path] = script_content\n            self._script_cache[script_path] = script_content\n            return True\n        except Exception as e:\n            print(f\"Error loading script {script_path}: {e}\")\n            return False\n    \n    def execute_script(self, script_path: str, context: Dict[str, Any] = None) -> ScriptResult:\n        \"\"\"Execute a script with the given context.\"\"\"\n        if script_path not in self._scripts:\n            if not self.load_script(script_path):\n                return ScriptResult(False, error=f\"Script not found: {script_path}\")\n        \n        script_content = self._scripts[script_path]\n        return self._execute_code(script_content, context or {})\n    \n    def execute_code(self, code: str, context: Dict[str, Any] = None) -> ScriptResult:\n        \"\"\"Execute arbitrary code with the given context.\"\"\"\n        return self._execute_code(code, context or {})\n    \n    def execute_force_script(self, script_path: str, field: Any, target_body: Any) -> Tuple[float, float]:\n        \"\"\"Execute a force field script and return the force vector.\n        \n        This method is specifically designed for force field scripts.\n        It executes the script with the force field and target body in context,\n        and expects the script to return a force vector as (fx, fy).\n        \n        Args:\n            script_path: Path to the force field script\n            field: The ForceField object\n            target_body: The PhysicsBody object being affected\n        \n        Returns:\n            A tuple (fx, fy) representing the force to apply, or (0, 0) on error\n        \"\"\"\n        context = {\n            'field': field,\n            'target_body': target_body\n        }\n        \n        result = self.execute_script(script_path, context)\n        \n        if result.success and result.return_value is not None:\n            try:\n                if isinstance(result.return_value, (tuple, list)) and len(result.return_value) >= 2:\n                    return (float(result.return_value[0]), float(result.return_value[1]))\n            except (TypeError, ValueError) as e:\n                print(f\"Force script returned invalid value: {e}\")\n        \n        return (0.0, 0.0)\n    \n    def _execute_code(self, code: str, context: Dict[str, Any]) -> ScriptResult:\n        \"\"\"Internal method to execute code.\"\"\"\n        try:\n            # Create a restricted global namespace\n            safe_globals = self._create_safe_globals()\n            \n            # Add context variables to local namespace\n            local_vars = context.copy()\n            \n            # Add helper functions\n            local_vars['__builtins__'] = safe_globals['__builtins__']\n            \n            # Execute the code\n            exec(compile(code, '<script>', 'exec'), safe_globals, local_vars)\n            \n            # Check for return value (scripts can set __return__ or use return in a function)\n            return_value = local_vars.get('__return__', None)\n            \n            return ScriptResult(True, return_value=return_value)\n        except SyntaxError as e:\n            return ScriptResult(False, error=f\"Syntax error: {e}\")\n        except Exception as e:\n            tb = traceback.format_exc()\n            return ScriptResult(False, error=f\"Runtime error: {e}\n{tb}\")\n    \n    def _create_safe_globals(self) -> Dict[str, Any]:\n        \"\"\"Create a safe global namespace for script execution.\"\"\"\n        import math\n        import random\n        \n        safe_builtins = {\n            'abs': abs,\n            'all': all,\n            'any': any,\n            'bool': bool,\n            'dict': dict,\n            'enumerate': enumerate,\n            'filter': filter,\n            'float': float,\n            'int': int,\n            'len': len,\n            'list': list,\n            'map': map,\n            'max': max,\n            'min': min,\n            'print': print,\n            'range': range,\n            'round': round,\n            'set': set,\n            'sorted': sorted,\n            'str': str,\n            'sum': sum,\n            'tuple': tuple,\n            'zip': zip,\n            'True': True,\n            'False': False,\n            'None': None,\n        }\n        \n        return {\n            '__builtins__': safe_builtins,\n            'math': math,\n            'random': random,\n        }\n    \n    def register_callback(self, name: str, callback: Callable) -> None:\n        \"\"\"Register a callback function that scripts can call.\"\"\"\n        self._script_callbacks[name] = callback\n    \n    def unregister_callback(self, name: str) -> None:\n        \"\"\"Unregister a callback function.\"\"\"\n        if name in self._script_callbacks:\n            del self._script_callbacks[name]\n    \n    def set_global_variable(self, name: str, value: Any) -> None:\n        \"\"\"Set a global variable accessible to all scripts.\"\"\"\n        self._global_context.set(name, value)\n    \n    def get_global_variable(self, name: str, default: Any = None) -> Any:\n        \"\"\"Get a global variable.\"\"\"\n        return self._global_context.get(name, default)\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the script cache.\"\"\"\n        self._scripts.clear()\n        self._compiled_scripts.clear()\n        self._script_cache.clear()\n    \n    def reload_script(self, script_path: str) -> bool:\n        \"\"\"Reload a script from disk.\"\"\"\n        if script_path in self._scripts:\n            del self._scripts[script_path]\n        if script_path in self._compiled_scripts:\n            del self._compiled_scripts[script_path]\n        if script_path in self._script_cache:\n            del self._script_cache[script_path]\n        return self.load_script(script_path)\n",
          "physage_academy/src/physage_academy/physics/engine.py": "\"\"\"Physics engine for PhySage Academy.\"\"\"\nfrom typing import List, Dict, Optional, Tuple, Any, Callable\nimport math\n\nfrom physage_academy.engine.scene import Scene, PhysicsBody, ForceField, Vec2d\nfrom physage_academy.scripting.engine import ScriptingEngine\n\n\nclass CollisionInfo:\n    \"\"\"Information about a collision between two bodies.\"\"\"\n    \n    def __init__(self, body_a: PhysicsBody, body_b: PhysicsBody,\n                 normal: Vec2d, penetration: float, contact_point: Vec2d):\n        self.body_a = body_a\n        self.body_b = body_b\n        self.normal = normal\n        self.penetration = penetration\n        self.contact_point = contact_point\n\n\nclass PhysicsEngine:\n    \"\"\"Main physics simulation engine.\"\"\"\n    \n    def __init__(self, scene: Optional[Scene] = None):\n        self._scene = scene\n        self._gravity = Vec2d(0, 980)  # pixels per second squared\n        self._time_step = 1.0 / 60.0\n        self._velocity_iterations = 8\n        self._position_iterations = 3\n        self._collision_callbacks: List[Callable[[CollisionInfo], None]] = []\n        self._scripting_engine: Optional[ScriptingEngine] = None\n        self._paused = False\n    \n    @property\n    def scene(self) -> Optional[Scene]:\n        \"\"\"Get the current scene.\"\"\"\n        return self._scene\n    \n    @scene.setter\n    def scene(self, value: Scene) -> None:\n        \"\"\"Set the current scene.\"\"\"\n        self._scene = value\n    \n    @property\n    def gravity(self) -> Vec2d:\n        \"\"\"Get gravity vector.\"\"\"\n        return self._gravity\n    \n    @gravity.setter\n    def gravity(self, value: Vec2d) -> None:\n        \"\"\"Set gravity vector.\"\"\"\n        self._gravity = value\n    \n    @property\n    def time_step(self) -> float:\n        \"\"\"Get the simulation time step.\"\"\"\n        return self._time_step\n    \n    @time_step.setter\n    def time_step(self, value: float) -> None:\n        \"\"\"Set the simulation time step.\"\"\"\n        self._time_step = max(0.001, value)\n    \n    @property\n    def scripting_engine(self) -> Optional[ScriptingEngine]:\n        \"\"\"Get the scripting engine.\"\"\"\n        return self._scripting_engine\n    \n    @scripting_engine.setter\n    def scripting_engine(self, value: ScriptingEngine) -> None:\n        \"\"\"Set the scripting engine for force field scripts.\"\"\"\n        self._scripting_engine = value\n    \n    def pause(self) -> None:\n        \"\"\"Pause the simulation.\"\"\"\n        self._paused = True\n    \n    def resume(self) -> None:\n        \"\"\"Resume the simulation.\"\"\"\n        self._paused = False\n    \n    def is_paused(self) -> bool:\n        \"\"\"Check if simulation is paused.\"\"\"\n        return self._paused\n    \n    def step(self, dt: Optional[float] = None) -> None:\n        \"\"\"Perform one physics simulation step.\"\"\"\n        if self._paused or not self._scene:\n            return\n        \n        time_step = dt if dt is not None else self._time_step\n        bodies = self._scene.get_dynamic_bodies()\n        \n        # Apply gravity to all dynamic bodies\n        for body in bodies:\n            if not body.is_static:\n                gravity_force = Vec2d(\n                    self._gravity.x * body.mass,\n                    self._gravity.y * body.mass\n                )\n                self._apply_force(body, gravity_force, time_step)\n        \n        # Apply force fields\n        self._apply_force_fields(bodies, time_step)\n        \n        # Integrate velocities\n        for body in bodies:\n            if not body.is_static:\n                body.position = Vec2d(\n                    body.position.x + body.velocity.x * time_step,\n                    body.position.y + body.velocity.y * time_step\n                )\n        \n        # Detect and resolve collisions\n        collisions = self._detect_collisions()\n        for collision in collisions:\n            self._resolve_collision(collision)\n            for callback in self._collision_callbacks:\n                callback(collision)\n        \n        # Apply bounds constraints\n        self._apply_bounds_constraints(bodies)\n    \n    def _apply_force_fields(self, bodies: List[PhysicsBody], time_step: float) -> None:\n        \"\"\"Apply force fields to all bodies within their radius.\"\"\"\n        if not self._scene or not self._scripting_engine:\n            return\n        \n        force_fields = self._scene.get_all_force_fields()\n        \n        for field in force_fields:\n            if not field.enabled:\n                continue\n            \n            for body in bodies:\n                if body.is_static:\n                    continue\n                \n                # Check if body is within force field radius\n                distance = field.position.distance_to(body.position)\n                if distance <= field.radius:\n                    # Execute the force field script\n                    force_tuple = self._scripting_engine.execute_force_script(\n                        field.script_path,\n                        field,\n                        body\n                    )\n                    \n                    # Apply the returned force\n                    if force_tuple and (force_tuple[0] != 0 or force_tuple[1] != 0):\n                        force = Vec2d(force_tuple[0], force_tuple[1])\n                        self._apply_force(body, force, time_step)\n    \n    def _apply_force(self, body: PhysicsBody, force: Vec2d, dt: float) -> None:\n        \"\"\"Apply a force to a body.\"\"\"\n        if body.is_static or body.mass <= 0:\n            return\n        \n        acceleration = Vec2d(force.x / body.mass, force.y / body.mass)\n        body.velocity = Vec2d(\n            body.velocity.x + acceleration.x * dt,\n            body.velocity.y + acceleration.y * dt\n        )\n    \n    def _detect_collisions(self) -> List[CollisionInfo]:\n        \"\"\"Detect collisions between all bodies.\"\"\"\n        if not self._scene:\n            return []\n        \n        collisions = []\n        bodies = self._scene.get_all_physics_bodies()\n        \n        for i, body_a in enumerate(bodies):\n            for body_b in bodies[i + 1:]:\n                collision = self._check_collision(body_a, body_b)\n                if collision:\n                    collisions.append(collision)\n        \n        return collisions\n    \n    def _check_collision(self, body_a: PhysicsBody, body_b: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check for collision between two bodies.\"\"\"\n        if body_a.shape_type == \"circle\" and body_b.shape_type == \"circle\":\n            return self._check_circle_circle(body_a, body_b)\n        elif body_a.shape_type == \"box\" and body_b.shape_type == \"box\":\n            return self._check_box_box(body_a, body_b)\n        else:\n            return self._check_circle_box(body_a, body_b)\n    \n    def _check_circle_circle(self, a: PhysicsBody, b: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check collision between two circles.\"\"\"\n        diff = Vec2d(b.position.x - a.position.x, b.position.y - a.position.y)\n        dist_sq = diff.length_sq\n        radius_sum = a.radius + b.radius\n        \n        if dist_sq >= radius_sum * radius_sum:\n            return None\n        \n        dist = math.sqrt(dist_sq) if dist_sq > 0 else 0.001\n        normal = Vec2d(diff.x / dist, diff.y / dist) if dist > 0 else Vec2d(1, 0)\n        penetration = radius_sum - dist\n        contact = Vec2d(\n            a.position.x + normal.x * a.radius,\n            a.position.y + normal.y * a.radius\n        )\n        \n        return CollisionInfo(a, b, normal, penetration, contact)\n    \n    def _check_box_box(self, a: PhysicsBody, b: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check collision between two boxes (AABB).\"\"\"\n        a_half_w, a_half_h = a.width / 2, a.height / 2\n        b_half_w, b_half_h = b.width / 2, b.height / 2\n        \n        dx = b.position.x - a.position.x\n        dy = b.position.y - a.position.y\n        \n        overlap_x = a_half_w + b_half_w - abs(dx)\n        overlap_y = a_half_h + b_half_h - abs(dy)\n        \n        if overlap_x <= 0 or overlap_y <= 0:\n            return None\n        \n        if overlap_x < overlap_y:\n            normal = Vec2d(1 if dx > 0 else -1, 0)\n            penetration = overlap_x\n        else:\n            normal = Vec2d(0, 1 if dy > 0 else -1)\n            penetration = overlap_y\n        \n        contact = Vec2d(\n            (a.position.x + b.position.x) / 2,\n            (a.position.y + b.position.y) / 2\n        )\n        \n        return CollisionInfo(a, b, normal, penetration, contact)\n    \n    def _check_circle_box(self, circle: PhysicsBody, box: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check collision between a circle and a box.\"\"\"\n        if circle.shape_type != \"circle\":\n            circle, box = box, circle\n        \n        half_w, half_h = box.width / 2, box.height / 2\n        \n        closest_x = max(box.position.x - half_w,\n                       min(circle.position.x, box.position.x + half_w))\n        closest_y = max(box.position.y - half_h,\n                       min(circle.position.y, box.position.y + half_h))\n        \n        dx = circle.position.x - closest_x\n        dy = circle.position.y - closest_y\n        dist_sq = dx * dx + dy * dy\n        \n        if dist_sq >= circle.radius * circle.radius:\n            return None\n        \n        dist = math.sqrt(dist_sq) if dist_sq > 0 else 0.001\n        normal = Vec2d(dx / dist, dy / dist) if dist > 0 else Vec2d(1, 0)\n        penetration = circle.radius - dist\n        contact = Vec2d(closest_x, closest_y)\n        \n        return CollisionInfo(circle, box, normal, penetration, contact)\n    \n    def _resolve_collision(self, collision: CollisionInfo) -> None:\n        \"\"\"Resolve a collision between two bodies.\"\"\"\n        a, b = collision.body_a, collision.body_b\n        \n        if a.is_static and b.is_static:\n            return\n        \n        # Calculate relative velocity\n        rel_vel = Vec2d(\n            b.velocity.x - a.velocity.x,\n            b.velocity.y - a.velocity.y\n        )\n        \n        # Calculate relative velocity along collision normal\n        vel_along_normal = (\n            rel_vel.x * collision.normal.x +\n            rel_vel.y * collision.normal.y\n        )\n        \n        # Don't resolve if velocities are separating\n        if vel_along_normal > 0:\n            return\n        \n        # Calculate restitution (bounciness)\n        restitution = min(a.restitution, b.restitution)\n        \n        # Calculate impulse scalar\n        inv_mass_a = 0 if a.is_static else 1 / a.mass\n        inv_mass_b = 0 if b.is_static else 1 / b.mass\n        \n        j = -(1 + restitution) * vel_along_normal\n        j /= inv_mass_a + inv_mass_b\n        \n        # Apply impulse\n        impulse = Vec2d(\n            j * collision.normal.x,\n            j * collision.normal.y\n        )\n        \n        if not a.is_static:\n            a.velocity = Vec2d(\n                a.velocity.x - inv_mass_a * impulse.x,\n                a.velocity.y - inv_mass_a * impulse.y\n            )\n        \n        if not b.is_static:\n            b.velocity = Vec2d(\n                b.velocity.x + inv_mass_b * impulse.x,\n                b.velocity.y + inv_mass_b * impulse.y\n            )\n        \n        # Positional correction to prevent sinking\n        correction_percent = 0.8\n        slop = 0.01\n        correction_mag = max(collision.penetration - slop, 0) / (inv_mass_a + inv_mass_b) * correction_percent\n        correction = Vec2d(\n            correction_mag * collision.normal.x,\n            correction_mag * collision.normal.y\n        )\n        \n        if not a.is_static:\n            a.position = Vec2d(\n                a.position.x - inv_mass_a * correction.x,\n                a.position.y - inv_mass_a * correction.y\n            )\n        \n        if not b.is_static:\n            b.position = Vec2d(\n                b.position.x + inv_mass_b * correction.x,\n                b.position.y + inv_mass_b * correction.y\n            )\n    \n    def _apply_bounds_constraints(self, bodies: List[PhysicsBody]) -> None:\n        \"\"\"Keep bodies within scene bounds.\"\"\"\n        if not self._scene:\n            return\n        \n        width, height = self._scene.bounds\n        \n        for body in bodies:\n            if body.is_static:\n                continue\n            \n            radius = body.radius if body.shape_type == \"circle\" else max(body.width, body.height) / 2\n            \n            # Left bound\n            if body.position.x - radius < 0:\n                body.position = Vec2d(radius, body.position.y)\n                body.velocity = Vec2d(-body.velocity.x * body.restitution, body.velocity.y)\n            \n            # Right bound\n            if body.position.x + radius > width:\n                body.position = Vec2d(width - radius, body.position.y)\n                body.velocity = Vec2d(-body.velocity.x * body.restitution, body.velocity.y)\n            \n            # Top bound\n            if body.position.y - radius < 0:\n                body.position = Vec2d(body.position.x, radius)\n                body.velocity = Vec2d(body.velocity.x, -body.velocity.y * body.restitution)\n            \n            # Bottom bound\n            if body.position.y + radius > height:\n                body.position = Vec2d(body.position.x, height - radius)\n                body.velocity = Vec2d(body.velocity.x, -body.velocity.y * body.restitution)\n    \n    def add_collision_callback(self, callback: Callable[[CollisionInfo], None]) -> None:\n        \"\"\"Add a callback to be called on collisions.\"\"\"\n        self._collision_callbacks.append(callback)\n    \n    def remove_collision_callback(self, callback: Callable[[CollisionInfo], None]) -> None:\n        \"\"\"Remove a collision callback.\"\"\"\n        if callback in self._collision_callbacks:\n            self._collision_callbacks.remove(callback)\n    \n    def raycast(self, origin: Vec2d, direction: Vec2d, max_distance: float = 1000) -> Optional[Tuple[PhysicsBody, Vec2d, float]]:\n        \"\"\"Cast a ray and return the first body hit.\"\"\"\n        if not self._scene:\n            return None\n        \n        closest_hit = None\n        closest_dist = max_distance\n        \n        dir_normalized = direction.normalized()\n        \n        for body in self._scene.get_all_physics_bodies():\n            hit = self._raycast_body(origin, dir_normalized, body, closest_dist)\n            if hit and hit[1] < closest_dist:\n                closest_hit = (body, hit[0], hit[1])\n                closest_dist = hit[1]\n        \n        return closest_hit\n    \n    def _raycast_body(self, origin: Vec2d, direction: Vec2d, body: PhysicsBody, max_dist: float) -> Optional[Tuple[Vec2d, float]]:\n        \"\"\"Raycast against a single body.\"\"\"\n        if body.shape_type == \"circle\":\n            return self._raycast_circle(origin, direction, body.position, body.radius, max_dist)\n        else:\n            return self._raycast_box(origin, direction, body, max_dist)\n    \n    def _raycast_circle(self, origin: Vec2d, direction: Vec2d, center: Vec2d, radius: float, max_dist: float) -> Optional[Tuple[Vec2d, float]]:\n        \"\"\"Raycast against a circle.\"\"\"\n        oc = Vec2d(origin.x - center.x, origin.y - center.y)\n        \n        a = direction.x * direction.x + direction.y * direction.y\n        b = 2 * (oc.x * direction.x + oc.y * direction.y)\n        c = oc.x * oc.x + oc.y * oc.y - radius * radius\n        \n        discriminant = b * b - 4 * a * c\n        \n        if discriminant < 0:\n            return None\n        \n        t = (-b - math.sqrt(discriminant)) / (2 * a)\n        \n        if t < 0 or t > max_dist:\n            return None\n        \n        hit_point = Vec2d(origin.x + direction.x * t, origin.y + direction.y * t)\n        return (hit_point, t)\n    \n    def _raycast_box(self, origin: Vec2d, direction: Vec2d, body: PhysicsBody, max_dist: float) -> Optional[Tuple[Vec2d, float]]:\n        \"\"\"Raycast against a box (AABB).\"\"\"\n        half_w, half_h = body.width / 2, body.height / 2\n        min_x = body.position.x - half_w\n        max_x = body.position.x + half_w\n        min_y = body.position.y - half_h\n        max_y = body.position.y + half_h\n        \n        t_min = 0.0\n        t_max = max_dist\n        \n        for i, (o, d, mn, mx) in enumerate([\n            (origin.x, direction.x, min_x, max_x),\n            (origin.y, direction.y, min_y, max_y)\n        ]):\n            if abs(d) < 1e-8:\n                if o < mn or o > mx:\n                    return None\n            else:\n                t1 = (mn - o) / d\n                t2 = (mx - o) / d\n                if t1 > t2:\n                    t1, t2 = t2, t1\n                t_min = max(t_min, t1)\n                t_max = min(t_max, t2)\n                if t_min > t_max:\n                    return None\n        \n        if t_min < 0:\n            return None\n        \n        hit_point = Vec2d(origin.x + direction.x * t_min, origin.y + direction.y * t_min)\n        return (hit_point, t_min)\n",
          "scripts/attractor_field.py": "# Attractor Force Field Script\n# This script implements a gravity-like attractive force.\n# The context provides 'field' (ForceField) and 'target_body' (PhysicsBody).\n\nimport math\n\n# Calculate direction vector from body to field center\ndx = field.position.x - target_body.position.x\ndy = field.position.y - target_body.position.y\n\n# Calculate squared distance\ndistance_sq = dx * dx + dy * dy\n\n# Avoid singularity at the center\nif distance_sq < 1.0:\n    __return__ = (0, 0)\nelse:\n    # Calculate distance\n    distance = math.sqrt(distance_sq)\n    \n    # Normalize direction\n    norm_x = dx / distance\n    norm_y = dy / distance\n    \n    # Force magnitude using inverse square law\n    # F = G * m1 * m2 / r^2 (simplified: G * m / r^2)\n    force_magnitude = (10000.0 * target_body.mass) / distance_sq\n    \n    # Calculate force vector\n    fx = norm_x * force_magnitude\n    fy = norm_y * force_magnitude\n    \n    # Return force vector\n    __return__ = (fx, fy)\n",
          "physage_academy/tests/test_integration.py": "\"\"\"Integration tests for PhySage Academy.\"\"\"\nimport unittest\nimport os\nimport sys\nimport tempfile\nimport math\n\n# Add source directory to path\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom physage_academy.editor.service import EditorService\nfrom physage_academy.physics.engine import PhysicsEngine\nfrom physage_academy.scripting.engine import ScriptingEngine\nfrom physage_academy.engine.scene import Scene, Vec2d, PhysicsBody, ForceField\n\n\nclass TestEditorPhysicsIntegration(unittest.TestCase):\n    \"\"\"Test integration between editor and physics systems.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.editor = EditorService()\n        self.editor.new_scene(\"Test Scene\")\n        self.physics = PhysicsEngine(self.editor.scene)\n        self.scripting = ScriptingEngine()\n        self.physics.scripting_engine = self.scripting\n    \n    def test_create_and_simulate_physics_body(self):\n        \"\"\"Test creating a physics body and simulating it.\"\"\"\n        # Create a dynamic body\n        body = self.editor.create_physics_body(100, 100, mass=1.0, is_static=False)\n        self.assertIsNotNone(body)\n        \n        initial_y = body.position.y\n        \n        # Run simulation for a few steps\n        for _ in range(10):\n            self.physics.step(1/60)\n        \n        # Body should have fallen due to gravity\n        self.assertGreater(body.position.y, initial_y)\n    \n    def test_static_body_does_not_move(self):\n        \"\"\"Test that static bodies don't move.\"\"\"\n        body = self.editor.create_physics_body(100, 100, mass=1.0, is_static=True)\n        self.assertIsNotNone(body)\n        \n        initial_pos = Vec2d(body.position.x, body.position.y)\n        \n        # Run simulation\n        for _ in range(10):\n            self.physics.step(1/60)\n        \n        # Static body should not have moved\n        self.assertEqual(body.position.x, initial_pos.x)\n        self.assertEqual(body.position.y, initial_pos.y)\n    \n    def test_undo_redo_physics_body_creation(self):\n        \"\"\"Test undo/redo for physics body creation.\"\"\"\n        body = self.editor.create_physics_body(100, 100, mass=1.0)\n        body_id = body.id\n        \n        # Body should exist\n        self.assertIsNotNone(self.editor.scene.get_physics_body(body_id))\n        \n        # Undo creation\n        self.assertTrue(self.editor.undo())\n        self.assertIsNone(self.editor.scene.get_physics_body(body_id))\n        \n        # Redo creation\n        self.assertTrue(self.editor.redo())\n        self.assertIsNotNone(self.editor.scene.get_physics_body(body_id))\n\n\nclass TestForceFieldIntegration(unittest.TestCase):\n    \"\"\"Test programmable force field integration.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.editor = EditorService()\n        self.editor.new_scene(\"Force Field Test Scene\")\n        self.physics = PhysicsEngine(self.editor.scene)\n        self.scripting = ScriptingEngine()\n        self.physics.scripting_engine = self.scripting\n        # Disable gravity for cleaner force field tests\n        self.physics.gravity = Vec2d(0, 0)\n    \n    def test_programmable_force_field_attractor(self):\n        \"\"\"Test that an attractor force field pulls objects toward it.\"\"\"\n        # Create a dynamic physics body at position (100, 0)\n        body = self.editor.create_physics_body(\n            x=100.0, y=0.0,\n            mass=1.0,\n            is_static=False,\n            shape_type=\"circle\",\n            radius=5.0\n        )\n        self.assertIsNotNone(body)\n        \n        # Record initial position\n        initial_x = body.position.x\n        initial_y = body.position.y\n        \n        # Get the path to the attractor script\n        # The script should be at the project root in scripts/attractor_field.py\n        script_path = os.path.join(\n            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),\n            'scripts', 'attractor_field.py'\n        )\n        \n        # If script doesn't exist at that path, create a temporary one\n        if not os.path.exists(script_path):\n            script_dir = os.path.dirname(script_path)\n            os.makedirs(script_dir, exist_ok=True)\n            with open(script_path, 'w') as f:\n                f.write('''# Attractor Force Field Script\nimport math\n\ndx = field.position.x - target_body.position.x\ndy = field.position.y - target_body.position.y\ndistance_sq = dx * dx + dy * dy\n\nif distance_sq < 1.0:\n    __return__ = (0, 0)\nelse:\n    distance = math.sqrt(distance_sq)\n    norm_x = dx / distance\n    norm_y = dy / distance\n    force_magnitude = (10000.0 * target_body.mass) / distance_sq\n    fx = norm_x * force_magnitude\n    fy = norm_y * force_magnitude\n    __return__ = (fx, fy)\n''')\n        \n        # Create an attractive force field at origin (0, 0) with large radius\n        force_field = self.editor.create_force_field(\n            x=0.0, y=0.0,\n            radius=500.0,\n            script_path=script_path\n        )\n        self.assertIsNotNone(force_field)\n        self.assertEqual(force_field.position.x, 0.0)\n        self.assertEqual(force_field.position.y, 0.0)\n        self.assertEqual(force_field.radius, 500.0)\n        \n        # Run simulation for 100 steps\n        for _ in range(100):\n            self.physics.step(1/60)\n        \n        # The body should have moved toward the origin\n        # Since it started at (100, 0) and the attractor is at (0, 0),\n        # the x position should have decreased (moved left toward origin)\n        final_x = body.position.x\n        \n        # Assert that the object moved toward the origin\n        self.assertLess(final_x, initial_x, \n            f\"Body should have moved toward origin. Initial x: {initial_x}, Final x: {final_x}\")\n        \n        # Calculate distance to origin\n        initial_distance = math.sqrt(initial_x**2 + initial_y**2)\n        final_distance = math.sqrt(final_x**2 + body.position.y**2)\n        \n        self.assertLess(final_distance, initial_distance,\n            f\"Body should be closer to origin. Initial distance: {initial_distance}, Final distance: {final_distance}\")\n    \n    def test_force_field_creation_and_deletion(self):\n        \"\"\"Test creating and deleting force fields.\"\"\"\n        # Create a force field\n        field = self.editor.create_force_field(\n            x=50.0, y=50.0,\n            radius=100.0,\n            script_path=\"dummy_script.py\"\n        )\n        self.assertIsNotNone(field)\n        field_id = field.id\n        \n        # Verify it exists in the scene\n        self.assertIsNotNone(self.editor.scene.get_force_field(field_id))\n        self.assertEqual(len(self.editor.scene.get_all_force_fields()), 1)\n        \n        # Delete the force field\n        result = self.editor.delete_force_field(field_id)\n        self.assertTrue(result)\n        \n        # Verify it's gone\n        self.assertIsNone(self.editor.scene.get_force_field(field_id))\n        self.assertEqual(len(self.editor.scene.get_all_force_fields()), 0)\n    \n    def test_force_field_undo_redo(self):\n        \"\"\"Test undo/redo for force field operations.\"\"\"\n        # Create a force field\n        field = self.editor.create_force_field(\n            x=25.0, y=25.0,\n            radius=50.0,\n            script_path=\"test_script.py\"\n        )\n        field_id = field.id\n        \n        # Undo creation\n        self.assertTrue(self.editor.undo())\n        self.assertIsNone(self.editor.scene.get_force_field(field_id))\n        \n        # Redo creation\n        self.assertTrue(self.editor.redo())\n        self.assertIsNotNone(self.editor.scene.get_force_field(field_id))\n    \n    def test_force_field_contains_point(self):\n        \"\"\"Test force field containment check.\"\"\"\n        field = ForceField(\n            id=\"test-field\",\n            position=Vec2d(0, 0),\n            radius=100.0,\n            script_path=\"test.py\"\n        )\n        \n        # Point inside\n        self.assertTrue(field.contains(Vec2d(50, 50)))\n        self.assertTrue(field.contains(Vec2d(0, 0)))\n        self.assertTrue(field.contains(Vec2d(99, 0)))\n        \n        # Point outside\n        self.assertFalse(field.contains(Vec2d(150, 0)))\n        self.assertFalse(field.contains(Vec2d(0, 150)))\n    \n    def test_repulsor_force_field(self):\n        \"\"\"Test a repulsor (opposite of attractor) force field.\"\"\"\n        # Create a dynamic body near the origin\n        body = self.editor.create_physics_body(\n            x=20.0, y=0.0,\n            mass=1.0,\n            is_static=False\n        )\n        initial_x = body.position.x\n        \n        # Create a temporary repulsor script\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write('''import math\ndx = target_body.position.x - field.position.x\ndy = target_body.position.y - field.position.y\ndistance_sq = dx * dx + dy * dy\nif distance_sq < 1.0:\n    __return__ = (0, 0)\nelse:\n    distance = math.sqrt(distance_sq)\n    norm_x = dx / distance\n    norm_y = dy / distance\n    force_magnitude = (5000.0 * target_body.mass) / distance_sq\n    __return__ = (norm_x * force_magnitude, norm_y * force_magnitude)\n''')\n            script_path = f.name\n        \n        try:\n            # Create repulsor at origin\n            self.editor.create_force_field(\n                x=0.0, y=0.0,\n                radius=200.0,\n                script_path=script_path\n            )\n            \n            # Run simulation\n            for _ in range(50):\n                self.physics.step(1/60)\n            \n            # Body should have moved away from origin\n            self.assertGreater(body.position.x, initial_x,\n                \"Body should have been pushed away from origin\")\n        finally:\n            os.unlink(script_path)\n\n\nclass TestSceneSerializationIntegration(unittest.TestCase):\n    \"\"\"Test scene serialization with force fields.\"\"\"\n    \n    def test_scene_with_force_fields_serialization(self):\n        \"\"\"Test that scenes with force fields can be serialized and deserialized.\"\"\"\n        # Create a scene with various objects\n        scene = Scene(name=\"Serialization Test\")\n        \n        # Add a physics body\n        body = PhysicsBody(\n            id=\"body-1\",\n            position=Vec2d(100, 100),\n            mass=2.0\n        )\n        scene.add_physics_body(body)\n        \n        # Add a force field\n        field = ForceField(\n            id=\"field-1\",\n            position=Vec2d(50, 50),\n            radius=150.0,\n            script_path=\"scripts/attractor_field.py\"\n        )\n        scene.add_force_field(field)\n        \n        # Serialize\n        data = scene.to_dict()\n        \n        # Verify serialization\n        self.assertEqual(data[\"name\"], \"Serialization Test\")\n        self.assertEqual(len(data[\"force_fields\"]), 1)\n        self.assertEqual(data[\"force_fields\"][0][\"id\"], \"field-1\")\n        self.assertEqual(data[\"force_fields\"][0][\"radius\"], 150.0)\n        \n        # Deserialize\n        restored_scene = Scene.from_dict(data)\n        \n        # Verify restoration\n        self.assertEqual(restored_scene.name, \"Serialization Test\")\n        restored_fields = restored_scene.get_all_force_fields()\n        self.assertEqual(len(restored_fields), 1)\n        self.assertEqual(restored_fields[0].id, \"field-1\")\n        self.assertEqual(restored_fields[0].radius, 150.0)\n        self.assertEqual(restored_fields[0].script_path, \"scripts/attractor_field.py\")\n\n\nclass TestMultipleForceFields(unittest.TestCase):\n    \"\"\"Test scenarios with multiple force fields.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.editor = EditorService()\n        self.editor.new_scene(\"Multi Force Field Test\")\n        self.physics = PhysicsEngine(self.editor.scene)\n        self.scripting = ScriptingEngine()\n        self.physics.scripting_engine = self.scripting\n        self.physics.gravity = Vec2d(0, 0)\n    \n    def test_multiple_force_fields_affect_body(self):\n        \"\"\"Test that multiple force fields can affect a single body.\"\"\"\n        # Create a body\n        body = self.editor.create_physics_body(\n            x=50.0, y=50.0,\n            mass=1.0,\n            is_static=False\n        )\n        \n        # Create a simple constant force script\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write('__return__ = (100, 0)\n')  # Push right\n            script1 = f.name\n        \n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write('__return__ = (0, 100)\n')  # Push down\n            script2 = f.name\n        \n        try:\n            # Create two force fields with different forces\n            self.editor.create_force_field(x=0, y=0, radius=200, script_path=script1)\n            self.editor.create_force_field(x=100, y=100, radius=200, script_path=script2)\n            \n            initial_x = body.position.x\n            initial_y = body.position.y\n            \n            # Run simulation\n            for _ in range(20):\n                self.physics.step(1/60)\n            \n            # Body should have moved in both x and y directions\n            self.assertGreater(body.position.x, initial_x)\n            self.assertGreater(body.position.y, initial_y)\n        finally:\n            os.unlink(script1)\n            os.unlink(script2)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"
        },
        "generated_files": [
          "physage_academy/src/physage_academy/engine/scene.py",
          "physage_academy/src/physage_academy/editor/commands.py",
          "physage_academy/src/physage_academy/editor/service.py",
          "physage_academy/src/physage_academy/scripting/engine.py",
          "physage_academy/src/physage_academy/physics/engine.py",
          "scripts/attractor_field.py",
          "physage_academy/tests/test_integration.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.722687941743414,
              "dependency_traversal_accuracy": 0.8492739951069457,
              "cross_file_reasoning_depth": 0.18107142857142858,
              "system_thinking_score": 0.35030510064530734,
              "robustness_score": 0.2549776007964161,
              "comprehensiveness_score": 0.7231843546147598,
              "innovation_score": 0.25,
              "solution_elegance_score": 0.5972941245144602
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09033599271792675,
              "dependency_traversal_weighted": 0.10615924938836821,
              "cross_file_reasoning_weighted": 0.022633928571428572,
              "system_thinking_weighted": 0.04378813758066342,
              "robustness_weighted": 0.031872200099552016,
              "comprehensiveness_weighted": 0.09039804432684498,
              "innovation_weighted": 0.03125,
              "solution_elegance_weighted": 0.07466176556430752
            },
            "total_software_engineering_score": 0.4910993182490914
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.0,
              "execution_time": 0.43689465522766113,
              "errors": [
                "  File \"physage_academy/src/physage_academy/scripting/engine.py\", line 134",
                "    return ScriptResult(False, error=f\"Runtime error: {e}",
                "                                     ^",
                "SyntaxError: unterminated f-string literal (detected at line 134)",
                "  File \"physage_academy/tests/test_integration.py\", line 340",
                "    f.write('__return__ = (100, 0)",
                "            ^",
                "SyntaxError: unterminated string literal (detected at line 340)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "physage_academy/src/physage_academy/engine/scene.py",
                "physage_academy/src/physage_academy/editor/commands.py",
                "physage_academy/src/physage_academy/editor/service.py",
                "physage_academy/src/physage_academy/scripting/engine.py",
                "physage_academy/src/physage_academy/physics/engine.py",
                "scripts/attractor_field.py",
                "physage_academy/tests/test_integration.py"
              ],
              "scoring_breakdown": {
                "no_credit": 0.0
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 7,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 7 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.2262100114567727,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.0,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.2262100114567727,
              "idc_weight": 0.2,
              "total_functional_score": 0.35524200229135455
            }
          },
          "code_quality_details": {
            "files_analyzed": 7,
            "quality_checks": {
              "physage_academy/src/physage_academy/engine/scene.py": {
                "line_count": 314,
                "non_empty_lines": 262,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 35,
                "class_count": 5,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "physage_academy/src/physage_academy/editor/commands.py": {
                "line_count": 332,
                "non_empty_lines": 264,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 42,
                "class_count": 12,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "physage_academy/src/physage_academy/editor/service.py": {
                "line_count": 292,
                "non_empty_lines": 242,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 27,
                "class_count": 2,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "physage_academy/src/physage_academy/scripting/engine.py": {
                "line_count": 209,
                "non_empty_lines": 168,
                "comment_lines": 5,
                "comment_ratio": 0.02976190476190476,
                "function_count": 18,
                "class_count": 3,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "physage_academy/src/physage_academy/physics/engine.py": {
                "line_count": 456,
                "non_empty_lines": 357,
                "comment_lines": 19,
                "comment_ratio": 0.05322128851540616,
                "function_count": 29,
                "class_count": 9,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "scripts/attractor_field.py": {
                "line_count": 35,
                "non_empty_lines": 26,
                "comment_lines": 12,
                "comment_ratio": 0.46153846153846156,
                "function_count": 0,
                "class_count": 0,
                "import_count": 2,
                "quality_score": 0.7
              },
              "physage_academy/tests/test_integration.py": {
                "line_count": 371,
                "non_empty_lines": 302,
                "comment_lines": 48,
                "comment_ratio": 0.15894039735099338,
                "function_count": 13,
                "class_count": 4,
                "import_count": 17,
                "quality_score": 0.9999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.8099999999999998,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.818070652173913,
              "multi_session_memory_retention": 0.8392512077294685
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4090353260869565,
              "multi_session_memory_retention_weighted": 0.41962560386473424
            },
            "total_longcontext_utilization_score": 0.8286609299516907
          }
        },
        "timestamp": "2026-01-14T20:43:14.175880"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_blockchain_nft_medium_035_feature_implementation_expert_01",
        "scenario_title": "Implement Governance-Controlled Special Edition NFT Airdrops",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.577543593727673,
        "functional_correctness_score": 0.36744608819345664,
        "code_quality_score": 0.7649999999999998,
        "longcontext_utilization_score": 0.7982870370370371,
        "total_score": 2.870399838264049,
        "generation_time": 248.98994755744934,
        "code_files_generated": 10,
        "total_lines_generated": 2504,
        "parsing_success": true,
        "solution_code": {
          "contracts/Governance.sol": "// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";\nimport \"./ShowTimeNFT.sol\";\n\ncontract Governance is Ownable {\n    enum ProposalType { Parameter, Upgrade, Treasury, Airdrop }\n    enum ProposalState { Pending, Active, Succeeded, Defeated, Executed, Cancelled }\n\n    struct Proposal {\n        uint256 id;\n        address proposer;\n        string description;\n        ProposalType proposalType;\n        uint256 startTime;\n        uint256 endTime;\n        uint256 forVotes;\n        uint256 againstVotes;\n        bool executed;\n        bool cancelled;\n        string nftMetadataURI;\n        mapping(address => bool) hasVoted;\n    }\n\n    IERC20 public governanceToken;\n    ShowTimeNFT public showTimeNFT;\n    \n    uint256 public votingPeriod = 3 days;\n    uint256 public votingDelay = 1 days;\n    uint256 public proposalThreshold = 100 * 10**18;\n    uint256 public quorumVotes = 1000 * 10**18;\n    \n    uint256 public proposalCount;\n    mapping(uint256 => Proposal) public proposals;\n    \n    event ProposalCreated(\n        uint256 indexed proposalId,\n        address indexed proposer,\n        string description,\n        ProposalType proposalType,\n        uint256 startTime,\n        uint256 endTime\n    );\n    event VoteCast(uint256 indexed proposalId, address indexed voter, bool support, uint256 votes);\n    event ProposalExecuted(uint256 indexed proposalId);\n    event ProposalCancelled(uint256 indexed proposalId);\n    event AirdropExecuted(uint256 indexed proposalId, string metadataURI, uint256 recipientCount);\n\n    constructor(address _governanceToken, address _showTimeNFT) Ownable(msg.sender) {\n        governanceToken = IERC20(_governanceToken);\n        showTimeNFT = ShowTimeNFT(_showTimeNFT);\n    }\n\n    function setShowTimeNFT(address _showTimeNFT) external onlyOwner {\n        showTimeNFT = ShowTimeNFT(_showTimeNFT);\n    }\n\n    function propose(\n        string memory _description,\n        ProposalType _proposalType\n    ) public returns (uint256) {\n        return _propose(_description, _proposalType, \"\");\n    }\n\n    function proposeAirdrop(\n        string memory _description,\n        string memory _nftMetadataURI\n    ) public returns (uint256) {\n        require(bytes(_nftMetadataURI).length > 0, \"Metadata URI required for airdrop\");\n        return _propose(_description, ProposalType.Airdrop, _nftMetadataURI);\n    }\n\n    function _propose(\n        string memory _description,\n        ProposalType _proposalType,\n        string memory _nftMetadataURI\n    ) internal returns (uint256) {\n        require(\n            governanceToken.balanceOf(msg.sender) >= proposalThreshold,\n            \"Below proposal threshold\"\n        );\n\n        proposalCount++;\n        uint256 proposalId = proposalCount;\n        \n        Proposal storage newProposal = proposals[proposalId];\n        newProposal.id = proposalId;\n        newProposal.proposer = msg.sender;\n        newProposal.description = _description;\n        newProposal.proposalType = _proposalType;\n        newProposal.startTime = block.timestamp + votingDelay;\n        newProposal.endTime = block.timestamp + votingDelay + votingPeriod;\n        newProposal.forVotes = 0;\n        newProposal.againstVotes = 0;\n        newProposal.executed = false;\n        newProposal.cancelled = false;\n        newProposal.nftMetadataURI = _nftMetadataURI;\n\n        emit ProposalCreated(\n            proposalId,\n            msg.sender,\n            _description,\n            _proposalType,\n            newProposal.startTime,\n            newProposal.endTime\n        );\n\n        return proposalId;\n    }\n\n    function vote(uint256 _proposalId, bool _support) external {\n        Proposal storage proposal = proposals[_proposalId];\n        require(getProposalState(_proposalId) == ProposalState.Active, \"Proposal not active\");\n        require(!proposal.hasVoted[msg.sender], \"Already voted\");\n\n        uint256 votes = governanceToken.balanceOf(msg.sender);\n        require(votes > 0, \"No voting power\");\n\n        proposal.hasVoted[msg.sender] = true;\n\n        if (_support) {\n            proposal.forVotes += votes;\n        } else {\n            proposal.againstVotes += votes;\n        }\n\n        emit VoteCast(_proposalId, msg.sender, _support, votes);\n    }\n\n    function execute(uint256 _proposalId) external {\n        require(getProposalState(_proposalId) == ProposalState.Succeeded, \"Proposal not succeeded\");\n        \n        Proposal storage proposal = proposals[_proposalId];\n        proposal.executed = true;\n\n        _execute(proposal);\n\n        emit ProposalExecuted(_proposalId);\n    }\n\n    function _execute(Proposal storage proposal) internal {\n        if (proposal.proposalType == ProposalType.Airdrop) {\n            require(address(showTimeNFT) != address(0), \"ShowTimeNFT not set\");\n            require(bytes(proposal.nftMetadataURI).length > 0, \"No metadata URI\");\n            \n            showTimeNFT.airdropToStakers(proposal.nftMetadataURI);\n            \n            emit AirdropExecuted(proposal.id, proposal.nftMetadataURI, 0);\n        }\n        // Other proposal types can be handled here\n    }\n\n    function cancel(uint256 _proposalId) external {\n        Proposal storage proposal = proposals[_proposalId];\n        require(msg.sender == proposal.proposer || msg.sender == owner(), \"Not authorized\");\n        require(!proposal.executed, \"Already executed\");\n        require(!proposal.cancelled, \"Already cancelled\");\n\n        proposal.cancelled = true;\n        emit ProposalCancelled(_proposalId);\n    }\n\n    function getProposalState(uint256 _proposalId) public view returns (ProposalState) {\n        Proposal storage proposal = proposals[_proposalId];\n        \n        if (proposal.cancelled) {\n            return ProposalState.Cancelled;\n        }\n        if (proposal.executed) {\n            return ProposalState.Executed;\n        }\n        if (block.timestamp < proposal.startTime) {\n            return ProposalState.Pending;\n        }\n        if (block.timestamp <= proposal.endTime) {\n            return ProposalState.Active;\n        }\n        if (proposal.forVotes > proposal.againstVotes && proposal.forVotes >= quorumVotes) {\n            return ProposalState.Succeeded;\n        }\n        return ProposalState.Defeated;\n    }\n\n    function getProposalInfo(uint256 _proposalId) external view returns (\n        uint256 id,\n        address proposer,\n        string memory description,\n        ProposalType proposalType,\n        uint256 startTime,\n        uint256 endTime,\n        uint256 forVotes,\n        uint256 againstVotes,\n        bool executed,\n        bool cancelled,\n        string memory nftMetadataURI\n    ) {\n        Proposal storage proposal = proposals[_proposalId];\n        return (\n            proposal.id,\n            proposal.proposer,\n            proposal.description,\n            proposal.proposalType,\n            proposal.startTime,\n            proposal.endTime,\n            proposal.forVotes,\n            proposal.againstVotes,\n            proposal.executed,\n            proposal.cancelled,\n            proposal.nftMetadataURI\n        );\n    }\n\n    function hasVoted(uint256 _proposalId, address _voter) external view returns (bool) {\n        return proposals[_proposalId].hasVoted[_voter];\n    }\n\n    function setVotingPeriod(uint256 _votingPeriod) external onlyOwner {\n        votingPeriod = _votingPeriod;\n    }\n\n    function setVotingDelay(uint256 _votingDelay) external onlyOwner {\n        votingDelay = _votingDelay;\n    }\n\n    function setProposalThreshold(uint256 _proposalThreshold) external onlyOwner {\n        proposalThreshold = _proposalThreshold;\n    }\n\n    function setQuorumVotes(uint256 _quorumVotes) external onlyOwner {\n        quorumVotes = _quorumVotes;\n    }\n}",
          "contracts/StakingPool.sol": "// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport \"@openzeppelin/contracts/token/ERC721/IERC721.sol\";\nimport \"@openzeppelin/contracts/token/ERC721/IERC721Receiver.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@openzeppelin/contracts/utils/ReentrancyGuard.sol\";\n\ncontract StakingPool is IERC721Receiver, Ownable, ReentrancyGuard {\n    IERC721 public nftContract;\n    \n    struct StakeInfo {\n        address owner;\n        uint256 stakedAt;\n        uint256 lastClaimTime;\n    }\n    \n    mapping(uint256 => StakeInfo) public stakes;\n    mapping(address => uint256[]) public stakerTokens;\n    \n    address[] private _allStakers;\n    mapping(address => bool) private _isStaker;\n    mapping(address => uint256) private _stakerIndex;\n    \n    uint256 public rewardRate = 10 * 10**18;\n    uint256 public totalStaked;\n    \n    event NFTStaked(address indexed owner, uint256 indexed tokenId, uint256 timestamp);\n    event NFTUnstaked(address indexed owner, uint256 indexed tokenId, uint256 timestamp);\n    event RewardsClaimed(address indexed owner, uint256 amount);\n    \n    constructor(address _nftContract) Ownable(msg.sender) {\n        nftContract = IERC721(_nftContract);\n    }\n    \n    function stake(uint256 _tokenId) external nonReentrant {\n        require(nftContract.ownerOf(_tokenId) == msg.sender, \"Not token owner\");\n        \n        nftContract.safeTransferFrom(msg.sender, address(this), _tokenId);\n        \n        stakes[_tokenId] = StakeInfo({\n            owner: msg.sender,\n            stakedAt: block.timestamp,\n            lastClaimTime: block.timestamp\n        });\n        \n        stakerTokens[msg.sender].push(_tokenId);\n        totalStaked++;\n        \n        if (!_isStaker[msg.sender]) {\n            _stakerIndex[msg.sender] = _allStakers.length;\n            _allStakers.push(msg.sender);\n            _isStaker[msg.sender] = true;\n        }\n        \n        emit NFTStaked(msg.sender, _tokenId, block.timestamp);\n    }\n    \n    function unstake(uint256 _tokenId) external nonReentrant {\n        StakeInfo storage stakeInfo = stakes[_tokenId];\n        require(stakeInfo.owner == msg.sender, \"Not stake owner\");\n        \n        nftContract.safeTransferFrom(address(this), msg.sender, _tokenId);\n        \n        _removeTokenFromStaker(msg.sender, _tokenId);\n        delete stakes[_tokenId];\n        totalStaked--;\n        \n        if (stakerTokens[msg.sender].length == 0) {\n            _removeStaker(msg.sender);\n        }\n        \n        emit NFTUnstaked(msg.sender, _tokenId, block.timestamp);\n    }\n    \n    function _removeTokenFromStaker(address _staker, uint256 _tokenId) internal {\n        uint256[] storage tokens = stakerTokens[_staker];\n        for (uint256 i = 0; i < tokens.length; i++) {\n            if (tokens[i] == _tokenId) {\n                tokens[i] = tokens[tokens.length - 1];\n                tokens.pop();\n                break;\n            }\n        }\n    }\n    \n    function _removeStaker(address _staker) internal {\n        if (!_isStaker[_staker]) return;\n        \n        uint256 index = _stakerIndex[_staker];\n        uint256 lastIndex = _allStakers.length - 1;\n        \n        if (index != lastIndex) {\n            address lastStaker = _allStakers[lastIndex];\n            _allStakers[index] = lastStaker;\n            _stakerIndex[lastStaker] = index;\n        }\n        \n        _allStakers.pop();\n        delete _stakerIndex[_staker];\n        _isStaker[_staker] = false;\n    }\n    \n    function getAllStakers() external view returns (address[] memory) {\n        return _allStakers;\n    }\n    \n    function getStakerCount() external view returns (uint256) {\n        return _allStakers.length;\n    }\n    \n    function isStaker(address _address) external view returns (bool) {\n        return _isStaker[_address];\n    }\n    \n    function getStakedTokens(address _staker) external view returns (uint256[] memory) {\n        return stakerTokens[_staker];\n    }\n    \n    function getStakeInfo(uint256 _tokenId) external view returns (\n        address owner,\n        uint256 stakedAt,\n        uint256 lastClaimTime\n    ) {\n        StakeInfo storage info = stakes[_tokenId];\n        return (info.owner, info.stakedAt, info.lastClaimTime);\n    }\n    \n    function calculateRewards(uint256 _tokenId) public view returns (uint256) {\n        StakeInfo storage stakeInfo = stakes[_tokenId];\n        if (stakeInfo.owner == address(0)) return 0;\n        \n        uint256 stakingDuration = block.timestamp - stakeInfo.lastClaimTime;\n        return (stakingDuration * rewardRate) / 1 days;\n    }\n    \n    function setRewardRate(uint256 _newRate) external onlyOwner {\n        rewardRate = _newRate;\n    }\n    \n    function onERC721Received(\n        address,\n        address,\n        uint256,\n        bytes calldata\n    ) external pure override returns (bytes4) {\n        return this.onERC721Received.selector;\n    }\n}",
          "contracts/ShowTimeNFT.sol": "// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\nimport \"@openzeppelin/contracts/token/ERC721/extensions/ERC721URIStorage.sol\";\nimport \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Enumerable.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@openzeppelin/contracts/utils/ReentrancyGuard.sol\";\n\ninterface IStakingPool {\n    function getAllStakers() external view returns (address[] memory);\n}\n\ncontract ShowTimeNFT is ERC721, ERC721URIStorage, ERC721Enumerable, Ownable, ReentrancyGuard {\n    uint256 private _tokenIdCounter;\n    \n    address public stakingPool;\n    address public governanceContract;\n    \n    uint256 public mintPrice = 0.01 ether;\n    uint256 public maxSupply = 10000;\n    bool public mintingEnabled = true;\n    \n    mapping(uint256 => bool) public isSpecialEdition;\n    \n    event NFTMinted(address indexed to, uint256 indexed tokenId, string tokenURI);\n    event SpecialEditionMinted(address indexed to, uint256 indexed tokenId, string tokenURI);\n    event AirdropCompleted(uint256 recipientCount, string metadataURI);\n    event StakingPoolUpdated(address indexed oldPool, address indexed newPool);\n    event GovernanceContractUpdated(address indexed oldGovernance, address indexed newGovernance);\n    \n    modifier onlyGovernance() {\n        require(msg.sender == governanceContract, \"Only governance can call\");\n        _;\n    }\n    \n    constructor() ERC721(\"ShowTime Stash\", \"STS\") Ownable(msg.sender) {\n        _tokenIdCounter = 0;\n    }\n    \n    function setStakingPool(address _stakingPool) external onlyOwner {\n        address oldPool = stakingPool;\n        stakingPool = _stakingPool;\n        emit StakingPoolUpdated(oldPool, _stakingPool);\n    }\n    \n    function setGovernanceContract(address _governanceContract) external onlyOwner {\n        address oldGovernance = governanceContract;\n        governanceContract = _governanceContract;\n        emit GovernanceContractUpdated(oldGovernance, _governanceContract);\n    }\n    \n    function mint(string memory _tokenURI) external payable nonReentrant {\n        require(mintingEnabled, \"Minting is disabled\");\n        require(msg.value >= mintPrice, \"Insufficient payment\");\n        require(_tokenIdCounter < maxSupply, \"Max supply reached\");\n        \n        uint256 tokenId = _tokenIdCounter;\n        _tokenIdCounter++;\n        \n        _safeMint(msg.sender, tokenId);\n        _setTokenURI(tokenId, _tokenURI);\n        \n        emit NFTMinted(msg.sender, tokenId, _tokenURI);\n    }\n    \n    function mintByOwner(address _to, string memory _tokenURI) external onlyOwner {\n        require(_tokenIdCounter < maxSupply, \"Max supply reached\");\n        \n        uint256 tokenId = _tokenIdCounter;\n        _tokenIdCounter++;\n        \n        _safeMint(_to, tokenId);\n        _setTokenURI(tokenId, _tokenURI);\n        \n        emit NFTMinted(_to, tokenId, _tokenURI);\n    }\n    \n    function airdropToStakers(string calldata _metadataURI) external onlyGovernance nonReentrant {\n        require(stakingPool != address(0), \"Staking pool not set\");\n        require(bytes(_metadataURI).length > 0, \"Metadata URI required\");\n        \n        address[] memory stakers = IStakingPool(stakingPool).getAllStakers();\n        require(stakers.length > 0, \"No stakers to airdrop to\");\n        \n        uint256 mintedCount = 0;\n        \n        for (uint256 i = 0; i < stakers.length; i++) {\n            address staker = stakers[i];\n            if (staker != address(0)) {\n                uint256 tokenId = _tokenIdCounter;\n                _tokenIdCounter++;\n                \n                _safeMint(staker, tokenId);\n                _setTokenURI(tokenId, _metadataURI);\n                isSpecialEdition[tokenId] = true;\n                \n                emit SpecialEditionMinted(staker, tokenId, _metadataURI);\n                mintedCount++;\n            }\n        }\n        \n        emit AirdropCompleted(mintedCount, _metadataURI);\n    }\n    \n    function setMintPrice(uint256 _newPrice) external onlyOwner {\n        mintPrice = _newPrice;\n    }\n    \n    function setMaxSupply(uint256 _newMaxSupply) external onlyOwner {\n        require(_newMaxSupply >= _tokenIdCounter, \"Cannot set below current supply\");\n        maxSupply = _newMaxSupply;\n    }\n    \n    function setMintingEnabled(bool _enabled) external onlyOwner {\n        mintingEnabled = _enabled;\n    }\n    \n    function withdraw() external onlyOwner {\n        uint256 balance = address(this).balance;\n        require(balance > 0, \"No balance to withdraw\");\n        payable(owner()).transfer(balance);\n    }\n    \n    function getCurrentTokenId() external view returns (uint256) {\n        return _tokenIdCounter;\n    }\n    \n    // Override functions for multiple inheritance\n    function _update(address to, uint256 tokenId, address auth)\n        internal\n        override(ERC721, ERC721Enumerable)\n        returns (address)\n    {\n        return super._update(to, tokenId, auth);\n    }\n\n    function _increaseBalance(address account, uint128 value)\n        internal\n        override(ERC721, ERC721Enumerable)\n    {\n        super._increaseBalance(account, value);\n    }\n\n    function tokenURI(uint256 tokenId)\n        public\n        view\n        override(ERC721, ERC721URIStorage)\n        returns (string memory)\n    {\n        return super.tokenURI(tokenId);\n    }\n\n    function supportsInterface(bytes4 interfaceId)\n        public\n        view\n        override(ERC721, ERC721URIStorage, ERC721Enumerable)\n        returns (bool)\n    {\n        return super.supportsInterface(interfaceId);\n    }\n}",
          "src/showtime_stash/domain/governance.py": "\"\"\"Domain models for governance functionality.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Optional, List\nfrom decimal import Decimal\n\n\nclass ProposalType(Enum):\n    \"\"\"Types of governance proposals.\"\"\"\n    PARAMETER = \"parameter\"\n    UPGRADE = \"upgrade\"\n    TREASURY = \"treasury\"\n    AIRDROP = \"airdrop\"\n\n\nclass ProposalState(Enum):\n    \"\"\"States of a governance proposal.\"\"\"\n    PENDING = \"pending\"\n    ACTIVE = \"active\"\n    SUCCEEDED = \"succeeded\"\n    DEFEATED = \"defeated\"\n    EXECUTED = \"executed\"\n    CANCELLED = \"cancelled\"\n\n\n@dataclass\nclass Vote:\n    \"\"\"Represents a vote on a proposal.\"\"\"\n    voter_address: str\n    proposal_id: int\n    support: bool\n    votes: Decimal\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    transaction_hash: Optional[str] = None\n\n    def __post_init__(self):\n        if isinstance(self.votes, (int, float)):\n            self.votes = Decimal(str(self.votes))\n\n\n@dataclass\nclass Proposal:\n    \"\"\"Represents a governance proposal.\"\"\"\n    id: int\n    proposer: str\n    description: str\n    proposal_type: ProposalType\n    start_time: datetime\n    end_time: datetime\n    for_votes: Decimal = Decimal(\"0\")\n    against_votes: Decimal = Decimal(\"0\")\n    executed: bool = False\n    cancelled: bool = False\n    nft_metadata_uri: Optional[str] = None\n    transaction_hash: Optional[str] = None\n    votes: List[Vote] = field(default_factory=list)\n\n    def __post_init__(self):\n        if isinstance(self.for_votes, (int, float)):\n            self.for_votes = Decimal(str(self.for_votes))\n        if isinstance(self.against_votes, (int, float)):\n            self.against_votes = Decimal(str(self.against_votes))\n\n    @property\n    def state(self) -> ProposalState:\n        \"\"\"Calculate the current state of the proposal.\"\"\"\n        if self.cancelled:\n            return ProposalState.CANCELLED\n        if self.executed:\n            return ProposalState.EXECUTED\n        \n        now = datetime.utcnow()\n        if now < self.start_time:\n            return ProposalState.PENDING\n        if now <= self.end_time:\n            return ProposalState.ACTIVE\n        \n        # Voting period ended - check results\n        if self.for_votes > self.against_votes:\n            return ProposalState.SUCCEEDED\n        return ProposalState.DEFEATED\n\n    @property\n    def total_votes(self) -> Decimal:\n        \"\"\"Calculate total votes cast.\"\"\"\n        return self.for_votes + self.against_votes\n\n    @property\n    def approval_percentage(self) -> float:\n        \"\"\"Calculate approval percentage.\"\"\"\n        if self.total_votes == 0:\n            return 0.0\n        return float(self.for_votes / self.total_votes * 100)\n\n    def is_airdrop_proposal(self) -> bool:\n        \"\"\"Check if this is an airdrop proposal.\"\"\"\n        return self.proposal_type == ProposalType.AIRDROP\n\n    def has_valid_metadata_uri(self) -> bool:\n        \"\"\"Check if the proposal has a valid metadata URI (for airdrop proposals).\"\"\"\n        return bool(self.nft_metadata_uri and len(self.nft_metadata_uri) > 0)\n\n\n@dataclass\nclass AirdropProposalRequest:\n    \"\"\"Request model for creating an airdrop proposal.\"\"\"\n    description: str\n    nft_metadata_uri: str\n    proposer_address: Optional[str] = None\n\n    def validate(self) -> List[str]:\n        \"\"\"Validate the airdrop proposal request.\"\"\"\n        errors = []\n        if not self.description or len(self.description.strip()) == 0:\n            errors.append(\"Description is required\")\n        if not self.nft_metadata_uri or len(self.nft_metadata_uri.strip()) == 0:\n            errors.append(\"NFT metadata URI is required\")\n        if self.nft_metadata_uri and not self.nft_metadata_uri.startswith((\"ipfs://\", \"https://\", \"http://\")):\n            errors.append(\"NFT metadata URI must be a valid URL or IPFS link\")\n        return errors\n\n\n@dataclass\nclass GovernanceConfig:\n    \"\"\"Configuration for governance parameters.\"\"\"\n    voting_period_days: int = 3\n    voting_delay_days: int = 1\n    proposal_threshold: Decimal = Decimal(\"100\")\n    quorum_votes: Decimal = Decimal(\"1000\")\n\n    def __post_init__(self):\n        if isinstance(self.proposal_threshold, (int, float)):\n            self.proposal_threshold = Decimal(str(self.proposal_threshold))\n        if isinstance(self.quorum_votes, (int, float)):\n            self.quorum_votes = Decimal(str(self.quorum_votes))\n\n\n@dataclass\nclass GovernanceStats:\n    \"\"\"Statistics about governance activity.\"\"\"\n    total_proposals: int = 0\n    active_proposals: int = 0\n    executed_proposals: int = 0\n    total_votes_cast: int = 0\n    unique_voters: int = 0\n    airdrop_proposals_executed: int = 0\n\n\n@dataclass\nclass AirdropResult:\n    \"\"\"Result of an airdrop execution.\"\"\"\n    proposal_id: int\n    metadata_uri: str\n    recipient_count: int\n    transaction_hash: str\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    success: bool = True\n    error_message: Optional[str] = None",
          "src/showtime_stash/interfaces/api.py": "\"\"\"FastAPI interface for ShowTime Stash platform.\"\"\"\n\nfrom fastapi import FastAPI, HTTPException, Depends, Query, Body\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\nfrom datetime import datetime\nfrom decimal import Decimal\nimport logging\n\nfrom ..domain.governance import (\n    ProposalType,\n    ProposalState,\n    Proposal,\n    AirdropProposalRequest,\n    GovernanceStats\n)\nfrom ..domain.nft import NFT, NFTMetadata\nfrom ..application.services import (\n    GovernanceService,\n    NFTService,\n    StakingService\n)\n\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(\n    title=\"ShowTime Stash API\",\n    description=\"API for NFT marketplace with governance and staking\",\n    version=\"1.0.0\"\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Pydantic models for request/response\nclass NFTResponse(BaseModel):\n    token_id: int\n    owner: str\n    metadata_uri: str\n    is_special_edition: bool = False\n\n    class Config:\n        from_attributes = True\n\n\nclass StakeRequest(BaseModel):\n    token_id: int\n    user_address: str\n\n\nclass StakeResponse(BaseModel):\n    success: bool\n    transaction_hash: Optional[str] = None\n    message: str\n\n\nclass ProposalResponse(BaseModel):\n    id: int\n    proposer: str\n    description: str\n    proposal_type: str\n    state: str\n    start_time: datetime\n    end_time: datetime\n    for_votes: str\n    against_votes: str\n    executed: bool\n    cancelled: bool\n    nft_metadata_uri: Optional[str] = None\n\n    class Config:\n        from_attributes = True\n\n\nclass CreateProposalRequest(BaseModel):\n    description: str = Field(..., min_length=1, max_length=1000)\n    proposal_type: str = Field(..., description=\"Type of proposal\")\n    proposer_address: str = Field(..., description=\"Address of the proposer\")\n\n\nclass CreateAirdropProposalRequest(BaseModel):\n    description: str = Field(..., min_length=1, max_length=1000, description=\"Description of the airdrop proposal\")\n    nft_metadata_uri: str = Field(..., min_length=1, description=\"IPFS or HTTP URI for the NFT metadata\")\n    proposer_address: Optional[str] = Field(None, description=\"Address of the proposer\")\n\n\nclass VoteRequest(BaseModel):\n    proposal_id: int\n    voter_address: str\n    support: bool\n\n\nclass VoteResponse(BaseModel):\n    success: bool\n    transaction_hash: Optional[str] = None\n    message: str\n\n\nclass ExecuteProposalRequest(BaseModel):\n    proposal_id: int\n    executor_address: str\n\n\nclass ExecuteProposalResponse(BaseModel):\n    success: bool\n    transaction_hash: Optional[str] = None\n    message: str\n    airdrop_recipient_count: Optional[int] = None\n\n\nclass GovernanceStatsResponse(BaseModel):\n    total_proposals: int\n    active_proposals: int\n    executed_proposals: int\n    total_votes_cast: int\n    unique_voters: int\n    airdrop_proposals_executed: int\n\n\nclass StakerListResponse(BaseModel):\n    stakers: List[str]\n    count: int\n\n\n# Dependency injection for services\ndef get_governance_service() -> GovernanceService:\n    \"\"\"Get governance service instance.\"\"\"\n    from ..application.factories import ServiceFactory\n    return ServiceFactory.get_governance_service()\n\n\ndef get_nft_service() -> NFTService:\n    \"\"\"Get NFT service instance.\"\"\"\n    from ..application.factories import ServiceFactory\n    return ServiceFactory.get_nft_service()\n\n\ndef get_staking_service() -> StakingService:\n    \"\"\"Get staking service instance.\"\"\"\n    from ..application.factories import ServiceFactory\n    return ServiceFactory.get_staking_service()\n\n\n# Health check\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"timestamp\": datetime.utcnow().isoformat()}\n\n\n# NFT Endpoints\n@app.get(\"/nfts/{token_id}\", response_model=NFTResponse)\nasync def get_nft(\n    token_id: int,\n    nft_service: NFTService = Depends(get_nft_service)\n):\n    \"\"\"Get NFT details by token ID.\"\"\"\n    try:\n        nft = await nft_service.get_nft(token_id)\n        if not nft:\n            raise HTTPException(status_code=404, detail=\"NFT not found\")\n        return NFTResponse(\n            token_id=nft.token_id,\n            owner=nft.owner,\n            metadata_uri=nft.metadata_uri,\n            is_special_edition=nft.is_special_edition\n        )\n    except Exception as e:\n        logger.error(f\"Error fetching NFT {token_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/nfts/owner/{address}\", response_model=List[NFTResponse])\nasync def get_nfts_by_owner(\n    address: str,\n    nft_service: NFTService = Depends(get_nft_service)\n):\n    \"\"\"Get all NFTs owned by an address.\"\"\"\n    try:\n        nfts = await nft_service.get_nfts_by_owner(address)\n        return [\n            NFTResponse(\n                token_id=nft.token_id,\n                owner=nft.owner,\n                metadata_uri=nft.metadata_uri,\n                is_special_edition=nft.is_special_edition\n            )\n            for nft in nfts\n        ]\n    except Exception as e:\n        logger.error(f\"Error fetching NFTs for owner {address}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n# Staking Endpoints\n@app.post(\"/staking/stake\", response_model=StakeResponse)\nasync def stake_nft(\n    request: StakeRequest,\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Stake an NFT.\"\"\"\n    try:\n        result = await staking_service.stake(request.token_id, request.user_address)\n        return StakeResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message\n        )\n    except Exception as e:\n        logger.error(f\"Error staking NFT {request.token_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/staking/unstake\", response_model=StakeResponse)\nasync def unstake_nft(\n    request: StakeRequest,\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Unstake an NFT.\"\"\"\n    try:\n        result = await staking_service.unstake(request.token_id, request.user_address)\n        return StakeResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message\n        )\n    except Exception as e:\n        logger.error(f\"Error unstaking NFT {request.token_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/staking/stakers\", response_model=StakerListResponse)\nasync def get_all_stakers(\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Get all current stakers.\"\"\"\n    try:\n        stakers = await staking_service.get_all_stakers()\n        return StakerListResponse(stakers=stakers, count=len(stakers))\n    except Exception as e:\n        logger.error(f\"Error fetching stakers: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/staking/user/{address}\")\nasync def get_user_stakes(\n    address: str,\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Get staked tokens for a user.\"\"\"\n    try:\n        stakes = await staking_service.get_user_stakes(address)\n        return {\"address\": address, \"staked_tokens\": stakes}\n    except Exception as e:\n        logger.error(f\"Error fetching stakes for {address}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n# Governance Endpoints\n@app.get(\"/proposals\", response_model=List[ProposalResponse])\nasync def get_proposals(\n    state: Optional[str] = Query(None, description=\"Filter by proposal state\"),\n    proposal_type: Optional[str] = Query(None, description=\"Filter by proposal type\"),\n    limit: int = Query(50, ge=1, le=100),\n    offset: int = Query(0, ge=0),\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Get list of governance proposals.\"\"\"\n    try:\n        proposals = await governance_service.get_proposals(\n            state=state,\n            proposal_type=proposal_type,\n            limit=limit,\n            offset=offset\n        )\n        return [\n            ProposalResponse(\n                id=p.id,\n                proposer=p.proposer,\n                description=p.description,\n                proposal_type=p.proposal_type.value,\n                state=p.state.value,\n                start_time=p.start_time,\n                end_time=p.end_time,\n                for_votes=str(p.for_votes),\n                against_votes=str(p.against_votes),\n                executed=p.executed,\n                cancelled=p.cancelled,\n                nft_metadata_uri=p.nft_metadata_uri\n            )\n            for p in proposals\n        ]\n    except Exception as e:\n        logger.error(f\"Error fetching proposals: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/proposals/{proposal_id}\", response_model=ProposalResponse)\nasync def get_proposal(\n    proposal_id: int,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Get details of a specific proposal.\"\"\"\n    try:\n        proposal = await governance_service.get_proposal(proposal_id)\n        if not proposal:\n            raise HTTPException(status_code=404, detail=\"Proposal not found\")\n        return ProposalResponse(\n            id=proposal.id,\n            proposer=proposal.proposer,\n            description=proposal.description,\n            proposal_type=proposal.proposal_type.value,\n            state=proposal.state.value,\n            start_time=proposal.start_time,\n            end_time=proposal.end_time,\n            for_votes=str(proposal.for_votes),\n            against_votes=str(proposal.against_votes),\n            executed=proposal.executed,\n            cancelled=proposal.cancelled,\n            nft_metadata_uri=proposal.nft_metadata_uri\n        )\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Error fetching proposal {proposal_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals\", response_model=ProposalResponse)\nasync def create_proposal(\n    request: CreateProposalRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Create a new governance proposal.\"\"\"\n    try:\n        proposal_type = ProposalType(request.proposal_type.lower())\n        proposal = await governance_service.create_proposal(\n            description=request.description,\n            proposal_type=proposal_type,\n            proposer_address=request.proposer_address\n        )\n        return ProposalResponse(\n            id=proposal.id,\n            proposer=proposal.proposer,\n            description=proposal.description,\n            proposal_type=proposal.proposal_type.value,\n            state=proposal.state.value,\n            start_time=proposal.start_time,\n            end_time=proposal.end_time,\n            for_votes=str(proposal.for_votes),\n            against_votes=str(proposal.against_votes),\n            executed=proposal.executed,\n            cancelled=proposal.cancelled,\n            nft_metadata_uri=proposal.nft_metadata_uri\n        )\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error creating proposal: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals/airdrop\", response_model=ProposalResponse)\nasync def create_airdrop_proposal(\n    request: CreateAirdropProposalRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Create a new airdrop governance proposal.\n    \n    This endpoint creates a proposal to airdrop special edition NFTs\n    to all users currently staking NFTs on the platform.\n    \"\"\"\n    try:\n        # Validate the request\n        airdrop_request = AirdropProposalRequest(\n            description=request.description,\n            nft_metadata_uri=request.nft_metadata_uri,\n            proposer_address=request.proposer_address\n        )\n        \n        validation_errors = airdrop_request.validate()\n        if validation_errors:\n            raise HTTPException(\n                status_code=400,\n                detail={\"errors\": validation_errors}\n            )\n        \n        # Create the airdrop proposal\n        proposal = await governance_service.create_airdrop_proposal(\n            description=request.description,\n            nft_metadata_uri=request.nft_metadata_uri,\n            proposer_address=request.proposer_address\n        )\n        \n        return ProposalResponse(\n            id=proposal.id,\n            proposer=proposal.proposer,\n            description=proposal.description,\n            proposal_type=proposal.proposal_type.value,\n            state=proposal.state.value,\n            start_time=proposal.start_time,\n            end_time=proposal.end_time,\n            for_votes=str(proposal.for_votes),\n            against_votes=str(proposal.against_votes),\n            executed=proposal.executed,\n            cancelled=proposal.cancelled,\n            nft_metadata_uri=proposal.nft_metadata_uri\n        )\n    except HTTPException:\n        raise\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error creating airdrop proposal: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals/{proposal_id}/vote\", response_model=VoteResponse)\nasync def vote_on_proposal(\n    proposal_id: int,\n    request: VoteRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Vote on a governance proposal.\"\"\"\n    try:\n        result = await governance_service.vote(\n            proposal_id=proposal_id,\n            voter_address=request.voter_address,\n            support=request.support\n        )\n        return VoteResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message\n        )\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error voting on proposal {proposal_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals/{proposal_id}/execute\", response_model=ExecuteProposalResponse)\nasync def execute_proposal(\n    proposal_id: int,\n    request: ExecuteProposalRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Execute a passed governance proposal.\"\"\"\n    try:\n        result = await governance_service.execute_proposal(\n            proposal_id=proposal_id,\n            executor_address=request.executor_address\n        )\n        return ExecuteProposalResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message,\n            airdrop_recipient_count=getattr(result, 'airdrop_recipient_count', None)\n        )\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error executing proposal {proposal_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/governance/stats\", response_model=GovernanceStatsResponse)\nasync def get_governance_stats(\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Get governance statistics.\"\"\"\n    try:\n        stats = await governance_service.get_stats()\n        return GovernanceStatsResponse(\n            total_proposals=stats.total_proposals,\n            active_proposals=stats.active_proposals,\n            executed_proposals=stats.executed_proposals,\n            total_votes_cast=stats.total_votes_cast,\n            unique_voters=stats.unique_voters,\n            airdrop_proposals_executed=stats.airdrop_proposals_executed\n        )\n    except Exception as e:\n        logger.error(f\"Error fetching governance stats: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))",
          "src/showtime_stash/application/services.py": "\"\"\"Application services for ShowTime Stash platform.\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Optional, List\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nimport logging\n\nfrom ..domain.governance import (\n    Proposal,\n    ProposalType,\n    ProposalState,\n    Vote,\n    GovernanceStats,\n    AirdropResult\n)\nfrom ..domain.nft import NFT\nfrom ..infrastructure.blockchain_connector import BlockchainConnector\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ServiceResult:\n    \"\"\"Generic result from service operations.\"\"\"\n    success: bool\n    message: str\n    transaction_hash: Optional[str] = None\n    data: Optional[dict] = None\n\n\n@dataclass\nclass ExecuteResult(ServiceResult):\n    \"\"\"Result from executing a proposal.\"\"\"\n    airdrop_recipient_count: Optional[int] = None\n\n\nclass GovernanceService:\n    \"\"\"Service for governance operations.\"\"\"\n    \n    def __init__(self, blockchain_connector: BlockchainConnector):\n        self.blockchain = blockchain_connector\n        self._proposals_cache: dict = {}\n    \n    async def get_proposals(\n        self,\n        state: Optional[str] = None,\n        proposal_type: Optional[str] = None,\n        limit: int = 50,\n        offset: int = 0\n    ) -> List[Proposal]:\n        \"\"\"Get list of proposals with optional filtering.\"\"\"\n        try:\n            proposals = await self.blockchain.get_all_proposals()\n            \n            # Apply filters\n            if state:\n                state_enum = ProposalState(state.lower())\n                proposals = [p for p in proposals if p.state == state_enum]\n            \n            if proposal_type:\n                type_enum = ProposalType(proposal_type.lower())\n                proposals = [p for p in proposals if p.proposal_type == type_enum]\n            \n            # Apply pagination\n            return proposals[offset:offset + limit]\n        except Exception as e:\n            logger.error(f\"Error fetching proposals: {e}\")\n            raise\n    \n    async def get_proposal(self, proposal_id: int) -> Optional[Proposal]:\n        \"\"\"Get a specific proposal by ID.\"\"\"\n        try:\n            return await self.blockchain.get_proposal(proposal_id)\n        except Exception as e:\n            logger.error(f\"Error fetching proposal {proposal_id}: {e}\")\n            raise\n    \n    async def create_proposal(\n        self,\n        description: str,\n        proposal_type: ProposalType,\n        proposer_address: str\n    ) -> Proposal:\n        \"\"\"Create a new governance proposal.\"\"\"\n        try:\n            tx_hash = await self.blockchain.create_proposal(\n                description=description,\n                proposal_type=proposal_type.value,\n                proposer_address=proposer_address\n            )\n            \n            # Fetch the created proposal\n            proposal_id = await self.blockchain.get_latest_proposal_id()\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            proposal.transaction_hash = tx_hash\n            \n            return proposal\n        except Exception as e:\n            logger.error(f\"Error creating proposal: {e}\")\n            raise\n    \n    async def create_airdrop_proposal(\n        self,\n        description: str,\n        nft_metadata_uri: str,\n        proposer_address: Optional[str] = None\n    ) -> Proposal:\n        \"\"\"Create a new airdrop governance proposal.\"\"\"\n        try:\n            if not nft_metadata_uri:\n                raise ValueError(\"NFT metadata URI is required for airdrop proposals\")\n            \n            tx_hash = await self.blockchain.create_airdrop_proposal(\n                description=description,\n                nft_metadata_uri=nft_metadata_uri,\n                proposer_address=proposer_address\n            )\n            \n            # Fetch the created proposal\n            proposal_id = await self.blockchain.get_latest_proposal_id()\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            proposal.transaction_hash = tx_hash\n            \n            logger.info(f\"Created airdrop proposal {proposal_id} with metadata URI: {nft_metadata_uri}\")\n            return proposal\n        except Exception as e:\n            logger.error(f\"Error creating airdrop proposal: {e}\")\n            raise\n    \n    async def vote(\n        self,\n        proposal_id: int,\n        voter_address: str,\n        support: bool\n    ) -> ServiceResult:\n        \"\"\"Vote on a proposal.\"\"\"\n        try:\n            # Verify proposal exists and is active\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            if not proposal:\n                return ServiceResult(\n                    success=False,\n                    message=\"Proposal not found\"\n                )\n            \n            if proposal.state != ProposalState.ACTIVE:\n                return ServiceResult(\n                    success=False,\n                    message=f\"Proposal is not active. Current state: {proposal.state.value}\"\n                )\n            \n            # Submit vote\n            tx_hash = await self.blockchain.vote(\n                proposal_id=proposal_id,\n                voter_address=voter_address,\n                support=support\n            )\n            \n            return ServiceResult(\n                success=True,\n                message=\"Vote submitted successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error voting on proposal {proposal_id}: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def execute_proposal(\n        self,\n        proposal_id: int,\n        executor_address: str\n    ) -> ExecuteResult:\n        \"\"\"Execute a passed proposal.\"\"\"\n        try:\n            # Verify proposal exists and has succeeded\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            if not proposal:\n                return ExecuteResult(\n                    success=False,\n                    message=\"Proposal not found\"\n                )\n            \n            if proposal.state != ProposalState.SUCCEEDED:\n                return ExecuteResult(\n                    success=False,\n                    message=f\"Proposal cannot be executed. Current state: {proposal.state.value}\"\n                )\n            \n            # Execute the proposal\n            tx_hash = await self.blockchain.execute_proposal(\n                proposal_id=proposal_id,\n                executor_address=executor_address\n            )\n            \n            # For airdrop proposals, get recipient count\n            airdrop_count = None\n            if proposal.proposal_type == ProposalType.AIRDROP:\n                airdrop_count = await self.blockchain.get_airdrop_recipient_count(tx_hash)\n                logger.info(f\"Airdrop proposal {proposal_id} executed. Recipients: {airdrop_count}\")\n            \n            return ExecuteResult(\n                success=True,\n                message=\"Proposal executed successfully\",\n                transaction_hash=tx_hash,\n                airdrop_recipient_count=airdrop_count\n            )\n        except Exception as e:\n            logger.error(f\"Error executing proposal {proposal_id}: {e}\")\n            return ExecuteResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def get_stats(self) -> GovernanceStats:\n        \"\"\"Get governance statistics.\"\"\"\n        try:\n            return await self.blockchain.get_governance_stats()\n        except Exception as e:\n            logger.error(f\"Error fetching governance stats: {e}\")\n            raise\n\n\nclass NFTService:\n    \"\"\"Service for NFT operations.\"\"\"\n    \n    def __init__(self, blockchain_connector: BlockchainConnector):\n        self.blockchain = blockchain_connector\n    \n    async def get_nft(self, token_id: int) -> Optional[NFT]:\n        \"\"\"Get NFT by token ID.\"\"\"\n        try:\n            return await self.blockchain.get_nft(token_id)\n        except Exception as e:\n            logger.error(f\"Error fetching NFT {token_id}: {e}\")\n            raise\n    \n    async def get_nfts_by_owner(self, owner_address: str) -> List[NFT]:\n        \"\"\"Get all NFTs owned by an address.\"\"\"\n        try:\n            return await self.blockchain.get_nfts_by_owner(owner_address)\n        except Exception as e:\n            logger.error(f\"Error fetching NFTs for {owner_address}: {e}\")\n            raise\n    \n    async def mint_nft(\n        self,\n        to_address: str,\n        metadata_uri: str\n    ) -> ServiceResult:\n        \"\"\"Mint a new NFT.\"\"\"\n        try:\n            tx_hash = await self.blockchain.mint_nft(\n                to_address=to_address,\n                metadata_uri=metadata_uri\n            )\n            return ServiceResult(\n                success=True,\n                message=\"NFT minted successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error minting NFT: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n\n\nclass StakingService:\n    \"\"\"Service for staking operations.\"\"\"\n    \n    def __init__(self, blockchain_connector: BlockchainConnector):\n        self.blockchain = blockchain_connector\n    \n    async def stake(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> ServiceResult:\n        \"\"\"Stake an NFT.\"\"\"\n        try:\n            tx_hash = await self.blockchain.stake_nft(\n                token_id=token_id,\n                user_address=user_address\n            )\n            return ServiceResult(\n                success=True,\n                message=\"NFT staked successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error staking NFT {token_id}: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def unstake(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> ServiceResult:\n        \"\"\"Unstake an NFT.\"\"\"\n        try:\n            tx_hash = await self.blockchain.unstake_nft(\n                token_id=token_id,\n                user_address=user_address\n            )\n            return ServiceResult(\n                success=True,\n                message=\"NFT unstaked successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error unstaking NFT {token_id}: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def get_all_stakers(self) -> List[str]:\n        \"\"\"Get all current stakers.\"\"\"\n        try:\n            return await self.blockchain.get_all_stakers()\n        except Exception as e:\n            logger.error(f\"Error fetching stakers: {e}\")\n            raise\n    \n    async def get_user_stakes(self, user_address: str) -> List[int]:\n        \"\"\"Get staked token IDs for a user.\"\"\"\n        try:\n            return await self.blockchain.get_user_stakes(user_address)\n        except Exception as e:\n            logger.error(f\"Error fetching stakes for {user_address}: {e}\")\n            raise\n    \n    async def is_staker(self, address: str) -> bool:\n        \"\"\"Check if an address is currently staking.\"\"\"\n        try:\n            return await self.blockchain.is_staker(address)\n        except Exception as e:\n            logger.error(f\"Error checking staker status for {address}: {e}\")\n            raise",
          "tests/contract_tests/test_governance_airdrop.py": "\"\"\"Integration tests for governance-controlled NFT airdrops.\"\"\"\n\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\n\nfrom src.showtime_stash.domain.governance import (\n    Proposal,\n    ProposalType,\n    ProposalState,\n    AirdropProposalRequest,\n    Vote\n)\nfrom src.showtime_stash.domain.nft import NFT\nfrom src.showtime_stash.application.services import (\n    GovernanceService,\n    StakingService,\n    NFTService,\n    ServiceResult,\n    ExecuteResult\n)\n\n\nclass MockBlockchainConnector:\n    \"\"\"Mock blockchain connector for testing.\"\"\"\n    \n    def __init__(self):\n        self.proposals = {}\n        self.stakers = []\n        self.nfts = {}\n        self.stakes = {}\n        self.proposal_count = 0\n        self.token_count = 0\n        self.votes = {}\n    \n    async def create_airdrop_proposal(\n        self,\n        description: str,\n        nft_metadata_uri: str,\n        proposer_address: str = None\n    ) -> str:\n        self.proposal_count += 1\n        proposal_id = self.proposal_count\n        \n        self.proposals[proposal_id] = Proposal(\n            id=proposal_id,\n            proposer=proposer_address or \"0xProposer\",\n            description=description,\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3),\n            nft_metadata_uri=nft_metadata_uri\n        )\n        return f\"0xTxHash{proposal_id}\"\n    \n    async def get_latest_proposal_id(self) -> int:\n        return self.proposal_count\n    \n    async def get_proposal(self, proposal_id: int) -> Proposal:\n        return self.proposals.get(proposal_id)\n    \n    async def get_all_proposals(self) -> list:\n        return list(self.proposals.values())\n    \n    async def vote(\n        self,\n        proposal_id: int,\n        voter_address: str,\n        support: bool\n    ) -> str:\n        proposal = self.proposals.get(proposal_id)\n        if proposal:\n            votes = Decimal(\"500\")  # Simulated voting power\n            if support:\n                proposal.for_votes += votes\n            else:\n                proposal.against_votes += votes\n            \n            if proposal_id not in self.votes:\n                self.votes[proposal_id] = []\n            self.votes[proposal_id].append(Vote(\n                voter_address=voter_address,\n                proposal_id=proposal_id,\n                support=support,\n                votes=votes\n            ))\n        return f\"0xVoteTx{proposal_id}_{voter_address}\"\n    \n    async def execute_proposal(\n        self,\n        proposal_id: int,\n        executor_address: str\n    ) -> str:\n        proposal = self.proposals.get(proposal_id)\n        if proposal:\n            proposal.executed = True\n            \n            # Simulate airdrop execution\n            if proposal.proposal_type == ProposalType.AIRDROP:\n                for staker in self.stakers:\n                    self.token_count += 1\n                    self.nfts[self.token_count] = NFT(\n                        token_id=self.token_count,\n                        owner=staker,\n                        metadata_uri=proposal.nft_metadata_uri,\n                        is_special_edition=True\n                    )\n        return f\"0xExecuteTx{proposal_id}\"\n    \n    async def get_airdrop_recipient_count(self, tx_hash: str) -> int:\n        return len(self.stakers)\n    \n    async def stake_nft(self, token_id: int, user_address: str) -> str:\n        if user_address not in self.stakers:\n            self.stakers.append(user_address)\n        if user_address not in self.stakes:\n            self.stakes[user_address] = []\n        self.stakes[user_address].append(token_id)\n        return f\"0xStakeTx{token_id}\"\n    \n    async def unstake_nft(self, token_id: int, user_address: str) -> str:\n        if user_address in self.stakes:\n            if token_id in self.stakes[user_address]:\n                self.stakes[user_address].remove(token_id)\n            if len(self.stakes[user_address]) == 0:\n                self.stakers.remove(user_address)\n        return f\"0xUnstakeTx{token_id}\"\n    \n    async def get_all_stakers(self) -> list:\n        return self.stakers.copy()\n    \n    async def get_user_stakes(self, user_address: str) -> list:\n        return self.stakes.get(user_address, [])\n    \n    async def is_staker(self, address: str) -> bool:\n        return address in self.stakers\n    \n    async def get_nft(self, token_id: int) -> NFT:\n        return self.nfts.get(token_id)\n    \n    async def get_nfts_by_owner(self, owner_address: str) -> list:\n        return [nft for nft in self.nfts.values() if nft.owner == owner_address]\n    \n    async def mint_nft(self, to_address: str, metadata_uri: str) -> str:\n        self.token_count += 1\n        self.nfts[self.token_count] = NFT(\n            token_id=self.token_count,\n            owner=to_address,\n            metadata_uri=metadata_uri,\n            is_special_edition=False\n        )\n        return f\"0xMintTx{self.token_count}\"\n    \n    async def get_governance_stats(self):\n        from src.showtime_stash.domain.governance import GovernanceStats\n        return GovernanceStats(\n            total_proposals=len(self.proposals),\n            active_proposals=sum(1 for p in self.proposals.values() if p.state == ProposalState.ACTIVE),\n            executed_proposals=sum(1 for p in self.proposals.values() if p.executed),\n            total_votes_cast=sum(len(v) for v in self.votes.values()),\n            unique_voters=len(set(v.voter_address for votes in self.votes.values() for v in votes)),\n            airdrop_proposals_executed=sum(\n                1 for p in self.proposals.values()\n                if p.proposal_type == ProposalType.AIRDROP and p.executed\n            )\n        )\n\n\n@pytest.fixture\ndef mock_blockchain():\n    \"\"\"Create a mock blockchain connector.\"\"\"\n    return MockBlockchainConnector()\n\n\n@pytest.fixture\ndef governance_service(mock_blockchain):\n    \"\"\"Create governance service with mock blockchain.\"\"\"\n    return GovernanceService(mock_blockchain)\n\n\n@pytest.fixture\ndef staking_service(mock_blockchain):\n    \"\"\"Create staking service with mock blockchain.\"\"\"\n    return StakingService(mock_blockchain)\n\n\n@pytest.fixture\ndef nft_service(mock_blockchain):\n    \"\"\"Create NFT service with mock blockchain.\"\"\"\n    return NFTService(mock_blockchain)\n\n\nclass TestAirdropProposalRequest:\n    \"\"\"Tests for AirdropProposalRequest validation.\"\"\"\n    \n    def test_valid_request(self):\n        \"\"\"Test valid airdrop proposal request.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Airdrop special NFTs to stakers\",\n            nft_metadata_uri=\"ipfs://QmTest123\"\n        )\n        errors = request.validate()\n        assert len(errors) == 0\n    \n    def test_missing_description(self):\n        \"\"\"Test request with missing description.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"\",\n            nft_metadata_uri=\"ipfs://QmTest123\"\n        )\n        errors = request.validate()\n        assert \"Description is required\" in errors\n    \n    def test_missing_metadata_uri(self):\n        \"\"\"Test request with missing metadata URI.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Test airdrop\",\n            nft_metadata_uri=\"\"\n        )\n        errors = request.validate()\n        assert \"NFT metadata URI is required\" in errors\n    \n    def test_invalid_metadata_uri(self):\n        \"\"\"Test request with invalid metadata URI.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Test airdrop\",\n            nft_metadata_uri=\"invalid-uri\"\n        )\n        errors = request.validate()\n        assert \"NFT metadata URI must be a valid URL or IPFS link\" in errors\n    \n    def test_valid_https_uri(self):\n        \"\"\"Test request with valid HTTPS URI.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Test airdrop\",\n            nft_metadata_uri=\"https://example.com/metadata.json\"\n        )\n        errors = request.validate()\n        assert len(errors) == 0\n\n\nclass TestGovernanceAirdropIntegration:\n    \"\"\"Integration tests for the full airdrop flow.\"\"\"\n    \n    @pytest.mark.asyncio\n    async def test_full_airdrop_flow(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"\n        Test the complete airdrop flow:\n        1. User stakes an NFT\n        2. Another user creates an Airdrop proposal\n        3. Users vote to pass the proposal\n        4. Proposal is executed\n        5. Verify staker received the special edition NFT\n        \"\"\"\n        # Setup: Mint initial NFT for staking\n        staker_address = \"0xStaker1\"\n        non_staker_address = \"0xNonStaker\"\n        proposer_address = \"0xProposer\"\n        voter1_address = \"0xVoter1\"\n        voter2_address = \"0xVoter2\"\n        \n        # Mint an NFT to the staker\n        mint_result = await nft_service.mint_nft(\n            to_address=staker_address,\n            metadata_uri=\"ipfs://QmOriginalNFT\"\n        )\n        assert mint_result.success\n        \n        # Step 1: User stakes an NFT\n        stake_result = await staking_service.stake(\n            token_id=1,\n            user_address=staker_address\n        )\n        assert stake_result.success\n        \n        # Verify staker is in the stakers list\n        stakers = await staking_service.get_all_stakers()\n        assert staker_address in stakers\n        assert non_staker_address not in stakers\n        \n        # Step 2: Create an Airdrop proposal\n        airdrop_metadata_uri = \"ipfs://QmSpecialEditionNFT\"\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Airdrop special edition NFTs to all stakers\",\n            nft_metadata_uri=airdrop_metadata_uri,\n            proposer_address=proposer_address\n        )\n        \n        assert proposal is not None\n        assert proposal.proposal_type == ProposalType.AIRDROP\n        assert proposal.nft_metadata_uri == airdrop_metadata_uri\n        assert proposal.id == 1\n        \n        # Step 3: Users vote to pass the proposal\n        # Make proposal active by adjusting timestamps in mock\n        mock_blockchain.proposals[1].start_time = datetime.utcnow() - timedelta(hours=1)\n        mock_blockchain.proposals[1].end_time = datetime.utcnow() + timedelta(days=3)\n        \n        vote1_result = await governance_service.vote(\n            proposal_id=1,\n            voter_address=voter1_address,\n            support=True\n        )\n        assert vote1_result.success\n        \n        vote2_result = await governance_service.vote(\n            proposal_id=1,\n            voter_address=voter2_address,\n            support=True\n        )\n        assert vote2_result.success\n        \n        # Verify votes were recorded\n        updated_proposal = await governance_service.get_proposal(1)\n        assert updated_proposal.for_votes == Decimal(\"1000\")  # 500 * 2 voters\n        \n        # Step 4: Execute the proposal after voting period\n        # Simulate voting period ended\n        mock_blockchain.proposals[1].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        execute_result = await governance_service.execute_proposal(\n            proposal_id=1,\n            executor_address=proposer_address\n        )\n        assert execute_result.success\n        assert execute_result.airdrop_recipient_count == 1  # Only one staker\n        \n        # Step 5: Verify staker received the special edition NFT\n        staker_nfts = await nft_service.get_nfts_by_owner(staker_address)\n        special_edition_nfts = [nft for nft in staker_nfts if nft.is_special_edition]\n        \n        assert len(special_edition_nfts) == 1\n        assert special_edition_nfts[0].metadata_uri == airdrop_metadata_uri\n        \n        # Verify non-staker did NOT receive the NFT\n        non_staker_nfts = await nft_service.get_nfts_by_owner(non_staker_address)\n        assert len(non_staker_nfts) == 0\n    \n    @pytest.mark.asyncio\n    async def test_multiple_stakers_receive_airdrop(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test that multiple stakers all receive the airdrop.\"\"\"\n        stakers = [\"0xStaker1\", \"0xStaker2\", \"0xStaker3\"]\n        \n        # Mint and stake NFTs for multiple users\n        for i, staker in enumerate(stakers, start=1):\n            await nft_service.mint_nft(\n                to_address=staker,\n                metadata_uri=f\"ipfs://QmNFT{i}\"\n            )\n            await staking_service.stake(\n                token_id=i,\n                user_address=staker\n            )\n        \n        # Verify all stakers are registered\n        all_stakers = await staking_service.get_all_stakers()\n        assert len(all_stakers) == 3\n        \n        # Create and pass airdrop proposal\n        airdrop_uri = \"ipfs://QmMultiStakerAirdrop\"\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Multi-staker airdrop\",\n            nft_metadata_uri=airdrop_uri,\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Make proposal pass immediately for testing\n        mock_blockchain.proposals[proposal.id].for_votes = Decimal(\"10000\")\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        # Execute\n        result = await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        assert result.success\n        assert result.airdrop_recipient_count == 3\n        \n        # Verify each staker received exactly one special edition NFT\n        for staker in stakers:\n            nfts = await nft_service.get_nfts_by_owner(staker)\n            special_nfts = [n for n in nfts if n.is_special_edition]\n            assert len(special_nfts) == 1\n            assert special_nfts[0].metadata_uri == airdrop_uri\n    \n    @pytest.mark.asyncio\n    async def test_unstaked_user_not_in_airdrop(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test that a user who unstakes before execution doesn't receive airdrop.\"\"\"\n        staker1 = \"0xStaker1\"\n        staker2 = \"0xStaker2\"\n        \n        # Both users stake\n        for i, staker in enumerate([staker1, staker2], start=1):\n            await nft_service.mint_nft(to_address=staker, metadata_uri=f\"ipfs://QmNFT{i}\")\n            await staking_service.stake(token_id=i, user_address=staker)\n        \n        # Create proposal\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Test unstake\",\n            nft_metadata_uri=\"ipfs://QmAirdrop\",\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Staker2 unstakes before execution\n        await staking_service.unstake(token_id=2, user_address=staker2)\n        \n        # Verify staker2 is no longer in stakers list\n        current_stakers = await staking_service.get_all_stakers()\n        assert staker1 in current_stakers\n        assert staker2 not in current_stakers\n        \n        # Execute proposal\n        mock_blockchain.proposals[proposal.id].for_votes = Decimal(\"10000\")\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        result = await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        assert result.success\n        assert result.airdrop_recipient_count == 1  # Only staker1\n        \n        # Verify only staker1 received airdrop\n        staker1_special = [n for n in await nft_service.get_nfts_by_owner(staker1) if n.is_special_edition]\n        staker2_special = [n for n in await nft_service.get_nfts_by_owner(staker2) if n.is_special_edition]\n        \n        assert len(staker1_special) == 1\n        assert len(staker2_special) == 0\n    \n    @pytest.mark.asyncio\n    async def test_defeated_proposal_not_executed(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test that a defeated proposal cannot be executed.\"\"\"\n        # Setup staker\n        await nft_service.mint_nft(to_address=\"0xStaker\", metadata_uri=\"ipfs://QmNFT\")\n        await staking_service.stake(token_id=1, user_address=\"0xStaker\")\n        \n        # Create proposal\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Defeated proposal\",\n            nft_metadata_uri=\"ipfs://QmDefeated\",\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Vote against\n        mock_blockchain.proposals[proposal.id].against_votes = Decimal(\"10000\")\n        mock_blockchain.proposals[proposal.id].for_votes = Decimal(\"100\")\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        # Verify proposal is defeated\n        updated_proposal = await governance_service.get_proposal(proposal.id)\n        assert updated_proposal.state == ProposalState.DEFEATED\n        \n        # Attempt to execute should fail\n        result = await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        assert not result.success\n        assert \"cannot be executed\" in result.message.lower()\n    \n    @pytest.mark.asyncio\n    async def test_governance_stats_after_airdrop(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test governance statistics are updated after airdrop execution.\"\"\"\n        # Setup and execute an airdrop\n        await nft_service.mint_nft(to_address=\"0xStaker\", metadata_uri=\"ipfs://QmNFT\")\n        await staking_service.stake(token_id=1, user_address=\"0xStaker\")\n        \n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Stats test\",\n            nft_metadata_uri=\"ipfs://QmStats\",\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Vote\n        await governance_service.vote(\n            proposal_id=proposal.id,\n            voter_address=\"0xVoter1\",\n            support=True\n        )\n        \n        # Execute\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        \n        # Check stats\n        stats = await governance_service.get_stats()\n        assert stats.total_proposals == 1\n        assert stats.executed_proposals == 1\n        assert stats.airdrop_proposals_executed == 1\n        assert stats.total_votes_cast == 1\n        assert stats.unique_voters == 1\n\n\nclass TestProposalModel:\n    \"\"\"Tests for Proposal domain model.\"\"\"\n    \n    def test_airdrop_proposal_type_check(self):\n        \"\"\"Test is_airdrop_proposal method.\"\"\"\n        airdrop_proposal = Proposal(\n            id=1,\n            proposer=\"0xProposer\",\n            description=\"Airdrop test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=3),\n            nft_metadata_uri=\"ipfs://QmTest\"\n        )\n        assert airdrop_proposal.is_airdrop_proposal()\n        \n        regular_proposal = Proposal(\n            id=2,\n            proposer=\"0xProposer\",\n            description=\"Regular test\",\n            proposal_type=ProposalType.PARAMETER,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=3)\n        )\n        assert not regular_proposal.is_airdrop_proposal()\n    \n    def test_metadata_uri_validation(self):\n        \"\"\"Test has_valid_metadata_uri method.\"\"\"\n        with_uri = Proposal(\n            id=1,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=1),\n            nft_metadata_uri=\"ipfs://QmValid\"\n        )\n        assert with_uri.has_valid_metadata_uri()\n        \n        without_uri = Proposal(\n            id=2,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=1),\n            nft_metadata_uri=None\n        )\n        assert not without_uri.has_valid_metadata_uri()\n        \n        empty_uri = Proposal(\n            id=3,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=1),\n            nft_metadata_uri=\"\"\n        )\n        assert not empty_uri.has_valid_metadata_uri()\n    \n    def test_proposal_state_calculation(self):\n        \"\"\"Test proposal state calculation.\"\"\"\n        # Pending proposal\n        pending = Proposal(\n            id=1,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() + timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3)\n        )\n        assert pending.state == ProposalState.PENDING\n        \n        # Active proposal\n        active = Proposal(\n            id=2,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3)\n        )\n        assert active.state == ProposalState.ACTIVE\n        \n        # Succeeded proposal\n        succeeded = Proposal(\n            id=3,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(days=4),\n            end_time=datetime.utcnow() - timedelta(hours=1),\n            for_votes=Decimal(\"1000\"),\n            against_votes=Decimal(\"100\")\n        )\n        assert succeeded.state == ProposalState.SUCCEEDED\n        \n        # Defeated proposal\n        defeated = Proposal(\n            id=4,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(days=4),\n            end_time=datetime.utcnow() - timedelta(hours=1),\n            for_votes=Decimal(\"100\"),\n            against_votes=Decimal(\"1000\")\n        )\n        assert defeated.state == ProposalState.DEFEATED\n        \n        # Executed proposal\n        executed = Proposal(\n            id=5,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(days=4),\n            end_time=datetime.utcnow() - timedelta(hours=1),\n            executed=True\n        )\n        assert executed.state == ProposalState.EXECUTED\n        \n        # Cancelled proposal\n        cancelled = Proposal(\n            id=6,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3),\n            cancelled=True\n        )\n        assert cancelled.state == ProposalState.CANCELLED\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])",
          "src/showtime_stash/domain/nft.py": "\"\"\"Domain models for NFT functionality.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Optional, List, Dict, Any\nfrom enum import Enum\n\n\nclass NFTState(Enum):\n    \"\"\"States of an NFT.\"\"\"\n    MINTED = \"minted\"\n    LISTED = \"listed\"\n    STAKED = \"staked\"\n    TRANSFERRED = \"transferred\"\n    BURNED = \"burned\"\n\n\n@dataclass\nclass NFTMetadata:\n    \"\"\"Metadata for an NFT.\"\"\"\n    name: str\n    description: str\n    image: str\n    attributes: List[Dict[str, Any]] = field(default_factory=list)\n    external_url: Optional[str] = None\n    animation_url: Optional[str] = None\n    background_color: Optional[str] = None\n\n\n@dataclass\nclass NFT:\n    \"\"\"Represents an NFT on the platform.\"\"\"\n    token_id: int\n    owner: str\n    metadata_uri: str\n    is_special_edition: bool = False\n    state: NFTState = NFTState.MINTED\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    metadata: Optional[NFTMetadata] = None\n    transaction_hash: Optional[str] = None\n\n    def is_staked(self) -> bool:\n        \"\"\"Check if NFT is currently staked.\"\"\"\n        return self.state == NFTState.STAKED\n\n    def is_transferable(self) -> bool:\n        \"\"\"Check if NFT can be transferred.\"\"\"\n        return self.state not in [NFTState.STAKED, NFTState.BURNED]\n\n\n@dataclass\nclass NFTCollection:\n    \"\"\"Represents a collection of NFTs.\"\"\"\n    name: str\n    symbol: str\n    contract_address: str\n    total_supply: int = 0\n    max_supply: int = 10000\n    base_uri: Optional[str] = None\n    owner: Optional[str] = None\n\n\n@dataclass\nclass MintRequest:\n    \"\"\"Request to mint a new NFT.\"\"\"\n    to_address: str\n    metadata_uri: str\n    is_special_edition: bool = False\n\n\n@dataclass\nclass TransferRequest:\n    \"\"\"Request to transfer an NFT.\"\"\"\n    token_id: int\n    from_address: str\n    to_address: str",
          "src/showtime_stash/application/factories.py": "\"\"\"Factory classes for creating service instances.\"\"\"\n\nfrom typing import Optional\nimport os\n\nfrom .services import GovernanceService, NFTService, StakingService\nfrom ..infrastructure.blockchain_connector import BlockchainConnector\n\n\nclass ServiceFactory:\n    \"\"\"Factory for creating application services.\"\"\"\n    \n    _blockchain_connector: Optional[BlockchainConnector] = None\n    _governance_service: Optional[GovernanceService] = None\n    _nft_service: Optional[NFTService] = None\n    _staking_service: Optional[StakingService] = None\n    \n    @classmethod\n    def get_blockchain_connector(cls) -> BlockchainConnector:\n        \"\"\"Get or create blockchain connector instance.\"\"\"\n        if cls._blockchain_connector is None:\n            rpc_url = os.getenv(\"BLOCKCHAIN_RPC_URL\", \"http://localhost:8545\")\n            cls._blockchain_connector = BlockchainConnector(rpc_url=rpc_url)\n        return cls._blockchain_connector\n    \n    @classmethod\n    def get_governance_service(cls) -> GovernanceService:\n        \"\"\"Get or create governance service instance.\"\"\"\n        if cls._governance_service is None:\n            connector = cls.get_blockchain_connector()\n            cls._governance_service = GovernanceService(connector)\n        return cls._governance_service\n    \n    @classmethod\n    def get_nft_service(cls) -> NFTService:\n        \"\"\"Get or create NFT service instance.\"\"\"\n        if cls._nft_service is None:\n            connector = cls.get_blockchain_connector()\n            cls._nft_service = NFTService(connector)\n        return cls._nft_service\n    \n    @classmethod\n    def get_staking_service(cls) -> StakingService:\n        \"\"\"Get or create staking service instance.\"\"\"\n        if cls._staking_service is None:\n            connector = cls.get_blockchain_connector()\n            cls._staking_service = StakingService(connector)\n        return cls._staking_service\n    \n    @classmethod\n    def reset(cls):\n        \"\"\"Reset all cached instances (useful for testing).\"\"\"\n        cls._blockchain_connector = None\n        cls._governance_service = None\n        cls._nft_service = None\n        cls._staking_service = None\n    \n    @classmethod\n    def set_blockchain_connector(cls, connector: BlockchainConnector):\n        \"\"\"Set a custom blockchain connector (useful for testing).\"\"\"\n        cls._blockchain_connector = connector\n        # Reset services so they use the new connector\n        cls._governance_service = None\n        cls._nft_service = None\n        cls._staking_service = None",
          "src/showtime_stash/infrastructure/blockchain_connector.py": "\"\"\"Blockchain connector for interacting with smart contracts.\"\"\"\n\nfrom typing import Optional, List\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nimport logging\nimport os\n\nfrom ..domain.governance import Proposal, ProposalType, ProposalState, GovernanceStats\nfrom ..domain.nft import NFT\n\nlogger = logging.getLogger(__name__)\n\n\nclass BlockchainConnector:\n    \"\"\"Connector for blockchain interactions.\"\"\"\n    \n    def __init__(self, rpc_url: str = None):\n        self.rpc_url = rpc_url or os.getenv(\"BLOCKCHAIN_RPC_URL\", \"http://localhost:8545\")\n        self.governance_address = os.getenv(\"GOVERNANCE_CONTRACT_ADDRESS\")\n        self.nft_address = os.getenv(\"NFT_CONTRACT_ADDRESS\")\n        self.staking_address = os.getenv(\"STAKING_CONTRACT_ADDRESS\")\n        self._web3 = None\n        self._governance_contract = None\n        self._nft_contract = None\n        self._staking_contract = None\n    \n    def _get_web3(self):\n        \"\"\"Get Web3 instance (lazy loading).\"\"\"\n        if self._web3 is None:\n            try:\n                from web3 import Web3\n                self._web3 = Web3(Web3.HTTPProvider(self.rpc_url))\n            except ImportError:\n                logger.warning(\"Web3 not installed, using mock mode\")\n                self._web3 = None\n        return self._web3\n    \n    # Governance methods\n    async def create_proposal(\n        self,\n        description: str,\n        proposal_type: str,\n        proposer_address: str\n    ) -> str:\n        \"\"\"Create a governance proposal.\"\"\"\n        logger.info(f\"Creating proposal: {description[:50]}...\")\n        # In production, this would interact with the smart contract\n        return \"0x\" + \"0\" * 64\n    \n    async def create_airdrop_proposal(\n        self,\n        description: str,\n        nft_metadata_uri: str,\n        proposer_address: Optional[str] = None\n    ) -> str:\n        \"\"\"Create an airdrop governance proposal.\"\"\"\n        logger.info(f\"Creating airdrop proposal with metadata: {nft_metadata_uri}\")\n        # In production, this would call the proposeAirdrop function\n        return \"0x\" + \"0\" * 64\n    \n    async def get_proposal(self, proposal_id: int) -> Optional[Proposal]:\n        \"\"\"Get a proposal by ID.\"\"\"\n        logger.info(f\"Fetching proposal {proposal_id}\")\n        # In production, this would fetch from the smart contract\n        return None\n    \n    async def get_all_proposals(self) -> List[Proposal]:\n        \"\"\"Get all proposals.\"\"\"\n        logger.info(\"Fetching all proposals\")\n        return []\n    \n    async def get_latest_proposal_id(self) -> int:\n        \"\"\"Get the latest proposal ID.\"\"\"\n        return 0\n    \n    async def vote(\n        self,\n        proposal_id: int,\n        voter_address: str,\n        support: bool\n    ) -> str:\n        \"\"\"Vote on a proposal.\"\"\"\n        logger.info(f\"Voting on proposal {proposal_id}: support={support}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def execute_proposal(\n        self,\n        proposal_id: int,\n        executor_address: str\n    ) -> str:\n        \"\"\"Execute a passed proposal.\"\"\"\n        logger.info(f\"Executing proposal {proposal_id}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def get_airdrop_recipient_count(self, tx_hash: str) -> int:\n        \"\"\"Get the number of recipients from an airdrop transaction.\"\"\"\n        return 0\n    \n    async def get_governance_stats(self) -> GovernanceStats:\n        \"\"\"Get governance statistics.\"\"\"\n        return GovernanceStats()\n    \n    # NFT methods\n    async def get_nft(self, token_id: int) -> Optional[NFT]:\n        \"\"\"Get NFT by token ID.\"\"\"\n        logger.info(f\"Fetching NFT {token_id}\")\n        return None\n    \n    async def get_nfts_by_owner(self, owner_address: str) -> List[NFT]:\n        \"\"\"Get all NFTs owned by an address.\"\"\"\n        logger.info(f\"Fetching NFTs for owner {owner_address}\")\n        return []\n    \n    async def mint_nft(\n        self,\n        to_address: str,\n        metadata_uri: str\n    ) -> str:\n        \"\"\"Mint a new NFT.\"\"\"\n        logger.info(f\"Minting NFT to {to_address}\")\n        return \"0x\" + \"0\" * 64\n    \n    # Staking methods\n    async def stake_nft(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> str:\n        \"\"\"Stake an NFT.\"\"\"\n        logger.info(f\"Staking NFT {token_id} for {user_address}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def unstake_nft(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> str:\n        \"\"\"Unstake an NFT.\"\"\"\n        logger.info(f\"Unstaking NFT {token_id} for {user_address}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def get_all_stakers(self) -> List[str]:\n        \"\"\"Get all current stakers.\"\"\"\n        logger.info(\"Fetching all stakers\")\n        return []\n    \n    async def get_user_stakes(self, user_address: str) -> List[int]:\n        \"\"\"Get staked token IDs for a user.\"\"\"\n        logger.info(f\"Fetching stakes for {user_address}\")\n        return []\n    \n    async def is_staker(self, address: str) -> bool:\n        \"\"\"Check if an address is currently staking.\"\"\"\n        return False"
        },
        "generated_files": [
          "contracts/Governance.sol",
          "contracts/StakingPool.sol",
          "contracts/ShowTimeNFT.sol",
          "src/showtime_stash/domain/governance.py",
          "src/showtime_stash/interfaces/api.py",
          "src/showtime_stash/application/services.py",
          "tests/contract_tests/test_governance_airdrop.py",
          "src/showtime_stash/domain/nft.py",
          "src/showtime_stash/application/factories.py",
          "src/showtime_stash/infrastructure/blockchain_connector.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.771341085271318,
              "dependency_traversal_accuracy": 0.7021916263761296,
              "cross_file_reasoning_depth": 0.46749999999999997,
              "system_thinking_score": 0.46527523626456346,
              "robustness_score": 0.41090255591054314,
              "comprehensiveness_score": 0.6919444677988902,
              "innovation_score": 0.53125,
              "solution_elegance_score": 0.5799437781999403
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09641763565891474,
              "dependency_traversal_weighted": 0.0877739532970162,
              "cross_file_reasoning_weighted": 0.058437499999999996,
              "system_thinking_weighted": 0.05815940453307043,
              "robustness_weighted": 0.05136281948881789,
              "comprehensiveness_weighted": 0.08649305847486127,
              "innovation_weighted": 0.06640625,
              "solution_elegance_weighted": 0.07249297227499253
            },
            "total_software_engineering_score": 0.577543593727673
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.0,
              "execution_time": 0.6297681331634521,
              "errors": [
                "  File \"contracts/Governance.py\", line 1",
                "    // SPDX-License-Identifier: MIT",
                "    ^^",
                "SyntaxError: invalid syntax",
                "  File \"contracts/StakingPool.py\", line 1",
                "    // SPDX-License-Identifier: MIT",
                "    ^^",
                "SyntaxError: invalid syntax",
                "  File \"contracts/ShowTimeNFT.py\", line 1",
                "    // SPDX-License-Identifier: MIT",
                "    ^^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "contracts/Governance.sol",
                "contracts/StakingPool.sol",
                "contracts/ShowTimeNFT.sol",
                "src/showtime_stash/domain/governance.py",
                "src/showtime_stash/interfaces/api.py",
                "src/showtime_stash/application/services.py",
                "tests/contract_tests/test_governance_airdrop.py",
                "src/showtime_stash/domain/nft.py",
                "src/showtime_stash/application/factories.py",
                "src/showtime_stash/infrastructure/blockchain_connector.py"
              ],
              "scoring_breakdown": {
                "no_credit": 0.0
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 10,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 10 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.2872304409672831,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.0,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.2872304409672831,
              "idc_weight": 0.2,
              "total_functional_score": 0.36744608819345664
            }
          },
          "code_quality_details": {
            "files_analyzed": 10,
            "quality_checks": {
              "contracts/Governance.sol": {
                "line_count": 234,
                "non_empty_lines": 196,
                "comment_lines": 2,
                "comment_ratio": 0.01020408163265306,
                "function_count": 0,
                "class_count": 0,
                "import_count": 3,
                "quality_score": 0.7
              },
              "contracts/StakingPool.sol": {
                "line_count": 149,
                "non_empty_lines": 116,
                "comment_lines": 1,
                "comment_ratio": 0.008620689655172414,
                "function_count": 0,
                "class_count": 0,
                "import_count": 4,
                "quality_score": 0.7
              },
              "contracts/ShowTimeNFT.sol": {
                "line_count": 162,
                "non_empty_lines": 127,
                "comment_lines": 2,
                "comment_ratio": 0.015748031496062992,
                "function_count": 0,
                "class_count": 0,
                "import_count": 5,
                "quality_score": 0.7
              },
              "src/showtime_stash/domain/governance.py": {
                "line_count": 160,
                "non_empty_lines": 132,
                "comment_lines": 1,
                "comment_ratio": 0.007575757575757576,
                "function_count": 9,
                "class_count": 9,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "src/showtime_stash/interfaces/api.py": {
                "line_count": 491,
                "non_empty_lines": 423,
                "comment_lines": 8,
                "comment_ratio": 0.018912529550827423,
                "function_count": 17,
                "class_count": 15,
                "import_count": 25,
                "quality_score": 0.7999999999999999
              },
              "src/showtime_stash/application/services.py": {
                "line_count": 347,
                "non_empty_lines": 301,
                "comment_lines": 9,
                "comment_ratio": 0.029900332225913623,
                "function_count": 18,
                "class_count": 7,
                "import_count": 17,
                "quality_score": 0.7999999999999999
              },
              "tests/contract_tests/test_governance_airdrop.py": {
                "line_count": 665,
                "non_empty_lines": 568,
                "comment_lines": 40,
                "comment_ratio": 0.07042253521126761,
                "function_count": 34,
                "class_count": 7,
                "import_count": 15,
                "quality_score": 0.6
              },
              "src/showtime_stash/domain/nft.py": {
                "line_count": 76,
                "non_empty_lines": 61,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 2,
                "class_count": 6,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "src/showtime_stash/application/factories.py": {
                "line_count": 65,
                "non_empty_lines": 54,
                "comment_lines": 1,
                "comment_ratio": 0.018518518518518517,
                "function_count": 6,
                "class_count": 1,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "src/showtime_stash/infrastructure/blockchain_connector.py": {
                "line_count": 155,
                "non_empty_lines": 131,
                "comment_lines": 6,
                "comment_ratio": 0.04580152671755725,
                "function_count": 19,
                "class_count": 1,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7649999999999998,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8058333333333334,
              "multi_session_memory_retention": 0.7907407407407407
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4029166666666667,
              "multi_session_memory_retention_weighted": 0.39537037037037037
            },
            "total_longcontext_utilization_score": 0.7982870370370371
          }
        },
        "timestamp": "2026-01-14T20:47:24.499914"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_mobile_game_medium_096_feature_implementation_expert_01",
        "scenario_title": "Implement Time-Sensitive Special Orders Feature",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5341221203221902,
        "functional_correctness_score": 0.3940485714285714,
        "code_quality_score": 0.7883333333333333,
        "longcontext_utilization_score": 0.9263667076167073,
        "total_score": 2.9108337849289248,
        "generation_time": 225.40432119369507,
        "code_files_generated": 12,
        "total_lines_generated": 2159,
        "parsing_success": true,
        "solution_code": {
          "tycoon_tactics/domain/special_order.py": "\"\"\"Special Order domain model for time-sensitive delivery contracts.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Dict\nfrom uuid import UUID, uuid4\n\n\nclass SpecialOrderStatus:\n    \"\"\"Status constants for special orders.\"\"\"\n    PENDING = \"PENDING\"\n    ACCEPTED = \"ACCEPTED\"\n    COMPLETED = \"COMPLETED\"\n    EXPIRED = \"EXPIRED\"\n\n\n@dataclass\nclass SpecialOrder:\n    \"\"\"Represents a time-sensitive special delivery order.\n    \n    Special orders are high-value contracts that appear periodically.\n    Players must fulfill them within a time limit to earn rewards.\n    \"\"\"\n    id: UUID\n    name: str\n    product_requirements: Dict[str, int]\n    destination_address: str\n    reward_cash: int\n    reward_reputation: int\n    time_to_live_seconds: int\n    created_at: datetime\n    status: str = field(default=SpecialOrderStatus.PENDING)\n    \n    @classmethod\n    def create(\n        cls,\n        name: str,\n        product_requirements: Dict[str, int],\n        destination_address: str,\n        reward_cash: int,\n        reward_reputation: int,\n        time_to_live_seconds: int = 3600,\n    ) -> \"SpecialOrder\":\n        \"\"\"Factory method to create a new special order.\"\"\"\n        return cls(\n            id=uuid4(),\n            name=name,\n            product_requirements=product_requirements,\n            destination_address=destination_address,\n            reward_cash=reward_cash,\n            reward_reputation=reward_reputation,\n            time_to_live_seconds=time_to_live_seconds,\n            created_at=datetime.utcnow(),\n            status=SpecialOrderStatus.PENDING,\n        )\n    \n    def is_expired(self) -> bool:\n        \"\"\"Check if the order has expired based on TTL.\"\"\"\n        elapsed = (datetime.utcnow() - self.created_at).total_seconds()\n        return elapsed > self.time_to_live_seconds\n    \n    def remaining_time_seconds(self) -> int:\n        \"\"\"Get remaining time in seconds before expiration.\"\"\"\n        elapsed = (datetime.utcnow() - self.created_at).total_seconds()\n        remaining = self.time_to_live_seconds - elapsed\n        return max(0, int(remaining))\n    \n    def accept(self) -> None:\n        \"\"\"Mark the order as accepted.\"\"\"\n        if self.status != SpecialOrderStatus.PENDING:\n            raise ValueError(f\"Cannot accept order with status: {self.status}\")\n        if self.is_expired():\n            self.status = SpecialOrderStatus.EXPIRED\n            raise ValueError(\"Cannot accept expired order\")\n        self.status = SpecialOrderStatus.ACCEPTED\n    \n    def complete(self) -> None:\n        \"\"\"Mark the order as completed.\"\"\"\n        if self.status != SpecialOrderStatus.ACCEPTED:\n            raise ValueError(f\"Cannot complete order with status: {self.status}\")\n        self.status = SpecialOrderStatus.COMPLETED\n    \n    def expire(self) -> None:\n        \"\"\"Mark the order as expired.\"\"\"\n        if self.status == SpecialOrderStatus.PENDING:\n            self.status = SpecialOrderStatus.EXPIRED\n",
          "tycoon_tactics/adapters/persistence/orm_models.py": "\"\"\"SQLAlchemy ORM models for persistence.\"\"\"\nfrom datetime import datetime\nfrom typing import Optional\nfrom uuid import UUID\n\nfrom sqlalchemy import (\n    Column,\n    DateTime,\n    Float,\n    ForeignKey,\n    Integer,\n    String,\n    Table,\n    Text,\n    JSON,\n    create_engine,\n)\nfrom sqlalchemy.orm import declarative_base, relationship\n\nBase = declarative_base()\n\n\nclass FranchiseOrm(Base):\n    \"\"\"ORM model for Franchise domain entity.\"\"\"\n    __tablename__ = \"franchises\"\n\n    id = Column(String(36), primary_key=True)\n    name = Column(String(255), nullable=False)\n    location = Column(String(255), nullable=False)\n    franchise_type = Column(String(100), nullable=False)\n    level = Column(Integer, default=1)\n    revenue = Column(Float, default=0.0)\n    expenses = Column(Float, default=0.0)\n    reputation = Column(Integer, default=50)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass SupplyChainOrm(Base):\n    \"\"\"ORM model for SupplyChain domain entity.\"\"\"\n    __tablename__ = \"supply_chains\"\n\n    id = Column(String(36), primary_key=True)\n    franchise_id = Column(String(36), ForeignKey(\"franchises.id\"), nullable=False)\n    inventory = Column(Text, default=\"{}\")  # JSON string of inventory\n    suppliers = Column(Text, default=\"[]\")  # JSON string of suppliers\n    logistics_efficiency = Column(Float, default=1.0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass MarketOrm(Base):\n    \"\"\"ORM model for Market domain entity.\"\"\"\n    __tablename__ = \"markets\"\n\n    id = Column(String(36), primary_key=True)\n    name = Column(String(255), nullable=False)\n    region = Column(String(255), nullable=False)\n    demand_level = Column(Float, default=1.0)\n    competition_level = Column(Float, default=1.0)\n    price_multiplier = Column(Float, default=1.0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass PlayerStatsOrm(Base):\n    \"\"\"ORM model for player statistics.\"\"\"\n    __tablename__ = \"player_stats\"\n\n    id = Column(String(36), primary_key=True)\n    player_id = Column(String(36), nullable=False, unique=True)\n    total_cash = Column(Integer, default=10000)\n    total_reputation = Column(Integer, default=0)\n    franchises_owned = Column(Integer, default=0)\n    orders_completed = Column(Integer, default=0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass SpecialOrderOrm(Base):\n    \"\"\"ORM model for SpecialOrder domain entity.\"\"\"\n    __tablename__ = \"special_orders\"\n\n    id = Column(String(36), primary_key=True)\n    name = Column(String(255), nullable=False)\n    product_requirements = Column(JSON, nullable=False)  # Dict[str, int]\n    destination_address = Column(String(500), nullable=False)\n    reward_cash = Column(Integer, nullable=False)\n    reward_reputation = Column(Integer, nullable=False)\n    time_to_live_seconds = Column(Integer, nullable=False)\n    created_at = Column(DateTime, nullable=False)\n    status = Column(String(50), nullable=False, default=\"PENDING\")\n\n\ndef create_tables(engine):\n    \"\"\"Create all tables in the database.\"\"\"\n    Base.metadata.create_all(engine)\n\n\ndef drop_tables(engine):\n    \"\"\"Drop all tables from the database.\"\"\"\n    Base.metadata.drop_all(engine)\n",
          "tycoon_tactics/domain/ports.py": "\"\"\"Port interfaces (abstract base classes) for the domain layer.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom uuid import UUID\n\nfrom tycoon_tactics.domain.franchise import Franchise\nfrom tycoon_tactics.domain.supply_chain import SupplyChain\nfrom tycoon_tactics.domain.market import Market\nfrom tycoon_tactics.domain.special_order import SpecialOrder\n\n\nclass AbstractRepository(ABC):\n    \"\"\"Abstract repository interface for domain persistence.\"\"\"\n\n    # Franchise methods\n    @abstractmethod\n    def add_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Add a new franchise to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_franchise(self, franchise_id: UUID) -> Optional[Franchise]:\n        \"\"\"Get a franchise by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_franchises(self) -> List[Franchise]:\n        \"\"\"List all franchises.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Update an existing franchise.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete_franchise(self, franchise_id: UUID) -> None:\n        \"\"\"Delete a franchise by its ID.\"\"\"\n        raise NotImplementedError\n\n    # SupplyChain methods\n    @abstractmethod\n    def add_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Add a new supply chain to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_supply_chain(self, supply_chain_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_supply_chain_by_franchise(self, franchise_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by franchise ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Update an existing supply chain.\"\"\"\n        raise NotImplementedError\n\n    # Market methods\n    @abstractmethod\n    def add_market(self, market: Market) -> None:\n        \"\"\"Add a new market to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_market(self, market_id: UUID) -> Optional[Market]:\n        \"\"\"Get a market by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_markets(self) -> List[Market]:\n        \"\"\"List all markets.\"\"\"\n        raise NotImplementedError\n\n    # Special Order methods\n    @abstractmethod\n    def add_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Add a new special order to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_special_order(self, order_id: UUID) -> Optional[SpecialOrder]:\n        \"\"\"Get a special order by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_active_special_orders(self) -> List[SpecialOrder]:\n        \"\"\"List all active (pending) special orders.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Update an existing special order.\"\"\"\n        raise NotImplementedError\n\n    # Player stats methods\n    @abstractmethod\n    def get_player_cash(self, player_id: UUID) -> int:\n        \"\"\"Get player's current cash.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_player_cash(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's cash by adding amount.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_player_reputation(self, player_id: UUID) -> int:\n        \"\"\"Get player's current reputation.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_player_reputation(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's reputation by adding amount.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractLocationService(ABC):\n    \"\"\"Abstract interface for location services.\"\"\"\n\n    @abstractmethod\n    def get_current_location(self) -> tuple[float, float]:\n        \"\"\"Get current GPS coordinates (latitude, longitude).\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def calculate_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n        \"\"\"Calculate distance between two coordinates in kilometers.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractPaymentService(ABC):\n    \"\"\"Abstract interface for in-app purchase services.\"\"\"\n\n    @abstractmethod\n    def purchase_item(self, item_id: str, price: float) -> bool:\n        \"\"\"Process an in-app purchase.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def restore_purchases(self) -> List[str]:\n        \"\"\"Restore previous purchases.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractAnalyticsService(ABC):\n    \"\"\"Abstract interface for analytics services.\"\"\"\n\n    @abstractmethod\n    def track_event(self, event_name: str, properties: dict) -> None:\n        \"\"\"Track an analytics event.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set_user_property(self, property_name: str, value: str) -> None:\n        \"\"\"Set a user property for analytics.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractCrashReportingService(ABC):\n    \"\"\"Abstract interface for crash reporting services.\"\"\"\n\n    @abstractmethod\n    def capture_exception(self, exception: Exception) -> None:\n        \"\"\"Capture and report an exception.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def add_breadcrumb(self, message: str, category: str) -> None:\n        \"\"\"Add a breadcrumb for debugging.\"\"\"\n        raise NotImplementedError\n",
          "tycoon_tactics/adapters/persistence/sqlite_repository.py": "\"\"\"SQLite implementation of the repository pattern.\"\"\"\nimport json\nfrom datetime import datetime\nfrom typing import List, Optional\nfrom uuid import UUID\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, Session\n\nfrom tycoon_tactics.domain.franchise import Franchise\nfrom tycoon_tactics.domain.supply_chain import SupplyChain\nfrom tycoon_tactics.domain.market import Market\nfrom tycoon_tactics.domain.special_order import SpecialOrder, SpecialOrderStatus\nfrom tycoon_tactics.domain.ports import AbstractRepository\nfrom tycoon_tactics.adapters.persistence.orm_models import (\n    Base,\n    FranchiseOrm,\n    SupplyChainOrm,\n    MarketOrm,\n    PlayerStatsOrm,\n    SpecialOrderOrm,\n    create_tables,\n)\n\n\nclass SQLiteRepository(AbstractRepository):\n    \"\"\"SQLite implementation of the abstract repository.\"\"\"\n\n    def __init__(self, db_path: str = \"tycoon_tactics.db\"):\n        \"\"\"Initialize the SQLite repository.\"\"\"\n        self.engine = create_engine(f\"sqlite:///{db_path}\", echo=False)\n        create_tables(self.engine)\n        self.SessionLocal = sessionmaker(bind=self.engine)\n\n    def _get_session(self) -> Session:\n        \"\"\"Get a new database session.\"\"\"\n        return self.SessionLocal()\n\n    # Franchise methods\n    def add_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Add a new franchise to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = FranchiseOrm(\n                id=str(franchise.id),\n                name=franchise.name,\n                location=franchise.location,\n                franchise_type=franchise.franchise_type,\n                level=franchise.level,\n                revenue=franchise.revenue,\n                expenses=franchise.expenses,\n                reputation=franchise.reputation,\n                created_at=franchise.created_at,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_franchise(self, franchise_id: UUID) -> Optional[Franchise]:\n        \"\"\"Get a franchise by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(FranchiseOrm).filter(\n                FranchiseOrm.id == str(franchise_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_franchise(orm_obj)\n            return None\n\n    def list_franchises(self) -> List[Franchise]:\n        \"\"\"List all franchises.\"\"\"\n        with self._get_session() as session:\n            orm_objects = session.query(FranchiseOrm).all()\n            return [self._orm_to_franchise(obj) for obj in orm_objects]\n\n    def update_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Update an existing franchise.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(FranchiseOrm).filter(\n                FranchiseOrm.id == str(franchise.id)\n            ).first()\n            if orm_obj:\n                orm_obj.name = franchise.name\n                orm_obj.location = franchise.location\n                orm_obj.franchise_type = franchise.franchise_type\n                orm_obj.level = franchise.level\n                orm_obj.revenue = franchise.revenue\n                orm_obj.expenses = franchise.expenses\n                orm_obj.reputation = franchise.reputation\n                orm_obj.updated_at = datetime.utcnow()\n                session.commit()\n\n    def delete_franchise(self, franchise_id: UUID) -> None:\n        \"\"\"Delete a franchise by its ID.\"\"\"\n        with self._get_session() as session:\n            session.query(FranchiseOrm).filter(\n                FranchiseOrm.id == str(franchise_id)\n            ).delete()\n            session.commit()\n\n    def _orm_to_franchise(self, orm_obj: FranchiseOrm) -> Franchise:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return Franchise(\n            id=UUID(orm_obj.id),\n            name=orm_obj.name,\n            location=orm_obj.location,\n            franchise_type=orm_obj.franchise_type,\n            level=orm_obj.level,\n            revenue=orm_obj.revenue,\n            expenses=orm_obj.expenses,\n            reputation=orm_obj.reputation,\n            created_at=orm_obj.created_at,\n        )\n\n    # SupplyChain methods\n    def add_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Add a new supply chain to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = SupplyChainOrm(\n                id=str(supply_chain.id),\n                franchise_id=str(supply_chain.franchise_id),\n                inventory=json.dumps(supply_chain.inventory),\n                suppliers=json.dumps(supply_chain.suppliers),\n                logistics_efficiency=supply_chain.logistics_efficiency,\n                created_at=supply_chain.created_at,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_supply_chain(self, supply_chain_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SupplyChainOrm).filter(\n                SupplyChainOrm.id == str(supply_chain_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_supply_chain(orm_obj)\n            return None\n\n    def get_supply_chain_by_franchise(self, franchise_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by franchise ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SupplyChainOrm).filter(\n                SupplyChainOrm.franchise_id == str(franchise_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_supply_chain(orm_obj)\n            return None\n\n    def update_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Update an existing supply chain.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SupplyChainOrm).filter(\n                SupplyChainOrm.id == str(supply_chain.id)\n            ).first()\n            if orm_obj:\n                orm_obj.inventory = json.dumps(supply_chain.inventory)\n                orm_obj.suppliers = json.dumps(supply_chain.suppliers)\n                orm_obj.logistics_efficiency = supply_chain.logistics_efficiency\n                orm_obj.updated_at = datetime.utcnow()\n                session.commit()\n\n    def _orm_to_supply_chain(self, orm_obj: SupplyChainOrm) -> SupplyChain:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return SupplyChain(\n            id=UUID(orm_obj.id),\n            franchise_id=UUID(orm_obj.franchise_id),\n            inventory=json.loads(orm_obj.inventory),\n            suppliers=json.loads(orm_obj.suppliers),\n            logistics_efficiency=orm_obj.logistics_efficiency,\n            created_at=orm_obj.created_at,\n        )\n\n    # Market methods\n    def add_market(self, market: Market) -> None:\n        \"\"\"Add a new market to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = MarketOrm(\n                id=str(market.id),\n                name=market.name,\n                region=market.region,\n                demand_level=market.demand_level,\n                competition_level=market.competition_level,\n                price_multiplier=market.price_multiplier,\n                created_at=market.created_at,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_market(self, market_id: UUID) -> Optional[Market]:\n        \"\"\"Get a market by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(MarketOrm).filter(\n                MarketOrm.id == str(market_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_market(orm_obj)\n            return None\n\n    def list_markets(self) -> List[Market]:\n        \"\"\"List all markets.\"\"\"\n        with self._get_session() as session:\n            orm_objects = session.query(MarketOrm).all()\n            return [self._orm_to_market(obj) for obj in orm_objects]\n\n    def _orm_to_market(self, orm_obj: MarketOrm) -> Market:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return Market(\n            id=UUID(orm_obj.id),\n            name=orm_obj.name,\n            region=orm_obj.region,\n            demand_level=orm_obj.demand_level,\n            competition_level=orm_obj.competition_level,\n            price_multiplier=orm_obj.price_multiplier,\n            created_at=orm_obj.created_at,\n        )\n\n    # Special Order methods\n    def add_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Add a new special order to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = SpecialOrderOrm(\n                id=str(order.id),\n                name=order.name,\n                product_requirements=order.product_requirements,\n                destination_address=order.destination_address,\n                reward_cash=order.reward_cash,\n                reward_reputation=order.reward_reputation,\n                time_to_live_seconds=order.time_to_live_seconds,\n                created_at=order.created_at,\n                status=order.status,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_special_order(self, order_id: UUID) -> Optional[SpecialOrder]:\n        \"\"\"Get a special order by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SpecialOrderOrm).filter(\n                SpecialOrderOrm.id == str(order_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_special_order(orm_obj)\n            return None\n\n    def list_active_special_orders(self) -> List[SpecialOrder]:\n        \"\"\"List all active (pending) special orders.\"\"\"\n        with self._get_session() as session:\n            orm_objects = session.query(SpecialOrderOrm).filter(\n                SpecialOrderOrm.status == SpecialOrderStatus.PENDING\n            ).all()\n            orders = []\n            for orm_obj in orm_objects:\n                order = self._orm_to_special_order(orm_obj)\n                # Check if expired and update status\n                if order.is_expired():\n                    order.expire()\n                    self.update_special_order(order)\n                else:\n                    orders.append(order)\n            return orders\n\n    def update_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Update an existing special order.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SpecialOrderOrm).filter(\n                SpecialOrderOrm.id == str(order.id)\n            ).first()\n            if orm_obj:\n                orm_obj.name = order.name\n                orm_obj.product_requirements = order.product_requirements\n                orm_obj.destination_address = order.destination_address\n                orm_obj.reward_cash = order.reward_cash\n                orm_obj.reward_reputation = order.reward_reputation\n                orm_obj.time_to_live_seconds = order.time_to_live_seconds\n                orm_obj.status = order.status\n                session.commit()\n\n    def _orm_to_special_order(self, orm_obj: SpecialOrderOrm) -> SpecialOrder:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return SpecialOrder(\n            id=UUID(orm_obj.id),\n            name=orm_obj.name,\n            product_requirements=orm_obj.product_requirements,\n            destination_address=orm_obj.destination_address,\n            reward_cash=orm_obj.reward_cash,\n            reward_reputation=orm_obj.reward_reputation,\n            time_to_live_seconds=orm_obj.time_to_live_seconds,\n            created_at=orm_obj.created_at,\n            status=orm_obj.status,\n        )\n\n    # Player stats methods\n    def _ensure_player_stats(self, session: Session, player_id: UUID) -> PlayerStatsOrm:\n        \"\"\"Ensure player stats exist, create if not.\"\"\"\n        stats = session.query(PlayerStatsOrm).filter(\n            PlayerStatsOrm.player_id == str(player_id)\n        ).first()\n        if not stats:\n            stats = PlayerStatsOrm(\n                id=str(player_id),\n                player_id=str(player_id),\n                total_cash=10000,\n                total_reputation=0,\n            )\n            session.add(stats)\n            session.commit()\n        return stats\n\n    def get_player_cash(self, player_id: UUID) -> int:\n        \"\"\"Get player's current cash.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            return stats.total_cash\n\n    def update_player_cash(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's cash by adding amount.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            stats.total_cash += amount\n            stats.updated_at = datetime.utcnow()\n            session.commit()\n\n    def get_player_reputation(self, player_id: UUID) -> int:\n        \"\"\"Get player's current reputation.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            return stats.total_reputation\n\n    def update_player_reputation(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's reputation by adding amount.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            stats.total_reputation += amount\n            stats.updated_at = datetime.utcnow()\n            session.commit()\n",
          "tycoon_tactics/application/use_cases.py": "\"\"\"Application use cases for the game.\"\"\"\nimport random\nfrom dataclasses import dataclass\nfrom typing import List, Optional\nfrom uuid import UUID\n\nfrom tycoon_tactics.domain.franchise import Franchise\nfrom tycoon_tactics.domain.supply_chain import SupplyChain\nfrom tycoon_tactics.domain.market import Market\nfrom tycoon_tactics.domain.special_order import SpecialOrder, SpecialOrderStatus\nfrom tycoon_tactics.domain.ports import AbstractRepository\nfrom tycoon_tactics.application.event_bus import EventBus\nfrom tycoon_tactics.application.game_events import (\n    FranchiseCreatedEvent,\n    SupplyChainUpdatedEvent,\n)\n\n\nclass InsufficientInventoryError(Exception):\n    \"\"\"Raised when player doesn't have enough inventory to fulfill an order.\"\"\"\n    def __init__(self, missing_items: dict):\n        self.missing_items = missing_items\n        super().__init__(f\"Insufficient inventory: {missing_items}\")\n\n\nclass OrderNotFoundError(Exception):\n    \"\"\"Raised when a special order is not found.\"\"\"\n    pass\n\n\nclass InvalidOrderStatusError(Exception):\n    \"\"\"Raised when trying to perform an action on an order with invalid status.\"\"\"\n    pass\n\n\n@dataclass\nclass CreateFranchiseUseCase:\n    \"\"\"Use case for creating a new franchise.\"\"\"\n    repository: AbstractRepository\n    event_bus: EventBus\n\n    def execute(\n        self,\n        name: str,\n        location: str,\n        franchise_type: str,\n    ) -> Franchise:\n        \"\"\"Create a new franchise and persist it.\"\"\"\n        franchise = Franchise.create(\n            name=name,\n            location=location,\n            franchise_type=franchise_type,\n        )\n        self.repository.add_franchise(franchise)\n        \n        # Create associated supply chain\n        supply_chain = SupplyChain.create(franchise_id=franchise.id)\n        self.repository.add_supply_chain(supply_chain)\n        \n        # Publish event\n        self.event_bus.publish(FranchiseCreatedEvent(\n            franchise_id=franchise.id,\n            name=franchise.name,\n            location=franchise.location,\n        ))\n        \n        return franchise\n\n\n@dataclass\nclass GetFranchiseUseCase:\n    \"\"\"Use case for retrieving a franchise.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, franchise_id: UUID) -> Optional[Franchise]:\n        \"\"\"Get a franchise by ID.\"\"\"\n        return self.repository.get_franchise(franchise_id)\n\n\n@dataclass\nclass ListFranchisesUseCase:\n    \"\"\"Use case for listing all franchises.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self) -> List[Franchise]:\n        \"\"\"List all franchises.\"\"\"\n        return self.repository.list_franchises()\n\n\n@dataclass\nclass UpdateInventoryUseCase:\n    \"\"\"Use case for updating supply chain inventory.\"\"\"\n    repository: AbstractRepository\n    event_bus: EventBus\n\n    def execute(\n        self,\n        franchise_id: UUID,\n        product_name: str,\n        quantity: int,\n    ) -> SupplyChain:\n        \"\"\"Update inventory for a franchise's supply chain.\"\"\"\n        supply_chain = self.repository.get_supply_chain_by_franchise(franchise_id)\n        if not supply_chain:\n            raise ValueError(f\"Supply chain not found for franchise: {franchise_id}\")\n        \n        supply_chain.add_inventory(product_name, quantity)\n        self.repository.update_supply_chain(supply_chain)\n        \n        self.event_bus.publish(SupplyChainUpdatedEvent(\n            supply_chain_id=supply_chain.id,\n            franchise_id=franchise_id,\n            inventory=supply_chain.inventory,\n        ))\n        \n        return supply_chain\n\n\n@dataclass\nclass GetSupplyChainUseCase:\n    \"\"\"Use case for retrieving a supply chain.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, franchise_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by franchise ID.\"\"\"\n        return self.repository.get_supply_chain_by_franchise(franchise_id)\n\n\n@dataclass\nclass ListMarketsUseCase:\n    \"\"\"Use case for listing all markets.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self) -> List[Market]:\n        \"\"\"List all available markets.\"\"\"\n        return self.repository.list_markets()\n\n\n# Special Order Use Cases\n\n@dataclass\nclass GenerateRandomSpecialOrderUseCase:\n    \"\"\"Use case for generating random special orders periodically.\"\"\"\n    repository: AbstractRepository\n\n    # Product pools for random generation\n    PRODUCT_NAMES = [\n        \"Electronics\", \"Clothing\", \"Food\", \"Beverages\", \"Furniture\",\n        \"Toys\", \"Books\", \"Sports Equipment\", \"Home Appliances\", \"Cosmetics\",\n        \"Pharmaceuticals\", \"Office Supplies\", \"Auto Parts\", \"Garden Supplies\", \"Pet Supplies\"\n    ]\n\n    DESTINATIONS = [\n        \"Downtown Distribution Center\", \"Northside Mall\", \"Westfield Shopping Plaza\",\n        \"Harbor Warehouse\", \"Airport Cargo Terminal\", \"Central Business District\",\n        \"Suburban Retail Park\", \"Industrial Zone Hub\", \"University Campus Store\",\n        \"Medical Center Supply Depot\", \"Tech Park Fulfillment Center\"\n    ]\n\n    ORDER_NAMES = [\n        \"Urgent Restock Order\", \"Premium Client Request\", \"Emergency Supply Run\",\n        \"VIP Customer Order\", \"Seasonal Rush Delivery\", \"Corporate Bulk Order\",\n        \"Flash Sale Fulfillment\", \"Holiday Special Order\", \"Clearance Redistribution\",\n        \"New Store Opening Supply\", \"Event Catering Supply\", \"Grand Opening Stock\"\n    ]\n\n    def execute(self) -> SpecialOrder:\n        \"\"\"Generate a new random special order and save it.\"\"\"\n        # Generate random requirements (1-3 products)\n        num_products = random.randint(1, 3)\n        products = random.sample(self.PRODUCT_NAMES, num_products)\n        product_requirements = {\n            product: random.randint(5, 50) for product in products\n        }\n\n        # Calculate rewards based on requirements\n        total_items = sum(product_requirements.values())\n        base_cash = total_items * random.randint(10, 25)\n        base_reputation = total_items // 5 + random.randint(5, 20)\n\n        # Random TTL between 30 minutes and 2 hours\n        ttl_seconds = random.randint(1800, 7200)\n\n        order = SpecialOrder.create(\n            name=random.choice(self.ORDER_NAMES),\n            product_requirements=product_requirements,\n            destination_address=random.choice(self.DESTINATIONS),\n            reward_cash=base_cash,\n            reward_reputation=base_reputation,\n            time_to_live_seconds=ttl_seconds,\n        )\n\n        self.repository.add_special_order(order)\n        return order\n\n\n@dataclass\nclass ListActiveSpecialOrdersUseCase:\n    \"\"\"Use case for listing all active special orders.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self) -> List[SpecialOrder]:\n        \"\"\"List all active (pending) special orders.\"\"\"\n        return self.repository.list_active_special_orders()\n\n\n@dataclass\nclass GetSpecialOrderUseCase:\n    \"\"\"Use case for retrieving a specific special order.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, order_id: UUID) -> Optional[SpecialOrder]:\n        \"\"\"Get a special order by ID.\"\"\"\n        return self.repository.get_special_order(order_id)\n\n\n@dataclass\nclass AcceptSpecialOrderUseCase:\n    \"\"\"Use case for accepting and fulfilling a special order.\"\"\"\n    repository: AbstractRepository\n    event_bus: EventBus\n    player_id: UUID\n\n    def execute(self, order_id: UUID, franchise_id: UUID) -> SpecialOrder:\n        \"\"\"Accept a special order if player has sufficient inventory.\n        \n        Args:\n            order_id: The ID of the special order to accept\n            franchise_id: The ID of the franchise whose inventory to use\n            \n        Returns:\n            The updated special order\n            \n        Raises:\n            OrderNotFoundError: If the order doesn't exist\n            InvalidOrderStatusError: If the order is not in PENDING status\n            InsufficientInventoryError: If player lacks required inventory\n        \"\"\"\n        # Fetch the order\n        order = self.repository.get_special_order(order_id)\n        if not order:\n            raise OrderNotFoundError(f\"Special order not found: {order_id}\")\n\n        # Check if order is expired\n        if order.is_expired():\n            order.expire()\n            self.repository.update_special_order(order)\n            raise InvalidOrderStatusError(\"Order has expired\")\n\n        # Verify order status is PENDING\n        if order.status != SpecialOrderStatus.PENDING:\n            raise InvalidOrderStatusError(\n                f\"Cannot accept order with status: {order.status}\"\n            )\n\n        # Get the player's supply chain inventory\n        supply_chain = self.repository.get_supply_chain_by_franchise(franchise_id)\n        if not supply_chain:\n            raise ValueError(f\"Supply chain not found for franchise: {franchise_id}\")\n\n        # Check if player has required inventory\n        missing_items = {}\n        for product, required_qty in order.product_requirements.items():\n            available_qty = supply_chain.inventory.get(product, 0)\n            if available_qty < required_qty:\n                missing_items[product] = required_qty - available_qty\n\n        if missing_items:\n            raise InsufficientInventoryError(missing_items)\n\n        # Deduct products from inventory\n        for product, required_qty in order.product_requirements.items():\n            supply_chain.remove_inventory(product, required_qty)\n        \n        self.repository.update_supply_chain(supply_chain)\n\n        # Update order status to ACCEPTED (and immediately COMPLETED since we're fulfilling it)\n        order.accept()\n        order.complete()\n        self.repository.update_special_order(order)\n\n        # Add rewards to player\n        self.repository.update_player_cash(self.player_id, order.reward_cash)\n        self.repository.update_player_reputation(self.player_id, order.reward_reputation)\n\n        return order\n\n\n@dataclass\nclass GetPlayerStatsUseCase:\n    \"\"\"Use case for retrieving player statistics.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, player_id: UUID) -> dict:\n        \"\"\"Get player's current stats.\"\"\"\n        return {\n            \"cash\": self.repository.get_player_cash(player_id),\n            \"reputation\": self.repository.get_player_reputation(player_id),\n        }\n",
          "tycoon_tactics/adapters/ui/screens.py": "\"\"\"UI Screens for the game using Kivy.\"\"\"\nfrom typing import Callable, List, Optional\nfrom uuid import UUID\n\nfrom kivy.uix.screenmanager import Screen\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.gridlayout import GridLayout\nfrom kivy.uix.scrollview import ScrollView\nfrom kivy.uix.label import Label\nfrom kivy.uix.button import Button\nfrom kivy.uix.popup import Popup\nfrom kivy.uix.textinput import TextInput\nfrom kivy.properties import ObjectProperty, StringProperty, NumericProperty\nfrom kivy.clock import Clock\n\n\nclass BaseScreen(Screen):\n    \"\"\"Base screen class with common functionality.\"\"\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.container = None\n\n    def show_error(self, message: str):\n        \"\"\"Display an error popup.\"\"\"\n        popup = Popup(\n            title=\"Error\",\n            content=Label(text=message),\n            size_hint=(0.8, 0.3),\n        )\n        popup.open()\n\n    def show_success(self, message: str):\n        \"\"\"Display a success popup.\"\"\"\n        popup = Popup(\n            title=\"Success\",\n            content=Label(text=message),\n            size_hint=(0.8, 0.3),\n        )\n        popup.open()\n\n\nclass MainMenuScreen(BaseScreen):\n    \"\"\"Main menu screen.\"\"\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(name=\"main_menu\", **kwargs)\n        self._build_ui()\n\n    def _build_ui(self):\n        \"\"\"Build the main menu UI.\"\"\"\n        layout = BoxLayout(orientation=\"vertical\", padding=20, spacing=10)\n        \n        title = Label(\n            text=\"Tycoon Tactics:\nFranchise Frontier\",\n            font_size=\"32sp\",\n            size_hint_y=0.3,\n            halign=\"center\",\n        )\n        layout.add_widget(title)\n\n        btn_new_game = Button(text=\"New Game\", size_hint_y=0.15)\n        btn_new_game.bind(on_press=lambda x: self._start_new_game())\n        layout.add_widget(btn_new_game)\n\n        btn_continue = Button(text=\"Continue\", size_hint_y=0.15)\n        btn_continue.bind(on_press=lambda x: self._continue_game())\n        layout.add_widget(btn_continue)\n\n        btn_settings = Button(text=\"Settings\", size_hint_y=0.15)\n        btn_settings.bind(on_press=lambda x: self._open_settings())\n        layout.add_widget(btn_settings)\n\n        btn_quit = Button(text=\"Quit\", size_hint_y=0.15)\n        btn_quit.bind(on_press=lambda x: self._quit_game())\n        layout.add_widget(btn_quit)\n\n        self.add_widget(layout)\n\n    def _start_new_game(self):\n        \"\"\"Start a new game.\"\"\"\n        self.manager.current = \"game\"\n\n    def _continue_game(self):\n        \"\"\"Continue existing game.\"\"\"\n        self.manager.current = \"game\"\n\n    def _open_settings(self):\n        \"\"\"Open settings screen.\"\"\"\n        self.manager.current = \"settings\"\n\n    def _quit_game(self):\n        \"\"\"Quit the game.\"\"\"\n        from kivy.app import App\n        App.get_running_app().stop()\n\n\nclass GameScreen(BaseScreen):\n    \"\"\"Main game screen.\"\"\"\n    \n    pending_orders_count = NumericProperty(0)\n    \n    def __init__(\n        self,\n        list_franchises_callback: Callable = None,\n        create_franchise_callback: Callable = None,\n        list_special_orders_callback: Callable = None,\n        get_player_stats_callback: Callable = None,\n        **kwargs\n    ):\n        super().__init__(name=\"game\", **kwargs)\n        self.list_franchises = list_franchises_callback\n        self.create_franchise = create_franchise_callback\n        self.list_special_orders = list_special_orders_callback\n        self.get_player_stats = get_player_stats_callback\n        self._build_ui()\n        # Schedule periodic refresh of pending orders count\n        Clock.schedule_interval(self._update_pending_orders_count, 30)\n\n    def _build_ui(self):\n        \"\"\"Build the game screen UI.\"\"\"\n        main_layout = BoxLayout(orientation=\"vertical\", padding=10, spacing=5)\n\n        # Header with player stats\n        header = BoxLayout(size_hint_y=0.1, spacing=10)\n        self.cash_label = Label(text=\"Cash: $10,000\", font_size=\"16sp\")\n        self.reputation_label = Label(text=\"Reputation: 0\", font_size=\"16sp\")\n        header.add_widget(self.cash_label)\n        header.add_widget(self.reputation_label)\n        main_layout.add_widget(header)\n\n        # Action buttons row\n        actions = BoxLayout(size_hint_y=0.1, spacing=10)\n        \n        btn_franchises = Button(text=\"Franchises\")\n        btn_franchises.bind(on_press=lambda x: self._show_franchises())\n        actions.add_widget(btn_franchises)\n\n        btn_supply = Button(text=\"Supply Chain\")\n        btn_supply.bind(on_press=lambda x: self._show_supply_chain())\n        actions.add_widget(btn_supply)\n\n        btn_market = Button(text=\"Market\")\n        btn_market.bind(on_press=lambda x: self._show_market())\n        actions.add_widget(btn_market)\n\n        # Special Orders button with badge\n        self.btn_special_orders = Button(text=\"Special Orders (0)\")\n        self.btn_special_orders.bind(on_press=lambda x: self._show_special_orders())\n        actions.add_widget(self.btn_special_orders)\n\n        main_layout.add_widget(actions)\n\n        # Main content area\n        self.content_area = BoxLayout(orientation=\"vertical\", size_hint_y=0.7)\n        welcome_label = Label(\n            text=\"Welcome to Tycoon Tactics!\n\nSelect an option above to get started.\",\n            halign=\"center\",\n        )\n        self.content_area.add_widget(welcome_label)\n        main_layout.add_widget(self.content_area)\n\n        # Bottom navigation\n        bottom_nav = BoxLayout(size_hint_y=0.1, spacing=10)\n        \n        btn_back = Button(text=\"Main Menu\")\n        btn_back.bind(on_press=lambda x: self._go_to_main_menu())\n        bottom_nav.add_widget(btn_back)\n\n        main_layout.add_widget(bottom_nav)\n\n        self.add_widget(main_layout)\n\n    def on_enter(self):\n        \"\"\"Called when screen is entered.\"\"\"\n        self._update_player_stats()\n        self._update_pending_orders_count()\n\n    def _update_player_stats(self):\n        \"\"\"Update player stats display.\"\"\"\n        if self.get_player_stats:\n            try:\n                stats = self.get_player_stats()\n                self.cash_label.text = f\"Cash: ${stats.get('cash', 0):}\"\n                self.reputation_label.text = f\"Reputation: {stats.get('reputation', 0)}\"\n            except Exception:\n                pass\n\n    def _update_pending_orders_count(self, dt=None):\n        \"\"\"Update the pending orders count badge.\"\"\"\n        if self.list_special_orders:\n            try:\n                orders = self.list_special_orders()\n                self.pending_orders_count = len(orders)\n                self.btn_special_orders.text = f\"Special Orders ({self.pending_orders_count})\"\n            except Exception:\n                self.btn_special_orders.text = \"Special Orders (0)\"\n\n    def _show_franchises(self):\n        \"\"\"Display franchises list.\"\"\"\n        self.content_area.clear_widgets()\n        \n        layout = BoxLayout(orientation=\"vertical\", spacing=5)\n        \n        # Header\n        header = BoxLayout(size_hint_y=0.1)\n        header.add_widget(Label(text=\"Your Franchises\", font_size=\"20sp\"))\n        btn_add = Button(text=\"+ Add New\", size_hint_x=0.3)\n        btn_add.bind(on_press=lambda x: self._show_create_franchise_dialog())\n        header.add_widget(btn_add)\n        layout.add_widget(header)\n\n        # Franchise list\n        scroll = ScrollView(size_hint_y=0.9)\n        franchise_list = GridLayout(cols=1, spacing=5, size_hint_y=None)\n        franchise_list.bind(minimum_height=franchise_list.setter(\"height\"))\n\n        if self.list_franchises:\n            franchises = self.list_franchises()\n            for franchise in franchises:\n                item = BoxLayout(size_hint_y=None, height=60)\n                item.add_widget(Label(text=franchise.name))\n                item.add_widget(Label(text=f\"Level: {franchise.level}\"))\n                item.add_widget(Label(text=f\"Rep: {franchise.reputation}\"))\n                franchise_list.add_widget(item)\n\n        if not franchise_list.children:\n            franchise_list.add_widget(\n                Label(text=\"No franchises yet. Create one!\", size_hint_y=None, height=60)\n            )\n\n        scroll.add_widget(franchise_list)\n        layout.add_widget(scroll)\n        \n        self.content_area.add_widget(layout)\n\n    def _show_create_franchise_dialog(self):\n        \"\"\"Show dialog to create a new franchise.\"\"\"\n        content = BoxLayout(orientation=\"vertical\", spacing=10, padding=10)\n        \n        content.add_widget(Label(text=\"Franchise Name:\"))\n        name_input = TextInput(multiline=False)\n        content.add_widget(name_input)\n\n        content.add_widget(Label(text=\"Location:\"))\n        location_input = TextInput(multiline=False)\n        content.add_widget(location_input)\n\n        content.add_widget(Label(text=\"Type (restaurant/retail/service):\"))\n        type_input = TextInput(multiline=False)\n        content.add_widget(type_input)\n\n        buttons = BoxLayout(size_hint_y=0.3, spacing=10)\n        \n        popup = Popup(\n            title=\"Create New Franchise\",\n            content=content,\n            size_hint=(0.9, 0.7),\n        )\n\n        btn_cancel = Button(text=\"Cancel\")\n        btn_cancel.bind(on_press=lambda x: popup.dismiss())\n        buttons.add_widget(btn_cancel)\n\n        btn_create = Button(text=\"Create\")\n        btn_create.bind(on_press=lambda x: self._do_create_franchise(\n            popup, name_input.text, location_input.text, type_input.text\n        ))\n        buttons.add_widget(btn_create)\n\n        content.add_widget(buttons)\n        popup.open()\n\n    def _do_create_franchise(self, popup, name: str, location: str, franchise_type: str):\n        \"\"\"Execute franchise creation.\"\"\"\n        if not name or not location or not franchise_type:\n            self.show_error(\"Please fill in all fields\")\n            return\n\n        if self.create_franchise:\n            try:\n                self.create_franchise(name, location, franchise_type)\n                popup.dismiss()\n                self.show_success(f\"Franchise '{name}' created!\")\n                self._show_franchises()\n            except Exception as e:\n                self.show_error(str(e))\n\n    def _show_supply_chain(self):\n        \"\"\"Display supply chain management.\"\"\"\n        self.content_area.clear_widgets()\n        self.content_area.add_widget(\n            Label(text=\"Supply Chain Management\n\nComing soon...\")\n        )\n\n    def _show_market(self):\n        \"\"\"Display market information.\"\"\"\n        self.content_area.clear_widgets()\n        self.content_area.add_widget(\n            Label(text=\"Market Overview\n\nComing soon...\")\n        )\n\n    def _show_special_orders(self):\n        \"\"\"Navigate to special orders screen.\"\"\"\n        self.manager.current = \"special_orders\"\n\n    def _go_to_main_menu(self):\n        \"\"\"Return to main menu.\"\"\"\n        self.manager.current = \"main_menu\"\n\n\nclass SpecialOrdersScreen(BaseScreen):\n    \"\"\"Screen for displaying and managing special orders.\"\"\"\n    \n    def __init__(\n        self,\n        list_orders_callback: Callable = None,\n        accept_order_callback: Callable = None,\n        get_franchises_callback: Callable = None,\n        **kwargs\n    ):\n        super().__init__(name=\"special_orders\", **kwargs)\n        self.list_orders = list_orders_callback\n        self.accept_order = accept_order_callback\n        self.get_franchises = get_franchises_callback\n        self._build_ui()\n\n    def _build_ui(self):\n        \"\"\"Build the special orders screen UI.\"\"\"\n        main_layout = BoxLayout(orientation=\"vertical\", padding=10, spacing=5)\n\n        # Header\n        header = BoxLayout(size_hint_y=0.1, spacing=10)\n        header.add_widget(Label(text=\"Special Orders\", font_size=\"24sp\"))\n        btn_refresh = Button(text=\"Refresh\", size_hint_x=0.3)\n        btn_refresh.bind(on_press=lambda x: self._refresh_orders())\n        header.add_widget(btn_refresh)\n        main_layout.add_widget(header)\n\n        # Orders list\n        self.orders_scroll = ScrollView(size_hint_y=0.8)\n        self.orders_list = GridLayout(cols=1, spacing=10, size_hint_y=None, padding=5)\n        self.orders_list.bind(minimum_height=self.orders_list.setter(\"height\"))\n        self.orders_scroll.add_widget(self.orders_list)\n        main_layout.add_widget(self.orders_scroll)\n\n        # Bottom navigation\n        bottom_nav = BoxLayout(size_hint_y=0.1, spacing=10)\n        btn_back = Button(text=\"Back to Game\")\n        btn_back.bind(on_press=lambda x: self._go_back())\n        bottom_nav.add_widget(btn_back)\n        main_layout.add_widget(bottom_nav)\n\n        self.add_widget(main_layout)\n\n    def on_enter(self):\n        \"\"\"Called when screen is entered.\"\"\"\n        self._refresh_orders()\n\n    def _refresh_orders(self):\n        \"\"\"Refresh the orders list.\"\"\"\n        self.orders_list.clear_widgets()\n\n        if not self.list_orders:\n            self.orders_list.add_widget(\n                Label(text=\"Orders not available\", size_hint_y=None, height=60)\n            )\n            return\n\n        try:\n            orders = self.list_orders()\n            \n            if not orders:\n                self.orders_list.add_widget(\n                    Label(\n                        text=\"No special orders available.\nCheck back later!\",\n                        size_hint_y=None,\n                        height=100,\n                        halign=\"center\",\n                    )\n                )\n                return\n\n            for order in orders:\n                order_widget = self._create_order_widget(order)\n                self.orders_list.add_widget(order_widget)\n\n        except Exception as e:\n            self.orders_list.add_widget(\n                Label(text=f\"Error loading orders: {e}\", size_hint_y=None, height=60)\n            )\n\n    def _create_order_widget(self, order) -> BoxLayout:\n        \"\"\"Create a widget for displaying a single order.\"\"\"\n        container = BoxLayout(\n            orientation=\"vertical\",\n            size_hint_y=None,\n            height=200,\n            padding=10,\n            spacing=5,\n        )\n\n        # Order name and time remaining\n        header = BoxLayout(size_hint_y=0.2)\n        header.add_widget(Label(text=order.name, font_size=\"18sp\", bold=True))\n        remaining = order.remaining_time_seconds()\n        minutes = remaining // 60\n        seconds = remaining % 60\n        time_label = Label(\n            text=f\"Time: {minutes}m {seconds}s\",\n            color=(1, 0.5, 0, 1) if remaining < 600 else (0, 1, 0, 1),\n        )\n        header.add_widget(time_label)\n        container.add_widget(header)\n\n        # Destination\n        container.add_widget(\n            Label(text=f\"Deliver to: {order.destination_address}\", size_hint_y=0.15)\n        )\n\n        # Requirements\n        req_text = \"Required: \" + \", \".join(\n            f\"{qty}x {product}\" for product, qty in order.product_requirements.items()\n        )\n        container.add_widget(Label(text=req_text, size_hint_y=0.2))\n\n        # Rewards\n        rewards = BoxLayout(size_hint_y=0.2)\n        rewards.add_widget(Label(text=f\"Cash: ${order.reward_cash:}\", color=(0, 1, 0, 1)))\n        rewards.add_widget(Label(text=f\"Reputation: +{order.reward_reputation}\", color=(0, 0.7, 1, 1)))\n        container.add_widget(rewards)\n\n        # Accept button\n        btn_accept = Button(\n            text=\"Accept Order\",\n            size_hint_y=0.25,\n            background_color=(0, 0.7, 0, 1),\n        )\n        btn_accept.bind(on_press=lambda x, o=order: self._show_accept_dialog(o))\n        container.add_widget(btn_accept)\n\n        return container\n\n    def _show_accept_dialog(self, order):\n        \"\"\"Show dialog to select franchise for order fulfillment.\"\"\"\n        content = BoxLayout(orientation=\"vertical\", spacing=10, padding=10)\n        \n        content.add_widget(Label(text=\"Select franchise to fulfill order:\"))\n\n        franchises = []\n        if self.get_franchises:\n            try:\n                franchises = self.get_franchises()\n            except Exception:\n                pass\n\n        popup = Popup(\n            title=f\"Accept: {order.name}\",\n            content=content,\n            size_hint=(0.9, 0.6),\n        )\n\n        if not franchises:\n            content.add_widget(Label(text=\"No franchises available!\"))\n            btn_close = Button(text=\"Close\", size_hint_y=0.3)\n            btn_close.bind(on_press=lambda x: popup.dismiss())\n            content.add_widget(btn_close)\n        else:\n            scroll = ScrollView(size_hint_y=0.7)\n            franchise_list = GridLayout(cols=1, spacing=5, size_hint_y=None)\n            franchise_list.bind(minimum_height=franchise_list.setter(\"height\"))\n\n            for franchise in franchises:\n                btn = Button(\n                    text=f\"{franchise.name} ({franchise.location})\",\n                    size_hint_y=None,\n                    height=50,\n                )\n                btn.bind(on_press=lambda x, f=franchise, o=order, p=popup: self._do_accept_order(p, o, f))\n                franchise_list.add_widget(btn)\n\n            scroll.add_widget(franchise_list)\n            content.add_widget(scroll)\n\n            btn_cancel = Button(text=\"Cancel\", size_hint_y=0.2)\n            btn_cancel.bind(on_press=lambda x: popup.dismiss())\n            content.add_widget(btn_cancel)\n\n        popup.open()\n\n    def _do_accept_order(self, popup, order, franchise):\n        \"\"\"Execute order acceptance.\"\"\"\n        popup.dismiss()\n\n        if not self.accept_order:\n            self.show_error(\"Order acceptance not available\")\n            return\n\n        try:\n            self.accept_order(order.id, franchise.id)\n            self.show_success(\n                f\"Order completed!\n\n\"\n                f\"Earned: ${order.reward_cash:}\n\"\n                f\"Reputation: +{order.reward_reputation}\"\n            )\n            self._refresh_orders()\n        except Exception as e:\n            error_msg = str(e)\n            if \"Insufficient\" in error_msg:\n                self.show_error(f\"Not enough inventory!\n{error_msg}\")\n            elif \"expired\" in error_msg.lower():\n                self.show_error(\"This order has expired!\")\n                self._refresh_orders()\n            else:\n                self.show_error(f\"Failed to accept order:\n{error_msg}\")\n\n    def _go_back(self):\n        \"\"\"Return to game screen.\"\"\"\n        self.manager.current = \"game\"\n\n\nclass SettingsScreen(BaseScreen):\n    \"\"\"Settings screen.\"\"\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(name=\"settings\", **kwargs)\n        self._build_ui()\n\n    def _build_ui(self):\n        \"\"\"Build the settings screen UI.\"\"\"\n        layout = BoxLayout(orientation=\"vertical\", padding=20, spacing=10)\n        \n        layout.add_widget(Label(text=\"Settings\", font_size=\"24sp\", size_hint_y=0.1))\n\n        settings_area = GridLayout(cols=2, spacing=10, size_hint_y=0.7)\n        \n        settings_area.add_widget(Label(text=\"Sound Effects:\"))\n        btn_sound = Button(text=\"On\")\n        settings_area.add_widget(btn_sound)\n\n        settings_area.add_widget(Label(text=\"Music:\"))\n        btn_music = Button(text=\"On\")\n        settings_area.add_widget(btn_music)\n\n        settings_area.add_widget(Label(text=\"Notifications:\"))\n        btn_notif = Button(text=\"On\")\n        settings_area.add_widget(btn_notif)\n\n        layout.add_widget(settings_area)\n\n        btn_back = Button(text=\"Back\", size_hint_y=0.1)\n        btn_back.bind(on_press=lambda x: self._go_back())\n        layout.add_widget(btn_back)\n\n        self.add_widget(layout)\n\n    def _go_back(self):\n        \"\"\"Return to main menu.\"\"\"\n        self.manager.current = \"main_menu\"\n",
          "tycoon_tactics/adapters/ui/main_app.py": "\"\"\"Main Kivy application for Tycoon Tactics.\"\"\"\nfrom uuid import UUID, uuid4\n\nfrom kivy.app import App\nfrom kivy.uix.screenmanager import ScreenManager\nfrom kivy.clock import Clock\n\nfrom tycoon_tactics.adapters.ui.screens import (\n    MainMenuScreen,\n    GameScreen,\n    SpecialOrdersScreen,\n    SettingsScreen,\n)\nfrom tycoon_tactics.config.containers import Container\n\n\nclass TycoonTacticsApp(App):\n    \"\"\"Main application class for Tycoon Tactics: Franchise Frontier.\"\"\"\n    \n    title = \"Tycoon Tactics: Franchise Frontier\"\n    \n    def __init__(self, container: Container = None, **kwargs):\n        super().__init__(**kwargs)\n        self.container = container or Container()\n        # Default player ID (in real app, this would come from auth)\n        self.player_id = uuid4()\n        self._special_order_generation_event = None\n\n    def build(self):\n        \"\"\"Build and return the root widget.\"\"\"\n        self.screen_manager = ScreenManager()\n        \n        # Create screens with callbacks\n        main_menu = MainMenuScreen()\n        \n        game_screen = GameScreen(\n            list_franchises_callback=self._list_franchises,\n            create_franchise_callback=self._create_franchise,\n            list_special_orders_callback=self._list_special_orders,\n            get_player_stats_callback=self._get_player_stats,\n        )\n        \n        special_orders_screen = SpecialOrdersScreen(\n            list_orders_callback=self._list_special_orders,\n            accept_order_callback=self._accept_special_order,\n            get_franchises_callback=self._list_franchises,\n        )\n        \n        settings_screen = SettingsScreen()\n\n        # Add screens to manager\n        self.screen_manager.add_widget(main_menu)\n        self.screen_manager.add_widget(game_screen)\n        self.screen_manager.add_widget(special_orders_screen)\n        self.screen_manager.add_widget(settings_screen)\n\n        # Schedule periodic special order generation (every 5 minutes = 300 seconds)\n        self._special_order_generation_event = Clock.schedule_interval(\n            self._generate_special_order,\n            300  # 5 minutes\n        )\n        \n        # Generate an initial special order on startup\n        Clock.schedule_once(self._generate_special_order, 5)\n\n        return self.screen_manager\n\n    def on_stop(self):\n        \"\"\"Called when the application is stopping.\"\"\"\n        if self._special_order_generation_event:\n            self._special_order_generation_event.cancel()\n\n    # Callback methods that bridge UI to use cases\n    \n    def _list_franchises(self):\n        \"\"\"List all franchises.\"\"\"\n        use_case = self.container.list_franchises_use_case()\n        return use_case.execute()\n\n    def _create_franchise(self, name: str, location: str, franchise_type: str):\n        \"\"\"Create a new franchise.\"\"\"\n        use_case = self.container.create_franchise_use_case()\n        return use_case.execute(name, location, franchise_type)\n\n    def _list_special_orders(self):\n        \"\"\"List active special orders.\"\"\"\n        use_case = self.container.list_active_special_orders_use_case()\n        return use_case.execute()\n\n    def _accept_special_order(self, order_id: UUID, franchise_id: UUID):\n        \"\"\"Accept a special order.\"\"\"\n        use_case = self.container.accept_special_order_use_case(self.player_id)\n        return use_case.execute(order_id, franchise_id)\n\n    def _get_player_stats(self):\n        \"\"\"Get player statistics.\"\"\"\n        use_case = self.container.get_player_stats_use_case()\n        return use_case.execute(self.player_id)\n\n    def _generate_special_order(self, dt=None):\n        \"\"\"Generate a new random special order.\"\"\"\n        try:\n            use_case = self.container.generate_random_special_order_use_case()\n            order = use_case.execute()\n            print(f\"Generated special order: {order.name}\")\n        except Exception as e:\n            print(f\"Error generating special order: {e}\")\n\n\ndef run_app():\n    \"\"\"Run the application.\"\"\"\n    app = TycoonTacticsApp()\n    app.run()\n\n\nif __name__ == \"__main__\":\n    run_app()\n",
          "tycoon_tactics/config/containers.py": "\"\"\"Dependency injection container configuration.\"\"\"\nfrom uuid import UUID\n\nfrom tycoon_tactics.adapters.persistence.sqlite_repository import SQLiteRepository\nfrom tycoon_tactics.application.event_bus import EventBus\nfrom tycoon_tactics.application.use_cases import (\n    CreateFranchiseUseCase,\n    GetFranchiseUseCase,\n    ListFranchisesUseCase,\n    UpdateInventoryUseCase,\n    GetSupplyChainUseCase,\n    ListMarketsUseCase,\n    GenerateRandomSpecialOrderUseCase,\n    ListActiveSpecialOrdersUseCase,\n    GetSpecialOrderUseCase,\n    AcceptSpecialOrderUseCase,\n    GetPlayerStatsUseCase,\n)\n\n\nclass Container:\n    \"\"\"Dependency injection container for the application.\"\"\"\n    \n    def __init__(self, db_path: str = \"tycoon_tactics.db\"):\n        \"\"\"Initialize the container with dependencies.\"\"\"\n        self._db_path = db_path\n        self._repository = None\n        self._event_bus = None\n\n    @property\n    def repository(self) -> SQLiteRepository:\n        \"\"\"Get or create the repository singleton.\"\"\"\n        if self._repository is None:\n            self._repository = SQLiteRepository(self._db_path)\n        return self._repository\n\n    @property\n    def event_bus(self) -> EventBus:\n        \"\"\"Get or create the event bus singleton.\"\"\"\n        if self._event_bus is None:\n            self._event_bus = EventBus()\n        return self._event_bus\n\n    # Franchise use cases\n    def create_franchise_use_case(self) -> CreateFranchiseUseCase:\n        \"\"\"Create a CreateFranchiseUseCase instance.\"\"\"\n        return CreateFranchiseUseCase(\n            repository=self.repository,\n            event_bus=self.event_bus,\n        )\n\n    def get_franchise_use_case(self) -> GetFranchiseUseCase:\n        \"\"\"Create a GetFranchiseUseCase instance.\"\"\"\n        return GetFranchiseUseCase(repository=self.repository)\n\n    def list_franchises_use_case(self) -> ListFranchisesUseCase:\n        \"\"\"Create a ListFranchisesUseCase instance.\"\"\"\n        return ListFranchisesUseCase(repository=self.repository)\n\n    # Supply chain use cases\n    def update_inventory_use_case(self) -> UpdateInventoryUseCase:\n        \"\"\"Create an UpdateInventoryUseCase instance.\"\"\"\n        return UpdateInventoryUseCase(\n            repository=self.repository,\n            event_bus=self.event_bus,\n        )\n\n    def get_supply_chain_use_case(self) -> GetSupplyChainUseCase:\n        \"\"\"Create a GetSupplyChainUseCase instance.\"\"\"\n        return GetSupplyChainUseCase(repository=self.repository)\n\n    # Market use cases\n    def list_markets_use_case(self) -> ListMarketsUseCase:\n        \"\"\"Create a ListMarketsUseCase instance.\"\"\"\n        return ListMarketsUseCase(repository=self.repository)\n\n    # Special Order use cases\n    def generate_random_special_order_use_case(self) -> GenerateRandomSpecialOrderUseCase:\n        \"\"\"Create a GenerateRandomSpecialOrderUseCase instance.\"\"\"\n        return GenerateRandomSpecialOrderUseCase(repository=self.repository)\n\n    def list_active_special_orders_use_case(self) -> ListActiveSpecialOrdersUseCase:\n        \"\"\"Create a ListActiveSpecialOrdersUseCase instance.\"\"\"\n        return ListActiveSpecialOrdersUseCase(repository=self.repository)\n\n    def get_special_order_use_case(self) -> GetSpecialOrderUseCase:\n        \"\"\"Create a GetSpecialOrderUseCase instance.\"\"\"\n        return GetSpecialOrderUseCase(repository=self.repository)\n\n    def accept_special_order_use_case(self, player_id: UUID) -> AcceptSpecialOrderUseCase:\n        \"\"\"Create an AcceptSpecialOrderUseCase instance.\"\"\"\n        return AcceptSpecialOrderUseCase(\n            repository=self.repository,\n            event_bus=self.event_bus,\n            player_id=player_id,\n        )\n\n    # Player stats use case\n    def get_player_stats_use_case(self) -> GetPlayerStatsUseCase:\n        \"\"\"Create a GetPlayerStatsUseCase instance.\"\"\"\n        return GetPlayerStatsUseCase(repository=self.repository)\n",
          "tycoon_tactics/domain/supply_chain.py": "\"\"\"Supply Chain domain model.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Dict, List\nfrom uuid import UUID, uuid4\n\n\n@dataclass\nclass SupplyChain:\n    \"\"\"Represents a franchise's supply chain.\"\"\"\n    id: UUID\n    franchise_id: UUID\n    inventory: Dict[str, int] = field(default_factory=dict)\n    suppliers: List[str] = field(default_factory=list)\n    logistics_efficiency: float = 1.0\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n    @classmethod\n    def create(cls, franchise_id: UUID) -> \"SupplyChain\":\n        \"\"\"Factory method to create a new supply chain.\"\"\"\n        return cls(\n            id=uuid4(),\n            franchise_id=franchise_id,\n            inventory={},\n            suppliers=[],\n            logistics_efficiency=1.0,\n            created_at=datetime.utcnow(),\n        )\n\n    def add_inventory(self, product_name: str, quantity: int) -> None:\n        \"\"\"Add items to inventory.\"\"\"\n        if quantity < 0:\n            raise ValueError(\"Quantity must be non-negative\")\n        current = self.inventory.get(product_name, 0)\n        self.inventory[product_name] = current + quantity\n\n    def remove_inventory(self, product_name: str, quantity: int) -> None:\n        \"\"\"Remove items from inventory.\"\"\"\n        if quantity < 0:\n            raise ValueError(\"Quantity must be non-negative\")\n        current = self.inventory.get(product_name, 0)\n        if current < quantity:\n            raise ValueError(\n                f\"Insufficient inventory for {product_name}: have {current}, need {quantity}\"\n            )\n        self.inventory[product_name] = current - quantity\n        # Clean up zero quantities\n        if self.inventory[product_name] == 0:\n            del self.inventory[product_name]\n\n    def get_inventory(self, product_name: str) -> int:\n        \"\"\"Get current inventory for a product.\"\"\"\n        return self.inventory.get(product_name, 0)\n\n    def add_supplier(self, supplier_name: str) -> None:\n        \"\"\"Add a supplier to the supply chain.\"\"\"\n        if supplier_name not in self.suppliers:\n            self.suppliers.append(supplier_name)\n\n    def remove_supplier(self, supplier_name: str) -> None:\n        \"\"\"Remove a supplier from the supply chain.\"\"\"\n        if supplier_name in self.suppliers:\n            self.suppliers.remove(supplier_name)\n\n    def improve_logistics(self, improvement: float) -> None:\n        \"\"\"Improve logistics efficiency.\"\"\"\n        if improvement < 0:\n            raise ValueError(\"Improvement must be non-negative\")\n        self.logistics_efficiency += improvement\n",
          "tycoon_tactics/application/game_events.py": "\"\"\"Game events for the event bus.\"\"\"\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Dict, Any\nfrom uuid import UUID\n\n\n@dataclass\nclass GameEvent:\n    \"\"\"Base class for game events.\"\"\"\n    timestamp: datetime = None\n\n    def __post_init__(self):\n        if self.timestamp is None:\n            self.timestamp = datetime.utcnow()\n\n\n@dataclass\nclass FranchiseCreatedEvent(GameEvent):\n    \"\"\"Event fired when a franchise is created.\"\"\"\n    franchise_id: UUID = None\n    name: str = \"\"\n    location: str = \"\"\n\n\n@dataclass\nclass FranchiseUpgradedEvent(GameEvent):\n    \"\"\"Event fired when a franchise is upgraded.\"\"\"\n    franchise_id: UUID = None\n    new_level: int = 0\n\n\n@dataclass\nclass SupplyChainUpdatedEvent(GameEvent):\n    \"\"\"Event fired when a supply chain is updated.\"\"\"\n    supply_chain_id: UUID = None\n    franchise_id: UUID = None\n    inventory: Dict[str, int] = None\n\n\n@dataclass\nclass MarketConditionsChangedEvent(GameEvent):\n    \"\"\"Event fired when market conditions change.\"\"\"\n    market_id: UUID = None\n    demand_level: float = 0.0\n    price_multiplier: float = 0.0\n\n\n@dataclass\nclass SpecialOrderCreatedEvent(GameEvent):\n    \"\"\"Event fired when a special order is created.\"\"\"\n    order_id: UUID = None\n    name: str = \"\"\n    reward_cash: int = 0\n    reward_reputation: int = 0\n\n\n@dataclass\nclass SpecialOrderAcceptedEvent(GameEvent):\n    \"\"\"Event fired when a special order is accepted.\"\"\"\n    order_id: UUID = None\n    player_id: UUID = None\n    franchise_id: UUID = None\n\n\n@dataclass\nclass SpecialOrderCompletedEvent(GameEvent):\n    \"\"\"Event fired when a special order is completed.\"\"\"\n    order_id: UUID = None\n    player_id: UUID = None\n    cash_earned: int = 0\n    reputation_earned: int = 0\n\n\n@dataclass\nclass SpecialOrderExpiredEvent(GameEvent):\n    \"\"\"Event fired when a special order expires.\"\"\"\n    order_id: UUID = None\n",
          "main.py": "\"\"\"Main entry point for Tycoon Tactics: Franchise Frontier.\"\"\"\nimport os\nimport sys\n\n# Add the project root to the path\nsys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\nfrom tycoon_tactics.adapters.ui.main_app import TycoonTacticsApp\nfrom tycoon_tactics.config.containers import Container\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    # Initialize the dependency injection container\n    container = Container(db_path=\"tycoon_tactics.db\")\n    \n    # Create and run the application\n    app = TycoonTacticsApp(container=container)\n    app.run()\n\n\nif __name__ == \"__main__\":\n    main()\n",
          "tests/unit/test_special_orders.py": "\"\"\"Unit tests for Special Orders feature.\"\"\"\nimport pytest\nfrom datetime import datetime, timedelta\nfrom uuid import uuid4\n\nfrom tycoon_tactics.domain.special_order import SpecialOrder, SpecialOrderStatus\nfrom tycoon_tactics.application.use_cases import (\n    GenerateRandomSpecialOrderUseCase,\n    AcceptSpecialOrderUseCase,\n    ListActiveSpecialOrdersUseCase,\n    InsufficientInventoryError,\n    OrderNotFoundError,\n    InvalidOrderStatusError,\n)\n\n\nclass TestSpecialOrderDomain:\n    \"\"\"Tests for SpecialOrder domain model.\"\"\"\n\n    def test_create_special_order(self):\n        \"\"\"Test creating a special order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10, \"Food\": 5},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n            time_to_live_seconds=3600,\n        )\n        \n        assert order.name == \"Test Order\"\n        assert order.product_requirements == {\"Electronics\": 10, \"Food\": 5}\n        assert order.destination_address == \"Test Address\"\n        assert order.reward_cash == 1000\n        assert order.reward_reputation == 50\n        assert order.time_to_live_seconds == 3600\n        assert order.status == SpecialOrderStatus.PENDING\n        assert order.id is not None\n        assert order.created_at is not None\n\n    def test_order_not_expired_initially(self):\n        \"\"\"Test that a new order is not expired.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n            time_to_live_seconds=3600,\n        )\n        \n        assert not order.is_expired()\n        assert order.remaining_time_seconds() > 0\n\n    def test_accept_order(self):\n        \"\"\"Test accepting an order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.accept()\n        assert order.status == SpecialOrderStatus.ACCEPTED\n\n    def test_complete_order(self):\n        \"\"\"Test completing an order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.accept()\n        order.complete()\n        assert order.status == SpecialOrderStatus.COMPLETED\n\n    def test_cannot_accept_non_pending_order(self):\n        \"\"\"Test that accepting a non-pending order raises an error.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.accept()\n        \n        with pytest.raises(ValueError):\n            order.accept()\n\n    def test_cannot_complete_non_accepted_order(self):\n        \"\"\"Test that completing a non-accepted order raises an error.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        with pytest.raises(ValueError):\n            order.complete()\n\n    def test_expire_order(self):\n        \"\"\"Test expiring an order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.expire()\n        assert order.status == SpecialOrderStatus.EXPIRED\n\n\nclass TestSpecialOrderUseCases:\n    \"\"\"Tests for Special Order use cases.\"\"\"\n\n    def test_generate_random_special_order(self, mock_repository):\n        \"\"\"Test generating a random special order.\"\"\"\n        use_case = GenerateRandomSpecialOrderUseCase(repository=mock_repository)\n        order = use_case.execute()\n        \n        assert order is not None\n        assert order.name in GenerateRandomSpecialOrderUseCase.ORDER_NAMES\n        assert len(order.product_requirements) >= 1\n        assert order.reward_cash > 0\n        assert order.reward_reputation > 0\n        assert order.status == SpecialOrderStatus.PENDING\n\n    def test_list_active_special_orders(self, mock_repository):\n        \"\"\"Test listing active special orders.\"\"\"\n        # Add some orders\n        order1 = SpecialOrder.create(\n            name=\"Order 1\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Address 1\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        order2 = SpecialOrder.create(\n            name=\"Order 2\",\n            product_requirements={\"Food\": 20},\n            destination_address=\"Address 2\",\n            reward_cash=2000,\n            reward_reputation=100,\n        )\n        mock_repository.add_special_order(order1)\n        mock_repository.add_special_order(order2)\n        \n        use_case = ListActiveSpecialOrdersUseCase(repository=mock_repository)\n        orders = use_case.execute()\n        \n        assert len(orders) == 2\n\n\n@pytest.fixture\ndef mock_repository():\n    \"\"\"Create a mock repository for testing.\"\"\"\n    from unittest.mock import MagicMock\n    from tycoon_tactics.domain.supply_chain import SupplyChain\n    \n    repo = MagicMock()\n    repo._orders = {}\n    repo._supply_chains = {}\n    repo._player_cash = {}\n    repo._player_reputation = {}\n    \n    def add_special_order(order):\n        repo._orders[order.id] = order\n    \n    def get_special_order(order_id):\n        return repo._orders.get(order_id)\n    \n    def list_active_special_orders():\n        return [o for o in repo._orders.values() if o.status == SpecialOrderStatus.PENDING]\n    \n    def update_special_order(order):\n        repo._orders[order.id] = order\n    \n    repo.add_special_order = add_special_order\n    repo.get_special_order = get_special_order\n    repo.list_active_special_orders = list_active_special_orders\n    repo.update_special_order = update_special_order\n    \n    return repo\n"
        },
        "generated_files": [
          "tycoon_tactics/domain/special_order.py",
          "tycoon_tactics/adapters/persistence/orm_models.py",
          "tycoon_tactics/domain/ports.py",
          "tycoon_tactics/adapters/persistence/sqlite_repository.py",
          "tycoon_tactics/application/use_cases.py",
          "tycoon_tactics/adapters/ui/screens.py",
          "tycoon_tactics/adapters/ui/main_app.py",
          "tycoon_tactics/config/containers.py",
          "tycoon_tactics/domain/supply_chain.py",
          "tycoon_tactics/application/game_events.py",
          "main.py",
          "tests/unit/test_special_orders.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8165511551155116,
              "dependency_traversal_accuracy": 0.8064165186699307,
              "cross_file_reasoning_depth": 0.3772916666666667,
              "system_thinking_score": 0.5078651782558038,
              "robustness_score": 0.12431681333950903,
              "comprehensiveness_score": 0.7239179872284528,
              "innovation_score": 0.275,
              "solution_elegance_score": 0.6416176433016468
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.10206889438943895,
              "dependency_traversal_weighted": 0.10080206483374134,
              "cross_file_reasoning_weighted": 0.047161458333333336,
              "system_thinking_weighted": 0.06348314728197547,
              "robustness_weighted": 0.015539601667438629,
              "comprehensiveness_weighted": 0.0904897484035566,
              "innovation_weighted": 0.034375,
              "solution_elegance_weighted": 0.08020220541270585
            },
            "total_software_engineering_score": 0.5341221203221902
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.7799184322357178,
              "errors": [
                "  File \"tycoon_tactics/adapters/ui/screens.py\", line 55",
                "    text=\"Tycoon Tactics:",
                "         ^",
                "SyntaxError: unterminated string literal (detected at line 55)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "tycoon_tactics/domain/special_order.py",
                "tycoon_tactics/adapters/persistence/orm_models.py",
                "tycoon_tactics/domain/ports.py",
                "tycoon_tactics/adapters/persistence/sqlite_repository.py",
                "tycoon_tactics/application/use_cases.py",
                "tycoon_tactics/adapters/ui/screens.py",
                "tycoon_tactics/adapters/ui/main_app.py",
                "tycoon_tactics/config/containers.py",
                "tycoon_tactics/domain/supply_chain.py",
                "tycoon_tactics/application/game_events.py",
                "main.py",
                "tests/unit/test_special_orders.py"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 12,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 12 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.2702428571428571,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.2702428571428571,
              "idc_weight": 0.2,
              "total_functional_score": 0.3940485714285714
            }
          },
          "code_quality_details": {
            "files_analyzed": 12,
            "quality_checks": {
              "tycoon_tactics/domain/special_order.py": {
                "line_count": 86,
                "non_empty_lines": 74,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 6,
                "class_count": 2,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/adapters/persistence/orm_models.py": {
                "line_count": 103,
                "non_empty_lines": 81,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 2,
                "class_count": 6,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/domain/ports.py": {
                "line_count": 175,
                "non_empty_lines": 135,
                "comment_lines": 5,
                "comment_ratio": 0.037037037037037035,
                "function_count": 28,
                "class_count": 5,
                "import_count": 14,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/adapters/persistence/sqlite_repository.py": {
                "line_count": 334,
                "non_empty_lines": 302,
                "comment_lines": 6,
                "comment_ratio": 0.019867549668874173,
                "function_count": 27,
                "class_count": 2,
                "import_count": 23,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/application/use_cases.py": {
                "line_count": 300,
                "non_empty_lines": 232,
                "comment_lines": 15,
                "comment_ratio": 0.06465517241379311,
                "function_count": 12,
                "class_count": 14,
                "import_count": 22,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/adapters/ui/screens.py": {
                "line_count": 573,
                "non_empty_lines": 457,
                "comment_lines": 16,
                "comment_ratio": 0.0350109409190372,
                "function_count": 32,
                "class_count": 6,
                "import_count": 26,
                "quality_score": 0.6
              },
              "tycoon_tactics/adapters/ui/main_app.py": {
                "line_count": 118,
                "non_empty_lines": 90,
                "comment_lines": 6,
                "comment_ratio": 0.06666666666666667,
                "function_count": 10,
                "class_count": 2,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/config/containers.py": {
                "line_count": 102,
                "non_empty_lines": 84,
                "comment_lines": 5,
                "comment_ratio": 0.05952380952380952,
                "function_count": 14,
                "class_count": 1,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/domain/supply_chain.py": {
                "line_count": 70,
                "non_empty_lines": 60,
                "comment_lines": 1,
                "comment_ratio": 0.016666666666666666,
                "function_count": 7,
                "class_count": 1,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "tycoon_tactics/application/game_events.py": {
                "line_count": 79,
                "non_empty_lines": 59,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 1,
                "class_count": 10,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "main.py": {
                "line_count": 24,
                "non_empty_lines": 16,
                "comment_lines": 3,
                "comment_ratio": 0.1875,
                "function_count": 1,
                "class_count": 0,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "tests/unit/test_special_orders.py": {
                "line_count": 195,
                "non_empty_lines": 160,
                "comment_lines": 1,
                "comment_ratio": 0.00625,
                "function_count": 14,
                "class_count": 2,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7883333333333333,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.9246621621621619,
              "multi_session_memory_retention": 0.9280712530712527
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.46233108108108095,
              "multi_session_memory_retention_weighted": 0.46403562653562636
            },
            "total_longcontext_utilization_score": 0.9263667076167073
          }
        },
        "timestamp": "2026-01-14T20:51:11.467922"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_data_warehouse_easy_084_feature_implementation_expert_01",
        "scenario_title": "Implement Pluggable Data Quality Gates with a Quarantine Mechanism",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.545682200380249,
        "functional_correctness_score": 0.35153426866634413,
        "code_quality_score": 0.792222222222222,
        "longcontext_utilization_score": 0.8693580316742082,
        "total_score": 2.84556704181934,
        "generation_time": 179.41712832450867,
        "code_files_generated": 9,
        "total_lines_generated": 1754,
        "parsing_success": true,
        "solution_code": {
          "timestack/validators.py": "\"\"\"Data Quality Validators for TimeStack Warehouse.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Tuple\n\n\nclass DataQualityValidator(ABC):\n    \"\"\"Abstract base class for data quality validators.\"\"\"\n    \n    @abstractmethod\n    def validate(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Validate a record.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n            If valid, error_message should be an empty string.\n        \"\"\"\n        pass\n\n\nclass NotNullValidator(DataQualityValidator):\n    \"\"\"Validator that checks if a specified field is not None.\"\"\"\n    \n    def __init__(self, field: str):\n        \"\"\"Initialize the validator.\n        \n        Args:\n            field: The name of the field to check.\n        \"\"\"\n        self.field = field\n    \n    def validate(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Check if the field exists and is not None.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n        \"\"\"\n        if self.field not in record:\n            return False, f\"Field '{self.field}' is missing from record.\"\n        \n        if record[self.field] is None:\n            return False, f\"Field '{self.field}' cannot be None.\"\n        \n        return True, \"\"\n\n\nclass FieldTypeValidator(DataQualityValidator):\n    \"\"\"Validator that checks if a specified field has the correct type.\"\"\"\n    \n    def __init__(self, field: str, expected_type: type):\n        \"\"\"Initialize the validator.\n        \n        Args:\n            field: The name of the field to check.\n            expected_type: The expected Python type for the field.\n        \"\"\"\n        self.field = field\n        self.expected_type = expected_type\n    \n    def validate(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Check if the field has the expected type.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n        \"\"\"\n        if self.field not in record:\n            return False, f\"Field '{self.field}' is missing from record.\"\n        \n        value = record[self.field]\n        \n        # Allow None values to pass type check (use NotNullValidator for null checks)\n        if value is None:\n            return True, \"\"\n        \n        if not isinstance(value, self.expected_type):\n            actual_type = type(value).__name__\n            expected_type_name = self.expected_type.__name__\n            return False, f\"Field '{self.field}' expected type '{expected_type_name}', got '{actual_type}'.\"\n        \n        return True, \"\"\n\n\nclass QuarantineRecord:\n    \"\"\"A signal class indicating a record should be quarantined.\"\"\"\n    \n    def __init__(self, original_record: dict, error: str):\n        \"\"\"Initialize the quarantine record.\n        \n        Args:\n            original_record: The original data record that failed validation.\n            error: The error message explaining why validation failed.\n        \"\"\"\n        self.original_record = original_record\n        self.error = error\n    \n    def to_dict(self) -> dict:\n        \"\"\"Convert to dictionary format for storage.\n        \n        Returns:\n            Dictionary containing original record and error.\n        \"\"\"\n        return {\n            \"original_record\": self.original_record,\n            \"error\": self.error\n        }\n",
          "timestack/steps.py": "\"\"\"Pipeline steps for data transformation.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Generator, List, Optional\n\nfrom timestack.validators import DataQualityValidator, QuarantineRecord\n\n\nclass BaseStep(ABC):\n    \"\"\"Abstract base class for pipeline steps.\"\"\"\n    \n    def __init__(self, name: str, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the step.\n        \n        Args:\n            name: The name of this step.\n            validators: Optional list of data quality validators to apply.\n        \"\"\"\n        self.name = name\n        self.validators = validators or []\n    \n    def validate_record(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Validate a record against all validators.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n        \"\"\"\n        for validator in self.validators:\n            is_valid, error = validator.validate(record)\n            if not is_valid:\n                return False, error\n        return True, \"\"\n    \n    def process(self, data: Any) -> Generator[Any, None, None]:\n        \"\"\"Process data through this step with validation.\n        \n        Args:\n            data: Input data to process.\n            \n        Yields:\n            Processed records or QuarantineRecord signals.\n        \"\"\"\n        # Handle different input types\n        if isinstance(data, dict):\n            records = [data]\n        elif isinstance(data, list):\n            records = data\n        elif hasattr(data, '__iter__'):\n            records = list(data)\n        else:\n            records = [data]\n        \n        for record in records:\n            # Validate before transformation\n            if isinstance(record, dict) and self.validators:\n                is_valid, error = self.validate_record(record)\n                if not is_valid:\n                    yield QuarantineRecord(record, error)\n                    continue\n            \n            # Apply transformation\n            result = self.transform(record)\n            if result is not None:\n                yield result\n    \n    @abstractmethod\n    def transform(self, record: Any) -> Any:\n        \"\"\"Transform a single record.\n        \n        Args:\n            record: The record to transform.\n            \n        Returns:\n            The transformed record.\n        \"\"\"\n        pass\n\n\n# Import Tuple for type hints\nfrom typing import Tuple\n\n\nclass IdentityStep(BaseStep):\n    \"\"\"A step that passes data through unchanged.\"\"\"\n    \n    def __init__(self, name: str = \"identity\", validators: Optional[List[DataQualityValidator]] = None):\n        super().__init__(name, validators)\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Return the record unchanged.\"\"\"\n        return record\n\n\nclass MapStep(BaseStep):\n    \"\"\"A step that applies a mapping function to each record.\"\"\"\n    \n    def __init__(self, name: str, map_func: callable, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the map step.\n        \n        Args:\n            name: The name of this step.\n            map_func: A function to apply to each record.\n            validators: Optional list of data quality validators.\n        \"\"\"\n        super().__init__(name, validators)\n        self.map_func = map_func\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Apply the mapping function to the record.\"\"\"\n        return self.map_func(record)\n\n\nclass FilterStep(BaseStep):\n    \"\"\"A step that filters records based on a predicate.\"\"\"\n    \n    def __init__(self, name: str, predicate: callable, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the filter step.\n        \n        Args:\n            name: The name of this step.\n            predicate: A function that returns True for records to keep.\n            validators: Optional list of data quality validators.\n        \"\"\"\n        super().__init__(name, validators)\n        self.predicate = predicate\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Filter the record based on the predicate.\"\"\"\n        if self.predicate(record):\n            return record\n        return None\n\n\nclass AddFieldStep(BaseStep):\n    \"\"\"A step that adds a new field to each record.\"\"\"\n    \n    def __init__(self, name: str, field_name: str, field_value: Any, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the add field step.\n        \n        Args:\n            name: The name of this step.\n            field_name: The name of the field to add.\n            field_value: The value to set (can be a callable).\n            validators: Optional list of data quality validators.\n        \"\"\"\n        super().__init__(name, validators)\n        self.field_name = field_name\n        self.field_value = field_value\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Add the field to the record.\"\"\"\n        if isinstance(record, dict):\n            record = record.copy()\n            if callable(self.field_value):\n                record[self.field_name] = self.field_value(record)\n            else:\n                record[self.field_name] = self.field_value\n        return record\n",
          "timestack/storage.py": "\"\"\"Storage backends for TimeStack Warehouse.\"\"\"\n\nimport json\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\n\nclass Storage(ABC):\n    \"\"\"Abstract base class for storage backends.\"\"\"\n    \n    @abstractmethod\n    def write(self, path: str, data: Any) -> None:\n        \"\"\"Write data to storage.\n        \n        Args:\n            path: The path to write to.\n            data: The data to write.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def read(self, path: str) -> Any:\n        \"\"\"Read data from storage.\n        \n        Args:\n            path: The path to read from.\n            \n        Returns:\n            The data read from storage.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists in storage.\n        \n        Args:\n            path: The path to check.\n            \n        Returns:\n            True if the path exists, False otherwise.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def list_files(self, path: str) -> List[str]:\n        \"\"\"List files in a directory.\n        \n        Args:\n            path: The directory path.\n            \n        Returns:\n            List of file paths.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def write_quarantine(self, pipeline_name: str, run_id: str, record: dict, error: str) -> str:\n        \"\"\"Write a quarantined record to storage.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            record: The original record that failed validation.\n            error: The error message explaining the failure.\n            \n        Returns:\n            The path where the quarantined record was written.\n        \"\"\"\n        pass\n\n\nclass LocalStorage(Storage):\n    \"\"\"Local filesystem storage backend.\"\"\"\n    \n    def __init__(self, base_path: str = \"./data\"):\n        \"\"\"Initialize local storage.\n        \n        Args:\n            base_path: The base directory for storage.\n        \"\"\"\n        self.base_path = Path(base_path)\n        self.base_path.mkdir(parents=True, exist_ok=True)\n    \n    def _get_full_path(self, path: str) -> Path:\n        \"\"\"Get the full path including base path.\"\"\"\n        return self.base_path / path\n    \n    def write(self, path: str, data: Any) -> None:\n        \"\"\"Write data to a local file.\"\"\"\n        full_path = self._get_full_path(path)\n        full_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        with open(full_path, 'w') as f:\n            if isinstance(data, (dict, list)):\n                json.dump(data, f, indent=2, default=str)\n            else:\n                f.write(str(data))\n    \n    def read(self, path: str) -> Any:\n        \"\"\"Read data from a local file.\"\"\"\n        full_path = self._get_full_path(path)\n        \n        with open(full_path, 'r') as f:\n            content = f.read()\n            try:\n                return json.loads(content)\n            except json.JSONDecodeError:\n                return content\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a local path exists.\"\"\"\n        return self._get_full_path(path).exists()\n    \n    def list_files(self, path: str) -> List[str]:\n        \"\"\"List files in a local directory.\"\"\"\n        full_path = self._get_full_path(path)\n        if not full_path.exists():\n            return []\n        \n        files = []\n        for item in full_path.iterdir():\n            if item.is_file():\n                files.append(str(item.relative_to(self.base_path)))\n        return files\n    \n    def write_quarantine(self, pipeline_name: str, run_id: str, record: dict, error: str) -> str:\n        \"\"\"Write a quarantined record to storage.\"\"\"\n        # Generate unique filename\n        record_id = str(uuid.uuid4())\n        quarantine_path = f\"quarantine/{pipeline_name}/{run_id}/{record_id}.json\"\n        \n        # Create quarantine data structure\n        quarantine_data = {\n            \"original_record\": record,\n            \"error\": error\n        }\n        \n        self.write(quarantine_path, quarantine_data)\n        return quarantine_path\n    \n    def get_quarantine_path(self, pipeline_name: str, run_id: str) -> str:\n        \"\"\"Get the quarantine directory path for a pipeline run.\"\"\"\n        return f\"quarantine/{pipeline_name}/{run_id}\"\n\n\nclass InMemoryStorage(Storage):\n    \"\"\"In-memory storage backend for testing.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize in-memory storage.\"\"\"\n        self._data: Dict[str, Any] = {}\n    \n    def write(self, path: str, data: Any) -> None:\n        \"\"\"Write data to memory.\"\"\"\n        self._data[path] = data\n    \n    def read(self, path: str) -> Any:\n        \"\"\"Read data from memory.\"\"\"\n        if path not in self._data:\n            raise FileNotFoundError(f\"Path not found: {path}\")\n        return self._data[path]\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists in memory.\"\"\"\n        return path in self._data\n    \n    def list_files(self, path: str) -> List[str]:\n        \"\"\"List files under a path prefix.\"\"\"\n        prefix = path.rstrip('/') + '/'\n        return [k for k in self._data.keys() if k.startswith(prefix)]\n    \n    def write_quarantine(self, pipeline_name: str, run_id: str, record: dict, error: str) -> str:\n        \"\"\"Write a quarantined record to memory.\"\"\"\n        record_id = str(uuid.uuid4())\n        quarantine_path = f\"quarantine/{pipeline_name}/{run_id}/{record_id}.json\"\n        \n        quarantine_data = {\n            \"original_record\": record,\n            \"error\": error\n        }\n        \n        self.write(quarantine_path, quarantine_data)\n        return quarantine_path\n    \n    def get_quarantine_path(self, pipeline_name: str, run_id: str) -> str:\n        \"\"\"Get the quarantine directory path for a pipeline run.\"\"\"\n        return f\"quarantine/{pipeline_name}/{run_id}\"\n    \n    def clear(self) -> None:\n        \"\"\"Clear all stored data.\"\"\"\n        self._data.clear()\n",
          "timestack/observers.py": "\"\"\"Pipeline observers for monitoring and logging.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\nimport logging\n\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass PipelineObserver(ABC):\n    \"\"\"Abstract base class for pipeline observers.\"\"\"\n    \n    def on_pipeline_start(self, pipeline_name: str, run_id: str) -> None:\n        \"\"\"Called when a pipeline starts.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n        \"\"\"\n        pass\n    \n    def on_pipeline_end(self, pipeline_name: str, run_id: str, success: bool) -> None:\n        \"\"\"Called when a pipeline ends.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            success: Whether the pipeline completed successfully.\n        \"\"\"\n        pass\n    \n    def on_step_start(self, step_name: str, pipeline_name: str, run_id: str) -> None:\n        \"\"\"Called when a step starts.\n        \n        Args:\n            step_name: The name of the step.\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n        \"\"\"\n        pass\n    \n    def on_step_end(self, step_name: str, pipeline_name: str, run_id: str, success: bool) -> None:\n        \"\"\"Called when a step ends.\n        \n        Args:\n            step_name: The name of the step.\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            success: Whether the step completed successfully.\n        \"\"\"\n        pass\n    \n    def on_record_processed(self, step_name: str, record: Any) -> None:\n        \"\"\"Called when a record is processed.\n        \n        Args:\n            step_name: The name of the step.\n            record: The processed record.\n        \"\"\"\n        pass\n    \n    def on_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        \"\"\"Called when an error occurs.\n        \n        Args:\n            error: The exception that occurred.\n            context: Additional context about the error.\n        \"\"\"\n        pass\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        \"\"\"Called when a record is quarantined.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            record: The original record that failed validation.\n            error: The error message explaining why validation failed.\n        \"\"\"\n        pass\n\n\nclass LoggingObserver(PipelineObserver):\n    \"\"\"Observer that logs pipeline events.\"\"\"\n    \n    def __init__(self, log_level: int = logging.INFO):\n        \"\"\"Initialize the logging observer.\n        \n        Args:\n            log_level: The logging level to use.\n        \"\"\"\n        self.log_level = log_level\n    \n    def on_pipeline_start(self, pipeline_name: str, run_id: str) -> None:\n        logger.log(self.log_level, f\"Pipeline '{pipeline_name}' started (run_id: {run_id})\")\n    \n    def on_pipeline_end(self, pipeline_name: str, run_id: str, success: bool) -> None:\n        status = \"successfully\" if success else \"with errors\"\n        logger.log(self.log_level, f\"Pipeline '{pipeline_name}' completed {status} (run_id: {run_id})\")\n    \n    def on_step_start(self, step_name: str, pipeline_name: str, run_id: str) -> None:\n        logger.log(self.log_level, f\"Step '{step_name}' started in pipeline '{pipeline_name}'\")\n    \n    def on_step_end(self, step_name: str, pipeline_name: str, run_id: str, success: bool) -> None:\n        status = \"successfully\" if success else \"with errors\"\n        logger.log(self.log_level, f\"Step '{step_name}' completed {status}\")\n    \n    def on_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        logger.error(f\"Error occurred: {error}. Context: {context}\")\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        logger.warning(f\"Record quarantined in pipeline '{pipeline_name}' (run_id: {run_id}): {error}\")\n\n\nclass QuarantineObserver(PipelineObserver):\n    \"\"\"Observer specifically for monitoring quarantined records.\"\"\"\n    \n    def __init__(self, verbose: bool = True):\n        \"\"\"Initialize the quarantine observer.\n        \n        Args:\n            verbose: If True, log full record details.\n        \"\"\"\n        self.verbose = verbose\n        self.quarantine_count = 0\n        self.quarantined_records: List[Dict[str, Any]] = []\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        \"\"\"Log quarantined record details to the console.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            record: The original record that failed validation.\n            error: The error message explaining why validation failed.\n        \"\"\"\n        self.quarantine_count += 1\n        self.quarantined_records.append({\n            \"pipeline_name\": pipeline_name,\n            \"run_id\": run_id,\n            \"record\": record,\n            \"error\": error,\n            \"timestamp\": datetime.now().isoformat()\n        })\n        \n        print(f\"[QUARANTINE] Pipeline: {pipeline_name} | Run: {run_id}\")\n        print(f\"[QUARANTINE] Error: {error}\")\n        if self.verbose:\n            print(f\"[QUARANTINE] Record: {record}\")\n        print(f\"[QUARANTINE] Total quarantined this session: {self.quarantine_count}\")\n        print(\"-\" * 60)\n    \n    def get_quarantine_count(self) -> int:\n        \"\"\"Get the total number of quarantined records.\"\"\"\n        return self.quarantine_count\n    \n    def get_quarantined_records(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all quarantined records observed.\"\"\"\n        return self.quarantined_records.copy()\n    \n    def reset(self) -> None:\n        \"\"\"Reset the quarantine count and records.\"\"\"\n        self.quarantine_count = 0\n        self.quarantined_records.clear()\n\n\nclass MetricsObserver(PipelineObserver):\n    \"\"\"Observer that collects metrics about pipeline execution.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the metrics observer.\"\"\"\n        self.metrics: Dict[str, Any] = {\n            \"pipelines\": {},\n            \"total_records_processed\": 0,\n            \"total_records_quarantined\": 0,\n            \"errors\": []\n        }\n    \n    def on_pipeline_start(self, pipeline_name: str, run_id: str) -> None:\n        if pipeline_name not in self.metrics[\"pipelines\"]:\n            self.metrics[\"pipelines\"][pipeline_name] = {\n                \"runs\": [],\n                \"total_runs\": 0\n            }\n        self.metrics[\"pipelines\"][pipeline_name][\"runs\"].append({\n            \"run_id\": run_id,\n            \"start_time\": datetime.now().isoformat(),\n            \"end_time\": None,\n            \"success\": None,\n            \"records_processed\": 0,\n            \"records_quarantined\": 0\n        })\n    \n    def on_pipeline_end(self, pipeline_name: str, run_id: str, success: bool) -> None:\n        if pipeline_name in self.metrics[\"pipelines\"]:\n            for run in self.metrics[\"pipelines\"][pipeline_name][\"runs\"]:\n                if run[\"run_id\"] == run_id:\n                    run[\"end_time\"] = datetime.now().isoformat()\n                    run[\"success\"] = success\n                    break\n            self.metrics[\"pipelines\"][pipeline_name][\"total_runs\"] += 1\n    \n    def on_record_processed(self, step_name: str, record: Any) -> None:\n        self.metrics[\"total_records_processed\"] += 1\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        self.metrics[\"total_records_quarantined\"] += 1\n        if pipeline_name in self.metrics[\"pipelines\"]:\n            for run in self.metrics[\"pipelines\"][pipeline_name][\"runs\"]:\n                if run[\"run_id\"] == run_id:\n                    run[\"records_quarantined\"] += 1\n                    break\n    \n    def on_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        self.metrics[\"errors\"].append({\n            \"error\": str(error),\n            \"context\": context,\n            \"timestamp\": datetime.now().isoformat()\n        })\n    \n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get all collected metrics.\"\"\"\n        return self.metrics.copy()\n",
          "timestack/pipeline.py": "\"\"\"Pipeline orchestration for TimeStack Warehouse.\"\"\"\n\nimport uuid\nfrom datetime import datetime\nfrom typing import Any, Dict, Generator, List, Optional\n\nfrom timestack.steps import BaseStep\nfrom timestack.storage import Storage, LocalStorage\nfrom timestack.observers import PipelineObserver\nfrom timestack.validators import QuarantineRecord\n\n\nclass Pipeline:\n    \"\"\"A data processing pipeline.\"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        steps: Optional[List[BaseStep]] = None,\n        storage: Optional[Storage] = None,\n        observers: Optional[List[PipelineObserver]] = None\n    ):\n        \"\"\"Initialize the pipeline.\n        \n        Args:\n            name: The name of the pipeline.\n            steps: List of processing steps.\n            storage: Storage backend for output.\n            observers: List of observers for monitoring.\n        \"\"\"\n        self.name = name\n        self.steps = steps or []\n        self.storage = storage or LocalStorage()\n        self.observers = observers or []\n        self.run_id: Optional[str] = None\n    \n    def add_step(self, step: BaseStep) -> 'Pipeline':\n        \"\"\"Add a step to the pipeline.\n        \n        Args:\n            step: The step to add.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.steps.append(step)\n        return self\n    \n    def add_observer(self, observer: PipelineObserver) -> 'Pipeline':\n        \"\"\"Add an observer to the pipeline.\n        \n        Args:\n            observer: The observer to add.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.observers.append(observer)\n        return self\n    \n    def _notify_observers(self, method: str, *args, **kwargs) -> None:\n        \"\"\"Notify all observers of an event.\n        \n        Args:\n            method: The observer method to call.\n            *args: Positional arguments to pass.\n            **kwargs: Keyword arguments to pass.\n        \"\"\"\n        for observer in self.observers:\n            if hasattr(observer, method):\n                getattr(observer, method)(*args, **kwargs)\n    \n    def _handle_quarantine(self, quarantine_record: QuarantineRecord) -> None:\n        \"\"\"Handle a quarantined record.\n        \n        Args:\n            quarantine_record: The quarantine record to handle.\n        \"\"\"\n        # Write to quarantine storage\n        self.storage.write_quarantine(\n            pipeline_name=self.name,\n            run_id=self.run_id,\n            record=quarantine_record.original_record,\n            error=quarantine_record.error\n        )\n        \n        # Notify observers\n        self._notify_observers(\n            'on_record_quarantined',\n            pipeline_name=self.name,\n            run_id=self.run_id,\n            record=quarantine_record.original_record,\n            error=quarantine_record.error\n        )\n    \n    def run(self, input_data: Any, output_path: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Run the pipeline on input data.\n        \n        Args:\n            input_data: The input data to process.\n            output_path: Optional path to write output.\n            \n        Returns:\n            A dictionary with run results.\n        \"\"\"\n        self.run_id = str(uuid.uuid4())\n        start_time = datetime.now()\n        success = True\n        processed_records = []\n        quarantined_count = 0\n        \n        try:\n            # Notify pipeline start\n            self._notify_observers('on_pipeline_start', self.name, self.run_id)\n            \n            # Prepare initial data\n            if isinstance(input_data, dict):\n                current_data = [input_data]\n            elif isinstance(input_data, list):\n                current_data = input_data\n            else:\n                current_data = list(input_data) if hasattr(input_data, '__iter__') else [input_data]\n            \n            # Process through each step\n            for step in self.steps:\n                self._notify_observers('on_step_start', step.name, self.name, self.run_id)\n                \n                step_success = True\n                next_data = []\n                \n                try:\n                    for record in current_data:\n                        # Skip if already a quarantine record (shouldn't happen, but safety check)\n                        if isinstance(record, QuarantineRecord):\n                            self._handle_quarantine(record)\n                            quarantined_count += 1\n                            continue\n                        \n                        # Process the record through the step\n                        for result in step.process(record):\n                            if isinstance(result, QuarantineRecord):\n                                # Handle quarantine\n                                self._handle_quarantine(result)\n                                quarantined_count += 1\n                            else:\n                                # Valid record, pass to next step\n                                next_data.append(result)\n                                self._notify_observers('on_record_processed', step.name, result)\n                \n                except Exception as e:\n                    step_success = False\n                    success = False\n                    self._notify_observers('on_error', e, {\n                        'step': step.name,\n                        'pipeline': self.name,\n                        'run_id': self.run_id\n                    })\n                    raise\n                \n                finally:\n                    self._notify_observers('on_step_end', step.name, self.name, self.run_id, step_success)\n                \n                current_data = next_data\n            \n            processed_records = current_data\n            \n            # Write output if path specified\n            if output_path and processed_records:\n                self.storage.write(output_path, processed_records)\n        \n        except Exception as e:\n            success = False\n            self._notify_observers('on_error', e, {\n                'pipeline': self.name,\n                'run_id': self.run_id\n            })\n            raise\n        \n        finally:\n            self._notify_observers('on_pipeline_end', self.name, self.run_id, success)\n        \n        end_time = datetime.now()\n        \n        return {\n            'run_id': self.run_id,\n            'pipeline_name': self.name,\n            'success': success,\n            'start_time': start_time.isoformat(),\n            'end_time': end_time.isoformat(),\n            'duration_seconds': (end_time - start_time).total_seconds(),\n            'records_processed': len(processed_records),\n            'records_quarantined': quarantined_count,\n            'output_path': output_path,\n            'output_data': processed_records\n        }\n\n\nclass PipelineBuilder:\n    \"\"\"Builder class for constructing pipelines.\"\"\"\n    \n    def __init__(self, name: str):\n        \"\"\"Initialize the builder.\n        \n        Args:\n            name: The name of the pipeline to build.\n        \"\"\"\n        self.name = name\n        self.steps: List[BaseStep] = []\n        self.storage: Optional[Storage] = None\n        self.observers: List[PipelineObserver] = []\n    \n    def with_step(self, step: BaseStep) -> 'PipelineBuilder':\n        \"\"\"Add a step to the pipeline.\"\"\"\n        self.steps.append(step)\n        return self\n    \n    def with_storage(self, storage: Storage) -> 'PipelineBuilder':\n        \"\"\"Set the storage backend.\"\"\"\n        self.storage = storage\n        return self\n    \n    def with_observer(self, observer: PipelineObserver) -> 'PipelineBuilder':\n        \"\"\"Add an observer.\"\"\"\n        self.observers.append(observer)\n        return self\n    \n    def build(self) -> Pipeline:\n        \"\"\"Build and return the pipeline.\"\"\"\n        return Pipeline(\n            name=self.name,\n            steps=self.steps,\n            storage=self.storage,\n            observers=self.observers\n        )\n",
          "timestack/__init__.py": "\"\"\"TimeStack Warehouse - A data pipeline framework with data quality controls.\"\"\"\n\nfrom timestack.pipeline import Pipeline, PipelineBuilder\nfrom timestack.steps import BaseStep, IdentityStep, MapStep, FilterStep, AddFieldStep\nfrom timestack.storage import Storage, LocalStorage, InMemoryStorage\nfrom timestack.observers import (\n    PipelineObserver,\n    LoggingObserver,\n    QuarantineObserver,\n    MetricsObserver\n)\nfrom timestack.validators import (\n    DataQualityValidator,\n    NotNullValidator,\n    FieldTypeValidator,\n    QuarantineRecord\n)\n\n__version__ = \"0.2.0\"\n\n__all__ = [\n    # Pipeline\n    \"Pipeline\",\n    \"PipelineBuilder\",\n    # Steps\n    \"BaseStep\",\n    \"IdentityStep\",\n    \"MapStep\",\n    \"FilterStep\",\n    \"AddFieldStep\",\n    # Storage\n    \"Storage\",\n    \"LocalStorage\",\n    \"InMemoryStorage\",\n    # Observers\n    \"PipelineObserver\",\n    \"LoggingObserver\",\n    \"QuarantineObserver\",\n    \"MetricsObserver\",\n    # Validators\n    \"DataQualityValidator\",\n    \"NotNullValidator\",\n    \"FieldTypeValidator\",\n    \"QuarantineRecord\",\n]\n",
          "main.py": "\"\"\"Main entry point demonstrating TimeStack Warehouse with Data Quality Gates.\"\"\"\n\nfrom timestack import (\n    Pipeline,\n    PipelineBuilder,\n    MapStep,\n    IdentityStep,\n    LocalStorage,\n    LoggingObserver,\n    QuarantineObserver,\n    NotNullValidator,\n    FieldTypeValidator\n)\n\n\ndef main():\n    \"\"\"Demonstrate the data quality and quarantine system.\"\"\"\n    \n    print(\"=\" * 60)\n    print(\"TimeStack Warehouse - Data Quality Gates Demo\")\n    print(\"=\" * 60)\n    \n    # Sample data with some invalid records\n    input_data = [\n        {\"user_id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\", \"age\": 30},\n        {\"user_id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\", \"age\": 25},\n        {\"user_id\": None, \"name\": \"Charlie\", \"email\": \"charlie@example.com\", \"age\": 35},  # Invalid: null user_id\n        {\"user_id\": 4, \"name\": \"Diana\", \"email\": \"diana@example.com\", \"age\": \"twenty-eight\"},  # Invalid: wrong type for age\n        {\"user_id\": 5, \"name\": \"Eve\", \"email\": \"eve@example.com\", \"age\": 22},\n        {\"name\": \"Frank\", \"email\": \"frank@example.com\", \"age\": 40},  # Invalid: missing user_id\n    ]\n    \n    print(f\"\nInput data: {len(input_data)} records\")\n    print(\"-\" * 40)\n    \n    # Create validators\n    validators = [\n        NotNullValidator(\"user_id\"),\n        FieldTypeValidator(\"age\", int)\n    ]\n    \n    # Create a step with validators\n    validated_step = IdentityStep(name=\"validate_users\", validators=validators)\n    \n    # Create a transformation step\n    def enrich_user(record):\n        record = record.copy()\n        record[\"processed\"] = True\n        record[\"full_info\"] = f\"{record['name']} ({record['email']})\"\n        return record\n    \n    transform_step = MapStep(name=\"enrich_users\", map_func=enrich_user)\n    \n    # Create observers\n    logging_observer = LoggingObserver()\n    quarantine_observer = QuarantineObserver(verbose=True)\n    \n    # Build the pipeline\n    pipeline = (\n        PipelineBuilder(\"user_processing_pipeline\")\n        .with_step(validated_step)\n        .with_step(transform_step)\n        .with_storage(LocalStorage(\"./demo_output\"))\n        .with_observer(logging_observer)\n        .with_observer(quarantine_observer)\n        .build()\n    )\n    \n    print(\"\nRunning pipeline...\")\n    print(\"=\" * 60)\n    \n    # Run the pipeline\n    result = pipeline.run(\n        input_data=input_data,\n        output_path=\"processed_users.json\"\n    )\n    \n    # Print results\n    print(\"\n\" + \"=\" * 60)\n    print(\"Pipeline Execution Summary\")\n    print(\"=\" * 60)\n    print(f\"Run ID: {result['run_id']}\")\n    print(f\"Success: {result['success']}\")\n    print(f\"Duration: {result['duration_seconds']:.3f} seconds\")\n    print(f\"Records Processed: {result['records_processed']}\")\n    print(f\"Records Quarantined: {result['records_quarantined']}\")\n    print(f\"Output Path: {result['output_path']}\")\n    \n    print(\"\n\" + \"-\" * 40)\n    print(\"Processed Records:\")\n    print(\"-\" * 40)\n    for record in result['output_data']:\n        print(f\"  - {record['name']}: user_id={record['user_id']}, age={record['age']}\")\n    \n    print(\"\n\" + \"-\" * 40)\n    print(f\"Quarantine Observer Stats:\")\n    print(\"-\" * 40)\n    print(f\"  Total quarantined: {quarantine_observer.get_quarantine_count()}\")\n    \n    print(\"\n\" + \"=\" * 60)\n    print(\"Demo completed successfully!\")\n    print(\"=\" * 60)\n\n\nif __name__ == \"__main__\":\n    main()\n",
          "tests/test_pipeline.py": "\"\"\"Tests for the TimeStack pipeline with data quality gates.\"\"\"\n\nimport pytest\nimport os\nimport shutil\nfrom typing import List\n\nfrom timestack import (\n    Pipeline,\n    PipelineBuilder,\n    BaseStep,\n    IdentityStep,\n    MapStep,\n    FilterStep,\n    LocalStorage,\n    InMemoryStorage,\n    LoggingObserver,\n    QuarantineObserver,\n    NotNullValidator,\n    FieldTypeValidator,\n    DataQualityValidator,\n    QuarantineRecord\n)\n\n\nclass TestValidators:\n    \"\"\"Tests for data quality validators.\"\"\"\n    \n    def test_not_null_validator_valid(self):\n        \"\"\"Test NotNullValidator with valid data.\"\"\"\n        validator = NotNullValidator(\"user_id\")\n        record = {\"user_id\": 123, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is True\n        assert error == \"\"\n    \n    def test_not_null_validator_null_value(self):\n        \"\"\"Test NotNullValidator with null value.\"\"\"\n        validator = NotNullValidator(\"user_id\")\n        record = {\"user_id\": None, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"user_id\" in error\n        assert \"None\" in error\n    \n    def test_not_null_validator_missing_field(self):\n        \"\"\"Test NotNullValidator with missing field.\"\"\"\n        validator = NotNullValidator(\"user_id\")\n        record = {\"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"missing\" in error.lower()\n    \n    def test_field_type_validator_valid(self):\n        \"\"\"Test FieldTypeValidator with valid data.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"age\": 25, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is True\n        assert error == \"\"\n    \n    def test_field_type_validator_wrong_type(self):\n        \"\"\"Test FieldTypeValidator with wrong type.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"age\": \"twenty-five\", \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"age\" in error\n        assert \"int\" in error\n    \n    def test_field_type_validator_allows_none(self):\n        \"\"\"Test FieldTypeValidator allows None values.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"age\": None, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is True  # None passes type check\n    \n    def test_field_type_validator_missing_field(self):\n        \"\"\"Test FieldTypeValidator with missing field.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"missing\" in error.lower()\n\n\nclass TestStepsWithValidators:\n    \"\"\"Tests for steps with validators.\"\"\"\n    \n    def test_step_with_validators_valid_record(self):\n        \"\"\"Test step processes valid records normally.\"\"\"\n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"test_step\", validators=validators)\n        \n        record = {\"id\": 1, \"value\": \"test\"}\n        results = list(step.process(record))\n        \n        assert len(results) == 1\n        assert results[0] == record\n    \n    def test_step_with_validators_invalid_record(self):\n        \"\"\"Test step yields QuarantineRecord for invalid records.\"\"\"\n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"test_step\", validators=validators)\n        \n        record = {\"id\": None, \"value\": \"test\"}\n        results = list(step.process(record))\n        \n        assert len(results) == 1\n        assert isinstance(results[0], QuarantineRecord)\n        assert results[0].original_record == record\n        assert \"id\" in results[0].error\n    \n    def test_step_with_multiple_validators(self):\n        \"\"\"Test step with multiple validators.\"\"\"\n        validators = [\n            NotNullValidator(\"id\"),\n            FieldTypeValidator(\"count\", int)\n        ]\n        step = IdentityStep(\"test_step\", validators=validators)\n        \n        # Valid record\n        valid_record = {\"id\": 1, \"count\": 10}\n        results = list(step.process(valid_record))\n        assert len(results) == 1\n        assert not isinstance(results[0], QuarantineRecord)\n        \n        # Invalid - null id\n        invalid_record1 = {\"id\": None, \"count\": 10}\n        results = list(step.process(invalid_record1))\n        assert isinstance(results[0], QuarantineRecord)\n        \n        # Invalid - wrong type\n        invalid_record2 = {\"id\": 2, \"count\": \"ten\"}\n        results = list(step.process(invalid_record2))\n        assert isinstance(results[0], QuarantineRecord)\n\n\nclass TestPipelineBasics:\n    \"\"\"Basic pipeline tests.\"\"\"\n    \n    def test_pipeline_creation(self):\n        \"\"\"Test basic pipeline creation.\"\"\"\n        pipeline = Pipeline(name=\"test_pipeline\")\n        assert pipeline.name == \"test_pipeline\"\n        assert len(pipeline.steps) == 0\n    \n    def test_pipeline_add_step(self):\n        \"\"\"Test adding steps to pipeline.\"\"\"\n        pipeline = Pipeline(name=\"test_pipeline\")\n        step = IdentityStep(\"step1\")\n        pipeline.add_step(step)\n        assert len(pipeline.steps) == 1\n    \n    def test_pipeline_builder(self):\n        \"\"\"Test pipeline builder pattern.\"\"\"\n        pipeline = (\n            PipelineBuilder(\"test_pipeline\")\n            .with_step(IdentityStep(\"step1\"))\n            .with_step(IdentityStep(\"step2\"))\n            .build()\n        )\n        assert pipeline.name == \"test_pipeline\"\n        assert len(pipeline.steps) == 2\n    \n    def test_pipeline_run_simple(self):\n        \"\"\"Test simple pipeline run.\"\"\"\n        pipeline = Pipeline(name=\"test_pipeline\")\n        pipeline.add_step(IdentityStep(\"identity\"))\n        \n        result = pipeline.run([{\"id\": 1}, {\"id\": 2}])\n        \n        assert result[\"success\"] is True\n        assert result[\"records_processed\"] == 2\n        assert len(result[\"output_data\"]) == 2\n\n\nclass TestPipelineWithDataQuarantine:\n    \"\"\"Tests for pipeline data quarantine functionality.\"\"\"\n    \n    def setup_method(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_output_dir = \"./test_quarantine_output\"\n        if os.path.exists(self.test_output_dir):\n            shutil.rmtree(self.test_output_dir)\n    \n    def teardown_method(self):\n        \"\"\"Clean up after tests.\"\"\"\n        if os.path.exists(self.test_output_dir):\n            shutil.rmtree(self.test_output_dir)\n    \n    def test_pipeline_with_data_quarantine(self):\n        \"\"\"Test pipeline correctly quarantines invalid records.\n        \n        This test:\n        a. Defines a pipeline with a step that uses a NotNullValidator.\n        b. Provides a mix of valid and invalid records as input.\n        c. Runs the pipeline.\n        d. Asserts that the valid records are correctly processed.\n        e. Asserts that the invalid records are NOT in the final output.\n        f. Asserts that the invalid records ARE present in the quarantine directory.\n        \"\"\"\n        # Create storage\n        storage = LocalStorage(self.test_output_dir)\n        \n        # Create quarantine observer to track quarantined records\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        # Create validators\n        validators = [NotNullValidator(\"user_id\")]\n        \n        # Create step with validators\n        validated_step = IdentityStep(name=\"validate_step\", validators=validators)\n        \n        # Build pipeline\n        pipeline = (\n            PipelineBuilder(\"test_quarantine_pipeline\")\n            .with_step(validated_step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        # Input data - mix of valid and invalid records\n        input_data = [\n            {\"user_id\": 1, \"name\": \"Alice\"},      # Valid\n            {\"user_id\": 2, \"name\": \"Bob\"},        # Valid\n            {\"user_id\": None, \"name\": \"Charlie\"}, # Invalid - null user_id\n            {\"user_id\": 3, \"name\": \"Diana\"},      # Valid\n            {\"name\": \"Eve\"},                       # Invalid - missing user_id\n        ]\n        \n        # Run pipeline\n        result = pipeline.run(\n            input_data=input_data,\n            output_path=\"output/processed.json\"\n        )\n        \n        # Assertions\n        # a. Pipeline should complete successfully\n        assert result[\"success\"] is True\n        \n        # b. Check counts\n        assert result[\"records_processed\"] == 3  # 3 valid records\n        assert result[\"records_quarantined\"] == 2  # 2 invalid records\n        \n        # c. Valid records should be in output\n        output_data = result[\"output_data\"]\n        assert len(output_data) == 3\n        \n        output_user_ids = [r[\"user_id\"] for r in output_data]\n        assert 1 in output_user_ids\n        assert 2 in output_user_ids\n        assert 3 in output_user_ids\n        \n        # d. Invalid records should NOT be in output\n        assert None not in output_user_ids\n        output_names = [r[\"name\"] for r in output_data]\n        assert \"Charlie\" not in output_names\n        assert \"Eve\" not in output_names\n        \n        # e. Check quarantine observer was notified\n        assert quarantine_observer.get_quarantine_count() == 2\n        \n        # f. Check quarantine directory exists and contains files\n        quarantine_path = storage.get_quarantine_path(\n            \"test_quarantine_pipeline\",\n            result[\"run_id\"]\n        )\n        quarantine_files = storage.list_files(quarantine_path)\n        assert len(quarantine_files) == 2\n        \n        # g. Verify quarantine file contents\n        quarantined_records = []\n        for file_path in quarantine_files:\n            data = storage.read(file_path)\n            quarantined_records.append(data)\n        \n        # Check that quarantine records have correct structure\n        for qr in quarantined_records:\n            assert \"original_record\" in qr\n            assert \"error\" in qr\n            assert \"user_id\" in qr[\"error\"].lower() or \"missing\" in qr[\"error\"].lower()\n        \n        # Check that Charlie and Eve's records are in quarantine\n        quarantined_names = [qr[\"original_record\"][\"name\"] for qr in quarantined_records]\n        assert \"Charlie\" in quarantined_names\n        assert \"Eve\" in quarantined_names\n    \n    def test_pipeline_quarantine_with_type_validator(self):\n        \"\"\"Test quarantine with FieldTypeValidator.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        validators = [\n            NotNullValidator(\"id\"),\n            FieldTypeValidator(\"count\", int)\n        ]\n        \n        step = IdentityStep(\"validate\", validators=validators)\n        \n        pipeline = (\n            PipelineBuilder(\"type_validation_pipeline\")\n            .with_step(step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": 1, \"count\": 10},        # Valid\n            {\"id\": 2, \"count\": \"twenty\"},  # Invalid - wrong type\n            {\"id\": 3, \"count\": 30},        # Valid\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 2\n        assert result[\"records_quarantined\"] == 1\n        assert quarantine_observer.get_quarantine_count() == 1\n        \n        # Check quarantine has the right record\n        quarantine_path = storage.get_quarantine_path(\n            \"type_validation_pipeline\",\n            result[\"run_id\"]\n        )\n        quarantine_files = storage.list_files(quarantine_path)\n        assert len(quarantine_files) == 1\n        \n        quarantined = storage.read(quarantine_files[0])\n        assert quarantined[\"original_record\"][\"id\"] == 2\n        assert \"count\" in quarantined[\"error\"]\n    \n    def test_pipeline_all_records_valid(self):\n        \"\"\"Test pipeline when all records are valid.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"validate\", validators=validators)\n        \n        pipeline = (\n            PipelineBuilder(\"all_valid_pipeline\")\n            .with_step(step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": 1, \"name\": \"A\"},\n            {\"id\": 2, \"name\": \"B\"},\n            {\"id\": 3, \"name\": \"C\"},\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 3\n        assert result[\"records_quarantined\"] == 0\n        assert quarantine_observer.get_quarantine_count() == 0\n    \n    def test_pipeline_all_records_invalid(self):\n        \"\"\"Test pipeline when all records are invalid.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"validate\", validators=validators)\n        \n        pipeline = (\n            PipelineBuilder(\"all_invalid_pipeline\")\n            .with_step(step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": None, \"name\": \"A\"},\n            {\"name\": \"B\"},  # Missing id\n            {\"id\": None, \"name\": \"C\"},\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 0\n        assert result[\"records_quarantined\"] == 3\n        assert quarantine_observer.get_quarantine_count() == 3\n    \n    def test_pipeline_multi_step_validation(self):\n        \"\"\"Test validation in multi-step pipeline.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        # First step validates id\n        step1 = IdentityStep(\n            \"validate_id\",\n            validators=[NotNullValidator(\"id\")]\n        )\n        \n        # Second step transforms\n        def add_processed_flag(record):\n            record = record.copy()\n            record[\"processed\"] = True\n            return record\n        \n        step2 = MapStep(\"transform\", add_processed_flag)\n        \n        # Third step validates processed flag exists\n        step3 = IdentityStep(\n            \"validate_processed\",\n            validators=[NotNullValidator(\"processed\")]\n        )\n        \n        pipeline = (\n            PipelineBuilder(\"multi_step_pipeline\")\n            .with_step(step1)\n            .with_step(step2)\n            .with_step(step3)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": 1, \"name\": \"A\"},\n            {\"id\": None, \"name\": \"B\"},  # Will be quarantined at step 1\n            {\"id\": 2, \"name\": \"C\"},\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 2\n        assert result[\"records_quarantined\"] == 1\n        \n        # Verify processed records have the flag\n        for record in result[\"output_data\"]:\n            assert record[\"processed\"] is True\n\n\nclass TestQuarantineObserver:\n    \"\"\"Tests for QuarantineObserver.\"\"\"\n    \n    def test_observer_tracks_quarantined_records(self):\n        \"\"\"Test observer correctly tracks quarantined records.\"\"\"\n        observer = QuarantineObserver(verbose=False)\n        \n        observer.on_record_quarantined(\n            \"test_pipeline\",\n            \"run-123\",\n            {\"id\": 1, \"name\": \"Test\"},\n            \"Field 'id' cannot be None.\"\n        )\n        \n        assert observer.get_quarantine_count() == 1\n        records = observer.get_quarantined_records()\n        assert len(records) == 1\n        assert records[0][\"pipeline_name\"] == \"test_pipeline\"\n        assert records[0][\"run_id\"] == \"run-123\"\n    \n    def test_observer_reset(self):\n        \"\"\"Test observer reset functionality.\"\"\"\n        observer = QuarantineObserver(verbose=False)\n        \n        observer.on_record_quarantined(\n            \"test\", \"run-1\", {\"id\": 1}, \"error\"\n        )\n        observer.on_record_quarantined(\n            \"test\", \"run-1\", {\"id\": 2}, \"error\"\n        )\n        \n        assert observer.get_quarantine_count() == 2\n        \n        observer.reset()\n        \n        assert observer.get_quarantine_count() == 0\n        assert len(observer.get_quarantined_records()) == 0\n\n\nclass TestStorage:\n    \"\"\"Tests for storage with quarantine support.\"\"\"\n    \n    def test_in_memory_storage_quarantine(self):\n        \"\"\"Test InMemoryStorage quarantine functionality.\"\"\"\n        storage = InMemoryStorage()\n        \n        path = storage.write_quarantine(\n            \"test_pipeline\",\n            \"run-123\",\n            {\"id\": 1, \"name\": \"Test\"},\n            \"Validation error\"\n        )\n        \n        assert storage.exists(path)\n        data = storage.read(path)\n        assert data[\"original_record\"][\"id\"] == 1\n        assert data[\"error\"] == \"Validation error\"\n    \n    def test_local_storage_quarantine(self):\n        \"\"\"Test LocalStorage quarantine functionality.\"\"\"\n        test_dir = \"./test_storage_quarantine\"\n        try:\n            storage = LocalStorage(test_dir)\n            \n            path = storage.write_quarantine(\n                \"test_pipeline\",\n                \"run-456\",\n                {\"id\": 2, \"name\": \"Test2\"},\n                \"Another error\"\n            )\n            \n            assert storage.exists(path)\n            data = storage.read(path)\n            assert data[\"original_record\"][\"id\"] == 2\n            assert data[\"error\"] == \"Another error\"\n        finally:\n            if os.path.exists(test_dir):\n                shutil.rmtree(test_dir)\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])\n",
          "README.md": "# TimeStack Warehouse\n\nA robust data pipeline framework with pluggable data quality gates and quarantine mechanisms.\n\n## Features\n\n- **Modular Pipeline Architecture**: Build data pipelines with reusable, composable steps\n- **Data Quality Validators**: Pluggable validation system to ensure data integrity\n- **Quarantine Mechanism**: Isolate invalid records for later inspection without halting pipelines\n- **Observer Pattern**: Monitor pipeline execution with customizable observers\n- **Flexible Storage**: Support for local filesystem and in-memory storage backends\n\n## Installation\n\n```bash\npip install -e .\n```\n\n## Quick Start\n\n```python\nfrom timestack import (\n    Pipeline,\n    PipelineBuilder,\n    IdentityStep,\n    MapStep,\n    LocalStorage,\n    QuarantineObserver,\n    NotNullValidator,\n    FieldTypeValidator\n)\n\n# Define validators\nvalidators = [\n    NotNullValidator(\"user_id\"),\n    FieldTypeValidator(\"age\", int)\n]\n\n# Create a step with validators\nvalidated_step = IdentityStep(name=\"validate\", validators=validators)\n\n# Build the pipeline\npipeline = (\n    PipelineBuilder(\"my_pipeline\")\n    .with_step(validated_step)\n    .with_storage(LocalStorage(\"./output\"))\n    .with_observer(QuarantineObserver())\n    .build()\n)\n\n# Run with mixed data\ndata = [\n    {\"user_id\": 1, \"name\": \"Alice\", \"age\": 30},  # Valid\n    {\"user_id\": None, \"name\": \"Bob\", \"age\": 25}, # Invalid - null user_id\n    {\"user_id\": 2, \"name\": \"Charlie\", \"age\": \"old\"}, # Invalid - wrong type\n]\n\nresult = pipeline.run(data, output_path=\"processed.json\")\n\nprint(f\"Processed: {result['records_processed']}\")\nprint(f\"Quarantined: {result['records_quarantined']}\")\n```\n\n## Data Quality Validators\n\n### Built-in Validators\n\n- **NotNullValidator(field)**: Ensures a field exists and is not None\n- **FieldTypeValidator(field, expected_type)**: Ensures a field has the correct Python type\n\n### Custom Validators\n\nCreate custom validators by extending `DataQualityValidator`:\n\n```python\nfrom timestack import DataQualityValidator\n\nclass RangeValidator(DataQualityValidator):\n    def __init__(self, field: str, min_val: float, max_val: float):\n        self.field = field\n        self.min_val = min_val\n        self.max_val = max_val\n    \n    def validate(self, record: dict) -> tuple[bool, str]:\n        value = record.get(self.field)\n        if value is None:\n            return True, \"\"  # Let NotNullValidator handle this\n        if not (self.min_val <= value <= self.max_val):\n            return False, f\"Field '{self.field}' value {value} not in range [{self.min_val}, {self.max_val}]\"\n        return True, \"\"\n```\n\n## Quarantine System\n\nWhen records fail validation:\n\n1. They are **not** processed by subsequent steps\n2. They are written to a quarantine directory: `<storage_base>/quarantine/<pipeline_name>/<run_id>/`\n3. Each quarantined record is saved as JSON with the original data and error message\n4. Observers are notified via `on_record_quarantined` event\n\n## Observers\n\n- **LoggingObserver**: Logs pipeline events to console/file\n- **QuarantineObserver**: Tracks and logs quarantined records\n- **MetricsObserver**: Collects execution metrics\n\n## Running Tests\n\n```bash\npytest tests/ -v\n```\n\n## Demo\n\n```bash\npython main.py\n```\n\n## Architecture\n\n```\ntimestack/\n\u251c\u2500\u2500 __init__.py      # Package exports\n\u251c\u2500\u2500 pipeline.py      # Pipeline orchestration\n\u251c\u2500\u2500 steps.py         # Processing steps\n\u251c\u2500\u2500 storage.py       # Storage backends\n\u251c\u2500\u2500 observers.py     # Pipeline observers\n\u2514\u2500\u2500 validators.py    # Data quality validators\n```\n\n## License\n\nMIT\n"
        },
        "generated_files": [
          "timestack/validators.py",
          "timestack/steps.py",
          "timestack/storage.py",
          "timestack/observers.py",
          "timestack/pipeline.py",
          "timestack/__init__.py",
          "main.py",
          "tests/test_pipeline.py",
          "README.md"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7566199813258636,
              "dependency_traversal_accuracy": 0.8257582716016394,
              "cross_file_reasoning_depth": 0.4463888888888889,
              "system_thinking_score": 0.3228655316543521,
              "robustness_score": 0.4311288483466363,
              "comprehensiveness_score": 0.7352145442871219,
              "innovation_score": 0.24375000000000002,
              "solution_elegance_score": 0.6037315369374893
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09457749766573295,
              "dependency_traversal_weighted": 0.10321978395020492,
              "cross_file_reasoning_weighted": 0.05579861111111111,
              "system_thinking_weighted": 0.040358191456794014,
              "robustness_weighted": 0.053891106043329536,
              "comprehensiveness_weighted": 0.09190181803589023,
              "innovation_weighted": 0.030468750000000003,
              "solution_elegance_weighted": 0.07546644211718616
            },
            "total_software_engineering_score": 0.545682200380249
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.0,
              "execution_time": 0.6232724189758301,
              "errors": [
                "  File \"README.py\", line 124",
                "    \u251c\u2500\u2500 __init__.py      # Package exports",
                "    ^",
                "SyntaxError: invalid character '\u251c' (U+251C)",
                "  File \"main.py\", line 33",
                "    print(f\"",
                "          ^",
                "SyntaxError: unterminated f-string literal (detected at line 33)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "timestack/validators.py",
                "timestack/steps.py",
                "timestack/storage.py",
                "timestack/observers.py",
                "timestack/pipeline.py",
                "timestack/__init__.py",
                "main.py",
                "tests/test_pipeline.py",
                "README.md"
              ],
              "scoring_breakdown": {
                "no_credit": 0.0
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 9,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 9 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.2076713433317207,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.0,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.2076713433317207,
              "idc_weight": 0.2,
              "total_functional_score": 0.35153426866634413
            }
          },
          "code_quality_details": {
            "files_analyzed": 9,
            "quality_checks": {
              "timestack/validators.py": {
                "line_count": 115,
                "non_empty_lines": 82,
                "comment_lines": 1,
                "comment_ratio": 0.012195121951219513,
                "function_count": 7,
                "class_count": 11,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "timestack/steps.py": {
                "line_count": 162,
                "non_empty_lines": 123,
                "comment_lines": 4,
                "comment_ratio": 0.032520325203252036,
                "function_count": 13,
                "class_count": 7,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "timestack/storage.py": {
                "line_count": 197,
                "non_empty_lines": 151,
                "comment_lines": 2,
                "comment_ratio": 0.013245033112582781,
                "function_count": 21,
                "class_count": 4,
                "import_count": 15,
                "quality_score": 0.7999999999999999
              },
              "timestack/observers.py": {
                "line_count": 228,
                "non_empty_lines": 179,
                "comment_lines": 1,
                "comment_ratio": 0.00558659217877095,
                "function_count": 26,
                "class_count": 5,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "timestack/pipeline.py": {
                "line_count": 235,
                "non_empty_lines": 191,
                "comment_lines": 10,
                "comment_ratio": 0.05235602094240838,
                "function_count": 11,
                "class_count": 3,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "timestack/__init__.py": {
                "line_count": 46,
                "non_empty_lines": 42,
                "comment_lines": 5,
                "comment_ratio": 0.11904761904761904,
                "function_count": 0,
                "class_count": 0,
                "import_count": 10,
                "quality_score": 0.7
              },
              "main.py": {
                "line_count": 113,
                "non_empty_lines": 92,
                "comment_lines": 8,
                "comment_ratio": 0.08695652173913043,
                "function_count": 2,
                "class_count": 1,
                "import_count": 2,
                "quality_score": 0.7999999999999999
              },
              "tests/test_pipeline.py": {
                "line_count": 523,
                "non_empty_lines": 418,
                "comment_lines": 25,
                "comment_ratio": 0.05980861244019139,
                "function_count": 26,
                "class_count": 7,
                "import_count": 7,
                "quality_score": 0.6
              },
              "README.md": {
                "line_count": 135,
                "non_empty_lines": 100,
                "comment_lines": 17,
                "comment_ratio": 0.17,
                "function_count": 2,
                "class_count": 1,
                "import_count": 4,
                "quality_score": 0.9999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.792222222222222,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8920343137254902,
              "multi_session_memory_retention": 0.8466817496229263
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4460171568627451,
              "multi_session_memory_retention_weighted": 0.42334087481146315
            },
            "total_longcontext_utilization_score": 0.8693580316742082
          }
        },
        "timestamp": "2026-01-14T20:54:12.341419"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_system_monitoring_medium_061_feature_implementation_expert_01",
        "scenario_title": "Implement Automated Deployment Rollback based on Performance Degradation",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.505444062230777,
        "functional_correctness_score": 0.6771423948220066,
        "code_quality_score": 0.8233333333333334,
        "longcontext_utilization_score": 0.79375,
        "total_score": 3.2468100500278974,
        "generation_time": 141.7461552619934,
        "code_files_generated": 6,
        "total_lines_generated": 1259,
        "parsing_success": true,
        "solution_code": {
          "PulseLink_SocialOps_Monitor/shared/events.py": "from dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any\nimport uuid\n\n\n@dataclass\nclass BaseEvent:\n    \"\"\"Base class for all events in the system.\"\"\"\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    source_service: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"event_id\": self.event_id,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"source_service\": self.source_service,\n            \"event_type\": self.__class__.__name__\n        }\n\n\n@dataclass\nclass DeploymentStartedEvent(BaseEvent):\n    \"\"\"Emitted when a deployment process begins.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    version: str = \"\"\n    environment: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"version\": self.version,\n            \"environment\": self.environment\n        })\n        return data\n\n\n@dataclass\nclass DeploymentSucceededEvent(BaseEvent):\n    \"\"\"Emitted when a deployment completes successfully.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    version: str = \"\"\n    environment: str = \"\"\n    duration_seconds: float = 0.0\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"version\": self.version,\n            \"environment\": self.environment,\n            \"duration_seconds\": self.duration_seconds\n        })\n        return data\n\n\n@dataclass\nclass DeploymentFailedEvent(BaseEvent):\n    \"\"\"Emitted when a deployment fails.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    version: str = \"\"\n    environment: str = \"\"\n    error_message: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"version\": self.version,\n            \"environment\": self.environment,\n            \"error_message\": self.error_message\n        })\n        return data\n\n\n@dataclass\nclass CriticalPerformanceDegradationDetectedEvent(BaseEvent):\n    \"\"\"Emitted when critical performance degradation is detected after a deployment.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    reason: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"reason\": self.reason\n        })\n        return data\n\n\n@dataclass\nclass ConfigurationChangedEvent(BaseEvent):\n    \"\"\"Emitted when configuration is changed.\"\"\"\n    config_key: str = \"\"\n    old_value: Optional[str] = None\n    new_value: Optional[str] = None\n    changed_by: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"config_key\": self.config_key,\n            \"old_value\": self.old_value,\n            \"new_value\": self.new_value,\n            \"changed_by\": self.changed_by\n        })\n        return data\n\n\n@dataclass\nclass SecurityAlertEvent(BaseEvent):\n    \"\"\"Emitted when a security issue is detected.\"\"\"\n    alert_id: str = \"\"\n    severity: str = \"\"\n    description: str = \"\"\n    affected_resource: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"alert_id\": self.alert_id,\n            \"severity\": self.severity,\n            \"description\": self.description,\n            \"affected_resource\": self.affected_resource\n        })\n        return data\n\n\n@dataclass\nclass LogAnomalyDetectedEvent(BaseEvent):\n    \"\"\"Emitted when an anomaly is detected in logs.\"\"\"\n    anomaly_id: str = \"\"\n    log_source: str = \"\"\n    pattern: str = \"\"\n    severity: str = \"\"\n    sample_entries: list = field(default_factory=list)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"anomaly_id\": self.anomaly_id,\n            \"log_source\": self.log_source,\n            \"pattern\": self.pattern,\n            \"severity\": self.severity,\n            \"sample_entries\": self.sample_entries\n        })\n        return data\n\n\n@dataclass\nclass PerformanceMetricEvent(BaseEvent):\n    \"\"\"Emitted when performance metrics are collected.\"\"\"\n    metric_name: str = \"\"\n    value: float = 0.0\n    unit: str = \"\"\n    tags: Dict[str, str] = field(default_factory=dict)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"metric_name\": self.metric_name,\n            \"value\": self.value,\n            \"unit\": self.unit,\n            \"tags\": self.tags\n        })\n        return data\n",
          "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py": "import logging\nfrom typing import Dict, Any, Optional, List, Callable\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nimport threading\nimport time\n\nfrom shared.events import (\n    BaseEvent,\n    PerformanceMetricEvent,\n    DeploymentSucceededEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass PerformanceThresholds:\n    \"\"\"Configuration for performance thresholds.\"\"\"\n    p99_latency_ms: float = 500.0\n    error_rate_percent: float = 5.0\n\n\n@dataclass\nclass PostDeploymentMonitoringState:\n    \"\"\"Tracks post-deployment monitoring state for a service.\"\"\"\n    deployment_id: str\n    service_name: str\n    start_time: datetime\n    end_time: datetime\n    is_active: bool = True\n\n\n@dataclass\nclass CurrentMetrics:\n    \"\"\"Current performance metrics for a service.\"\"\"\n    p99_latency_ms: float = 0.0\n    error_rate_percent: float = 0.0\n    request_count: int = 0\n    error_count: int = 0\n    last_updated: datetime = field(default_factory=datetime.utcnow)\n\n\nclass PerfPulseService:\n    \"\"\"Service for monitoring system performance metrics.\"\"\"\n    \n    def __init__(\n        self,\n        event_bus: EventBus,\n        thresholds: Optional[PerformanceThresholds] = None,\n        post_deployment_monitoring_duration_minutes: int = 5\n    ):\n        self.event_bus = event_bus\n        self.thresholds = thresholds or PerformanceThresholds()\n        self.post_deployment_monitoring_duration_minutes = post_deployment_monitoring_duration_minutes\n        \n        # Track post-deployment monitoring states by service name\n        self._monitoring_states: Dict[str, PostDeploymentMonitoringState] = {}\n        self._monitoring_lock = threading.Lock()\n        \n        # Current metrics by service name\n        self._current_metrics: Dict[str, CurrentMetrics] = {}\n        self._metrics_lock = threading.Lock()\n        \n        # Service state\n        self._running = False\n        self._monitor_thread: Optional[threading.Thread] = None\n        \n        # Subscribe to deployment events\n        self.event_bus.subscribe(DeploymentSucceededEvent, self._handle_deployment_succeeded)\n        \n        logger.info(\"PerfPulseService initialized with thresholds: P99 latency=%sms, error rate=%s%%\",\n                    self.thresholds.p99_latency_ms, self.thresholds.error_rate_percent)\n    \n    def start(self):\n        \"\"\"Start the performance monitoring service.\"\"\"\n        self._running = True\n        self._monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)\n        self._monitor_thread.start()\n        logger.info(\"PerfPulseService started\")\n    \n    def stop(self):\n        \"\"\"Stop the performance monitoring service.\"\"\"\n        self._running = False\n        if self._monitor_thread:\n            self._monitor_thread.join(timeout=5)\n        logger.info(\"PerfPulseService stopped\")\n    \n    def _handle_deployment_succeeded(self, event: DeploymentSucceededEvent):\n        \"\"\"Handle a successful deployment event by starting post-deployment monitoring.\"\"\"\n        logger.info(\"Received DeploymentSucceededEvent for service '%s', deployment_id='%s'\",\n                    event.service_name, event.deployment_id)\n        \n        now = datetime.utcnow()\n        monitoring_state = PostDeploymentMonitoringState(\n            deployment_id=event.deployment_id,\n            service_name=event.service_name,\n            start_time=now,\n            end_time=now + timedelta(minutes=self.post_deployment_monitoring_duration_minutes),\n            is_active=True\n        )\n        \n        with self._monitoring_lock:\n            self._monitoring_states[event.service_name] = monitoring_state\n        \n        logger.info(\"Started post-deployment monitoring for service '%s' until %s\",\n                    event.service_name, monitoring_state.end_time.isoformat())\n    \n    def update_metrics(self, service_name: str, p99_latency_ms: float, error_rate_percent: float):\n        \"\"\"Update current metrics for a service.\"\"\"\n        with self._metrics_lock:\n            self._current_metrics[service_name] = CurrentMetrics(\n                p99_latency_ms=p99_latency_ms,\n                error_rate_percent=error_rate_percent,\n                last_updated=datetime.utcnow()\n            )\n        \n        # Check if we need to emit a degradation event\n        self._check_post_deployment_thresholds(service_name)\n    \n    def record_request(self, service_name: str, latency_ms: float, is_error: bool = False):\n        \"\"\"Record a request for metrics calculation.\"\"\"\n        with self._metrics_lock:\n            if service_name not in self._current_metrics:\n                self._current_metrics[service_name] = CurrentMetrics()\n            \n            metrics = self._current_metrics[service_name]\n            metrics.request_count += 1\n            if is_error:\n                metrics.error_count += 1\n            \n            # Update error rate\n            if metrics.request_count > 0:\n                metrics.error_rate_percent = (metrics.error_count / metrics.request_count) * 100\n            \n            # Update P99 latency (simplified - in production would use a proper percentile calculation)\n            # For simplicity, we update if this latency is higher\n            if latency_ms > metrics.p99_latency_ms:\n                metrics.p99_latency_ms = latency_ms\n            \n            metrics.last_updated = datetime.utcnow()\n        \n        # Check thresholds\n        self._check_post_deployment_thresholds(service_name)\n    \n    def _check_post_deployment_thresholds(self, service_name: str):\n        \"\"\"Check if metrics breach thresholds during post-deployment monitoring.\"\"\"\n        with self._monitoring_lock:\n            monitoring_state = self._monitoring_states.get(service_name)\n            if not monitoring_state or not monitoring_state.is_active:\n                return\n            \n            # Check if monitoring period has expired\n            now = datetime.utcnow()\n            if now > monitoring_state.end_time:\n                monitoring_state.is_active = False\n                logger.info(\"Post-deployment monitoring period ended for service '%s'\", service_name)\n                return\n        \n        with self._metrics_lock:\n            metrics = self._current_metrics.get(service_name)\n            if not metrics:\n                return\n        \n        # Check thresholds\n        reasons = []\n        if metrics.p99_latency_ms > self.thresholds.p99_latency_ms:\n            reasons.append(f\"P99 latency {metrics.p99_latency_ms}ms exceeds threshold {self.thresholds.p99_latency_ms}ms\")\n        \n        if metrics.error_rate_percent > self.thresholds.error_rate_percent:\n            reasons.append(f\"Error rate {metrics.error_rate_percent}% exceeds threshold {self.thresholds.error_rate_percent}%\")\n        \n        if reasons:\n            # Stop monitoring and emit degradation event\n            with self._monitoring_lock:\n                monitoring_state = self._monitoring_states.get(service_name)\n                if monitoring_state and monitoring_state.is_active:\n                    monitoring_state.is_active = False\n                    \n                    reason = \"; \".join(reasons)\n                    degradation_event = CriticalPerformanceDegradationDetectedEvent(\n                        deployment_id=monitoring_state.deployment_id,\n                        service_name=service_name,\n                        reason=reason,\n                        source_service=\"perf_pulse\"\n                    )\n                    \n                    logger.warning(\n                        \"Critical performance degradation detected for service '%s' (deployment_id='%s'): %s\",\n                        service_name, monitoring_state.deployment_id, reason\n                    )\n                    \n                    self.event_bus.publish(degradation_event)\n    \n    def _monitoring_loop(self):\n        \"\"\"Background loop for continuous monitoring.\"\"\"\n        while self._running:\n            try:\n                # Clean up expired monitoring states\n                now = datetime.utcnow()\n                with self._monitoring_lock:\n                    for service_name, state in list(self._monitoring_states.items()):\n                        if state.is_active and now > state.end_time:\n                            state.is_active = False\n                            logger.info(\"Post-deployment monitoring period ended for service '%s'\", service_name)\n                \n                time.sleep(1)  # Check every second\n            except Exception as e:\n                logger.error(\"Error in monitoring loop: %s\", e)\n    \n    def get_monitoring_state(self, service_name: str) -> Optional[PostDeploymentMonitoringState]:\n        \"\"\"Get the current monitoring state for a service.\"\"\"\n        with self._monitoring_lock:\n            return self._monitoring_states.get(service_name)\n    \n    def get_current_metrics(self, service_name: str) -> Optional[CurrentMetrics]:\n        \"\"\"Get current metrics for a service.\"\"\"\n        with self._metrics_lock:\n            return self._current_metrics.get(service_name)\n    \n    def collect_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect and return all current metrics.\"\"\"\n        with self._metrics_lock:\n            return {\n                service: {\n                    \"p99_latency_ms\": m.p99_latency_ms,\n                    \"error_rate_percent\": m.error_rate_percent,\n                    \"request_count\": m.request_count,\n                    \"error_count\": m.error_count,\n                    \"last_updated\": m.last_updated.isoformat()\n                }\n                for service, m in self._current_metrics.items()\n            }\n    \n    def emit_metric_event(self, metric_name: str, value: float, unit: str, tags: Optional[Dict[str, str]] = None):\n        \"\"\"Emit a performance metric event.\"\"\"\n        event = PerformanceMetricEvent(\n            metric_name=metric_name,\n            value=value,\n            unit=unit,\n            tags=tags or {},\n            source_service=\"perf_pulse\"\n        )\n        self.event_bus.publish(event)\n        logger.debug(\"Emitted metric event: %s=%s%s\", metric_name, value, unit)\n",
          "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py": "import logging\nfrom typing import Dict, Any, Optional, List\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\nfrom shared.events import (\n    BaseEvent,\n    DeploymentStartedEvent,\n    DeploymentSucceededEvent,\n    DeploymentFailedEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\nlogger = logging.getLogger(__name__)\n\n\nclass DeploymentStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    SUCCEEDED = \"succeeded\"\n    FAILED = \"failed\"\n    ROLLED_BACK = \"rolled_back\"\n\n\n@dataclass\nclass Deployment:\n    \"\"\"Represents a deployment.\"\"\"\n    deployment_id: str\n    service_name: str\n    version: str\n    environment: str\n    status: DeploymentStatus\n    previous_version: Optional[str] = None\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    rollback_reason: Optional[str] = None\n\n\nclass DeployFlowService:\n    \"\"\"Service for managing deployments.\"\"\"\n    \n    def __init__(self, event_bus: EventBus):\n        self.event_bus = event_bus\n        self._deployments: Dict[str, Deployment] = {}\n        self._service_versions: Dict[str, str] = {}  # Track current version per service\n        \n        # Subscribe to performance degradation events for auto-rollback\n        self.event_bus.subscribe(\n            CriticalPerformanceDegradationDetectedEvent,\n            self._handle_performance_degradation\n        )\n        \n        logger.info(\"DeployFlowService initialized\")\n    \n    def create_deployment(\n        self,\n        service_name: str,\n        version: str,\n        environment: str = \"production\"\n    ) -> Deployment:\n        \"\"\"Create a new deployment.\"\"\"\n        deployment_id = str(uuid.uuid4())\n        previous_version = self._service_versions.get(service_name)\n        \n        deployment = Deployment(\n            deployment_id=deployment_id,\n            service_name=service_name,\n            version=version,\n            environment=environment,\n            status=DeploymentStatus.PENDING,\n            previous_version=previous_version\n        )\n        \n        self._deployments[deployment_id] = deployment\n        logger.info(\"Created deployment %s for service '%s' version '%s'\",\n                    deployment_id, service_name, version)\n        \n        return deployment\n    \n    def start_deployment(self, deployment_id: str) -> Deployment:\n        \"\"\"Start a deployment.\"\"\"\n        deployment = self._deployments.get(deployment_id)\n        if not deployment:\n            raise ValueError(f\"Deployment {deployment_id} not found\")\n        \n        if deployment.status != DeploymentStatus.PENDING:\n            raise ValueError(f\"Deployment {deployment_id} is not in pending state\")\n        \n        deployment.status = DeploymentStatus.IN_PROGRESS\n        deployment.started_at = datetime.utcnow()\n        \n        # Emit deployment started event\n        event = DeploymentStartedEvent(\n            deployment_id=deployment_id,\n            service_name=deployment.service_name,\n            version=deployment.version,\n            environment=deployment.environment,\n            source_service=\"deploy_flow\"\n        )\n        self.event_bus.publish(event)\n        \n        logger.info(\"Started deployment %s\", deployment_id)\n        return deployment\n    \n    def complete_deployment(self, deployment_id: str, success: bool = True, error_message: Optional[str] = None) -> Deployment:\n        \"\"\"Complete a deployment.\"\"\"\n        deployment = self._deployments.get(deployment_id)\n        if not deployment:\n            raise ValueError(f\"Deployment {deployment_id} not found\")\n        \n        if deployment.status != DeploymentStatus.IN_PROGRESS:\n            raise ValueError(f\"Deployment {deployment_id} is not in progress\")\n        \n        deployment.completed_at = datetime.utcnow()\n        \n        if success:\n            deployment.status = DeploymentStatus.SUCCEEDED\n            # Update the current version for the service\n            self._service_versions[deployment.service_name] = deployment.version\n            \n            # Emit deployment succeeded event\n            duration = (deployment.completed_at - deployment.started_at).total_seconds() if deployment.started_at else 0\n            event = DeploymentSucceededEvent(\n                deployment_id=deployment_id,\n                service_name=deployment.service_name,\n                version=deployment.version,\n                environment=deployment.environment,\n                duration_seconds=duration,\n                source_service=\"deploy_flow\"\n            )\n            self.event_bus.publish(event)\n            logger.info(\"Deployment %s succeeded\", deployment_id)\n        else:\n            deployment.status = DeploymentStatus.FAILED\n            deployment.error_message = error_message\n            \n            # Emit deployment failed event\n            event = DeploymentFailedEvent(\n                deployment_id=deployment_id,\n                service_name=deployment.service_name,\n                version=deployment.version,\n                environment=deployment.environment,\n                error_message=error_message or \"Unknown error\",\n                source_service=\"deploy_flow\"\n            )\n            self.event_bus.publish(event)\n            logger.error(\"Deployment %s failed: %s\", deployment_id, error_message)\n        \n        return deployment\n    \n    def rollback_deployment(self, deployment_id: str, reason: Optional[str] = None) -> Deployment:\n        \"\"\"Rollback a deployment to the previous version.\"\"\"\n        deployment = self._deployments.get(deployment_id)\n        if not deployment:\n            raise ValueError(f\"Deployment {deployment_id} not found\")\n        \n        if deployment.status not in [DeploymentStatus.SUCCEEDED, DeploymentStatus.IN_PROGRESS]:\n            raise ValueError(f\"Deployment {deployment_id} cannot be rolled back from state {deployment.status}\")\n        \n        if not deployment.previous_version:\n            raise ValueError(f\"No previous version available for rollback of deployment {deployment_id}\")\n        \n        logger.warning(\"Rolling back deployment %s for service '%s' from version '%s' to '%s'. Reason: %s\",\n                       deployment_id, deployment.service_name, deployment.version,\n                       deployment.previous_version, reason or \"Not specified\")\n        \n        # Update the service version back to previous\n        self._service_versions[deployment.service_name] = deployment.previous_version\n        \n        deployment.status = DeploymentStatus.ROLLED_BACK\n        deployment.rollback_reason = reason\n        deployment.completed_at = datetime.utcnow()\n        \n        logger.info(\"Deployment %s rolled back successfully\", deployment_id)\n        return deployment\n    \n    def _handle_performance_degradation(self, event: CriticalPerformanceDegradationDetectedEvent):\n        \"\"\"Handle critical performance degradation by triggering rollback.\"\"\"\n        logger.warning(\n            \"Received CriticalPerformanceDegradationDetectedEvent for deployment '%s' service '%s': %s\",\n            event.deployment_id, event.service_name, event.reason\n        )\n        \n        try:\n            deployment = self._deployments.get(event.deployment_id)\n            if not deployment:\n                logger.error(\"Cannot rollback: deployment %s not found\", event.deployment_id)\n                return\n            \n            if deployment.status == DeploymentStatus.ROLLED_BACK:\n                logger.info(\"Deployment %s already rolled back, ignoring\", event.deployment_id)\n                return\n            \n            self.rollback_deployment(\n                deployment_id=event.deployment_id,\n                reason=f\"Auto-rollback due to performance degradation: {event.reason}\"\n            )\n            \n        except Exception as e:\n            logger.error(\"Failed to rollback deployment %s: %s\", event.deployment_id, e)\n    \n    def get_deployment(self, deployment_id: str) -> Optional[Deployment]:\n        \"\"\"Get a deployment by ID.\"\"\"\n        return self._deployments.get(deployment_id)\n    \n    def get_deployments_for_service(self, service_name: str) -> List[Deployment]:\n        \"\"\"Get all deployments for a service.\"\"\"\n        return [\n            d for d in self._deployments.values()\n            if d.service_name == service_name\n        ]\n    \n    def get_current_version(self, service_name: str) -> Optional[str]:\n        \"\"\"Get the current deployed version for a service.\"\"\"\n        return self._service_versions.get(service_name)\n",
          "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py": "import unittest\nfrom unittest.mock import Mock, MagicMock, patch\nfrom datetime import datetime, timedelta\nimport time\n\nfrom services.perf_pulse.service import (\n    PerfPulseService,\n    PerformanceThresholds,\n    PostDeploymentMonitoringState,\n    CurrentMetrics\n)\nfrom shared.events import (\n    DeploymentSucceededEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\n\nclass TestPerfPulseService(unittest.TestCase):\n    \"\"\"Tests for PerfPulseService.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.event_bus = Mock(spec=EventBus)\n        self.event_bus.subscribe = Mock()\n        self.event_bus.publish = Mock()\n        \n        self.service = PerfPulseService(\n            event_bus=self.event_bus,\n            thresholds=PerformanceThresholds(\n                p99_latency_ms=500.0,\n                error_rate_percent=5.0\n            ),\n            post_deployment_monitoring_duration_minutes=5\n        )\n    \n    def tearDown(self):\n        \"\"\"Clean up after tests.\"\"\"\n        if self.service._running:\n            self.service.stop()\n    \n    def test_subscribes_to_deployment_succeeded_event(self):\n        \"\"\"Test that service subscribes to DeploymentSucceededEvent.\"\"\"\n        # Check that subscribe was called with DeploymentSucceededEvent\n        subscribe_calls = self.event_bus.subscribe.call_args_list\n        event_types = [call[0][0] for call in subscribe_calls]\n        self.assertIn(DeploymentSucceededEvent, event_types)\n    \n    def test_handle_deployment_succeeded_starts_monitoring(self):\n        \"\"\"Test that receiving DeploymentSucceededEvent starts post-deployment monitoring.\"\"\"\n        event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-123\",\n            service_name=\"test-service\",\n            version=\"1.0.0\",\n            environment=\"production\",\n            duration_seconds=60.0,\n            source_service=\"deploy_flow\"\n        )\n        \n        # Simulate receiving the event\n        self.service._handle_deployment_succeeded(event)\n        \n        # Check that monitoring state was created\n        state = self.service.get_monitoring_state(\"test-service\")\n        self.assertIsNotNone(state)\n        self.assertEqual(state.deployment_id, \"deploy-123\")\n        self.assertEqual(state.service_name, \"test-service\")\n        self.assertTrue(state.is_active)\n    \n    def test_emits_degradation_event_on_high_latency(self):\n        \"\"\"Test that CriticalPerformanceDegradationDetectedEvent is emitted when P99 latency exceeds threshold.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-456\",\n            service_name=\"latency-test-service\",\n            version=\"2.0.0\",\n            environment=\"production\",\n            duration_seconds=30.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Update metrics with high latency (above 500ms threshold)\n        self.service.update_metrics(\n            service_name=\"latency-test-service\",\n            p99_latency_ms=600.0,  # Above threshold\n            error_rate_percent=1.0  # Below threshold\n        )\n        \n        # Verify degradation event was published\n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, CriticalPerformanceDegradationDetectedEvent)\n        self.assertEqual(published_event.deployment_id, \"deploy-456\")\n        self.assertEqual(published_event.service_name, \"latency-test-service\")\n        self.assertIn(\"P99 latency\", published_event.reason)\n        self.assertIn(\"600.0ms\", published_event.reason)\n    \n    def test_emits_degradation_event_on_high_error_rate(self):\n        \"\"\"Test that CriticalPerformanceDegradationDetectedEvent is emitted when error rate exceeds threshold.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-789\",\n            service_name=\"error-test-service\",\n            version=\"3.0.0\",\n            environment=\"production\",\n            duration_seconds=45.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Update metrics with high error rate (above 5% threshold)\n        self.service.update_metrics(\n            service_name=\"error-test-service\",\n            p99_latency_ms=200.0,  # Below threshold\n            error_rate_percent=10.0  # Above threshold\n        )\n        \n        # Verify degradation event was published\n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, CriticalPerformanceDegradationDetectedEvent)\n        self.assertEqual(published_event.deployment_id, \"deploy-789\")\n        self.assertEqual(published_event.service_name, \"error-test-service\")\n        self.assertIn(\"Error rate\", published_event.reason)\n        self.assertIn(\"10.0%\", published_event.reason)\n    \n    def test_emits_degradation_event_with_both_thresholds_breached(self):\n        \"\"\"Test that reason includes both metrics when both thresholds are breached.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-both\",\n            service_name=\"both-test-service\",\n            version=\"4.0.0\",\n            environment=\"production\",\n            duration_seconds=20.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Update metrics with both thresholds breached\n        self.service.update_metrics(\n            service_name=\"both-test-service\",\n            p99_latency_ms=750.0,  # Above threshold\n            error_rate_percent=8.0  # Above threshold\n        )\n        \n        # Verify degradation event contains both reasons\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIn(\"P99 latency\", published_event.reason)\n        self.assertIn(\"Error rate\", published_event.reason)\n    \n    def test_no_event_when_metrics_below_thresholds(self):\n        \"\"\"Test that no degradation event is emitted when metrics are below thresholds.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-ok\",\n            service_name=\"ok-service\",\n            version=\"5.0.0\",\n            environment=\"production\",\n            duration_seconds=15.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Reset mock to clear the deployment event subscription call\n        self.event_bus.publish.reset_mock()\n        \n        # Update metrics below thresholds\n        self.service.update_metrics(\n            service_name=\"ok-service\",\n            p99_latency_ms=300.0,  # Below threshold\n            error_rate_percent=2.0  # Below threshold\n        )\n        \n        # Verify no degradation event was published\n        self.event_bus.publish.assert_not_called()\n    \n    def test_no_event_when_not_in_monitoring_period(self):\n        \"\"\"Test that no degradation event is emitted when not in post-deployment monitoring.\"\"\"\n        # Don't start monitoring - just update metrics\n        self.event_bus.publish.reset_mock()\n        \n        self.service.update_metrics(\n            service_name=\"no-monitoring-service\",\n            p99_latency_ms=1000.0,  # Way above threshold\n            error_rate_percent=50.0  # Way above threshold\n        )\n        \n        # Verify no degradation event was published\n        self.event_bus.publish.assert_not_called()\n    \n    def test_monitoring_stops_after_degradation_detected(self):\n        \"\"\"Test that monitoring stops after degradation is detected.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-stop\",\n            service_name=\"stop-test-service\",\n            version=\"6.0.0\",\n            environment=\"production\",\n            duration_seconds=10.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Trigger degradation\n        self.service.update_metrics(\n            service_name=\"stop-test-service\",\n            p99_latency_ms=600.0,\n            error_rate_percent=1.0\n        )\n        \n        # Verify monitoring is no longer active\n        state = self.service.get_monitoring_state(\"stop-test-service\")\n        self.assertFalse(state.is_active)\n        \n        # Reset mock and try to trigger again\n        self.event_bus.publish.reset_mock()\n        self.service.update_metrics(\n            service_name=\"stop-test-service\",\n            p99_latency_ms=800.0,\n            error_rate_percent=20.0\n        )\n        \n        # Verify no additional event was published\n        self.event_bus.publish.assert_not_called()\n    \n    def test_record_request_updates_metrics(self):\n        \"\"\"Test that record_request properly updates metrics.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-record\",\n            service_name=\"record-service\",\n            version=\"7.0.0\",\n            environment=\"production\",\n            duration_seconds=5.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Record some requests\n        self.service.record_request(\"record-service\", latency_ms=100.0, is_error=False)\n        self.service.record_request(\"record-service\", latency_ms=200.0, is_error=False)\n        self.service.record_request(\"record-service\", latency_ms=150.0, is_error=True)\n        \n        # Check metrics\n        metrics = self.service.get_current_metrics(\"record-service\")\n        self.assertIsNotNone(metrics)\n        self.assertEqual(metrics.request_count, 3)\n        self.assertEqual(metrics.error_count, 1)\n        self.assertAlmostEqual(metrics.error_rate_percent, 33.33, places=1)\n        self.assertEqual(metrics.p99_latency_ms, 200.0)\n    \n    def test_collect_metrics_returns_all_services(self):\n        \"\"\"Test that collect_metrics returns metrics for all services.\"\"\"\n        self.service.update_metrics(\"service-a\", 100.0, 1.0)\n        self.service.update_metrics(\"service-b\", 200.0, 2.0)\n        \n        all_metrics = self.service.collect_metrics()\n        \n        self.assertIn(\"service-a\", all_metrics)\n        self.assertIn(\"service-b\", all_metrics)\n        self.assertEqual(all_metrics[\"service-a\"][\"p99_latency_ms\"], 100.0)\n        self.assertEqual(all_metrics[\"service-b\"][\"p99_latency_ms\"], 200.0)\n\n\nclass TestPerformanceThresholds(unittest.TestCase):\n    \"\"\"Tests for PerformanceThresholds.\"\"\"\n    \n    def test_default_thresholds(self):\n        \"\"\"Test default threshold values.\"\"\"\n        thresholds = PerformanceThresholds()\n        self.assertEqual(thresholds.p99_latency_ms, 500.0)\n        self.assertEqual(thresholds.error_rate_percent, 5.0)\n    \n    def test_custom_thresholds(self):\n        \"\"\"Test custom threshold values.\"\"\"\n        thresholds = PerformanceThresholds(\n            p99_latency_ms=1000.0,\n            error_rate_percent=10.0\n        )\n        self.assertEqual(thresholds.p99_latency_ms, 1000.0)\n        self.assertEqual(thresholds.error_rate_percent, 10.0)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
          "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py": "import unittest\nfrom unittest.mock import Mock, MagicMock, patch, call\nfrom datetime import datetime\n\nfrom services.deploy_flow.service import (\n    DeployFlowService,\n    Deployment,\n    DeploymentStatus\n)\nfrom shared.events import (\n    DeploymentStartedEvent,\n    DeploymentSucceededEvent,\n    DeploymentFailedEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\n\nclass TestDeployFlowService(unittest.TestCase):\n    \"\"\"Tests for DeployFlowService.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.event_bus = Mock(spec=EventBus)\n        self.event_bus.subscribe = Mock()\n        self.event_bus.publish = Mock()\n        \n        self.service = DeployFlowService(event_bus=self.event_bus)\n    \n    def test_subscribes_to_performance_degradation_event(self):\n        \"\"\"Test that service subscribes to CriticalPerformanceDegradationDetectedEvent.\"\"\"\n        subscribe_calls = self.event_bus.subscribe.call_args_list\n        event_types = [call[0][0] for call in subscribe_calls]\n        self.assertIn(CriticalPerformanceDegradationDetectedEvent, event_types)\n    \n    def test_create_deployment(self):\n        \"\"\"Test creating a new deployment.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\",\n            environment=\"production\"\n        )\n        \n        self.assertIsNotNone(deployment.deployment_id)\n        self.assertEqual(deployment.service_name, \"test-service\")\n        self.assertEqual(deployment.version, \"1.0.0\")\n        self.assertEqual(deployment.environment, \"production\")\n        self.assertEqual(deployment.status, DeploymentStatus.PENDING)\n    \n    def test_start_deployment_emits_event(self):\n        \"\"\"Test that starting a deployment emits DeploymentStartedEvent.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        \n        self.service.start_deployment(deployment.deployment_id)\n        \n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, DeploymentStartedEvent)\n        self.assertEqual(published_event.deployment_id, deployment.deployment_id)\n    \n    def test_complete_deployment_success_emits_event(self):\n        \"\"\"Test that completing a deployment successfully emits DeploymentSucceededEvent.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.event_bus.publish.reset_mock()\n        \n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, DeploymentSucceededEvent)\n        self.assertEqual(published_event.deployment_id, deployment.deployment_id)\n    \n    def test_complete_deployment_failure_emits_event(self):\n        \"\"\"Test that a failed deployment emits DeploymentFailedEvent.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.event_bus.publish.reset_mock()\n        \n        self.service.complete_deployment(\n            deployment.deployment_id,\n            success=False,\n            error_message=\"Deployment failed\"\n        )\n        \n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, DeploymentFailedEvent)\n        self.assertEqual(published_event.error_message, \"Deployment failed\")\n    \n    def test_rollback_deployment(self):\n        \"\"\"Test rolling back a deployment.\"\"\"\n        # First deployment\n        self.service._service_versions[\"test-service\"] = \"0.9.0\"\n        \n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        # Rollback\n        rolled_back = self.service.rollback_deployment(\n            deployment.deployment_id,\n            reason=\"Performance issues\"\n        )\n        \n        self.assertEqual(rolled_back.status, DeploymentStatus.ROLLED_BACK)\n        self.assertEqual(rolled_back.rollback_reason, \"Performance issues\")\n        self.assertEqual(self.service.get_current_version(\"test-service\"), \"0.9.0\")\n    \n    def test_handle_performance_degradation_triggers_rollback(self):\n        \"\"\"Test that receiving CriticalPerformanceDegradationDetectedEvent triggers rollback.\"\"\"\n        # Set up a previous version\n        self.service._service_versions[\"degraded-service\"] = \"0.8.0\"\n        \n        # Create and complete a deployment\n        deployment = self.service.create_deployment(\n            service_name=\"degraded-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        # Verify deployment succeeded\n        self.assertEqual(deployment.status, DeploymentStatus.SUCCEEDED)\n        self.assertEqual(self.service.get_current_version(\"degraded-service\"), \"1.0.0\")\n        \n        # Simulate receiving performance degradation event\n        degradation_event = CriticalPerformanceDegradationDetectedEvent(\n            deployment_id=deployment.deployment_id,\n            service_name=\"degraded-service\",\n            reason=\"P99 latency 600.0ms exceeds threshold 500.0ms\",\n            source_service=\"perf_pulse\"\n        )\n        \n        self.service._handle_performance_degradation(degradation_event)\n        \n        # Verify rollback occurred\n        updated_deployment = self.service.get_deployment(deployment.deployment_id)\n        self.assertEqual(updated_deployment.status, DeploymentStatus.ROLLED_BACK)\n        self.assertIn(\"Auto-rollback\", updated_deployment.rollback_reason)\n        self.assertIn(\"P99 latency\", updated_deployment.rollback_reason)\n        self.assertEqual(self.service.get_current_version(\"degraded-service\"), \"0.8.0\")\n    \n    def test_handle_performance_degradation_ignores_unknown_deployment(self):\n        \"\"\"Test that unknown deployment IDs are handled gracefully.\"\"\"\n        degradation_event = CriticalPerformanceDegradationDetectedEvent(\n            deployment_id=\"unknown-deployment-id\",\n            service_name=\"unknown-service\",\n            reason=\"Some reason\",\n            source_service=\"perf_pulse\"\n        )\n        \n        # Should not raise an exception\n        self.service._handle_performance_degradation(degradation_event)\n    \n    def test_handle_performance_degradation_ignores_already_rolled_back(self):\n        \"\"\"Test that already rolled back deployments are ignored.\"\"\"\n        # Set up a previous version\n        self.service._service_versions[\"test-service\"] = \"0.7.0\"\n        \n        # Create, complete, and rollback a deployment\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        self.service.rollback_deployment(deployment.deployment_id, reason=\"Manual rollback\")\n        \n        # Try to trigger another rollback via event\n        degradation_event = CriticalPerformanceDegradationDetectedEvent(\n            deployment_id=deployment.deployment_id,\n            service_name=\"test-service\",\n            reason=\"Some reason\",\n            source_service=\"perf_pulse\"\n        )\n        \n        # Should not raise an exception and should remain in rolled back state\n        self.service._handle_performance_degradation(degradation_event)\n        self.assertEqual(deployment.status, DeploymentStatus.ROLLED_BACK)\n        self.assertEqual(deployment.rollback_reason, \"Manual rollback\")  # Original reason preserved\n    \n    def test_rollback_requires_previous_version(self):\n        \"\"\"Test that rollback fails if no previous version exists.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"new-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        with self.assertRaises(ValueError) as context:\n            self.service.rollback_deployment(deployment.deployment_id)\n        \n        self.assertIn(\"No previous version\", str(context.exception))\n    \n    def test_get_deployments_for_service(self):\n        \"\"\"Test retrieving all deployments for a service.\"\"\"\n        self.service.create_deployment(\"service-a\", \"1.0.0\")\n        self.service.create_deployment(\"service-a\", \"1.1.0\")\n        self.service.create_deployment(\"service-b\", \"2.0.0\")\n        \n        deployments_a = self.service.get_deployments_for_service(\"service-a\")\n        deployments_b = self.service.get_deployments_for_service(\"service-b\")\n        \n        self.assertEqual(len(deployments_a), 2)\n        self.assertEqual(len(deployments_b), 1)\n    \n    def test_deployment_tracks_previous_version(self):\n        \"\"\"Test that deployments track the previous version.\"\"\"\n        # Set initial version\n        self.service._service_versions[\"versioned-service\"] = \"0.5.0\"\n        \n        deployment = self.service.create_deployment(\n            service_name=\"versioned-service\",\n            version=\"1.0.0\"\n        )\n        \n        self.assertEqual(deployment.previous_version, \"0.5.0\")\n\n\nclass TestDeploymentStatus(unittest.TestCase):\n    \"\"\"Tests for DeploymentStatus enum.\"\"\"\n    \n    def test_status_values(self):\n        \"\"\"Test that all expected status values exist.\"\"\"\n        self.assertEqual(DeploymentStatus.PENDING.value, \"pending\")\n        self.assertEqual(DeploymentStatus.IN_PROGRESS.value, \"in_progress\")\n        self.assertEqual(DeploymentStatus.SUCCEEDED.value, \"succeeded\")\n        self.assertEqual(DeploymentStatus.FAILED.value, \"failed\")\n        self.assertEqual(DeploymentStatus.ROLLED_BACK.value, \"rolled_back\")\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
          "PulseLink_SocialOps_Monitor/shared/messaging.py": "import logging\nfrom typing import Dict, List, Callable, Type, Any\nfrom collections import defaultdict\nimport threading\n\nfrom shared.events import BaseEvent\n\nlogger = logging.getLogger(__name__)\n\n\nclass EventBus:\n    \"\"\"Simple event bus for publishing and subscribing to events.\"\"\"\n    \n    def __init__(self):\n        self._subscribers: Dict[Type[BaseEvent], List[Callable]] = defaultdict(list)\n        self._lock = threading.Lock()\n    \n    def subscribe(self, event_type: Type[BaseEvent], handler: Callable[[BaseEvent], None]):\n        \"\"\"Subscribe a handler to an event type.\"\"\"\n        with self._lock:\n            self._subscribers[event_type].append(handler)\n            logger.debug(\"Subscribed handler %s to event type %s\",\n                        handler.__name__ if hasattr(handler, '__name__') else str(handler),\n                        event_type.__name__)\n    \n    def unsubscribe(self, event_type: Type[BaseEvent], handler: Callable[[BaseEvent], None]):\n        \"\"\"Unsubscribe a handler from an event type.\"\"\"\n        with self._lock:\n            if handler in self._subscribers[event_type]:\n                self._subscribers[event_type].remove(handler)\n                logger.debug(\"Unsubscribed handler from event type %s\", event_type.__name__)\n    \n    def publish(self, event: BaseEvent):\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        event_type = type(event)\n        \n        with self._lock:\n            handlers = list(self._subscribers[event_type])\n        \n        logger.debug(\"Publishing event %s to %d handlers\", event_type.__name__, len(handlers))\n        \n        for handler in handlers:\n            try:\n                handler(event)\n            except Exception as e:\n                logger.error(\"Error in event handler for %s: %s\", event_type.__name__, e)\n    \n    def get_subscriber_count(self, event_type: Type[BaseEvent]) -> int:\n        \"\"\"Get the number of subscribers for an event type.\"\"\"\n        with self._lock:\n            return len(self._subscribers[event_type])\n    \n    def clear_subscribers(self, event_type: Type[BaseEvent] = None):\n        \"\"\"Clear subscribers for a specific event type or all event types.\"\"\"\n        with self._lock:\n            if event_type:\n                self._subscribers[event_type] = []\n            else:\n                self._subscribers.clear()\n\n\n# Global event bus instance\n_global_event_bus: EventBus = None\n\n\ndef get_event_bus() -> EventBus:\n    \"\"\"Get the global event bus instance.\"\"\"\n    global _global_event_bus\n    if _global_event_bus is None:\n        _global_event_bus = EventBus()\n    return _global_event_bus\n\n\ndef reset_event_bus():\n    \"\"\"Reset the global event bus (mainly for testing).\"\"\"\n    global _global_event_bus\n    _global_event_bus = None\n"
        },
        "generated_files": [
          "PulseLink_SocialOps_Monitor/shared/events.py",
          "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py",
          "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py",
          "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py",
          "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py",
          "PulseLink_SocialOps_Monitor/shared/messaging.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8383903830480848,
              "dependency_traversal_accuracy": 0.7570618377212007,
              "cross_file_reasoning_depth": 0.29680555555555554,
              "system_thinking_score": 0.3347075241269396,
              "robustness_score": 0.09023154499723206,
              "comprehensiveness_score": 0.6576790743013937,
              "innovation_score": 0.20110702938840352,
              "solution_elegance_score": 0.8675695487074062
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.1047987978810106,
              "dependency_traversal_weighted": 0.09463272971515009,
              "cross_file_reasoning_weighted": 0.03710069444444444,
              "system_thinking_weighted": 0.04183844051586745,
              "robustness_weighted": 0.011278943124654007,
              "comprehensiveness_weighted": 0.08220988428767421,
              "innovation_weighted": 0.02513837867355044,
              "solution_elegance_weighted": 0.10844619358842578
            },
            "total_software_engineering_score": 0.505444062230777
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.4018986225128174,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "PulseLink_SocialOps_Monitor/shared/events.py",
                "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py",
                "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py",
                "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py",
                "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py",
                "PulseLink_SocialOps_Monitor/shared/messaging.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 6,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 6 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.48571197411003236,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.48571197411003236,
              "idc_weight": 0.2,
              "total_functional_score": 0.6771423948220066
            }
          },
          "code_quality_details": {
            "files_analyzed": 6,
            "quality_checks": {
              "PulseLink_SocialOps_Monitor/shared/events.py": {
                "line_count": 177,
                "non_empty_lines": 149,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 9,
                "class_count": 10,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py": {
                "line_count": 248,
                "non_empty_lines": 202,
                "comment_lines": 13,
                "comment_ratio": 0.06435643564356436,
                "function_count": 12,
                "class_count": 4,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py": {
                "line_count": 220,
                "non_empty_lines": 177,
                "comment_lines": 6,
                "comment_ratio": 0.03389830508474576,
                "function_count": 9,
                "class_count": 3,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py": {
                "line_count": 288,
                "non_empty_lines": 244,
                "comment_lines": 26,
                "comment_ratio": 0.10655737704918032,
                "function_count": 14,
                "class_count": 2,
                "import_count": 12,
                "quality_score": 0.9999999999999999
              },
              "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py": {
                "line_count": 248,
                "non_empty_lines": 200,
                "comment_lines": 13,
                "comment_ratio": 0.065,
                "function_count": 14,
                "class_count": 2,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "PulseLink_SocialOps_Monitor/shared/messaging.py": {
                "line_count": 78,
                "non_empty_lines": 58,
                "comment_lines": 1,
                "comment_ratio": 0.017241379310344827,
                "function_count": 8,
                "class_count": 5,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.8233333333333334,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8083333333333333,
              "multi_session_memory_retention": 0.7791666666666666
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4041666666666667,
              "multi_session_memory_retention_weighted": 0.3895833333333333
            },
            "total_longcontext_utilization_score": 0.79375
          }
        },
        "timestamp": "2026-01-14T20:56:35.264532"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_game_engine_expert_032_feature_implementation_expert_01",
        "scenario_title": "Implement Server-Side NavMesh Pathfinding for AI Agents",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5126310018301251,
        "functional_correctness_score": 0.616018981018981,
        "code_quality_score": 0.7,
        "longcontext_utilization_score": 0.9338903743315508,
        "total_score": 3.116235662354497,
        "generation_time": 197.00688695907593,
        "code_files_generated": 7,
        "total_lines_generated": 1878,
        "parsing_success": true,
        "solution_code": {
          "ledgerquest/engine/pathfinding/__init__.py": "\"\"\"Pathfinding module for AI navigation.\"\"\"\n\nfrom ledgerquest.engine.pathfinding.navigator import Navigator\n\n__all__ = [\"Navigator\"]\n",
          "ledgerquest/engine/pathfinding/navigator.py": "\"\"\"Navigator service for NavMesh-based pathfinding using A* algorithm.\"\"\"\n\nimport heapq\nimport math\nfrom typing import Optional\n\n\nclass Navigator:\n    \"\"\"A navigation service that performs A* pathfinding on a NavMesh graph.\n    \n    The NavMesh is represented as an adjacency list where each node is a polygon\n    with a centroid position and connections to neighboring polygons.\n    \n    Expected navmesh_data format:\n    {\n        \"nodes\": {\n            \"node_id\": {\n                \"position\": (x, y),  # Centroid of the polygon\n                \"vertices\": [(x1, y1), (x2, y2), ...],  # Optional polygon vertices\n                \"neighbors\": [\"neighbor_id1\", \"neighbor_id2\", ...]\n            },\n            ...\n        }\n    }\n    \"\"\"\n    \n    def __init__(self, navmesh_data: Optional[dict] = None):\n        \"\"\"Initialize the Navigator with optional NavMesh data.\n        \n        Args:\n            navmesh_data: Dictionary containing the NavMesh graph structure.\n        \"\"\"\n        self._navmesh: dict = {}\n        self._nodes: dict = {}\n        if navmesh_data:\n            self.load_navmesh(navmesh_data)\n    \n    def load_navmesh(self, navmesh_data: dict) -> None:\n        \"\"\"Load a NavMesh graph from a dictionary representation.\n        \n        Args:\n            navmesh_data: Dictionary containing nodes with positions and neighbors.\n        \"\"\"\n        self._navmesh = navmesh_data\n        self._nodes = navmesh_data.get(\"nodes\", {})\n    \n    def _euclidean_distance(self, pos1: tuple, pos2: tuple) -> float:\n        \"\"\"Calculate Euclidean distance between two positions.\n        \n        Args:\n            pos1: First position as (x, y) tuple.\n            pos2: Second position as (x, y) tuple.\n            \n        Returns:\n            The Euclidean distance between the positions.\n        \"\"\"\n        dx = pos2[0] - pos1[0]\n        dy = pos2[1] - pos1[1]\n        return math.sqrt(dx * dx + dy * dy)\n    \n    def _point_in_polygon(self, point: tuple, vertices: list) -> bool:\n        \"\"\"Check if a point is inside a polygon using ray casting.\n        \n        Args:\n            point: The point to check as (x, y).\n            vertices: List of polygon vertices as [(x, y), ...].\n            \n        Returns:\n            True if point is inside the polygon, False otherwise.\n        \"\"\"\n        if not vertices or len(vertices) < 3:\n            return False\n            \n        x, y = point\n        n = len(vertices)\n        inside = False\n        \n        j = n - 1\n        for i in range(n):\n            xi, yi = vertices[i]\n            xj, yj = vertices[j]\n            \n            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n                inside = not inside\n            j = i\n            \n        return inside\n    \n    def _find_containing_node(self, position: tuple) -> Optional[str]:\n        \"\"\"Find the NavMesh node that contains the given position.\n        \n        Args:\n            position: The position to locate as (x, y).\n            \n        Returns:\n            The node ID containing the position, or None if not found.\n        \"\"\"\n        closest_node = None\n        closest_distance = float('inf')\n        \n        for node_id, node_data in self._nodes.items():\n            node_pos = node_data.get(\"position\", (0, 0))\n            vertices = node_data.get(\"vertices\", [])\n            \n            # Check if position is inside this polygon\n            if vertices and self._point_in_polygon(position, vertices):\n                return node_id\n            \n            # Track closest node as fallback\n            distance = self._euclidean_distance(position, node_pos)\n            if distance < closest_distance:\n                closest_distance = distance\n                closest_node = node_id\n        \n        # Return closest node if no containing polygon found\n        return closest_node\n    \n    def _reconstruct_path(self, came_from: dict, current: str, \n                          start_pos: tuple, end_pos: tuple) -> list:\n        \"\"\"Reconstruct the path from A* search results.\n        \n        Args:\n            came_from: Dictionary mapping each node to its predecessor.\n            current: The end node ID.\n            start_pos: The original start position.\n            end_pos: The original end position.\n            \n        Returns:\n            List of waypoint positions from start to end.\n        \"\"\"\n        path_nodes = [current]\n        while current in came_from:\n            current = came_from[current]\n            path_nodes.append(current)\n        \n        path_nodes.reverse()\n        \n        # Convert node IDs to positions\n        waypoints = [start_pos]\n        for node_id in path_nodes:\n            if node_id in self._nodes:\n                waypoints.append(self._nodes[node_id][\"position\"])\n        waypoints.append(end_pos)\n        \n        return waypoints\n    \n    def find_path(self, start_pos: tuple, end_pos: tuple) -> list:\n        \"\"\"Find a path from start position to end position using A* algorithm.\n        \n        Args:\n            start_pos: Starting position as (x, y) tuple.\n            end_pos: Destination position as (x, y) tuple.\n            \n        Returns:\n            Ordered list of waypoint positions from start to end.\n            Returns empty list if no path is possible.\n        \"\"\"\n        if not self._nodes:\n            return []\n        \n        # Find the nodes containing start and end positions\n        start_node = self._find_containing_node(start_pos)\n        end_node = self._find_containing_node(end_pos)\n        \n        if start_node is None or end_node is None:\n            return []\n        \n        # If start and end are in the same node, return direct path\n        if start_node == end_node:\n            return [start_pos, end_pos]\n        \n        # A* algorithm\n        open_set = []\n        heapq.heappush(open_set, (0, start_node))\n        \n        came_from = {}\n        g_score = {start_node: 0}\n        f_score = {start_node: self._euclidean_distance(\n            self._nodes[start_node][\"position\"], \n            self._nodes[end_node][\"position\"]\n        )}\n        \n        open_set_hash = {start_node}\n        \n        while open_set:\n            _, current = heapq.heappop(open_set)\n            open_set_hash.discard(current)\n            \n            if current == end_node:\n                return self._reconstruct_path(came_from, current, start_pos, end_pos)\n            \n            current_data = self._nodes.get(current, {})\n            current_pos = current_data.get(\"position\", (0, 0))\n            neighbors = current_data.get(\"neighbors\", [])\n            \n            for neighbor in neighbors:\n                if neighbor not in self._nodes:\n                    continue\n                    \n                neighbor_pos = self._nodes[neighbor][\"position\"]\n                tentative_g = g_score[current] + self._euclidean_distance(\n                    current_pos, neighbor_pos\n                )\n                \n                if neighbor not in g_score or tentative_g < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g\n                    f_score[neighbor] = tentative_g + self._euclidean_distance(\n                        neighbor_pos, self._nodes[end_node][\"position\"]\n                    )\n                    \n                    if neighbor not in open_set_hash:\n                        heapq.heappush(open_set, (f_score[neighbor], neighbor))\n                        open_set_hash.add(neighbor)\n        \n        # No path found\n        return []\n    \n    def is_loaded(self) -> bool:\n        \"\"\"Check if a NavMesh is currently loaded.\n        \n        Returns:\n            True if a NavMesh is loaded, False otherwise.\n        \"\"\"\n        return len(self._nodes) > 0\n",
          "ledgerquest/engine/ai/nodes.py": "\"\"\"Behavior Tree node implementations for AI decision making.\"\"\"\n\nimport math\nfrom abc import ABC, abstractmethod\nfrom enum import Enum, auto\nfrom typing import TYPE_CHECKING, Any, Callable, List, Optional\n\nif TYPE_CHECKING:\n    from ledgerquest.engine.ai.blackboard import Blackboard\n    from ledgerquest.engine.ecs.registry import Registry\n    from ledgerquest.engine.pathfinding.navigator import Navigator\n\n\nclass NodeStatus(Enum):\n    \"\"\"Status returned by behavior tree nodes after execution.\"\"\"\n    SUCCESS = auto()\n    FAILURE = auto()\n    RUNNING = auto()\n\n\nclass Node(ABC):\n    \"\"\"Abstract base class for all behavior tree nodes.\"\"\"\n    \n    def __init__(self, name: str = \"\"):\n        \"\"\"Initialize the node.\n        \n        Args:\n            name: Optional name for the node for debugging purposes.\n        \"\"\"\n        self.name = name or self.__class__.__name__\n    \n    @abstractmethod\n    def tick(self, blackboard: \"Blackboard\", entity_id: str, \n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute the node's logic.\n        \n        Args:\n            blackboard: The AI's memory/state storage.\n            entity_id: The ID of the entity being controlled.\n            registry: The ECS registry for accessing components.\n            \n        Returns:\n            The status of the node after execution.\n        \"\"\"\n        pass\n    \n    def reset(self) -> None:\n        \"\"\"Reset the node's internal state.\"\"\"\n        pass\n\n\nclass Composite(Node):\n    \"\"\"Base class for nodes that have multiple children.\"\"\"\n    \n    def __init__(self, children: Optional[List[Node]] = None, name: str = \"\"):\n        \"\"\"Initialize the composite node.\n        \n        Args:\n            children: List of child nodes.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.children: List[Node] = children or []\n        self._current_child_index: int = 0\n    \n    def add_child(self, child: Node) -> None:\n        \"\"\"Add a child node.\n        \n        Args:\n            child: The node to add as a child.\n        \"\"\"\n        self.children.append(child)\n    \n    def reset(self) -> None:\n        \"\"\"Reset this node and all children.\"\"\"\n        self._current_child_index = 0\n        for child in self.children:\n            child.reset()\n\n\nclass Sequence(Composite):\n    \"\"\"Executes children in order until one fails or all succeed.\"\"\"\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute children sequentially.\n        \n        Returns SUCCESS if all children succeed, FAILURE if any fails,\n        RUNNING if a child is still running.\n        \"\"\"\n        while self._current_child_index < len(self.children):\n            child = self.children[self._current_child_index]\n            status = child.tick(blackboard, entity_id, registry)\n            \n            if status == NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            elif status == NodeStatus.FAILURE:\n                self.reset()\n                return NodeStatus.FAILURE\n            \n            self._current_child_index += 1\n        \n        self.reset()\n        return NodeStatus.SUCCESS\n\n\nclass Selector(Composite):\n    \"\"\"Executes children in order until one succeeds or all fail.\"\"\"\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute children until one succeeds.\n        \n        Returns SUCCESS if any child succeeds, FAILURE if all fail,\n        RUNNING if a child is still running.\n        \"\"\"\n        while self._current_child_index < len(self.children):\n            child = self.children[self._current_child_index]\n            status = child.tick(blackboard, entity_id, registry)\n            \n            if status == NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            elif status == NodeStatus.SUCCESS:\n                self.reset()\n                return NodeStatus.SUCCESS\n            \n            self._current_child_index += 1\n        \n        self.reset()\n        return NodeStatus.FAILURE\n\n\nclass Decorator(Node):\n    \"\"\"Base class for nodes that modify a single child's behavior.\"\"\"\n    \n    def __init__(self, child: Optional[Node] = None, name: str = \"\"):\n        \"\"\"Initialize the decorator.\n        \n        Args:\n            child: The child node to decorate.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.child = child\n    \n    def reset(self) -> None:\n        \"\"\"Reset this node and its child.\"\"\"\n        if self.child:\n            self.child.reset()\n\n\nclass Inverter(Decorator):\n    \"\"\"Inverts the result of its child node.\"\"\"\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute child and invert SUCCESS/FAILURE.\"\"\"\n        if not self.child:\n            return NodeStatus.FAILURE\n        \n        status = self.child.tick(blackboard, entity_id, registry)\n        \n        if status == NodeStatus.SUCCESS:\n            return NodeStatus.FAILURE\n        elif status == NodeStatus.FAILURE:\n            return NodeStatus.SUCCESS\n        \n        return NodeStatus.RUNNING\n\n\nclass Repeater(Decorator):\n    \"\"\"Repeats its child a specified number of times.\"\"\"\n    \n    def __init__(self, child: Optional[Node] = None, times: int = 1, \n                 name: str = \"\"):\n        \"\"\"Initialize the repeater.\n        \n        Args:\n            child: The child node to repeat.\n            times: Number of times to repeat (-1 for infinite).\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(child, name)\n        self.times = times\n        self._count = 0\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute child repeatedly.\"\"\"\n        if not self.child:\n            return NodeStatus.FAILURE\n        \n        if self.times != -1 and self._count >= self.times:\n            self.reset()\n            return NodeStatus.SUCCESS\n        \n        status = self.child.tick(blackboard, entity_id, registry)\n        \n        if status == NodeStatus.SUCCESS or status == NodeStatus.FAILURE:\n            self._count += 1\n            self.child.reset()\n            \n            if self.times == -1:\n                return NodeStatus.RUNNING\n            elif self._count >= self.times:\n                self.reset()\n                return NodeStatus.SUCCESS\n            return NodeStatus.RUNNING\n        \n        return NodeStatus.RUNNING\n    \n    def reset(self) -> None:\n        \"\"\"Reset the repeater count.\"\"\"\n        super().reset()\n        self._count = 0\n\n\nclass Action(Node):\n    \"\"\"Base class for leaf nodes that perform actions.\"\"\"\n    pass\n\n\nclass Condition(Node):\n    \"\"\"Base class for leaf nodes that check conditions.\"\"\"\n    pass\n\n\nclass ConditionCheck(Condition):\n    \"\"\"A condition node that evaluates a callable.\"\"\"\n    \n    def __init__(self, condition: Callable[[\"Blackboard\", str, \"Registry\"], bool],\n                 name: str = \"\"):\n        \"\"\"Initialize the condition check.\n        \n        Args:\n            condition: A callable that returns True or False.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.condition = condition\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Evaluate the condition.\"\"\"\n        try:\n            result = self.condition(blackboard, entity_id, registry)\n            return NodeStatus.SUCCESS if result else NodeStatus.FAILURE\n        except Exception:\n            return NodeStatus.FAILURE\n\n\nclass ActionExecute(Action):\n    \"\"\"An action node that executes a callable.\"\"\"\n    \n    def __init__(self, action: Callable[[\"Blackboard\", str, \"Registry\"], NodeStatus],\n                 name: str = \"\"):\n        \"\"\"Initialize the action.\n        \n        Args:\n            action: A callable that returns a NodeStatus.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.action = action\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute the action.\"\"\"\n        try:\n            return self.action(blackboard, entity_id, registry)\n        except Exception:\n            return NodeStatus.FAILURE\n\n\nclass Wait(Action):\n    \"\"\"An action that waits for a specified number of ticks.\"\"\"\n    \n    def __init__(self, ticks: int = 1, name: str = \"\"):\n        \"\"\"Initialize the wait action.\n        \n        Args:\n            ticks: Number of ticks to wait.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.ticks = ticks\n        self._elapsed = 0\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Wait for the specified number of ticks.\"\"\"\n        self._elapsed += 1\n        if self._elapsed >= self.ticks:\n            self.reset()\n            return NodeStatus.SUCCESS\n        return NodeStatus.RUNNING\n    \n    def reset(self) -> None:\n        \"\"\"Reset the elapsed counter.\"\"\"\n        self._elapsed = 0\n\n\nclass SetBlackboardValue(Action):\n    \"\"\"An action that sets a value on the blackboard.\"\"\"\n    \n    def __init__(self, key: str, value: Any, name: str = \"\"):\n        \"\"\"Initialize the action.\n        \n        Args:\n            key: The blackboard key to set.\n            value: The value to set.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.key = key\n        self.value = value\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Set the value on the blackboard.\"\"\"\n        blackboard.set(self.key, self.value)\n        return NodeStatus.SUCCESS\n\n\nclass CheckBlackboardValue(Condition):\n    \"\"\"A condition that checks a blackboard value.\"\"\"\n    \n    def __init__(self, key: str, expected_value: Any = None, \n                 check_exists: bool = False, name: str = \"\"):\n        \"\"\"Initialize the condition.\n        \n        Args:\n            key: The blackboard key to check.\n            expected_value: The expected value (if not just checking existence).\n            check_exists: If True, only check if key exists.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.key = key\n        self.expected_value = expected_value\n        self.check_exists = check_exists\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Check the blackboard value.\"\"\"\n        if self.check_exists:\n            return NodeStatus.SUCCESS if blackboard.has(self.key) else NodeStatus.FAILURE\n        \n        value = blackboard.get(self.key)\n        if value == self.expected_value:\n            return NodeStatus.SUCCESS\n        return NodeStatus.FAILURE\n\n\nclass MoveTo(Action):\n    \"\"\"An action node that moves an entity to a target destination using pathfinding.\n    \n    This node retrieves a target destination from the Blackboard, uses the Navigator\n    service to calculate a path, and guides the entity along the waypoints by\n    modifying its VelocityComponent.\n    \n    Blackboard keys used:\n        - 'target_destination': tuple (x, y) - The destination to move to\n        - 'navigator': Navigator instance - The pathfinding service\n        - '_moveto_path': list - Internal storage for the calculated path\n        - '_moveto_waypoint_index': int - Current waypoint index\n    \"\"\"\n    \n    # Constants for movement\n    WAYPOINT_REACHED_THRESHOLD = 5.0  # Distance to consider waypoint reached\n    DEFAULT_MOVE_SPEED = 100.0  # Default movement speed\n    \n    def __init__(self, destination_key: str = \"target_destination\",\n                 speed: float = DEFAULT_MOVE_SPEED, name: str = \"\"):\n        \"\"\"Initialize the MoveTo action.\n        \n        Args:\n            destination_key: Blackboard key for the target destination.\n            speed: Movement speed for the entity.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name or \"MoveTo\")\n        self.destination_key = destination_key\n        self.speed = speed\n        self._path_key = \"_moveto_path\"\n        self._waypoint_index_key = \"_moveto_waypoint_index\"\n        self._initialized = False\n    \n    def _get_entity_position(self, entity_id: str, registry: \"Registry\") -> Optional[tuple]:\n        \"\"\"Get the current position of the entity.\n        \n        Args:\n            entity_id: The entity's ID.\n            registry: The ECS registry.\n            \n        Returns:\n            The entity's position as (x, y) or None if not found.\n        \"\"\"\n        try:\n            from ledgerquest.engine.physics.components import PositionComponent\n            position_comp = registry.get_component(entity_id, PositionComponent)\n            if position_comp:\n                return (position_comp.x, position_comp.y)\n        except Exception:\n            pass\n        return None\n    \n    def _set_entity_velocity(self, entity_id: str, registry: \"Registry\",\n                             direction: tuple, speed: float) -> bool:\n        \"\"\"Set the entity's velocity towards a direction.\n        \n        Args:\n            entity_id: The entity's ID.\n            registry: The ECS registry.\n            direction: Normalized direction vector (dx, dy).\n            speed: Movement speed.\n            \n        Returns:\n            True if velocity was set successfully, False otherwise.\n        \"\"\"\n        try:\n            from ledgerquest.engine.physics.components import VelocityComponent\n            velocity_comp = registry.get_component(entity_id, VelocityComponent)\n            if velocity_comp:\n                velocity_comp.vx = direction[0] * speed\n                velocity_comp.vy = direction[1] * speed\n                return True\n        except Exception:\n            pass\n        return False\n    \n    def _stop_entity(self, entity_id: str, registry: \"Registry\") -> None:\n        \"\"\"Stop the entity by setting velocity to zero.\n        \n        Args:\n            entity_id: The entity's ID.\n            registry: The ECS registry.\n        \"\"\"\n        self._set_entity_velocity(entity_id, registry, (0, 0), 0)\n    \n    def _calculate_distance(self, pos1: tuple, pos2: tuple) -> float:\n        \"\"\"Calculate distance between two positions.\n        \n        Args:\n            pos1: First position (x, y).\n            pos2: Second position (x, y).\n            \n        Returns:\n            Euclidean distance between positions.\n        \"\"\"\n        dx = pos2[0] - pos1[0]\n        dy = pos2[1] - pos1[1]\n        return math.sqrt(dx * dx + dy * dy)\n    \n    def _normalize_direction(self, pos1: tuple, pos2: tuple) -> tuple:\n        \"\"\"Calculate normalized direction from pos1 to pos2.\n        \n        Args:\n            pos1: Starting position (x, y).\n            pos2: Target position (x, y).\n            \n        Returns:\n            Normalized direction vector (dx, dy).\n        \"\"\"\n        dx = pos2[0] - pos1[0]\n        dy = pos2[1] - pos1[1]\n        distance = math.sqrt(dx * dx + dy * dy)\n        \n        if distance < 0.0001:\n            return (0.0, 0.0)\n        \n        return (dx / distance, dy / distance)\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute the MoveTo action.\n        \n        On first tick, retrieves destination and calculates path.\n        On subsequent ticks, moves entity towards next waypoint.\n        \n        Args:\n            blackboard: The AI's blackboard for state storage.\n            entity_id: The entity being controlled.\n            registry: The ECS registry.\n            \n        Returns:\n            RUNNING while moving, SUCCESS when destination reached,\n            FAILURE if no path found or missing components.\n        \"\"\"\n        # Get current entity position\n        current_pos = self._get_entity_position(entity_id, registry)\n        if current_pos is None:\n            return NodeStatus.FAILURE\n        \n        # Check if we need to initialize/calculate path\n        path = blackboard.get(self._path_key)\n        \n        if path is None:\n            # First tick - calculate path\n            destination = blackboard.get(self.destination_key)\n            if destination is None:\n                return NodeStatus.FAILURE\n            \n            # Get navigator from blackboard\n            navigator = blackboard.get(\"navigator\")\n            if navigator is None:\n                return NodeStatus.FAILURE\n            \n            # Calculate path\n            path = navigator.find_path(current_pos, destination)\n            \n            if not path:\n                # No path found\n                return NodeStatus.FAILURE\n            \n            # Store path and initialize waypoint index\n            blackboard.set(self._path_key, path)\n            blackboard.set(self._waypoint_index_key, 0)\n        \n        # Get current waypoint index\n        waypoint_index = blackboard.get(self._waypoint_index_key, 0)\n        \n        # Check if we've reached the end of the path\n        if waypoint_index >= len(path):\n            self._stop_entity(entity_id, registry)\n            self._cleanup_blackboard(blackboard)\n            return NodeStatus.SUCCESS\n        \n        # Get current target waypoint\n        target_waypoint = path[waypoint_index]\n        \n        # Check if we've reached the current waypoint\n        distance_to_waypoint = self._calculate_distance(current_pos, target_waypoint)\n        \n        if distance_to_waypoint <= self.WAYPOINT_REACHED_THRESHOLD:\n            # Move to next waypoint\n            waypoint_index += 1\n            blackboard.set(self._waypoint_index_key, waypoint_index)\n            \n            # Check if this was the last waypoint\n            if waypoint_index >= len(path):\n                self._stop_entity(entity_id, registry)\n                self._cleanup_blackboard(blackboard)\n                return NodeStatus.SUCCESS\n            \n            # Update target to next waypoint\n            target_waypoint = path[waypoint_index]\n        \n        # Move towards current waypoint\n        direction = self._normalize_direction(current_pos, target_waypoint)\n        self._set_entity_velocity(entity_id, registry, direction, self.speed)\n        \n        return NodeStatus.RUNNING\n    \n    def _cleanup_blackboard(self, blackboard: \"Blackboard\") -> None:\n        \"\"\"Clean up internal state from the blackboard.\n        \n        Args:\n            blackboard: The blackboard to clean up.\n        \"\"\"\n        blackboard.set(self._path_key, None)\n        blackboard.set(self._waypoint_index_key, None)\n    \n    def reset(self) -> None:\n        \"\"\"Reset the node's internal state.\"\"\"\n        self._initialized = False\n",
          "ledgerquest/services/game_loop/ai_updater.py": "\"\"\"AI Updater service for processing AI behavior trees in the game loop.\"\"\"\n\nfrom typing import TYPE_CHECKING, Dict, List, Optional, Set\n\nfrom ledgerquest.engine.ai.behavior_tree import BehaviorTree\nfrom ledgerquest.engine.ai.blackboard import Blackboard\nfrom ledgerquest.engine.pathfinding.navigator import Navigator\n\nif TYPE_CHECKING:\n    from ledgerquest.engine.ecs.registry import Registry\n\n\nclass AIUpdater:\n    \"\"\"Service responsible for updating AI entities each game tick.\n    \n    The AIUpdater processes all entities with AI components, executing their\n    behavior trees and managing their blackboards. It also provides shared\n    services like the Navigator for pathfinding.\n    \"\"\"\n    \n    def __init__(self, registry: Optional[\"Registry\"] = None,\n                 navmesh_data: Optional[dict] = None):\n        \"\"\"Initialize the AI Updater.\n        \n        Args:\n            registry: The ECS registry for accessing entity components.\n            navmesh_data: Optional NavMesh data for pathfinding.\n        \"\"\"\n        self._registry = registry\n        self._behavior_trees: Dict[str, BehaviorTree] = {}\n        self._blackboards: Dict[str, Blackboard] = {}\n        self._active_entities: Set[str] = set()\n        \n        # Initialize the Navigator service\n        self._navigator = Navigator(navmesh_data)\n    \n    @property\n    def navigator(self) -> Navigator:\n        \"\"\"Get the Navigator service instance.\n        \n        Returns:\n            The Navigator instance for pathfinding.\n        \"\"\"\n        return self._navigator\n    \n    def set_registry(self, registry: \"Registry\") -> None:\n        \"\"\"Set the ECS registry.\n        \n        Args:\n            registry: The ECS registry to use.\n        \"\"\"\n        self._registry = registry\n    \n    def load_navmesh(self, navmesh_data: dict) -> None:\n        \"\"\"Load a NavMesh for pathfinding.\n        \n        Args:\n            navmesh_data: The NavMesh data structure.\n        \"\"\"\n        self._navigator.load_navmesh(navmesh_data)\n    \n    def register_entity(self, entity_id: str, behavior_tree: BehaviorTree,\n                        blackboard: Optional[Blackboard] = None) -> None:\n        \"\"\"Register an entity with the AI system.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            behavior_tree: The behavior tree to control this entity.\n            blackboard: Optional pre-configured blackboard. Creates new if None.\n        \"\"\"\n        self._behavior_trees[entity_id] = behavior_tree\n        self._blackboards[entity_id] = blackboard or Blackboard()\n        self._active_entities.add(entity_id)\n        \n        # Inject navigator into the blackboard\n        self._blackboards[entity_id].set(\"navigator\", self._navigator)\n    \n    def unregister_entity(self, entity_id: str) -> None:\n        \"\"\"Unregister an entity from the AI system.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n        \"\"\"\n        self._behavior_trees.pop(entity_id, None)\n        self._blackboards.pop(entity_id, None)\n        self._active_entities.discard(entity_id)\n    \n    def get_blackboard(self, entity_id: str) -> Optional[Blackboard]:\n        \"\"\"Get the blackboard for an entity.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            \n        Returns:\n            The entity's blackboard or None if not registered.\n        \"\"\"\n        return self._blackboards.get(entity_id)\n    \n    def get_behavior_tree(self, entity_id: str) -> Optional[BehaviorTree]:\n        \"\"\"Get the behavior tree for an entity.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            \n        Returns:\n            The entity's behavior tree or None if not registered.\n        \"\"\"\n        return self._behavior_trees.get(entity_id)\n    \n    def set_entity_active(self, entity_id: str, active: bool) -> None:\n        \"\"\"Set whether an entity's AI is active.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            active: Whether the AI should be active.\n        \"\"\"\n        if entity_id in self._behavior_trees:\n            if active:\n                self._active_entities.add(entity_id)\n            else:\n                self._active_entities.discard(entity_id)\n    \n    def update(self, delta_time: float = 0.0) -> None:\n        \"\"\"Update all active AI entities.\n        \n        This method is called each game tick to process all registered\n        AI entities. It executes their behavior trees with access to\n        the Navigator service via the blackboard.\n        \n        Args:\n            delta_time: Time elapsed since last update in seconds.\n        \"\"\"\n        if self._registry is None:\n            return\n        \n        for entity_id in list(self._active_entities):\n            self._update_entity(entity_id, delta_time)\n    \n    def _update_entity(self, entity_id: str, delta_time: float) -> None:\n        \"\"\"Update a single AI entity.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            delta_time: Time elapsed since last update.\n        \"\"\"\n        behavior_tree = self._behavior_trees.get(entity_id)\n        blackboard = self._blackboards.get(entity_id)\n        \n        if behavior_tree is None or blackboard is None:\n            return\n        \n        # Ensure navigator is available in blackboard\n        if not blackboard.has(\"navigator\"):\n            blackboard.set(\"navigator\", self._navigator)\n        \n        # Store delta_time in blackboard for nodes that need it\n        blackboard.set(\"delta_time\", delta_time)\n        \n        # Execute the behavior tree\n        try:\n            behavior_tree.tick(blackboard, entity_id, self._registry)\n        except Exception as e:\n            # Log error but don't crash the game loop\n            # In production, this would use proper logging\n            pass\n    \n    def get_active_entity_count(self) -> int:\n        \"\"\"Get the number of active AI entities.\n        \n        Returns:\n            Count of active AI entities.\n        \"\"\"\n        return len(self._active_entities)\n    \n    def get_registered_entity_ids(self) -> List[str]:\n        \"\"\"Get all registered entity IDs.\n        \n        Returns:\n            List of registered entity IDs.\n        \"\"\"\n        return list(self._behavior_trees.keys())\n    \n    def clear(self) -> None:\n        \"\"\"Clear all registered entities and reset state.\"\"\"\n        self._behavior_trees.clear()\n        self._blackboards.clear()\n        self._active_entities.clear()\n",
          "tests/unit/engine/pathfinding/__init__.py": "\"\"\"Unit tests for pathfinding module.\"\"\"\n",
          "tests/unit/engine/pathfinding/test_navigator.py": "\"\"\"Unit tests for the Navigator pathfinding service.\"\"\"\n\nimport pytest\nimport math\n\nfrom ledgerquest.engine.pathfinding.navigator import Navigator\n\n\nclass TestNavigator:\n    \"\"\"Test suite for the Navigator class.\"\"\"\n    \n    @pytest.fixture\n    def simple_navmesh(self):\n        \"\"\"Create a simple NavMesh for testing.\n        \n        Layout:\n        [A] -- [B] -- [C]\n         |      |      |\n        [D] -- [E] -- [F]\n        \"\"\"\n        return {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-10, -10), (10, -10), (10, 10), (-10, 10)],\n                    \"neighbors\": [\"B\", \"D\"]\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"vertices\": [(40, -10), (60, -10), (60, 10), (40, 10)],\n                    \"neighbors\": [\"A\", \"C\", \"E\"]\n                },\n                \"C\": {\n                    \"position\": (100, 0),\n                    \"vertices\": [(90, -10), (110, -10), (110, 10), (90, 10)],\n                    \"neighbors\": [\"B\", \"F\"]\n                },\n                \"D\": {\n                    \"position\": (0, 50),\n                    \"vertices\": [(-10, 40), (10, 40), (10, 60), (-10, 60)],\n                    \"neighbors\": [\"A\", \"E\"]\n                },\n                \"E\": {\n                    \"position\": (50, 50),\n                    \"vertices\": [(40, 40), (60, 40), (60, 60), (40, 60)],\n                    \"neighbors\": [\"B\", \"D\", \"F\"]\n                },\n                \"F\": {\n                    \"position\": (100, 50),\n                    \"vertices\": [(90, 40), (110, 40), (110, 60), (90, 60)],\n                    \"neighbors\": [\"C\", \"E\"]\n                }\n            }\n        }\n    \n    @pytest.fixture\n    def disconnected_navmesh(self):\n        \"\"\"Create a NavMesh with disconnected regions.\"\"\"\n        return {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-10, -10), (10, -10), (10, 10), (-10, 10)],\n                    \"neighbors\": [\"B\"]\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"vertices\": [(40, -10), (60, -10), (60, 10), (40, 10)],\n                    \"neighbors\": [\"A\"]\n                },\n                # Disconnected region\n                \"X\": {\n                    \"position\": (200, 200),\n                    \"vertices\": [(190, 190), (210, 190), (210, 210), (190, 210)],\n                    \"neighbors\": [\"Y\"]\n                },\n                \"Y\": {\n                    \"position\": (250, 200),\n                    \"vertices\": [(240, 190), (260, 190), (260, 210), (240, 210)],\n                    \"neighbors\": [\"X\"]\n                }\n            }\n        }\n    \n    @pytest.fixture\n    def single_node_navmesh(self):\n        \"\"\"Create a NavMesh with a single node.\"\"\"\n        return {\n            \"nodes\": {\n                \"single\": {\n                    \"position\": (50, 50),\n                    \"vertices\": [(0, 0), (100, 0), (100, 100), (0, 100)],\n                    \"neighbors\": []\n                }\n            }\n        }\n    \n    def test_navigator_initialization_empty(self):\n        \"\"\"Test Navigator can be initialized without data.\"\"\"\n        navigator = Navigator()\n        assert navigator.is_loaded() is False\n    \n    def test_navigator_initialization_with_data(self, simple_navmesh):\n        \"\"\"Test Navigator initializes correctly with NavMesh data.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        assert navigator.is_loaded() is True\n    \n    def test_load_navmesh(self, simple_navmesh):\n        \"\"\"Test loading NavMesh after initialization.\"\"\"\n        navigator = Navigator()\n        assert navigator.is_loaded() is False\n        \n        navigator.load_navmesh(simple_navmesh)\n        assert navigator.is_loaded() is True\n    \n    def test_find_path_simple_valid(self, simple_navmesh):\n        \"\"\"Test finding a simple valid path.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Path from A to C (should go A -> B -> C)\n        start = (0, 0)\n        end = (100, 0)\n        \n        path = navigator.find_path(start, end)\n        \n        assert len(path) > 0\n        assert path[0] == start\n        assert path[-1] == end\n    \n    def test_find_path_diagonal(self, simple_navmesh):\n        \"\"\"Test finding a diagonal path.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Path from A to F (diagonal)\n        start = (0, 0)\n        end = (100, 50)\n        \n        path = navigator.find_path(start, end)\n        \n        assert len(path) > 0\n        assert path[0] == start\n        assert path[-1] == end\n    \n    def test_find_path_same_polygon(self, single_node_navmesh):\n        \"\"\"Test path when start and end are in the same polygon.\"\"\"\n        navigator = Navigator(single_node_navmesh)\n        \n        start = (25, 25)\n        end = (75, 75)\n        \n        path = navigator.find_path(start, end)\n        \n        # Should return direct path with just start and end\n        assert len(path) == 2\n        assert path[0] == start\n        assert path[1] == end\n    \n    def test_find_path_impossible_disconnected(self, disconnected_navmesh):\n        \"\"\"Test that impossible paths return empty list.\"\"\"\n        navigator = Navigator(disconnected_navmesh)\n        \n        # Try to path from region 1 to region 2 (disconnected)\n        start = (0, 0)  # Near node A\n        end = (200, 200)  # Near node X\n        \n        path = navigator.find_path(start, end)\n        \n        assert path == []\n    \n    def test_find_path_no_navmesh_loaded(self):\n        \"\"\"Test pathfinding with no NavMesh loaded.\"\"\"\n        navigator = Navigator()\n        \n        path = navigator.find_path((0, 0), (100, 100))\n        \n        assert path == []\n    \n    def test_find_path_empty_navmesh(self):\n        \"\"\"Test pathfinding with empty NavMesh.\"\"\"\n        navigator = Navigator({\"nodes\": {}})\n        \n        path = navigator.find_path((0, 0), (100, 100))\n        \n        assert path == []\n    \n    def test_find_path_returns_ordered_waypoints(self, simple_navmesh):\n        \"\"\"Test that returned path is properly ordered.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        start = (0, 0)\n        end = (100, 50)\n        \n        path = navigator.find_path(start, end)\n        \n        # Verify path is a list of tuples\n        assert isinstance(path, list)\n        for waypoint in path:\n            assert isinstance(waypoint, tuple)\n            assert len(waypoint) == 2\n    \n    def test_find_path_reverse_direction(self, simple_navmesh):\n        \"\"\"Test that pathfinding works in reverse direction.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Forward path\n        path_forward = navigator.find_path((0, 0), (100, 50))\n        # Reverse path\n        path_reverse = navigator.find_path((100, 50), (0, 0))\n        \n        assert len(path_forward) > 0\n        assert len(path_reverse) > 0\n        assert path_forward[0] == path_reverse[-1]\n        assert path_forward[-1] == path_reverse[0]\n    \n    def test_find_path_adjacent_nodes(self, simple_navmesh):\n        \"\"\"Test pathfinding between adjacent nodes.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # A and B are adjacent\n        start = (0, 0)\n        end = (50, 0)\n        \n        path = navigator.find_path(start, end)\n        \n        assert len(path) >= 2\n        assert path[0] == start\n        assert path[-1] == end\n    \n    def test_euclidean_distance_calculation(self):\n        \"\"\"Test internal distance calculation.\"\"\"\n        navigator = Navigator()\n        \n        # Test known distances\n        assert navigator._euclidean_distance((0, 0), (3, 4)) == 5.0\n        assert navigator._euclidean_distance((0, 0), (0, 0)) == 0.0\n        assert abs(navigator._euclidean_distance((0, 0), (1, 1)) - math.sqrt(2)) < 0.0001\n    \n    def test_point_in_polygon(self):\n        \"\"\"Test point-in-polygon detection.\"\"\"\n        navigator = Navigator()\n        \n        # Simple square polygon\n        square = [(0, 0), (10, 0), (10, 10), (0, 10)]\n        \n        # Point inside\n        assert navigator._point_in_polygon((5, 5), square) is True\n        \n        # Point outside\n        assert navigator._point_in_polygon((15, 5), square) is False\n        assert navigator._point_in_polygon((-5, 5), square) is False\n    \n    def test_find_containing_node(self, simple_navmesh):\n        \"\"\"Test finding the node containing a position.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Position inside node A\n        node = navigator._find_containing_node((0, 0))\n        assert node == \"A\"\n        \n        # Position inside node F\n        node = navigator._find_containing_node((100, 50))\n        assert node == \"F\"\n    \n    def test_path_optimality(self, simple_navmesh):\n        \"\"\"Test that A* finds reasonably optimal paths.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Path from A to F should not go through all nodes\n        path = navigator.find_path((0, 0), (100, 50))\n        \n        # A reasonable path should have limited waypoints\n        # Direct would be: start -> A -> B -> C -> F -> end or similar\n        # Should not visit all 6 nodes\n        assert len(path) <= 6  # start + max 4 intermediate + end\n\n\nclass TestNavigatorEdgeCases:\n    \"\"\"Test edge cases and error handling.\"\"\"\n    \n    def test_navmesh_with_invalid_neighbor_reference(self):\n        \"\"\"Test handling of invalid neighbor references.\"\"\"\n        navmesh = {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-10, -10), (10, -10), (10, 10), (-10, 10)],\n                    \"neighbors\": [\"B\", \"NONEXISTENT\"]  # Invalid reference\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"vertices\": [(40, -10), (60, -10), (60, 10), (40, 10)],\n                    \"neighbors\": [\"A\"]\n                }\n            }\n        }\n        \n        navigator = Navigator(navmesh)\n        \n        # Should still find path, ignoring invalid neighbor\n        path = navigator.find_path((0, 0), (50, 0))\n        assert len(path) > 0\n    \n    def test_navmesh_without_vertices(self):\n        \"\"\"Test NavMesh nodes without vertex data.\"\"\"\n        navmesh = {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"neighbors\": [\"B\"]\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"neighbors\": [\"A\"]\n                }\n            }\n        }\n        \n        navigator = Navigator(navmesh)\n        \n        # Should fall back to closest node matching\n        path = navigator.find_path((0, 0), (50, 0))\n        assert len(path) > 0\n    \n    def test_same_start_and_end(self, ):\n        \"\"\"Test pathfinding when start equals end.\"\"\"\n        navmesh = {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-50, -50), (50, -50), (50, 50), (-50, 50)],\n                    \"neighbors\": []\n                }\n            }\n        }\n        \n        navigator = Navigator(navmesh)\n        \n        path = navigator.find_path((0, 0), (0, 0))\n        \n        # Should return a valid path (start to end)\n        assert len(path) == 2\n        assert path[0] == (0, 0)\n        assert path[1] == (0, 0)\n",
          "tests/unit/engine/ai/test_behavior_tree.py": "\"\"\"Unit tests for the Behavior Tree system.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch\n\nfrom ledgerquest.engine.ai.behavior_tree import BehaviorTree\nfrom ledgerquest.engine.ai.blackboard import Blackboard\nfrom ledgerquest.engine.ai.nodes import (\n    NodeStatus,\n    Node,\n    Sequence,\n    Selector,\n    Inverter,\n    Repeater,\n    Action,\n    Condition,\n    ConditionCheck,\n    ActionExecute,\n    Wait,\n    SetBlackboardValue,\n    CheckBlackboardValue,\n    MoveTo,\n)\n\n\nclass TestNodeStatus:\n    \"\"\"Tests for NodeStatus enum.\"\"\"\n    \n    def test_status_values_exist(self):\n        \"\"\"Test that all required status values exist.\"\"\"\n        assert NodeStatus.SUCCESS is not None\n        assert NodeStatus.FAILURE is not None\n        assert NodeStatus.RUNNING is not None\n\n\nclass TestBlackboard:\n    \"\"\"Tests for the Blackboard class.\"\"\"\n    \n    def test_set_and_get(self):\n        \"\"\"Test setting and getting values.\"\"\"\n        bb = Blackboard()\n        bb.set(\"key\", \"value\")\n        assert bb.get(\"key\") == \"value\"\n    \n    def test_get_default(self):\n        \"\"\"Test getting with default value.\"\"\"\n        bb = Blackboard()\n        assert bb.get(\"nonexistent\", \"default\") == \"default\"\n    \n    def test_has(self):\n        \"\"\"Test checking key existence.\"\"\"\n        bb = Blackboard()\n        bb.set(\"exists\", True)\n        assert bb.has(\"exists\") is True\n        assert bb.has(\"nonexistent\") is False\n\n\nclass TestSequence:\n    \"\"\"Tests for the Sequence composite node.\"\"\"\n    \n    def test_all_success(self):\n        \"\"\"Test sequence returns SUCCESS when all children succeed.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.SUCCESS\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.SUCCESS\n        \n        sequence = Sequence([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n    \n    def test_failure_on_child_failure(self):\n        \"\"\"Test sequence returns FAILURE when a child fails.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.SUCCESS\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.FAILURE\n        \n        sequence = Sequence([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_running_on_child_running(self):\n        \"\"\"Test sequence returns RUNNING when a child is running.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.RUNNING\n        \n        sequence = Sequence([child1])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.RUNNING\n\n\nclass TestSelector:\n    \"\"\"Tests for the Selector composite node.\"\"\"\n    \n    def test_success_on_first_child_success(self):\n        \"\"\"Test selector returns SUCCESS when first child succeeds.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.SUCCESS\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.FAILURE\n        \n        selector = Selector([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = selector.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n        child2.tick.assert_not_called()\n    \n    def test_failure_when_all_fail(self):\n        \"\"\"Test selector returns FAILURE when all children fail.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.FAILURE\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.FAILURE\n        \n        selector = Selector([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = selector.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n\n\nclass TestInverter:\n    \"\"\"Tests for the Inverter decorator node.\"\"\"\n    \n    def test_inverts_success(self):\n        \"\"\"Test inverter converts SUCCESS to FAILURE.\"\"\"\n        child = Mock(spec=Node)\n        child.tick.return_value = NodeStatus.SUCCESS\n        \n        inverter = Inverter(child)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = inverter.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_inverts_failure(self):\n        \"\"\"Test inverter converts FAILURE to SUCCESS.\"\"\"\n        child = Mock(spec=Node)\n        child.tick.return_value = NodeStatus.FAILURE\n        \n        inverter = Inverter(child)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = inverter.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n    \n    def test_passes_running(self):\n        \"\"\"Test inverter passes through RUNNING.\"\"\"\n        child = Mock(spec=Node)\n        child.tick.return_value = NodeStatus.RUNNING\n        \n        inverter = Inverter(child)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = inverter.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.RUNNING\n\n\nclass TestWait:\n    \"\"\"Tests for the Wait action node.\"\"\"\n    \n    def test_returns_running_until_complete(self):\n        \"\"\"Test wait returns RUNNING until ticks complete.\"\"\"\n        wait = Wait(ticks=3)\n        bb = Blackboard()\n        registry = Mock()\n        \n        assert wait.tick(bb, \"entity1\", registry) == NodeStatus.RUNNING\n        assert wait.tick(bb, \"entity1\", registry) == NodeStatus.RUNNING\n        assert wait.tick(bb, \"entity1\", registry) == NodeStatus.SUCCESS\n\n\nclass TestSetBlackboardValue:\n    \"\"\"Tests for SetBlackboardValue action.\"\"\"\n    \n    def test_sets_value(self):\n        \"\"\"Test that value is set on blackboard.\"\"\"\n        action = SetBlackboardValue(\"test_key\", \"test_value\")\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = action.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n        assert bb.get(\"test_key\") == \"test_value\"\n\n\nclass TestCheckBlackboardValue:\n    \"\"\"Tests for CheckBlackboardValue condition.\"\"\"\n    \n    def test_check_exists_success(self):\n        \"\"\"Test checking key existence returns SUCCESS.\"\"\"\n        bb = Blackboard()\n        bb.set(\"exists\", True)\n        \n        condition = CheckBlackboardValue(\"exists\", check_exists=True)\n        registry = Mock()\n        \n        result = condition.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n    \n    def test_check_exists_failure(self):\n        \"\"\"Test checking missing key returns FAILURE.\"\"\"\n        bb = Blackboard()\n        \n        condition = CheckBlackboardValue(\"missing\", check_exists=True)\n        registry = Mock()\n        \n        result = condition.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_check_value_match(self):\n        \"\"\"Test checking value match returns SUCCESS.\"\"\"\n        bb = Blackboard()\n        bb.set(\"key\", \"expected\")\n        \n        condition = CheckBlackboardValue(\"key\", expected_value=\"expected\")\n        registry = Mock()\n        \n        result = condition.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n\n\nclass TestMoveTo:\n    \"\"\"Tests for the MoveTo action node.\"\"\"\n    \n    @pytest.fixture\n    def mock_registry(self):\n        \"\"\"Create a mock registry with position and velocity components.\"\"\"\n        registry = Mock()\n        \n        # Create mock position component\n        position_comp = Mock()\n        position_comp.x = 0\n        position_comp.y = 0\n        \n        # Create mock velocity component\n        velocity_comp = Mock()\n        velocity_comp.vx = 0\n        velocity_comp.vy = 0\n        \n        def get_component(entity_id, component_type):\n            if \"Position\" in str(component_type):\n                return position_comp\n            elif \"Velocity\" in str(component_type):\n                return velocity_comp\n            return None\n        \n        registry.get_component = Mock(side_effect=get_component)\n        registry._position_comp = position_comp\n        registry._velocity_comp = velocity_comp\n        \n        return registry\n    \n    @pytest.fixture\n    def mock_navigator(self):\n        \"\"\"Create a mock navigator.\"\"\"\n        navigator = Mock()\n        navigator.find_path.return_value = [(0, 0), (50, 0), (100, 0)]\n        return navigator\n    \n    def test_moveto_failure_no_destination(self, mock_registry):\n        \"\"\"Test MoveTo returns FAILURE when no destination set.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"navigator\", Mock())\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_moveto_failure_no_navigator(self, mock_registry):\n        \"\"\"Test MoveTo returns FAILURE when no navigator available.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 100))\n        # No navigator set\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_moveto_failure_no_path(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo returns FAILURE when no path found.\"\"\"\n        mock_navigator.find_path.return_value = []  # No path\n        \n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 100))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.FAILURE\n        mock_navigator.find_path.assert_called_once()\n    \n    def test_moveto_calculates_path_on_first_tick(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo calculates path on first tick.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        mock_navigator.find_path.assert_called_once_with((0, 0), (100, 0))\n        assert bb.get(\"_moveto_path\") is not None\n    \n    def test_moveto_returns_running_while_moving(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo returns RUNNING while entity is moving.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.RUNNING\n    \n    def test_moveto_stores_path_on_blackboard(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo stores calculated path on blackboard.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        moveto.tick(bb, \"entity1\", mock_registry)\n        \n        path = bb.get(\"_moveto_path\")\n        assert path is not None\n        assert len(path) == 3\n    \n    def test_moveto_sets_velocity_towards_waypoint(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo sets entity velocity towards current waypoint.\"\"\"\n        moveto = MoveTo(speed=100.0)\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        with patch('ledgerquest.engine.ai.nodes.MoveTo._set_entity_velocity') as mock_set_vel:\n            mock_set_vel.return_value = True\n            moveto.tick(bb, \"entity1\", mock_registry)\n            \n            # Should have called set_velocity\n            assert mock_set_vel.called\n    \n    def test_moveto_success_when_destination_reached(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo returns SUCCESS when destination is reached.\"\"\"\n        # Set position at the destination\n        mock_registry._position_comp.x = 100\n        mock_registry._position_comp.y = 0\n        \n        # Path that's already at the end\n        mock_navigator.find_path.return_value = [(100, 0), (100, 0)]\n        \n        moveto = MoveTo()\n        moveto.WAYPOINT_REACHED_THRESHOLD = 10.0\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        # First tick calculates path\n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        # Should reach destination quickly since we're already there\n        assert result == NodeStatus.SUCCESS\n    \n    def test_moveto_uses_custom_destination_key(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo can use custom blackboard key for destination.\"\"\"\n        moveto = MoveTo(destination_key=\"custom_dest\")\n        bb = Blackboard()\n        bb.set(\"custom_dest\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        mock_navigator.find_path.assert_called_once_with((0, 0), (100, 0))\n    \n    def test_moveto_reuses_path_on_subsequent_ticks(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo doesn't recalculate path on subsequent ticks.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        # First tick\n        moveto.tick(bb, \"entity1\", mock_registry)\n        # Second tick\n        moveto.tick(bb, \"entity1\", mock_registry)\n        # Third tick\n        moveto.tick(bb, \"entity1\", mock_registry)\n        \n        # Navigator should only be called once\n        assert mock_navigator.find_path.call_count == 1\n    \n    def test_moveto_advances_waypoints(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo advances through waypoints.\"\"\"\n        # Set position close to first waypoint\n        mock_registry._position_comp.x = 48\n        mock_registry._position_comp.y = 0\n        \n        moveto = MoveTo()\n        moveto.WAYPOINT_REACHED_THRESHOLD = 10.0\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        # First tick - calculates path, starts moving\n        moveto.tick(bb, \"entity1\", mock_registry)\n        \n        # Check waypoint index advances\n        waypoint_index = bb.get(\"_moveto_waypoint_index\")\n        assert waypoint_index is not None\n    \n    def test_moveto_cleans_up_on_success(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo cleans up blackboard state on success.\"\"\"\n        # Position at destination\n        mock_registry._position_comp.x = 100\n        mock_registry._position_comp.y = 0\n        \n        mock_navigator.find_path.return_value = [(100, 0), (100, 0)]\n        \n        moveto = MoveTo()\n        moveto.WAYPOINT_REACHED_THRESHOLD = 10.0\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.SUCCESS\n        assert bb.get(\"_moveto_path\") is None\n        assert bb.get(\"_moveto_waypoint_index\") is None\n    \n    def test_moveto_failure_no_position_component(self):\n        \"\"\"Test MoveTo returns FAILURE when entity has no position.\"\"\"\n        registry = Mock()\n        registry.get_component.return_value = None\n        \n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", Mock())\n        \n        result = moveto.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n\n\nclass TestBehaviorTree:\n    \"\"\"Tests for the BehaviorTree class.\"\"\"\n    \n    def test_tree_executes_root(self):\n        \"\"\"Test behavior tree executes its root node.\"\"\"\n        root = Mock(spec=Node)\n        root.tick.return_value = NodeStatus.SUCCESS\n        \n        tree = BehaviorTree(root)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = tree.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n        root.tick.assert_called_once_with(bb, \"entity1\", registry)\n    \n    def test_tree_without_root_returns_failure(self):\n        \"\"\"Test behavior tree without root returns FAILURE.\"\"\"\n        tree = BehaviorTree(None)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = tree.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n\n\nclass TestMoveToIntegration:\n    \"\"\"Integration tests for MoveTo with other nodes.\"\"\"\n    \n    def test_moveto_in_sequence(self):\n        \"\"\"Test MoveTo works correctly in a Sequence.\"\"\"\n        # Create mock components\n        registry = Mock()\n        position_comp = Mock()\n        position_comp.x = 0\n        position_comp.y = 0\n        velocity_comp = Mock()\n        velocity_comp.vx = 0\n        velocity_comp.vy = 0\n        \n        def get_component(entity_id, component_type):\n            if \"Position\" in str(component_type):\n                return position_comp\n            elif \"Velocity\" in str(component_type):\n                return velocity_comp\n            return None\n        \n        registry.get_component = Mock(side_effect=get_component)\n        \n        # Create navigator mock\n        navigator = Mock()\n        navigator.find_path.return_value = [(0, 0), (50, 0), (100, 0)]\n        \n        # Create behavior tree\n        set_dest = SetBlackboardValue(\"target_destination\", (100, 0))\n        moveto = MoveTo()\n        sequence = Sequence([set_dest, moveto])\n        \n        bb = Blackboard()\n        bb.set(\"navigator\", navigator)\n        \n        # First tick - sets destination, starts moving\n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.RUNNING\n        assert bb.get(\"target_destination\") == (100, 0)\n"
        },
        "generated_files": [
          "ledgerquest/engine/pathfinding/__init__.py",
          "ledgerquest/engine/pathfinding/navigator.py",
          "ledgerquest/engine/ai/nodes.py",
          "ledgerquest/services/game_loop/ai_updater.py",
          "tests/unit/engine/pathfinding/__init__.py",
          "tests/unit/engine/pathfinding/test_navigator.py",
          "tests/unit/engine/ai/test_behavior_tree.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.6761128262699972,
              "dependency_traversal_accuracy": 0.7380960260069933,
              "cross_file_reasoning_depth": 0.17273809523809525,
              "system_thinking_score": 0.4987305539894339,
              "robustness_score": 0.43320600083344907,
              "comprehensiveness_score": 0.7075354910404223,
              "innovation_score": 0.24375000000000002,
              "solution_elegance_score": 0.6308790212626104
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.08451410328374966,
              "dependency_traversal_weighted": 0.09226200325087416,
              "cross_file_reasoning_weighted": 0.021592261904761906,
              "system_thinking_weighted": 0.062341319248679236,
              "robustness_weighted": 0.05415075010418113,
              "comprehensiveness_weighted": 0.0884419363800528,
              "innovation_weighted": 0.030468750000000003,
              "solution_elegance_weighted": 0.0788598776578263
            },
            "total_software_engineering_score": 0.5126310018301251
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.44942545890808105,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "ledgerquest/engine/pathfinding/__init__.py",
                "ledgerquest/engine/pathfinding/navigator.py",
                "ledgerquest/engine/ai/nodes.py",
                "ledgerquest/services/game_loop/ai_updater.py",
                "tests/unit/engine/pathfinding/__init__.py",
                "tests/unit/engine/pathfinding/test_navigator.py",
                "tests/unit/engine/ai/test_behavior_tree.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 7,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 6 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.18009490509490508,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.18009490509490508,
              "idc_weight": 0.2,
              "total_functional_score": 0.616018981018981
            }
          },
          "code_quality_details": {
            "files_analyzed": 7,
            "quality_checks": {
              "ledgerquest/engine/pathfinding/__init__.py": {
                "line_count": 6,
                "non_empty_lines": 3,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 2,
                "quality_score": 0.5
              },
              "ledgerquest/engine/pathfinding/navigator.py": {
                "line_count": 226,
                "non_empty_lines": 174,
                "comment_lines": 8,
                "comment_ratio": 0.04597701149425287,
                "function_count": 8,
                "class_count": 1,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "ledgerquest/engine/ai/nodes.py": {
                "line_count": 567,
                "non_empty_lines": 435,
                "comment_lines": 16,
                "comment_ratio": 0.0367816091954023,
                "function_count": 34,
                "class_count": 21,
                "import_count": 21,
                "quality_score": 0.6
              },
              "ledgerquest/services/game_loop/ai_updater.py": {
                "line_count": 188,
                "non_empty_lines": 144,
                "comment_lines": 7,
                "comment_ratio": 0.04861111111111111,
                "function_count": 14,
                "class_count": 1,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "tests/unit/engine/pathfinding/__init__.py": {
                "line_count": 2,
                "non_empty_lines": 1,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.5
              },
              "tests/unit/engine/pathfinding/test_navigator.py": {
                "line_count": 344,
                "non_empty_lines": 274,
                "comment_lines": 22,
                "comment_ratio": 0.08029197080291971,
                "function_count": 22,
                "class_count": 2,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "tests/unit/engine/ai/test_behavior_tree.py": {
                "line_count": 545,
                "non_empty_lines": 399,
                "comment_lines": 20,
                "comment_ratio": 0.05012531328320802,
                "function_count": 37,
                "class_count": 11,
                "import_count": 9,
                "quality_score": 0.6
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.9522727272727272,
              "multi_session_memory_retention": 0.9155080213903742
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4761363636363636,
              "multi_session_memory_retention_weighted": 0.4577540106951871
            },
            "total_longcontext_utilization_score": 0.9338903743315508
          }
        },
        "timestamp": "2026-01-14T20:59:53.661651"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_api_rest_easy_078_feature_implementation_expert_01",
        "scenario_title": "Implement Per-Client Rate Limiting for API Endpoints",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.4961628741401457,
        "functional_correctness_score": 0.41559210526315793,
        "code_quality_score": 0.7999999999999999,
        "longcontext_utilization_score": 0.5665104166666668,
        "total_score": 2.698969114508362,
        "generation_time": 48.27198314666748,
        "code_files_generated": 4,
        "total_lines_generated": 389,
        "parsing_success": true,
        "solution_code": {
          "utilichain/middleware/__init__.py": "\"\"\"Middleware package for UtiliChain API Hub.\"\"\"\n\nfrom utilichain.middleware.rate_limiter import RateLimiter, RateLimitMiddleware\n\n__all__ = [\"RateLimiter\", \"RateLimitMiddleware\"]\n",
          "utilichain/middleware/rate_limiter.py": "\"\"\"Rate limiting middleware for UtiliChain API Hub.\n\nImplements a fixed-window counter algorithm for per-client rate limiting.\n\"\"\"\n\nimport os\nimport time\nfrom typing import Dict, Tuple, Optional\nfrom fastapi import Request, Response\nfrom fastapi.responses import JSONResponse\nfrom starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\n\n\nclass RateLimiter:\n    \"\"\"Fixed-window counter rate limiter.\n    \n    Tracks request counts per client identifier (API key or IP address)\n    within a 60-second window.\n    \"\"\"\n    \n    WINDOW_SIZE_SECONDS = 60\n    \n    def __init__(self, requests_per_minute: int = 60):\n        \"\"\"Initialize the rate limiter.\n        \n        Args:\n            requests_per_minute: Maximum number of requests allowed per minute.\n        \"\"\"\n        self.requests_per_minute = requests_per_minute\n        # Storage format: {client_id: (request_count, window_start_timestamp)}\n        self._storage: Dict[str, Tuple[int, float]] = {}\n    \n    def _get_window_start(self, current_time: float) -> float:\n        \"\"\"Calculate the start of the current window.\n        \n        Args:\n            current_time: Current Unix timestamp.\n            \n        Returns:\n            Unix timestamp of the window start.\n        \"\"\"\n        return (current_time // self.WINDOW_SIZE_SECONDS) * self.WINDOW_SIZE_SECONDS\n    \n    def _cleanup_expired(self, current_time: float) -> None:\n        \"\"\"Remove expired entries from storage.\n        \n        Args:\n            current_time: Current Unix timestamp.\n        \"\"\"\n        current_window = self._get_window_start(current_time)\n        expired_keys = [\n            key for key, (_, window_start) in self._storage.items()\n            if window_start < current_window\n        ]\n        for key in expired_keys:\n            del self._storage[key]\n    \n    def check_rate_limit(self, client_id: str) -> Tuple[bool, int, int, int]:\n        \"\"\"Check if a client has exceeded their rate limit.\n        \n        Args:\n            client_id: Unique identifier for the client (API key or IP).\n            \n        Returns:\n            Tuple of (is_allowed, limit, remaining, reset_timestamp)\n        \"\"\"\n        current_time = time.time()\n        current_window = self._get_window_start(current_time)\n        reset_timestamp = int(current_window + self.WINDOW_SIZE_SECONDS)\n        \n        # Periodic cleanup\n        self._cleanup_expired(current_time)\n        \n        # Get current count for client\n        if client_id in self._storage:\n            count, window_start = self._storage[client_id]\n            \n            # Check if we're in a new window\n            if window_start < current_window:\n                # Reset for new window\n                count = 0\n                window_start = current_window\n        else:\n            count = 0\n            window_start = current_window\n        \n        # Check if limit exceeded\n        if count >= self.requests_per_minute:\n            remaining = 0\n            return (False, self.requests_per_minute, remaining, reset_timestamp)\n        \n        # Increment count\n        count += 1\n        self._storage[client_id] = (count, window_start)\n        \n        remaining = max(0, self.requests_per_minute - count)\n        return (True, self.requests_per_minute, remaining, reset_timestamp)\n    \n    def get_client_identifier(self, request: Request) -> str:\n        \"\"\"Extract client identifier from request.\n        \n        Uses API key if present, otherwise falls back to IP address.\n        \n        Args:\n            request: The incoming FastAPI request.\n            \n        Returns:\n            Client identifier string.\n        \"\"\"\n        # Check for API key in header\n        api_key = request.headers.get(\"X-API-Key\")\n        if api_key:\n            return f\"api_key:{api_key}\"\n        \n        # Fall back to IP address\n        # Handle X-Forwarded-For for proxied requests\n        forwarded_for = request.headers.get(\"X-Forwarded-For\")\n        if forwarded_for:\n            # Take the first IP in the chain (original client)\n            client_ip = forwarded_for.split(\",\")[0].strip()\n        else:\n            client_ip = request.client.host if request.client else \"unknown\"\n        \n        return f\"ip:{client_ip}\"\n\n\nclass RateLimitMiddleware(BaseHTTPMiddleware):\n    \"\"\"FastAPI middleware for rate limiting.\"\"\"\n    \n    def __init__(self, app, rate_limiter: Optional[RateLimiter] = None):\n        \"\"\"Initialize the middleware.\n        \n        Args:\n            app: The FastAPI application.\n            rate_limiter: Optional RateLimiter instance. If not provided,\n                         creates one using RATE_LIMIT_PER_MINUTE env var.\n        \"\"\"\n        super().__init__(app)\n        \n        if rate_limiter is None:\n            # Get rate limit from environment variable\n            rate_limit = int(os.getenv(\"RATE_LIMIT_PER_MINUTE\", \"60\"))\n            self.rate_limiter = RateLimiter(requests_per_minute=rate_limit)\n        else:\n            self.rate_limiter = rate_limiter\n    \n    async def dispatch(\n        self, request: Request, call_next: RequestResponseEndpoint\n    ) -> Response:\n        \"\"\"Process the request and apply rate limiting.\n        \n        Args:\n            request: The incoming request.\n            call_next: The next middleware/endpoint to call.\n            \n        Returns:\n            The response with rate limit headers or 429 if limit exceeded.\n        \"\"\"\n        # Get client identifier\n        client_id = self.rate_limiter.get_client_identifier(request)\n        \n        # Check rate limit\n        is_allowed, limit, remaining, reset_timestamp = self.rate_limiter.check_rate_limit(\n            client_id\n        )\n        \n        if not is_allowed:\n            # Return 429 Too Many Requests\n            response = JSONResponse(\n                status_code=429,\n                content={\"detail\": \"Too Many Requests\"}\n            )\n            response.headers[\"X-RateLimit-Limit\"] = str(limit)\n            response.headers[\"X-RateLimit-Remaining\"] = str(remaining)\n            response.headers[\"X-RateLimit-Reset\"] = str(reset_timestamp)\n            return response\n        \n        # Process the request\n        response = await call_next(request)\n        \n        # Add rate limit headers to successful response\n        response.headers[\"X-RateLimit-Limit\"] = str(limit)\n        response.headers[\"X-RateLimit-Remaining\"] = str(remaining)\n        response.headers[\"X-RateLimit-Reset\"] = str(reset_timestamp)\n        \n        return response\n",
          "utilichain/main.py": "\"\"\"Main application module for UtiliChain API Hub.\n\nThis module initializes and configures the FastAPI application,\nincluding middleware, routers, and startup/shutdown events.\n\"\"\"\n\nimport os\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom utilichain.middleware.rate_limiter import RateLimitMiddleware\n\n# Application metadata\nAPP_TITLE = \"UtiliChain API Hub\"\nAPP_DESCRIPTION = \"A unified API gateway for utility chain services\"\nAPP_VERSION = \"0.1.0\"\n\n# Initialize FastAPI application\napp = FastAPI(\n    title=APP_TITLE,\n    description=APP_DESCRIPTION,\n    version=APP_VERSION,\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\",\n    openapi_url=\"/openapi.json\"\n)\n\n# Configure CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=os.getenv(\"CORS_ORIGINS\", \"*\").split(\",\"),\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add rate limiting middleware\napp.add_middleware(RateLimitMiddleware)\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Handle application startup tasks.\"\"\"\n    print(f\"Starting {APP_TITLE} v{APP_VERSION}\")\n    rate_limit = os.getenv(\"RATE_LIMIT_PER_MINUTE\", \"60\")\n    print(f\"Rate limiting enabled: {rate_limit} requests per minute\")\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    \"\"\"Handle application shutdown tasks.\"\"\"\n    print(f\"Shutting down {APP_TITLE}\")\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint returning API information.\"\"\"\n    return {\n        \"name\": APP_TITLE,\n        \"version\": APP_VERSION,\n        \"status\": \"operational\"\n    }\n\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint for monitoring.\"\"\"\n    return {\"status\": \"healthy\"}\n",
          "docs/api_reference.md": "# API Reference\n\nThis document provides detailed information about the UtiliChain API Hub endpoints and features.\n\n## Base URL\n\nThe API is available at the following base URL:\n\n- **Development**: `http://localhost:8000`\n- **Production**: `https://api.utilichain.example.com`\n\n## Authentication\n\nThe API supports authentication via API keys. Include your API key in the request header:\n\n```\nX-API-Key: your-api-key-here\n```\n\n## Rate Limiting\n\nThe UtiliChain API Hub implements rate limiting to ensure fair usage and protect against abuse.\n\n### How It Works\n\nRate limiting uses a **fixed-window counter** algorithm with a 60-second window. Each client is allowed a maximum number of requests within each window period.\n\n### Rate Limit Configuration\n\n- **Default Limit**: 60 requests per minute\n- **Window Size**: 60 seconds (1 minute)\n\nThe rate limit can be configured via the `RATE_LIMIT_PER_MINUTE` environment variable.\n\n### Client Identification\n\n- **Authenticated Requests**: Rate limits are applied per API key (identified by the `X-API-Key` header)\n- **Unauthenticated Requests**: Rate limits are applied per client IP address\n\n### Rate Limit Response Headers\n\nEvery API response includes the following headers to help you track your rate limit status:\n\n| Header | Description |\n|--------|-------------|\n| `X-RateLimit-Limit` | The maximum number of requests allowed in the current window |\n| `X-RateLimit-Remaining` | The number of requests remaining in the current window |\n| `X-RateLimit-Reset` | Unix timestamp (in seconds) indicating when the rate limit window resets |\n\n### Rate Limit Exceeded Response\n\nWhen you exceed the rate limit, the API responds with:\n\n- **HTTP Status Code**: `429 Too Many Requests`\n- **Response Body**:\n\n```json\n{\n    \"detail\": \"Too Many Requests\"\n}\n```\n\n### Best Practices\n\n1. **Monitor Headers**: Check the `X-RateLimit-Remaining` header to track your usage\n2. **Implement Backoff**: If you receive a 429 response, wait until the `X-RateLimit-Reset` timestamp before retrying\n3. **Cache Responses**: Where possible, cache API responses to reduce the number of requests\n4. **Use API Keys**: Authenticated requests with API keys have their own rate limit quota, separate from IP-based limits\n\n## Endpoints\n\n### Root Endpoint\n\n```\nGET /\n```\n\nReturns basic API information.\n\n**Response:**\n\n```json\n{\n    \"name\": \"UtiliChain API Hub\",\n    \"version\": \"0.1.0\",\n    \"status\": \"operational\"\n}\n```\n\n### Health Check\n\n```\nGET /health\n```\n\nReturns the health status of the API.\n\n**Response:**\n\n```json\n{\n    \"status\": \"healthy\"\n}\n```\n\n## Error Responses\n\nThe API uses standard HTTP status codes to indicate the success or failure of requests.\n\n| Status Code | Description |\n|-------------|-------------|\n| 200 | Success |\n| 400 | Bad Request - Invalid parameters |\n| 401 | Unauthorized - Invalid or missing API key |\n| 403 | Forbidden - Access denied |\n| 404 | Not Found - Resource does not exist |\n| 429 | Too Many Requests - Rate limit exceeded |\n| 500 | Internal Server Error |\n\n## OpenAPI Specification\n\nThe complete OpenAPI specification is available at:\n\n- **Swagger UI**: `/docs`\n- **ReDoc**: `/redoc`\n- **OpenAPI JSON**: `/openapi.json`\n"
        },
        "generated_files": [
          "utilichain/middleware/__init__.py",
          "utilichain/middleware/rate_limiter.py",
          "utilichain/main.py",
          "docs/api_reference.md"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.6703571428571429,
              "dependency_traversal_accuracy": 0.6372489239598278,
              "cross_file_reasoning_depth": 0.4641666666666667,
              "system_thinking_score": 0.47016472184417896,
              "robustness_score": 0.356426735218509,
              "comprehensiveness_score": 0.584293059125964,
              "innovation_score": 0.24587082262210797,
              "solution_elegance_score": 0.5407749208267685
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.08379464285714286,
              "dependency_traversal_weighted": 0.07965611549497847,
              "cross_file_reasoning_weighted": 0.05802083333333334,
              "system_thinking_weighted": 0.05877059023052237,
              "robustness_weighted": 0.04455334190231362,
              "comprehensiveness_weighted": 0.0730366323907455,
              "innovation_weighted": 0.030733852827763496,
              "solution_elegance_weighted": 0.06759686510334606
            },
            "total_software_engineering_score": 0.4961628741401457
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.2547798156738281,
              "errors": [
                "  File \"docs/api_reference.py\", line 3",
                "    This document provides detailed information about the UtiliChain API Hub endpoints and features.",
                "         ^^^^^^^^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "utilichain/middleware/__init__.py",
                "utilichain/middleware/rate_limiter.py",
                "utilichain/main.py",
                "docs/api_reference.md"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 4,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 4 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.3779605263157895,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.3779605263157895,
              "idc_weight": 0.2,
              "total_functional_score": 0.41559210526315793
            }
          },
          "code_quality_details": {
            "files_analyzed": 4,
            "quality_checks": {
              "utilichain/middleware/__init__.py": {
                "line_count": 6,
                "non_empty_lines": 3,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 2,
                "quality_score": 0.5
              },
              "utilichain/middleware/rate_limiter.py": {
                "line_count": 187,
                "non_empty_lines": 145,
                "comment_lines": 17,
                "comment_ratio": 0.11724137931034483,
                "function_count": 7,
                "class_count": 2,
                "import_count": 13,
                "quality_score": 0.9999999999999999
              },
              "utilichain/main.py": {
                "line_count": 69,
                "non_empty_lines": 53,
                "comment_lines": 4,
                "comment_ratio": 0.07547169811320754,
                "function_count": 4,
                "class_count": 0,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "docs/api_reference.md": {
                "line_count": 127,
                "non_empty_lines": 84,
                "comment_lines": 15,
                "comment_ratio": 0.17857142857142858,
                "function_count": 0,
                "class_count": 0,
                "import_count": 1,
                "quality_score": 0.8999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7999999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.5329166666666667,
              "multi_session_memory_retention": 0.6001041666666668
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.26645833333333335,
              "multi_session_memory_retention_weighted": 0.3000520833333334
            },
            "total_longcontext_utilization_score": 0.5665104166666668
          }
        },
        "timestamp": "2026-01-14T21:00:42.685032"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_mobile_game_hard_060_feature_implementation_expert_01",
        "scenario_title": "Implement Geofenced Quest Auto-Completion with User Confirmation",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5163372285421293,
        "functional_correctness_score": 0.4917093204709888,
        "code_quality_score": 0.7899999999999998,
        "longcontext_utilization_score": 0.5732536485253875,
        "total_score": 2.846865262053435,
        "generation_time": 140.38565731048584,
        "code_files_generated": 7,
        "total_lines_generated": 1292,
        "parsing_success": true,
        "solution_code": {
          "src/config.py": "\"\"\"Configuration settings for QuestSmith application.\"\"\"\n\n# Application settings\nAPP_NAME = \"QuestSmith\"\nAPP_VERSION = \"1.0.0\"\nDEBUG_MODE = True\n\n# Database settings\nDATABASE_URL = \"sqlite:///questsmith.db\"\nDATABASE_POOL_SIZE = 5\n\n# User settings\nMAX_ACTIVE_QUESTS = 10\nDEFAULT_USER_LEVEL = 1\nEXPERIENCE_MULTIPLIER = 1.0\n\n# Quest settings\nQUEST_EXPIRY_DAYS = 7\nMAX_QUEST_REWARDS = 5\n\n# Location settings\nDEFAULT_GEOFENCE_RADIUS_METERS = 100\n\n# Notification settings\nNOTIFICATION_ENABLED = True\nNOTIFICATION_SOUND = \"default\"\n\n# API settings\nAPI_TIMEOUT = 30\nAPI_RETRY_COUNT = 3\n",
          "src/utils.py": "\"\"\"Utility functions for QuestSmith application.\"\"\"\n\nimport math\nfrom typing import Tuple, Optional, List, Dict, Any\nimport re\nimport hashlib\nimport uuid\nfrom datetime import datetime, timedelta\n\n\ndef generate_unique_id() -> str:\n    \"\"\"Generate a unique identifier.\"\"\"\n    return str(uuid.uuid4())\n\n\ndef hash_password(password: str) -> str:\n    \"\"\"Hash a password using SHA-256.\"\"\"\n    return hashlib.sha256(password.encode()).hexdigest()\n\n\ndef validate_email(email: str) -> bool:\n    \"\"\"Validate an email address format.\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2}$'\n    return bool(re.match(pattern, email))\n\n\ndef format_datetime(dt: datetime) -> str:\n    \"\"\"Format a datetime object to a string.\"\"\"\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n\ndef parse_datetime(dt_string: str) -> datetime:\n    \"\"\"Parse a datetime string to a datetime object.\"\"\"\n    return datetime.strptime(dt_string, \"%Y-%m-%d %H:%M:%S\")\n\n\ndef calculate_experience_for_level(level: int) -> int:\n    \"\"\"Calculate total experience required for a given level.\"\"\"\n    return int(100 * (level ** 1.5))\n\n\ndef truncate_string(text: str, max_length: int = 100) -> str:\n    \"\"\"Truncate a string to a maximum length.\"\"\"\n    if len(text) <= max_length:\n        return text\n    return text[:max_length - 3] + \"...\"\n\n\ndef sanitize_input(text: str) -> str:\n    \"\"\"Sanitize user input by removing potentially harmful characters.\"\"\"\n    return re.sub(r'[<>\"\\'\\/\\\\]', '', text)\n\n\ndef calculate_haversine_distance(coord1: Tuple[float, float], coord2: Tuple[float, float]) -> float:\n    \"\"\"Calculate the distance in meters between two latitude/longitude points using the Haversine formula.\n    \n    Args:\n        coord1: A tuple of (latitude, longitude) for the first point.\n        coord2: A tuple of (latitude, longitude) for the second point.\n    \n    Returns:\n        The distance between the two points in meters.\n    \"\"\"\n    # Earth's radius in meters\n    EARTH_RADIUS_METERS = 6371000\n    \n    lat1, lon1 = coord1\n    lat2, lon2 = coord2\n    \n    # Convert latitude and longitude from degrees to radians\n    lat1_rad = math.radians(lat1)\n    lat2_rad = math.radians(lat2)\n    lon1_rad = math.radians(lon1)\n    lon2_rad = math.radians(lon2)\n    \n    # Differences in coordinates\n    delta_lat = lat2_rad - lat1_rad\n    delta_lon = lon2_rad - lon1_rad\n    \n    # Haversine formula\n    a = math.sin(delta_lat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon / 2) ** 2\n    c = 2 * math.asin(math.sqrt(a))\n    \n    # Calculate the distance\n    distance = EARTH_RADIUS_METERS * c\n    \n    return distance\n\n\ndef merge_dicts(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Merge two dictionaries, with dict2 values taking precedence.\"\"\"\n    result = dict1.copy()\n    result.update(dict2)\n    return result\n\n\ndef is_valid_coordinates(latitude: float, longitude: float) -> bool:\n    \"\"\"Validate if coordinates are within valid ranges.\"\"\"\n    return -90 <= latitude <= 90 and -180 <= longitude <= 180\n",
          "src/module_14.py": "\"\"\"Quest management system for QuestSmith.\"\"\"\n\nfrom typing import Optional, List, Dict, Any\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\nfrom src.config import DEFAULT_GEOFENCE_RADIUS_METERS\n\n\nclass QuestStatus(Enum):\n    \"\"\"Enumeration of possible quest statuses.\"\"\"\n    AVAILABLE = \"available\"\n    ACTIVE = \"active\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    EXPIRED = \"expired\"\n\n\nclass QuestDifficulty(Enum):\n    \"\"\"Enumeration of quest difficulty levels.\"\"\"\n    EASY = \"easy\"\n    MEDIUM = \"medium\"\n    HARD = \"hard\"\n    LEGENDARY = \"legendary\"\n\n\n@dataclass\nclass QuestLocation:\n    \"\"\"Represents a physical location associated with a quest.\"\"\"\n    latitude: float\n    longitude: float\n    location_name: str\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert location to dictionary.\"\"\"\n        return {\n            \"latitude\": self.latitude,\n            \"longitude\": self.longitude,\n            \"location_name\": self.location_name\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"QuestLocation\":\n        \"\"\"Create a QuestLocation from a dictionary.\"\"\"\n        return cls(\n            latitude=data[\"latitude\"],\n            longitude=data[\"longitude\"],\n            location_name=data[\"location_name\"]\n        )\n\n\n@dataclass\nclass QuestReward:\n    \"\"\"Represents rewards for completing a quest.\"\"\"\n    experience: int = 0\n    gold: int = 0\n    items: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Quest:\n    \"\"\"Represents a quest in the QuestSmith system.\"\"\"\n    quest_id: str\n    name: str\n    description: str\n    difficulty: QuestDifficulty\n    status: QuestStatus = QuestStatus.AVAILABLE\n    reward: QuestReward = field(default_factory=QuestReward)\n    created_at: datetime = field(default_factory=datetime.now)\n    completed_at: Optional[datetime] = None\n    expires_at: Optional[datetime] = None\n    user_id: Optional[str] = None\n    location: Optional[QuestLocation] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert quest to dictionary.\"\"\"\n        result = {\n            \"quest_id\": self.quest_id,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"difficulty\": self.difficulty.value,\n            \"status\": self.status.value,\n            \"reward\": {\n                \"experience\": self.reward.experience,\n                \"gold\": self.reward.gold,\n                \"items\": self.reward.items\n            },\n            \"created_at\": self.created_at.isoformat(),\n            \"completed_at\": self.completed_at.isoformat() if self.completed_at else None,\n            \"expires_at\": self.expires_at.isoformat() if self.expires_at else None,\n            \"user_id\": self.user_id,\n            \"location\": self.location.to_dict() if self.location else None\n        }\n        return result\n\n\nclass QuestManager:\n    \"\"\"Manages quest operations in the QuestSmith system.\"\"\"\n    \n    def __init__(self):\n        self._quests: Dict[str, Quest] = {}\n        self._user_quests: Dict[str, List[str]] = {}\n        self._geofence_service = None\n    \n    def set_geofence_service(self, geofence_service):\n        \"\"\"Set the geofence service for location-based quests.\"\"\"\n        self._geofence_service = geofence_service\n    \n    def create_quest(\n        self,\n        name: str,\n        description: str,\n        difficulty: QuestDifficulty,\n        reward: Optional[QuestReward] = None,\n        expires_at: Optional[datetime] = None,\n        location: Optional[QuestLocation] = None\n    ) -> Quest:\n        \"\"\"Create a new quest.\"\"\"\n        quest_id = str(uuid.uuid4())\n        quest = Quest(\n            quest_id=quest_id,\n            name=name,\n            description=description,\n            difficulty=difficulty,\n            reward=reward or QuestReward(),\n            expires_at=expires_at,\n            location=location\n        )\n        self._quests[quest_id] = quest\n        return quest\n    \n    def get_quest(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Retrieve a quest by its ID.\"\"\"\n        return self._quests.get(quest_id)\n    \n    def activate_quest(self, quest_id: str, user_id: str) -> bool:\n        \"\"\"Activate a quest for a user.\"\"\"\n        quest = self._quests.get(quest_id)\n        if not quest:\n            return False\n        \n        if quest.status != QuestStatus.AVAILABLE:\n            return False\n        \n        quest.status = QuestStatus.ACTIVE\n        quest.user_id = user_id\n        \n        if user_id not in self._user_quests:\n            self._user_quests[user_id] = []\n        self._user_quests[user_id].append(quest_id)\n        \n        # Register geofence if quest has location data\n        if quest.location and self._geofence_service:\n            self._geofence_service.register_geofence(\n                quest_id=quest_id,\n                latitude=quest.location.latitude,\n                longitude=quest.location.longitude,\n                radius_meters=DEFAULT_GEOFENCE_RADIUS_METERS\n            )\n        \n        return True\n    \n    def complete_quest(self, quest_id: str) -> Optional[QuestReward]:\n        \"\"\"Mark a quest as completed and return its rewards.\"\"\"\n        quest = self._quests.get(quest_id)\n        if not quest:\n            return None\n        \n        if quest.status != QuestStatus.ACTIVE:\n            return None\n        \n        quest.status = QuestStatus.COMPLETED\n        quest.completed_at = datetime.now()\n        \n        return quest.reward\n    \n    def fail_quest(self, quest_id: str) -> bool:\n        \"\"\"Mark a quest as failed.\"\"\"\n        quest = self._quests.get(quest_id)\n        if not quest:\n            return False\n        \n        quest.status = QuestStatus.FAILED\n        return True\n    \n    def get_user_quests(self, user_id: str, status: Optional[QuestStatus] = None) -> List[Quest]:\n        \"\"\"Get all quests for a user, optionally filtered by status.\"\"\"\n        quest_ids = self._user_quests.get(user_id, [])\n        quests = [self._quests[qid] for qid in quest_ids if qid in self._quests]\n        \n        if status:\n            quests = [q for q in quests if q.status == status]\n        \n        return quests\n    \n    def get_active_quests(self, user_id: str) -> List[Quest]:\n        \"\"\"Get all active quests for a user.\"\"\"\n        return self.get_user_quests(user_id, QuestStatus.ACTIVE)\n    \n    def get_available_quests(self) -> List[Quest]:\n        \"\"\"Get all available quests.\"\"\"\n        return [q for q in self._quests.values() if q.status == QuestStatus.AVAILABLE]\n\n\n# Global quest manager instance\nquest_manager = QuestManager()\n\n\ndef create_quest(\n    name: str,\n    description: str,\n    difficulty: QuestDifficulty,\n    reward: Optional[QuestReward] = None,\n    expires_at: Optional[datetime] = None,\n    location: Optional[QuestLocation] = None\n) -> Quest:\n    \"\"\"Create a new quest.\"\"\"\n    return quest_manager.create_quest(name, description, difficulty, reward, expires_at, location)\n\n\ndef get_quest(quest_id: str) -> Optional[Quest]:\n    \"\"\"Get a quest by ID.\"\"\"\n    return quest_manager.get_quest(quest_id)\n\n\ndef activate_quest(quest_id: str, user_id: str) -> bool:\n    \"\"\"Activate a quest for a user.\"\"\"\n    return quest_manager.activate_quest(quest_id, user_id)\n\n\ndef complete_quest(quest_id: str) -> Optional[QuestReward]:\n    \"\"\"Complete a quest and return rewards.\"\"\"\n    return quest_manager.complete_quest(quest_id)\n",
          "src/module_22.py": "\"\"\"Location services wrapper for QuestSmith.\"\"\"\n\nfrom typing import Optional, Dict, Any, Callable, List\nfrom dataclasses import dataclass\nfrom datetime import datetime\nimport uuid\n\n\n@dataclass\nclass Geofence:\n    \"\"\"Represents a geofence region.\"\"\"\n    geofence_id: str\n    quest_id: str\n    latitude: float\n    longitude: float\n    radius_meters: float\n    created_at: datetime\n    is_active: bool = True\n\n\n@dataclass\nclass LocationUpdate:\n    \"\"\"Represents a location update from the device.\"\"\"\n    latitude: float\n    longitude: float\n    accuracy: float\n    timestamp: datetime\n    altitude: Optional[float] = None\n    speed: Optional[float] = None\n\n\nclass LocationServicesWrapper:\n    \"\"\"Wrapper for device location services.\"\"\"\n    \n    def __init__(self):\n        self._geofences: Dict[str, Geofence] = {}\n        self._quest_geofence_map: Dict[str, str] = {}  # quest_id -> geofence_id\n        self._location_callbacks: List[Callable[[LocationUpdate], None]] = []\n        self._geofence_callbacks: List[Callable[[str, str], None]] = []  # (quest_id, event_type)\n        self._current_location: Optional[LocationUpdate] = None\n        self._is_tracking: bool = False\n    \n    def register_geofence(\n        self,\n        quest_id: str,\n        latitude: float,\n        longitude: float,\n        radius_meters: float\n    ) -> str:\n        \"\"\"Register a geofence for a quest location.\n        \n        Args:\n            quest_id: The unique identifier of the quest.\n            latitude: The latitude of the geofence center.\n            longitude: The longitude of the geofence center.\n            radius_meters: The radius of the geofence in meters.\n        \n        Returns:\n            The unique identifier of the created geofence.\n        \"\"\"\n        geofence_id = str(uuid.uuid4())\n        geofence = Geofence(\n            geofence_id=geofence_id,\n            quest_id=quest_id,\n            latitude=latitude,\n            longitude=longitude,\n            radius_meters=radius_meters,\n            created_at=datetime.now(),\n            is_active=True\n        )\n        self._geofences[geofence_id] = geofence\n        self._quest_geofence_map[quest_id] = geofence_id\n        return geofence_id\n    \n    def unregister_geofence(self, quest_id: str) -> bool:\n        \"\"\"Unregister a geofence associated with a quest.\n        \n        Args:\n            quest_id: The unique identifier of the quest.\n        \n        Returns:\n            True if the geofence was successfully unregistered, False otherwise.\n        \"\"\"\n        geofence_id = self._quest_geofence_map.get(quest_id)\n        if not geofence_id:\n            return False\n        \n        if geofence_id in self._geofences:\n            self._geofences[geofence_id].is_active = False\n            del self._geofences[geofence_id]\n        \n        del self._quest_geofence_map[quest_id]\n        return True\n    \n    def get_geofence_for_quest(self, quest_id: str) -> Optional[Geofence]:\n        \"\"\"Get the geofence associated with a quest.\"\"\"\n        geofence_id = self._quest_geofence_map.get(quest_id)\n        if geofence_id:\n            return self._geofences.get(geofence_id)\n        return None\n    \n    def get_active_geofences(self) -> List[Geofence]:\n        \"\"\"Get all active geofences.\"\"\"\n        return [g for g in self._geofences.values() if g.is_active]\n    \n    def register_location_callback(self, callback: Callable[[LocationUpdate], None]):\n        \"\"\"Register a callback for location updates.\"\"\"\n        self._location_callbacks.append(callback)\n    \n    def register_geofence_callback(self, callback: Callable[[str, str], None]):\n        \"\"\"Register a callback for geofence events.\n        \n        Args:\n            callback: A function that takes (quest_id, event_type) as arguments.\n                     event_type is either 'enter' or 'exit'.\n        \"\"\"\n        self._geofence_callbacks.append(callback)\n    \n    def start_location_tracking(self):\n        \"\"\"Start tracking the user's location.\"\"\"\n        self._is_tracking = True\n    \n    def stop_location_tracking(self):\n        \"\"\"Stop tracking the user's location.\"\"\"\n        self._is_tracking = False\n    \n    def get_current_location(self) -> Optional[LocationUpdate]:\n        \"\"\"Get the current cached location.\"\"\"\n        return self._current_location\n    \n    def simulate_location_update(self, latitude: float, longitude: float, accuracy: float = 10.0):\n        \"\"\"Simulate a location update (for testing purposes).\"\"\"\n        location = LocationUpdate(\n            latitude=latitude,\n            longitude=longitude,\n            accuracy=accuracy,\n            timestamp=datetime.now()\n        )\n        self._current_location = location\n        \n        # Notify location callbacks\n        for callback in self._location_callbacks:\n            callback(location)\n        \n        # Check geofences\n        self._check_geofences(location)\n    \n    def _check_geofences(self, location: LocationUpdate):\n        \"\"\"Check if the location triggers any geofences.\"\"\"\n        from src.utils import calculate_haversine_distance\n        \n        for geofence in self._geofences.values():\n            if not geofence.is_active:\n                continue\n            \n            distance = calculate_haversine_distance(\n                (location.latitude, location.longitude),\n                (geofence.latitude, geofence.longitude)\n            )\n            \n            if distance <= geofence.radius_meters:\n                # Trigger geofence enter event\n                for callback in self._geofence_callbacks:\n                    callback(geofence.quest_id, \"enter\")\n\n\n# Global location services instance\nlocation_services = LocationServicesWrapper()\n\n\ndef register_geofence(quest_id: str, latitude: float, longitude: float, radius_meters: float) -> str:\n    \"\"\"Register a geofence for a quest.\"\"\"\n    return location_services.register_geofence(quest_id, latitude, longitude, radius_meters)\n\n\ndef unregister_geofence(quest_id: str) -> bool:\n    \"\"\"Unregister a geofence for a quest.\"\"\"\n    return location_services.unregister_geofence(quest_id)\n\n\ndef get_location_services() -> LocationServicesWrapper:\n    \"\"\"Get the global location services instance.\"\"\"\n    return location_services\n",
          "src/module_31.py": "\"\"\"Push notification service for QuestSmith.\"\"\"\n\nfrom typing import Optional, List, Dict, Any, Callable\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\n\nclass NotificationPriority(Enum):\n    \"\"\"Priority levels for notifications.\"\"\"\n    LOW = \"low\"\n    NORMAL = \"normal\"\n    HIGH = \"high\"\n    URGENT = \"urgent\"\n\n\n@dataclass\nclass NotificationAction:\n    \"\"\"Represents an action button on a notification.\"\"\"\n    action_id: str\n    title: str\n    callback: Optional[Callable[[], None]] = None\n\n\n@dataclass\nclass LocalNotification:\n    \"\"\"Represents a local push notification.\"\"\"\n    notification_id: str\n    title: str\n    body: str\n    priority: NotificationPriority = NotificationPriority.NORMAL\n    actions: List[NotificationAction] = field(default_factory=list)\n    data: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=datetime.now)\n    delivered_at: Optional[datetime] = None\n    read_at: Optional[datetime] = None\n\n\nclass NotificationService:\n    \"\"\"Service for managing push notifications.\"\"\"\n    \n    def __init__(self):\n        self._notifications: Dict[str, LocalNotification] = {}\n        self._action_handlers: Dict[str, Callable[[str, str], None]] = {}  # action_id -> handler(notification_id, action_id)\n        self._pending_notifications: List[str] = []\n        self._is_enabled: bool = True\n    \n    def send_local_notification(\n        self,\n        title: str,\n        body: str,\n        priority: NotificationPriority = NotificationPriority.NORMAL,\n        actions: Optional[List[NotificationAction]] = None,\n        data: Optional[Dict[str, Any]] = None\n    ) -> str:\n        \"\"\"Send a local push notification.\n        \n        Args:\n            title: The notification title.\n            body: The notification body text.\n            priority: The notification priority level.\n            actions: Optional list of action buttons.\n            data: Optional custom data to attach to the notification.\n        \n        Returns:\n            The unique identifier of the notification.\n        \"\"\"\n        if not self._is_enabled:\n            return \"\"\n        \n        notification_id = str(uuid.uuid4())\n        notification = LocalNotification(\n            notification_id=notification_id,\n            title=title,\n            body=body,\n            priority=priority,\n            actions=actions or [],\n            data=data or {},\n            delivered_at=datetime.now()\n        )\n        self._notifications[notification_id] = notification\n        self._pending_notifications.append(notification_id)\n        \n        return notification_id\n    \n    def send_interactive_notification(\n        self,\n        title: str,\n        body: str,\n        actions: List[NotificationAction],\n        data: Optional[Dict[str, Any]] = None,\n        priority: NotificationPriority = NotificationPriority.HIGH\n    ) -> str:\n        \"\"\"Send an interactive notification with action buttons.\n        \n        Args:\n            title: The notification title.\n            body: The notification body text.\n            actions: List of action buttons for the notification.\n            data: Optional custom data to attach to the notification.\n            priority: The notification priority level.\n        \n        Returns:\n            The unique identifier of the notification.\n        \"\"\"\n        return self.send_local_notification(\n            title=title,\n            body=body,\n            priority=priority,\n            actions=actions,\n            data=data\n        )\n    \n    def register_action_handler(self, action_id: str, handler: Callable[[str, str], None]):\n        \"\"\"Register a handler for a notification action.\n        \n        Args:\n            action_id: The unique identifier of the action.\n            handler: A function that takes (notification_id, action_id) as arguments.\n        \"\"\"\n        self._action_handlers[action_id] = handler\n    \n    def handle_action(self, notification_id: str, action_id: str):\n        \"\"\"Handle a user action on a notification.\n        \n        Args:\n            notification_id: The notification that was acted upon.\n            action_id: The action that was taken.\n        \"\"\"\n        notification = self._notifications.get(notification_id)\n        if not notification:\n            return\n        \n        # Mark as read\n        notification.read_at = datetime.now()\n        \n        # Call registered handler\n        handler = self._action_handlers.get(action_id)\n        if handler:\n            handler(notification_id, action_id)\n        \n        # Call action-specific callback if present\n        for action in notification.actions:\n            if action.action_id == action_id and action.callback:\n                action.callback()\n    \n    def get_notification(self, notification_id: str) -> Optional[LocalNotification]:\n        \"\"\"Get a notification by its ID.\"\"\"\n        return self._notifications.get(notification_id)\n    \n    def get_pending_notifications(self) -> List[LocalNotification]:\n        \"\"\"Get all pending (unread) notifications.\"\"\"\n        return [\n            self._notifications[nid]\n            for nid in self._pending_notifications\n            if nid in self._notifications\n        ]\n    \n    def dismiss_notification(self, notification_id: str) -> bool:\n        \"\"\"Dismiss a notification.\"\"\"\n        if notification_id in self._pending_notifications:\n            self._pending_notifications.remove(notification_id)\n            return True\n        return False\n    \n    def clear_all_notifications(self):\n        \"\"\"Clear all pending notifications.\"\"\"\n        self._pending_notifications.clear()\n    \n    def enable_notifications(self):\n        \"\"\"Enable notifications.\"\"\"\n        self._is_enabled = True\n    \n    def disable_notifications(self):\n        \"\"\"Disable notifications.\"\"\"\n        self._is_enabled = False\n\n\n# Global notification service instance\nnotification_service = NotificationService()\n\n\ndef send_local_notification(\n    title: str,\n    body: str,\n    priority: NotificationPriority = NotificationPriority.NORMAL,\n    actions: Optional[List[NotificationAction]] = None,\n    data: Optional[Dict[str, Any]] = None\n) -> str:\n    \"\"\"Send a local push notification.\"\"\"\n    return notification_service.send_local_notification(title, body, priority, actions, data)\n\n\ndef send_interactive_notification(\n    title: str,\n    body: str,\n    actions: List[NotificationAction],\n    data: Optional[Dict[str, Any]] = None,\n    priority: NotificationPriority = NotificationPriority.HIGH\n) -> str:\n    \"\"\"Send an interactive notification with action buttons.\"\"\"\n    return notification_service.send_interactive_notification(title, body, actions, data, priority)\n\n\ndef register_action_handler(action_id: str, handler: Callable[[str, str], None]):\n    \"\"\"Register a handler for a notification action.\"\"\"\n    notification_service.register_action_handler(action_id, handler)\n\n\ndef handle_action(notification_id: str, action_id: str):\n    \"\"\"Handle a user action on a notification.\"\"\"\n    notification_service.handle_action(notification_id, action_id)\n\n\ndef get_notification_service() -> NotificationService:\n    \"\"\"Get the global notification service instance.\"\"\"\n    return notification_service\n",
          "src/module_7.py": "\"\"\"Background task handler for QuestSmith.\"\"\"\n\nfrom typing import Optional, Dict, Any, Callable, List\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\nfrom src.module_14 import get_quest, complete_quest, quest_manager\nfrom src.module_22 import unregister_geofence, get_location_services\nfrom src.module_31 import (\n    send_interactive_notification,\n    register_action_handler,\n    NotificationAction,\n    NotificationPriority\n)\n\n\nclass TaskType(Enum):\n    \"\"\"Types of background tasks.\"\"\"\n    GEOFENCE_TRIGGER = \"geofence_trigger\"\n    QUEST_EXPIRY_CHECK = \"quest_expiry_check\"\n    NOTIFICATION_DELIVERY = \"notification_delivery\"\n    DATA_SYNC = \"data_sync\"\n    LOCATION_UPDATE = \"location_update\"\n\n\nclass TaskStatus(Enum):\n    \"\"\"Status of a background task.\"\"\"\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass BackgroundTask:\n    \"\"\"Represents a background task.\"\"\"\n    task_id: str\n    task_type: TaskType\n    status: TaskStatus\n    data: Dict[str, Any]\n    created_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n\n\n# Constants for notification actions\nGEOFENCE_CONFIRM_ACTION_ID = \"geofence_quest_confirm\"\nGEOFENCE_DISMISS_ACTION_ID = \"geofence_quest_dismiss\"\n\n\nclass BackgroundTaskHandler:\n    \"\"\"Handles background tasks for the QuestSmith application.\"\"\"\n    \n    def __init__(self):\n        self._tasks: Dict[str, BackgroundTask] = {}\n        self._task_handlers: Dict[TaskType, Callable[[BackgroundTask], bool]] = {}\n        self._pending_geofence_notifications: Dict[str, str] = {}  # notification_id -> quest_id\n        self._initialize_handlers()\n        self._setup_notification_handlers()\n    \n    def _initialize_handlers(self):\n        \"\"\"Initialize task handlers for different task types.\"\"\"\n        self._task_handlers[TaskType.GEOFENCE_TRIGGER] = self._handle_geofence_trigger\n        self._task_handlers[TaskType.QUEST_EXPIRY_CHECK] = self._handle_quest_expiry_check\n        self._task_handlers[TaskType.NOTIFICATION_DELIVERY] = self._handle_notification_delivery\n        self._task_handlers[TaskType.DATA_SYNC] = self._handle_data_sync\n        self._task_handlers[TaskType.LOCATION_UPDATE] = self._handle_location_update\n    \n    def _setup_notification_handlers(self):\n        \"\"\"Setup handlers for notification actions.\"\"\"\n        register_action_handler(GEOFENCE_CONFIRM_ACTION_ID, self._handle_geofence_confirm_action)\n        register_action_handler(GEOFENCE_DISMISS_ACTION_ID, self._handle_geofence_dismiss_action)\n    \n    def create_task(\n        self,\n        task_type: TaskType,\n        data: Optional[Dict[str, Any]] = None\n    ) -> BackgroundTask:\n        \"\"\"Create a new background task.\"\"\"\n        task_id = str(uuid.uuid4())\n        task = BackgroundTask(\n            task_id=task_id,\n            task_type=task_type,\n            status=TaskStatus.PENDING,\n            data=data or {},\n            created_at=datetime.now()\n        )\n        self._tasks[task_id] = task\n        return task\n    \n    def execute_task(self, task_id: str) -> bool:\n        \"\"\"Execute a pending task.\"\"\"\n        task = self._tasks.get(task_id)\n        if not task:\n            return False\n        \n        if task.status != TaskStatus.PENDING:\n            return False\n        \n        task.status = TaskStatus.RUNNING\n        task.started_at = datetime.now()\n        \n        handler = self._task_handlers.get(task.task_type)\n        if not handler:\n            task.status = TaskStatus.FAILED\n            task.error_message = f\"No handler for task type: {task.task_type}\"\n            return False\n        \n        try:\n            success = handler(task)\n            task.status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            task.completed_at = datetime.now()\n            return success\n        except Exception as e:\n            task.status = TaskStatus.FAILED\n            task.error_message = str(e)\n            task.completed_at = datetime.now()\n            return False\n    \n    def _handle_geofence_trigger(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle a geofence trigger event.\n        \n        This is called when the user enters a geofenced area associated with a quest.\n        It sends an interactive notification asking the user to confirm quest completion.\n        \"\"\"\n        quest_id = task.data.get(\"quest_id\")\n        event_type = task.data.get(\"event_type\", \"enter\")\n        \n        if not quest_id:\n            task.error_message = \"No quest_id provided in geofence trigger\"\n            return False\n        \n        # Only handle 'enter' events\n        if event_type != \"enter\":\n            return True\n        \n        # Fetch the quest details\n        quest = get_quest(quest_id)\n        if not quest:\n            task.error_message = f\"Quest not found: {quest_id}\"\n            return False\n        \n        # Check if quest is still active\n        from src.module_14 import QuestStatus\n        if quest.status != QuestStatus.ACTIVE:\n            return True  # Quest is no longer active, nothing to do\n        \n        # Get location name\n        location_name = \"this location\"\n        if quest.location:\n            location_name = quest.location.location_name\n        \n        # Create notification actions\n        confirm_action = NotificationAction(\n            action_id=GEOFENCE_CONFIRM_ACTION_ID,\n            title=\"Confirm\"\n        )\n        dismiss_action = NotificationAction(\n            action_id=GEOFENCE_DISMISS_ACTION_ID,\n            title=\"Not Yet\"\n        )\n        \n        # Send interactive notification\n        notification_id = send_interactive_notification(\n            title=\"QuestSmith\",\n            body=f\"It looks like you're at {location_name}. Did you complete '{quest.name}'?\",\n            actions=[confirm_action, dismiss_action],\n            data={\"quest_id\": quest_id},\n            priority=NotificationPriority.HIGH\n        )\n        \n        # Store mapping for handling the response\n        self._pending_geofence_notifications[notification_id] = quest_id\n        \n        return True\n    \n    def _handle_geofence_confirm_action(self, notification_id: str, action_id: str):\n        \"\"\"Handle the 'Confirm' action from a geofence notification.\n        \n        This is called when the user taps 'Confirm' on the quest completion notification.\n        It completes the quest and unregisters the geofence.\n        \"\"\"\n        quest_id = self._pending_geofence_notifications.get(notification_id)\n        if not quest_id:\n            # Try to get quest_id from notification data\n            from src.module_31 import get_notification_service\n            notification = get_notification_service().get_notification(notification_id)\n            if notification and notification.data:\n                quest_id = notification.data.get(\"quest_id\")\n        \n        if not quest_id:\n            return\n        \n        # Complete the quest\n        reward = complete_quest(quest_id)\n        \n        if reward:\n            # Unregister the geofence to prevent repeated notifications and save battery\n            unregister_geofence(quest_id)\n            \n            # Clean up pending notification mapping\n            if notification_id in self._pending_geofence_notifications:\n                del self._pending_geofence_notifications[notification_id]\n    \n    def _handle_geofence_dismiss_action(self, notification_id: str, action_id: str):\n        \"\"\"Handle the 'Not Yet' action from a geofence notification.\"\"\"\n        # Just clean up the pending notification mapping\n        if notification_id in self._pending_geofence_notifications:\n            del self._pending_geofence_notifications[notification_id]\n    \n    def _handle_quest_expiry_check(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle quest expiry checking.\"\"\"\n        # Implementation for checking expired quests\n        return True\n    \n    def _handle_notification_delivery(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle notification delivery.\"\"\"\n        # Implementation for notification delivery\n        return True\n    \n    def _handle_data_sync(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle data synchronization.\"\"\"\n        # Implementation for data sync\n        return True\n    \n    def _handle_location_update(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle location update processing.\"\"\"\n        # Implementation for location updates\n        return True\n    \n    def get_task(self, task_id: str) -> Optional[BackgroundTask]:\n        \"\"\"Get a task by its ID.\"\"\"\n        return self._tasks.get(task_id)\n    \n    def get_pending_tasks(self) -> List[BackgroundTask]:\n        \"\"\"Get all pending tasks.\"\"\"\n        return [t for t in self._tasks.values() if t.status == TaskStatus.PENDING]\n\n\n# Global background task handler instance\ntask_handler = BackgroundTaskHandler()\n\n\ndef handle_geofence_event(quest_id: str, event_type: str = \"enter\"):\n    \"\"\"Handle a geofence event from the location services.\n    \n    This function is called when the user enters or exits a geofenced area.\n    \n    Args:\n        quest_id: The ID of the quest associated with the geofence.\n        event_type: The type of event ('enter' or 'exit').\n    \"\"\"\n    task = task_handler.create_task(\n        TaskType.GEOFENCE_TRIGGER,\n        data={\"quest_id\": quest_id, \"event_type\": event_type}\n    )\n    task_handler.execute_task(task.task_id)\n\n\ndef handle_quest_confirmation(quest_id: str):\n    \"\"\"Handle quest confirmation from a notification.\n    \n    This is called when the user confirms quest completion via notification.\n    \n    Args:\n        quest_id: The ID of the quest to complete.\n    \"\"\"\n    # Complete the quest\n    reward = complete_quest(quest_id)\n    \n    if reward:\n        # Unregister the geofence\n        unregister_geofence(quest_id)\n\n\ndef initialize_geofence_handler():\n    \"\"\"Initialize the geofence event handler.\n    \n    This connects the location services to the background task handler.\n    \"\"\"\n    location_services = get_location_services()\n    location_services.register_geofence_callback(handle_geofence_event)\n\n\ndef get_task_handler() -> BackgroundTaskHandler:\n    \"\"\"Get the global task handler instance.\"\"\"\n    return task_handler\n",
          "tests/test_utils.py": "\"\"\"Unit tests for utility functions.\"\"\"\n\nimport unittest\nimport math\nfrom datetime import datetime\n\nfrom src.utils import (\n    generate_unique_id,\n    hash_password,\n    validate_email,\n    format_datetime,\n    parse_datetime,\n    calculate_experience_for_level,\n    truncate_string,\n    sanitize_input,\n    calculate_haversine_distance,\n    is_valid_coordinates\n)\n\n\nclass TestUtilityFunctions(unittest.TestCase):\n    \"\"\"Test cases for utility functions.\"\"\"\n    \n    def test_generate_unique_id(self):\n        \"\"\"Test that unique IDs are generated.\"\"\"\n        id1 = generate_unique_id()\n        id2 = generate_unique_id()\n        self.assertNotEqual(id1, id2)\n        self.assertIsInstance(id1, str)\n        self.assertTrue(len(id1) > 0)\n    \n    def test_hash_password(self):\n        \"\"\"Test password hashing.\"\"\"\n        password = \"test_password\"\n        hashed = hash_password(password)\n        self.assertNotEqual(password, hashed)\n        self.assertEqual(len(hashed), 64)  # SHA-256 produces 64 hex characters\n        \n        # Same password should produce same hash\n        hashed2 = hash_password(password)\n        self.assertEqual(hashed, hashed2)\n    \n    def test_validate_email_valid(self):\n        \"\"\"Test email validation with valid emails.\"\"\"\n        valid_emails = [\n            \"test@example.com\",\n            \"user.name@domain.org\",\n            \"user+tag@example.co.uk\"\n        ]\n        for email in valid_emails:\n            self.assertTrue(validate_email(email), f\"{email} should be valid\")\n    \n    def test_validate_email_invalid(self):\n        \"\"\"Test email validation with invalid emails.\"\"\"\n        invalid_emails = [\n            \"not_an_email\",\n            \"@nodomain.com\",\n            \"missing@.com\",\n            \"\"\n        ]\n        for email in invalid_emails:\n            self.assertFalse(validate_email(email), f\"{email} should be invalid\")\n    \n    def test_format_datetime(self):\n        \"\"\"Test datetime formatting.\"\"\"\n        dt = datetime(2024, 1, 15, 10, 30, 45)\n        formatted = format_datetime(dt)\n        self.assertEqual(formatted, \"2024-01-15 10:30:45\")\n    \n    def test_parse_datetime(self):\n        \"\"\"Test datetime parsing.\"\"\"\n        dt_string = \"2024-01-15 10:30:45\"\n        parsed = parse_datetime(dt_string)\n        self.assertEqual(parsed.year, 2024)\n        self.assertEqual(parsed.month, 1)\n        self.assertEqual(parsed.day, 15)\n        self.assertEqual(parsed.hour, 10)\n        self.assertEqual(parsed.minute, 30)\n        self.assertEqual(parsed.second, 45)\n    \n    def test_calculate_experience_for_level(self):\n        \"\"\"Test experience calculation.\"\"\"\n        exp_level_1 = calculate_experience_for_level(1)\n        exp_level_10 = calculate_experience_for_level(10)\n        self.assertGreater(exp_level_10, exp_level_1)\n        self.assertEqual(exp_level_1, 100)\n    \n    def test_truncate_string(self):\n        \"\"\"Test string truncation.\"\"\"\n        short_text = \"Hello\"\n        long_text = \"This is a very long text that should be truncated\"\n        \n        self.assertEqual(truncate_string(short_text, 10), \"Hello\")\n        truncated = truncate_string(long_text, 20)\n        self.assertEqual(len(truncated), 20)\n        self.assertTrue(truncated.endswith(\"...\"))\n    \n    def test_sanitize_input(self):\n        \"\"\"Test input sanitization.\"\"\"\n        dirty_input = \"<script>alert('xss')</script>\"\n        clean = sanitize_input(dirty_input)\n        self.assertNotIn(\"<\", clean)\n        self.assertNotIn(\">\", clean)\n\n\nclass TestCalculateHaversineDistance(unittest.TestCase):\n    \"\"\"Test cases for the haversine distance calculation function.\"\"\"\n    \n    def test_calculate_haversine_distance_same_point(self):\n        \"\"\"Test that distance between same point is zero.\"\"\"\n        coord = (40.7128, -74.0060)  # New York City\n        distance = calculate_haversine_distance(coord, coord)\n        self.assertEqual(distance, 0.0)\n    \n    def test_calculate_haversine_distance_known_distance(self):\n        \"\"\"Test haversine distance with known real-world distance.\"\"\"\n        # New York City to Los Angeles\n        # Actual distance is approximately 3,944 km (3,944,000 meters)\n        new_york = (40.7128, -74.0060)\n        los_angeles = (34.0522, -118.2437)\n        \n        distance = calculate_haversine_distance(new_york, los_angeles)\n        \n        # Allow for some variance (within 50km of expected)\n        expected_distance = 3944000  # meters\n        self.assertAlmostEqual(distance, expected_distance, delta=50000)\n    \n    def test_calculate_haversine_distance_short_distance(self):\n        \"\"\"Test haversine distance for a short distance (within a city).\"\"\"\n        # Empire State Building to Times Square (approximately 1.2 km)\n        empire_state = (40.7484, -73.9857)\n        times_square = (40.7580, -73.9855)\n        \n        distance = calculate_haversine_distance(empire_state, times_square)\n        \n        # Should be approximately 1000-1200 meters\n        self.assertGreater(distance, 900)\n        self.assertLess(distance, 1500)\n    \n    def test_calculate_haversine_distance_symmetric(self):\n        \"\"\"Test that distance is symmetric (A to B equals B to A).\"\"\"\n        coord1 = (51.5074, -0.1278)  # London\n        coord2 = (48.8566, 2.3522)   # Paris\n        \n        distance_1_to_2 = calculate_haversine_distance(coord1, coord2)\n        distance_2_to_1 = calculate_haversine_distance(coord2, coord1)\n        \n        self.assertAlmostEqual(distance_1_to_2, distance_2_to_1, places=5)\n    \n    def test_calculate_haversine_distance_equator(self):\n        \"\"\"Test distance calculation along the equator.\"\"\"\n        # Two points on the equator, 1 degree apart\n        # 1 degree at equator is approximately 111.32 km\n        point1 = (0.0, 0.0)\n        point2 = (0.0, 1.0)\n        \n        distance = calculate_haversine_distance(point1, point2)\n        \n        # Should be approximately 111,320 meters\n        self.assertAlmostEqual(distance, 111320, delta=500)\n    \n    def test_calculate_haversine_distance_poles(self):\n        \"\"\"Test distance from North Pole to South Pole.\"\"\"\n        north_pole = (90.0, 0.0)\n        south_pole = (-90.0, 0.0)\n        \n        distance = calculate_haversine_distance(north_pole, south_pole)\n        \n        # Half the Earth's circumference, approximately 20,015 km\n        expected = 20015000  # meters\n        self.assertAlmostEqual(distance, expected, delta=100000)\n    \n    def test_calculate_haversine_distance_very_small(self):\n        \"\"\"Test distance calculation for very small distances (meters apart).\"\"\"\n        # Two points approximately 100 meters apart\n        point1 = (40.7128, -74.0060)\n        # Move approximately 100 meters north (about 0.0009 degrees)\n        point2 = (40.7137, -74.0060)\n        \n        distance = calculate_haversine_distance(point1, point2)\n        \n        # Should be approximately 100 meters\n        self.assertGreater(distance, 80)\n        self.assertLess(distance, 120)\n    \n    def test_calculate_haversine_distance_returns_float(self):\n        \"\"\"Test that the function returns a float.\"\"\"\n        coord1 = (0.0, 0.0)\n        coord2 = (1.0, 1.0)\n        \n        distance = calculate_haversine_distance(coord1, coord2)\n        \n        self.assertIsInstance(distance, float)\n    \n    def test_calculate_haversine_distance_negative_coordinates(self):\n        \"\"\"Test with negative latitude and longitude values.\"\"\"\n        # Sydney, Australia to Cape Town, South Africa\n        sydney = (-33.8688, 151.2093)\n        cape_town = (-33.9249, 18.4241)\n        \n        distance = calculate_haversine_distance(sydney, cape_town)\n        \n        # Should be approximately 11,000 km\n        self.assertGreater(distance, 10000000)\n        self.assertLess(distance, 12000000)\n\n\nclass TestIsValidCoordinates(unittest.TestCase):\n    \"\"\"Test cases for coordinate validation.\"\"\"\n    \n    def test_valid_coordinates(self):\n        \"\"\"Test with valid coordinates.\"\"\"\n        self.assertTrue(is_valid_coordinates(0, 0))\n        self.assertTrue(is_valid_coordinates(90, 180))\n        self.assertTrue(is_valid_coordinates(-90, -180))\n        self.assertTrue(is_valid_coordinates(45.5, -122.6))\n    \n    def test_invalid_latitude(self):\n        \"\"\"Test with invalid latitude.\"\"\"\n        self.assertFalse(is_valid_coordinates(91, 0))\n        self.assertFalse(is_valid_coordinates(-91, 0))\n    \n    def test_invalid_longitude(self):\n        \"\"\"Test with invalid longitude.\"\"\"\n        self.assertFalse(is_valid_coordinates(0, 181))\n        self.assertFalse(is_valid_coordinates(0, -181))\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"
        },
        "generated_files": [
          "src/config.py",
          "src/utils.py",
          "src/module_14.py",
          "src/module_22.py",
          "src/module_31.py",
          "src/module_7.py",
          "tests/test_utils.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7075428571428571,
              "dependency_traversal_accuracy": 0.746674198132594,
              "cross_file_reasoning_depth": 0.20440476190476192,
              "system_thinking_score": 0.3769943503717276,
              "robustness_score": 0.41539299930498513,
              "comprehensiveness_score": 0.72281212484994,
              "innovation_score": 0.1875,
              "solution_elegance_score": 0.7693765366301679
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.08844285714285714,
              "dependency_traversal_weighted": 0.09333427476657424,
              "cross_file_reasoning_weighted": 0.02555059523809524,
              "system_thinking_weighted": 0.04712429379646595,
              "robustness_weighted": 0.05192412491312314,
              "comprehensiveness_weighted": 0.0903515156062425,
              "innovation_weighted": 0.0234375,
              "solution_elegance_weighted": 0.09617206707877099
            },
            "total_software_engineering_score": 0.5163372285421293
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.456113338470459,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "src/config.py",
                "src/utils.py",
                "src/module_14.py",
                "src/module_22.py",
                "src/module_31.py",
                "src/module_7.py",
                "tests/test_utils.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.0,
              "tests_run": 4,
              "tests_passed": 0,
              "tests_failed": 4,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": false,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": false,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 7,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 6 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.30854660235494397,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.0,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.30854660235494397,
              "idc_weight": 0.2,
              "total_functional_score": 0.4917093204709888
            }
          },
          "code_quality_details": {
            "files_analyzed": 7,
            "quality_checks": {
              "src/config.py": {
                "line_count": 31,
                "non_empty_lines": 23,
                "comment_lines": 7,
                "comment_ratio": 0.30434782608695654,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.7
              },
              "src/utils.py": {
                "line_count": 100,
                "non_empty_lines": 68,
                "comment_lines": 5,
                "comment_ratio": 0.07352941176470588,
                "function_count": 11,
                "class_count": 0,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "src/module_14.py": {
                "line_count": 236,
                "non_empty_lines": 187,
                "comment_lines": 2,
                "comment_ratio": 0.0106951871657754,
                "function_count": 17,
                "class_count": 6,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "src/module_22.py": {
                "line_count": 184,
                "non_empty_lines": 144,
                "comment_lines": 4,
                "comment_ratio": 0.027777777777777776,
                "function_count": 15,
                "class_count": 4,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "src/module_31.py": {
                "line_count": 219,
                "non_empty_lines": 175,
                "comment_lines": 4,
                "comment_ratio": 0.022857142857142857,
                "function_count": 16,
                "class_count": 4,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "src/module_7.py": {
                "line_count": 291,
                "non_empty_lines": 229,
                "comment_lines": 20,
                "comment_ratio": 0.08733624454148471,
                "function_count": 18,
                "class_count": 7,
                "import_count": 24,
                "quality_score": 0.7999999999999999
              },
              "tests/test_utils.py": {
                "line_count": 231,
                "non_empty_lines": 181,
                "comment_lines": 15,
                "comment_ratio": 0.08287292817679558,
                "function_count": 21,
                "class_count": 3,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7899999999999998,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.5333498023715413,
              "multi_session_memory_retention": 0.6131574946792337
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.26667490118577064,
              "multi_session_memory_retention_weighted": 0.3065787473396169
            },
            "total_longcontext_utilization_score": 0.5732536485253875
          }
        },
        "timestamp": "2026-01-14T21:03:04.231492"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_data_streaming_hard_013_feature_implementation_expert_01",
        "scenario_title": "Implement Dynamic Backpressure for Stream Pipelines",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5107846745397264,
        "functional_correctness_score": 0.4237717497556207,
        "code_quality_score": 0.8116666666666665,
        "longcontext_utilization_score": 0.631858497253234,
        "total_score": 2.7848228890061675,
        "generation_time": 240.27305436134338,
        "code_files_generated": 6,
        "total_lines_generated": 1699,
        "parsing_success": true,
        "solution_code": {
          "src/config.py": "\"\"\"Configuration module for ChatterStream Nexus platform.\n\nThis module contains all configuration settings for the streaming platform,\nincluding pipeline settings, processing parameters, and backpressure configuration.\n\"\"\"\n\nimport os\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass BackpressureConfig:\n    \"\"\"Configuration for dynamic backpressure mechanism.\n    \n    Attributes:\n        enabled: Whether backpressure is active.\n        monitoring_interval_seconds: How often to check queue sizes.\n        high_watermark_threshold: Queue fullness percentage that triggers throttling.\n        low_watermark_threshold: Queue fullness percentage below which to ramp up.\n        throttle_factor: Multiplier for reducing rate when throttling.\n        ramp_up_factor: Multiplier for increasing rate when ramping up.\n        min_emission_rate: Minimum allowed emission rate (events/sec).\n        max_emission_rate: Maximum allowed emission rate (events/sec).\n    \"\"\"\n    enabled: bool = True\n    monitoring_interval_seconds: int = 5\n    high_watermark_threshold: float = 0.85\n    low_watermark_threshold: float = 0.25\n    throttle_factor: float = 0.9\n    ramp_up_factor: float = 1.1\n    min_emission_rate: float = 1.0\n    max_emission_rate: float = 10000.0\n\n\n@dataclass\nclass PipelineConfig:\n    \"\"\"Configuration for stream pipeline settings.\"\"\"\n    max_workers: int = 4\n    buffer_size: int = 1000\n    batch_size: int = 100\n    timeout_seconds: int = 30\n\n\n@dataclass\nclass MonitoringConfig:\n    \"\"\"Configuration for monitoring and metrics.\"\"\"\n    enabled: bool = True\n    metrics_port: int = 9090\n    log_level: str = \"INFO\"\n    health_check_interval: int = 10\n\n\n@dataclass\nclass Config:\n    \"\"\"Main configuration container for the platform.\n    \n    Aggregates all configuration sections including pipeline,\n    monitoring, and backpressure settings.\n    \"\"\"\n    pipeline: PipelineConfig = field(default_factory=PipelineConfig)\n    monitoring: MonitoringConfig = field(default_factory=MonitoringConfig)\n    backpressure: BackpressureConfig = field(default_factory=BackpressureConfig)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Config':\n        \"\"\"Create configuration from dictionary.\"\"\"\n        pipeline_data = data.get('pipeline', {})\n        monitoring_data = data.get('monitoring', {})\n        backpressure_data = data.get('backpressure', {})\n        \n        return cls(\n            pipeline=PipelineConfig(**pipeline_data),\n            monitoring=MonitoringConfig(**monitoring_data),\n            backpressure=BackpressureConfig(**backpressure_data)\n        )\n    \n    @classmethod\n    def from_env(cls) -> 'Config':\n        \"\"\"Create configuration from environment variables.\"\"\"\n        config = cls()\n        \n        # Backpressure settings from environment\n        if os.getenv('BACKPRESSURE_ENABLED'):\n            config.backpressure.enabled = os.getenv('BACKPRESSURE_ENABLED', 'true').lower() == 'true'\n        if os.getenv('BACKPRESSURE_MONITORING_INTERVAL'):\n            config.backpressure.monitoring_interval_seconds = int(os.getenv('BACKPRESSURE_MONITORING_INTERVAL', '5'))\n        if os.getenv('BACKPRESSURE_HIGH_WATERMARK'):\n            config.backpressure.high_watermark_threshold = float(os.getenv('BACKPRESSURE_HIGH_WATERMARK', '0.85'))\n        if os.getenv('BACKPRESSURE_LOW_WATERMARK'):\n            config.backpressure.low_watermark_threshold = float(os.getenv('BACKPRESSURE_LOW_WATERMARK', '0.25'))\n        if os.getenv('BACKPRESSURE_THROTTLE_FACTOR'):\n            config.backpressure.throttle_factor = float(os.getenv('BACKPRESSURE_THROTTLE_FACTOR', '0.9'))\n        if os.getenv('BACKPRESSURE_RAMP_UP_FACTOR'):\n            config.backpressure.ramp_up_factor = float(os.getenv('BACKPRESSURE_RAMP_UP_FACTOR', '1.1'))\n        \n        return config\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert configuration to dictionary.\"\"\"\n        return {\n            'pipeline': {\n                'max_workers': self.pipeline.max_workers,\n                'buffer_size': self.pipeline.buffer_size,\n                'batch_size': self.pipeline.batch_size,\n                'timeout_seconds': self.pipeline.timeout_seconds,\n            },\n            'monitoring': {\n                'enabled': self.monitoring.enabled,\n                'metrics_port': self.monitoring.metrics_port,\n                'log_level': self.monitoring.log_level,\n                'health_check_interval': self.monitoring.health_check_interval,\n            },\n            'backpressure': {\n                'enabled': self.backpressure.enabled,\n                'monitoring_interval_seconds': self.backpressure.monitoring_interval_seconds,\n                'high_watermark_threshold': self.backpressure.high_watermark_threshold,\n                'low_watermark_threshold': self.backpressure.low_watermark_threshold,\n                'throttle_factor': self.backpressure.throttle_factor,\n                'ramp_up_factor': self.backpressure.ramp_up_factor,\n                'min_emission_rate': self.backpressure.min_emission_rate,\n                'max_emission_rate': self.backpressure.max_emission_rate,\n            }\n        }\n\n\n# Global configuration instance\n_config: Optional[Config] = None\n\n\ndef get_config() -> Config:\n    \"\"\"Get the global configuration instance.\"\"\"\n    global _config\n    if _config is None:\n        _config = Config.from_env()\n    return _config\n\n\ndef set_config(config: Config) -> None:\n    \"\"\"Set the global configuration instance.\"\"\"\n    global _config\n    _config = config\n\n\ndef reset_config() -> None:\n    \"\"\"Reset the global configuration to defaults.\"\"\"\n    global _config\n    _config = None\n",
          "src/module_1.py": "\"\"\"Primary data source module for ChatterStream Nexus.\n\nThis module implements the main data source generator that produces\nevents for the stream processing pipeline.\n\"\"\"\n\nimport time\nimport threading\nimport queue\nfrom typing import Any, Dict, Optional, Callable, Iterator, List\nfrom dataclasses import dataclass, field\nimport logging\nimport random\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass DataEvent:\n    \"\"\"Represents a single data event from the source.\"\"\"\n    event_id: str\n    timestamp: float\n    payload: Dict[str, Any]\n    source_id: str\n    sequence_number: int\n\n\nclass DataSourceOne:\n    \"\"\"Primary data source generator for the streaming platform.\n    \n    This class generates data events at a configurable rate and supports\n    dynamic rate adjustment for backpressure handling.\n    \n    Attributes:\n        source_id: Unique identifier for this source.\n        initial_rate: Starting emission rate in events per second.\n        current_rate: Current emission rate (can be adjusted dynamically).\n    \"\"\"\n    \n    def __init__(\n        self,\n        source_id: str = \"source_1\",\n        initial_rate: float = 100.0,\n        max_rate: float = 10000.0,\n        min_rate: float = 1.0\n    ):\n        \"\"\"Initialize the data source.\n        \n        Args:\n            source_id: Unique identifier for this source.\n            initial_rate: Initial emission rate in events/second.\n            max_rate: Maximum allowed emission rate.\n            min_rate: Minimum allowed emission rate.\n        \"\"\"\n        self.source_id = source_id\n        self.initial_rate = initial_rate\n        self._current_rate = initial_rate\n        self._max_rate = max_rate\n        self._min_rate = min_rate\n        self._sequence_counter = 0\n        self._running = False\n        self._lock = threading.RLock()\n        self._output_queue: Optional[queue.Queue] = None\n        self._emission_thread: Optional[threading.Thread] = None\n        self._callbacks: List[Callable[[DataEvent], None]] = []\n        \n        logger.info(f\"DataSourceOne initialized: {source_id}, rate={initial_rate}\")\n    \n    @property\n    def current_rate(self) -> float:\n        \"\"\"Get the current emission rate.\"\"\"\n        with self._lock:\n            return self._current_rate\n    \n    def set_emission_rate(self, new_rate: float) -> None:\n        \"\"\"Set the emission rate dynamically.\n        \n        This method allows the backpressure controller to adjust the\n        data emission rate at runtime based on downstream capacity.\n        \n        Args:\n            new_rate: New emission rate in events per second.\n                     Will be clamped to [min_rate, max_rate].\n        \"\"\"\n        with self._lock:\n            old_rate = self._current_rate\n            # Clamp the rate to valid bounds\n            self._current_rate = max(self._min_rate, min(self._max_rate, new_rate))\n            \n            if old_rate != self._current_rate:\n                logger.info(\n                    f\"DataSourceOne [{self.source_id}] rate changed: \"\n                    f\"{old_rate:.2f} -> {self._current_rate:.2f} events/sec\"\n                )\n    \n    def get_emission_rate(self) -> float:\n        \"\"\"Get the current emission rate.\n        \n        Returns:\n            Current emission rate in events per second.\n        \"\"\"\n        return self.current_rate\n    \n    def _generate_event(self) -> DataEvent:\n        \"\"\"Generate a single data event.\"\"\"\n        with self._lock:\n            self._sequence_counter += 1\n            seq = self._sequence_counter\n        \n        return DataEvent(\n            event_id=str(uuid.uuid4()),\n            timestamp=time.time(),\n            payload={\n                \"data\": f\"event_data_{seq}\",\n                \"value\": random.random() * 100,\n                \"category\": random.choice([\"A\", \"B\", \"C\", \"D\"]),\n            },\n            source_id=self.source_id,\n            sequence_number=seq\n        )\n    \n    def _emission_loop(self) -> None:\n        \"\"\"Main emission loop running in a separate thread.\"\"\"\n        logger.info(f\"DataSourceOne [{self.source_id}] emission loop started\")\n        \n        while self._running:\n            try:\n                # Calculate sleep time based on current rate\n                with self._lock:\n                    rate = self._current_rate\n                \n                if rate <= 0:\n                    time.sleep(0.1)\n                    continue\n                \n                sleep_time = 1.0 / rate\n                \n                # Generate and emit event\n                event = self._generate_event()\n                \n                # Send to output queue if configured\n                if self._output_queue is not None:\n                    try:\n                        self._output_queue.put_nowait(event)\n                    except queue.Full:\n                        logger.warning(f\"Output queue full, dropping event {event.event_id}\")\n                \n                # Notify callbacks\n                for callback in self._callbacks:\n                    try:\n                        callback(event)\n                    except Exception as e:\n                        logger.error(f\"Callback error: {e}\")\n                \n                time.sleep(sleep_time)\n                \n            except Exception as e:\n                logger.error(f\"Error in emission loop: {e}\")\n                time.sleep(0.1)\n        \n        logger.info(f\"DataSourceOne [{self.source_id}] emission loop stopped\")\n    \n    def start(self, output_queue: Optional[queue.Queue] = None) -> None:\n        \"\"\"Start the data source emission.\n        \n        Args:\n            output_queue: Optional queue to send events to.\n        \"\"\"\n        if self._running:\n            logger.warning(f\"DataSourceOne [{self.source_id}] already running\")\n            return\n        \n        self._output_queue = output_queue\n        self._running = True\n        self._emission_thread = threading.Thread(\n            target=self._emission_loop,\n            name=f\"DataSource-{self.source_id}\",\n            daemon=True\n        )\n        self._emission_thread.start()\n        logger.info(f\"DataSourceOne [{self.source_id}] started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the data source emission.\"\"\"\n        self._running = False\n        if self._emission_thread is not None:\n            self._emission_thread.join(timeout=5.0)\n            self._emission_thread = None\n        logger.info(f\"DataSourceOne [{self.source_id}] stopped\")\n    \n    def register_callback(self, callback: Callable[[DataEvent], None]) -> None:\n        \"\"\"Register a callback for emitted events.\"\"\"\n        self._callbacks.append(callback)\n    \n    def unregister_callback(self, callback: Callable[[DataEvent], None]) -> None:\n        \"\"\"Unregister a callback.\"\"\"\n        if callback in self._callbacks:\n            self._callbacks.remove(callback)\n    \n    def generate_batch(self, count: int) -> Iterator[DataEvent]:\n        \"\"\"Generate a batch of events synchronously.\n        \n        Args:\n            count: Number of events to generate.\n            \n        Yields:\n            DataEvent objects.\n        \"\"\"\n        for _ in range(count):\n            yield self._generate_event()\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get source statistics.\"\"\"\n        with self._lock:\n            return {\n                \"source_id\": self.source_id,\n                \"current_rate\": self._current_rate,\n                \"initial_rate\": self.initial_rate,\n                \"sequence_counter\": self._sequence_counter,\n                \"running\": self._running,\n                \"min_rate\": self._min_rate,\n                \"max_rate\": self._max_rate,\n            }\n    \n    def is_running(self) -> bool:\n        \"\"\"Check if the source is running.\"\"\"\n        return self._running\n\n\n# Factory function for creating sources\ndef create_data_source(\n    source_id: str = \"source_1\",\n    initial_rate: float = 100.0,\n    **kwargs\n) -> DataSourceOne:\n    \"\"\"Factory function to create a DataSourceOne instance.\"\"\"\n    return DataSourceOne(source_id=source_id, initial_rate=initial_rate, **kwargs)\n",
          "src/module_2.py": "\"\"\"Secondary data source module for ChatterStream Nexus.\n\nThis module implements an alternative data source generator that produces\nevents for the stream processing pipeline with different characteristics.\n\"\"\"\n\nimport time\nimport threading\nimport queue\nfrom typing import Any, Dict, Optional, Callable, Iterator, List, Union\nfrom dataclasses import dataclass, field\nimport logging\nimport random\nimport uuid\nimport json\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass StreamEvent:\n    \"\"\"Represents a stream event from the secondary source.\"\"\"\n    event_id: str\n    timestamp: float\n    payload: Dict[str, Any]\n    source_id: str\n    sequence_number: int\n    event_type: str\n    priority: int = 0\n\n\nclass DataSourceTwo:\n    \"\"\"Secondary data source generator for the streaming platform.\n    \n    This class generates data events with different characteristics than\n    DataSourceOne, supporting multiple event types and priorities.\n    Supports dynamic rate adjustment for backpressure handling.\n    \n    Attributes:\n        source_id: Unique identifier for this source.\n        initial_rate: Starting emission rate in events per second.\n        current_rate: Current emission rate (can be adjusted dynamically).\n    \"\"\"\n    \n    EVENT_TYPES = [\"metric\", \"log\", \"trace\", \"alert\", \"heartbeat\"]\n    \n    def __init__(\n        self,\n        source_id: str = \"source_2\",\n        initial_rate: float = 50.0,\n        max_rate: float = 10000.0,\n        min_rate: float = 1.0,\n        event_types: Optional[List[str]] = None\n    ):\n        \"\"\"Initialize the secondary data source.\n        \n        Args:\n            source_id: Unique identifier for this source.\n            initial_rate: Initial emission rate in events/second.\n            max_rate: Maximum allowed emission rate.\n            min_rate: Minimum allowed emission rate.\n            event_types: List of event types to generate.\n        \"\"\"\n        self.source_id = source_id\n        self.initial_rate = initial_rate\n        self._current_rate = initial_rate\n        self._max_rate = max_rate\n        self._min_rate = min_rate\n        self._event_types = event_types or self.EVENT_TYPES\n        self._sequence_counter = 0\n        self._running = False\n        self._paused = False\n        self._lock = threading.RLock()\n        self._output_queue: Optional[queue.Queue] = None\n        self._emission_thread: Optional[threading.Thread] = None\n        self._callbacks: List[Callable[[StreamEvent], None]] = []\n        self._event_counts: Dict[str, int] = {et: 0 for et in self._event_types}\n        \n        logger.info(f\"DataSourceTwo initialized: {source_id}, rate={initial_rate}\")\n    \n    @property\n    def current_rate(self) -> float:\n        \"\"\"Get the current emission rate.\"\"\"\n        with self._lock:\n            return self._current_rate\n    \n    def set_emission_rate(self, new_rate: float) -> None:\n        \"\"\"Set the emission rate dynamically.\n        \n        This method allows the backpressure controller to adjust the\n        data emission rate at runtime based on downstream capacity.\n        \n        Args:\n            new_rate: New emission rate in events per second.\n                     Will be clamped to [min_rate, max_rate].\n        \"\"\"\n        with self._lock:\n            old_rate = self._current_rate\n            # Clamp the rate to valid bounds\n            self._current_rate = max(self._min_rate, min(self._max_rate, new_rate))\n            \n            if old_rate != self._current_rate:\n                logger.info(\n                    f\"DataSourceTwo [{self.source_id}] rate changed: \"\n                    f\"{old_rate:.2f} -> {self._current_rate:.2f} events/sec\"\n                )\n    \n    def get_emission_rate(self) -> float:\n        \"\"\"Get the current emission rate.\n        \n        Returns:\n            Current emission rate in events per second.\n        \"\"\"\n        return self.current_rate\n    \n    def _generate_event(self) -> StreamEvent:\n        \"\"\"Generate a single stream event.\"\"\"\n        with self._lock:\n            self._sequence_counter += 1\n            seq = self._sequence_counter\n        \n        event_type = random.choice(self._event_types)\n        priority = random.randint(0, 9)\n        \n        # Generate type-specific payload\n        if event_type == \"metric\":\n            payload = {\n                \"metric_name\": f\"metric_{random.randint(1, 100)}\",\n                \"value\": random.random() * 1000,\n                \"unit\": random.choice([\"ms\", \"bytes\", \"count\", \"percent\"]),\n            }\n        elif event_type == \"log\":\n            payload = {\n                \"level\": random.choice([\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\"]),\n                \"message\": f\"Log message {seq}\",\n                \"component\": f\"component_{random.randint(1, 10)}\",\n            }\n        elif event_type == \"trace\":\n            payload = {\n                \"trace_id\": str(uuid.uuid4()),\n                \"span_id\": str(uuid.uuid4())[:8],\n                \"duration_ms\": random.random() * 100,\n            }\n        elif event_type == \"alert\":\n            payload = {\n                \"severity\": random.choice([\"low\", \"medium\", \"high\", \"critical\"]),\n                \"title\": f\"Alert {seq}\",\n                \"resolved\": random.choice([True, False]),\n            }\n            priority = max(priority, 7)  # Alerts have higher priority\n        else:  # heartbeat\n            payload = {\n                \"status\": \"alive\",\n                \"uptime_seconds\": random.randint(0, 86400),\n            }\n        \n        with self._lock:\n            self._event_counts[event_type] += 1\n        \n        return StreamEvent(\n            event_id=str(uuid.uuid4()),\n            timestamp=time.time(),\n            payload=payload,\n            source_id=self.source_id,\n            sequence_number=seq,\n            event_type=event_type,\n            priority=priority\n        )\n    \n    def _emission_loop(self) -> None:\n        \"\"\"Main emission loop running in a separate thread.\"\"\"\n        logger.info(f\"DataSourceTwo [{self.source_id}] emission loop started\")\n        \n        while self._running:\n            try:\n                # Check if paused\n                if self._paused:\n                    time.sleep(0.1)\n                    continue\n                \n                # Calculate sleep time based on current rate\n                with self._lock:\n                    rate = self._current_rate\n                \n                if rate <= 0:\n                    time.sleep(0.1)\n                    continue\n                \n                sleep_time = 1.0 / rate\n                \n                # Generate and emit event\n                event = self._generate_event()\n                \n                # Send to output queue if configured\n                if self._output_queue is not None:\n                    try:\n                        self._output_queue.put_nowait(event)\n                    except queue.Full:\n                        logger.warning(\n                            f\"Output queue full, dropping event {event.event_id}\"\n                        )\n                \n                # Notify callbacks\n                for callback in self._callbacks:\n                    try:\n                        callback(event)\n                    except Exception as e:\n                        logger.error(f\"Callback error: {e}\")\n                \n                time.sleep(sleep_time)\n                \n            except Exception as e:\n                logger.error(f\"Error in emission loop: {e}\")\n                time.sleep(0.1)\n        \n        logger.info(f\"DataSourceTwo [{self.source_id}] emission loop stopped\")\n    \n    def start(self, output_queue: Optional[queue.Queue] = None) -> None:\n        \"\"\"Start the data source emission.\n        \n        Args:\n            output_queue: Optional queue to send events to.\n        \"\"\"\n        if self._running:\n            logger.warning(f\"DataSourceTwo [{self.source_id}] already running\")\n            return\n        \n        self._output_queue = output_queue\n        self._running = True\n        self._paused = False\n        self._emission_thread = threading.Thread(\n            target=self._emission_loop,\n            name=f\"DataSource-{self.source_id}\",\n            daemon=True\n        )\n        self._emission_thread.start()\n        logger.info(f\"DataSourceTwo [{self.source_id}] started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the data source emission.\"\"\"\n        self._running = False\n        if self._emission_thread is not None:\n            self._emission_thread.join(timeout=5.0)\n            self._emission_thread = None\n        logger.info(f\"DataSourceTwo [{self.source_id}] stopped\")\n    \n    def pause(self) -> None:\n        \"\"\"Pause event emission without stopping the thread.\"\"\"\n        self._paused = True\n        logger.info(f\"DataSourceTwo [{self.source_id}] paused\")\n    \n    def resume(self) -> None:\n        \"\"\"Resume event emission after pause.\"\"\"\n        self._paused = False\n        logger.info(f\"DataSourceTwo [{self.source_id}] resumed\")\n    \n    def register_callback(self, callback: Callable[[StreamEvent], None]) -> None:\n        \"\"\"Register a callback for emitted events.\"\"\"\n        self._callbacks.append(callback)\n    \n    def unregister_callback(self, callback: Callable[[StreamEvent], None]) -> None:\n        \"\"\"Unregister a callback.\"\"\"\n        if callback in self._callbacks:\n            self._callbacks.remove(callback)\n    \n    def generate_batch(self, count: int) -> Iterator[StreamEvent]:\n        \"\"\"Generate a batch of events synchronously.\n        \n        Args:\n            count: Number of events to generate.\n            \n        Yields:\n            StreamEvent objects.\n        \"\"\"\n        for _ in range(count):\n            yield self._generate_event()\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get source statistics.\"\"\"\n        with self._lock:\n            return {\n                \"source_id\": self.source_id,\n                \"current_rate\": self._current_rate,\n                \"initial_rate\": self.initial_rate,\n                \"sequence_counter\": self._sequence_counter,\n                \"running\": self._running,\n                \"paused\": self._paused,\n                \"min_rate\": self._min_rate,\n                \"max_rate\": self._max_rate,\n                \"event_counts\": dict(self._event_counts),\n                \"event_types\": list(self._event_types),\n            }\n    \n    def is_running(self) -> bool:\n        \"\"\"Check if the source is running.\"\"\"\n        return self._running and not self._paused\n    \n    def reset_counters(self) -> None:\n        \"\"\"Reset event counters.\"\"\"\n        with self._lock:\n            self._event_counts = {et: 0 for et in self._event_types}\n            logger.info(f\"DataSourceTwo [{self.source_id}] counters reset\")\n\n\n# Factory function for creating sources\ndef create_data_source(\n    source_id: str = \"source_2\",\n    initial_rate: float = 50.0,\n    **kwargs\n) -> DataSourceTwo:\n    \"\"\"Factory function to create a DataSourceTwo instance.\"\"\"\n    return DataSourceTwo(source_id=source_id, initial_rate=initial_rate, **kwargs)\n",
          "src/module_31.py": "\"\"\"Monitoring module for ChatterStream Nexus.\n\nThis module provides health monitoring, metrics collection, and\nperformance tracking for the streaming platform.\n\"\"\"\n\nimport time\nimport threading\nfrom typing import Any, Dict, Optional, List, Callable, TYPE_CHECKING\nfrom dataclasses import dataclass, field\nimport logging\nimport queue\n\nif TYPE_CHECKING:\n    from .module_20 import PipelineScheduler\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass HealthStatus:\n    \"\"\"Represents the health status of a component.\"\"\"\n    component_name: str\n    status: str  # \"healthy\", \"degraded\", \"unhealthy\"\n    last_check: float\n    details: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass QueueMetrics:\n    \"\"\"Metrics for a processing queue.\"\"\"\n    queue_name: str\n    current_size: int\n    max_size: int\n    fullness_percentage: float\n    \n    @classmethod\n    def from_queue_info(cls, name: str, current: int, maximum: int) -> 'QueueMetrics':\n        \"\"\"Create QueueMetrics from queue information.\"\"\"\n        fullness = (current / maximum) if maximum > 0 else 0.0\n        return cls(\n            queue_name=name,\n            current_size=current,\n            max_size=maximum,\n            fullness_percentage=fullness\n        )\n\n\n@dataclass\nclass MetricPoint:\n    \"\"\"A single metric data point.\"\"\"\n    name: str\n    value: float\n    timestamp: float\n    labels: Dict[str, str] = field(default_factory=dict)\n\n\nclass Monitor:\n    \"\"\"Central monitoring component for the streaming platform.\n    \n    Collects health and performance metrics from various components\n    including the pipeline scheduler's processing queues.\n    \"\"\"\n    \n    def __init__(self, check_interval: int = 10):\n        \"\"\"Initialize the monitor.\n        \n        Args:\n            check_interval: Interval in seconds between health checks.\n        \"\"\"\n        self.check_interval = check_interval\n        self._running = False\n        self._lock = threading.RLock()\n        self._health_statuses: Dict[str, HealthStatus] = {}\n        self._metrics: List[MetricPoint] = []\n        self._metrics_limit = 10000\n        self._check_thread: Optional[threading.Thread] = None\n        self._health_callbacks: List[Callable[[HealthStatus], None]] = []\n        self._scheduler_ref: Optional['PipelineScheduler'] = None\n        \n        logger.info(f\"Monitor initialized with check_interval={check_interval}s\")\n    \n    def set_scheduler(self, scheduler: 'PipelineScheduler') -> None:\n        \"\"\"Set reference to the pipeline scheduler for queue monitoring.\n        \n        Args:\n            scheduler: The PipelineScheduler instance to monitor.\n        \"\"\"\n        self._scheduler_ref = scheduler\n        logger.info(\"Monitor linked to PipelineScheduler\")\n    \n    def get_queue_fullness(self) -> float:\n        \"\"\"Get the fullness percentage of the most full queue.\n        \n        This method queries the pipeline scheduler for queue information\n        and returns the highest fullness percentage among all queues.\n        Used by the backpressure controller to determine throttling needs.\n        \n        Returns:\n            Float between 0.0 and 1.0 representing the fullest queue's\n            percentage (current_size / max_size). Returns 0.0 if no\n            scheduler is linked or no queues exist.\n        \"\"\"\n        if self._scheduler_ref is None:\n            logger.warning(\"No scheduler linked, returning 0.0 queue fullness\")\n            return 0.0\n        \n        try:\n            queue_info = self._scheduler_ref.get_queue_status()\n            if not queue_info:\n                return 0.0\n            \n            max_fullness = 0.0\n            for name, info in queue_info.items():\n                current = info.get('current_size', 0)\n                maximum = info.get('max_size', 1)\n                if maximum > 0:\n                    fullness = current / maximum\n                    max_fullness = max(max_fullness, fullness)\n            \n            return max_fullness\n            \n        except Exception as e:\n            logger.error(f\"Error getting queue fullness: {e}\")\n            return 0.0\n    \n    def get_all_queue_metrics(self) -> List[QueueMetrics]:\n        \"\"\"Get metrics for all monitored queues.\n        \n        Returns:\n            List of QueueMetrics for each queue in the scheduler.\n        \"\"\"\n        if self._scheduler_ref is None:\n            return []\n        \n        try:\n            queue_info = self._scheduler_ref.get_queue_status()\n            metrics = []\n            \n            for name, info in queue_info.items():\n                metrics.append(QueueMetrics.from_queue_info(\n                    name=name,\n                    current=info.get('current_size', 0),\n                    maximum=info.get('max_size', 1)\n                ))\n            \n            return metrics\n            \n        except Exception as e:\n            logger.error(f\"Error getting queue metrics: {e}\")\n            return []\n    \n    def record_metric(self, name: str, value: float, labels: Optional[Dict[str, str]] = None) -> None:\n        \"\"\"Record a metric data point.\n        \n        Args:\n            name: Metric name.\n            value: Metric value.\n            labels: Optional labels for the metric.\n        \"\"\"\n        with self._lock:\n            point = MetricPoint(\n                name=name,\n                value=value,\n                timestamp=time.time(),\n                labels=labels or {}\n            )\n            self._metrics.append(point)\n            \n            # Trim old metrics if limit exceeded\n            if len(self._metrics) > self._metrics_limit:\n                self._metrics = self._metrics[-self._metrics_limit:]\n    \n    def update_health(self, component: str, status: str, details: Optional[Dict[str, Any]] = None) -> None:\n        \"\"\"Update health status for a component.\n        \n        Args:\n            component: Component name.\n            status: Health status (\"healthy\", \"degraded\", \"unhealthy\").\n            details: Optional additional details.\n        \"\"\"\n        with self._lock:\n            health = HealthStatus(\n                component_name=component,\n                status=status,\n                last_check=time.time(),\n                details=details or {}\n            )\n            self._health_statuses[component] = health\n            \n            # Notify callbacks\n            for callback in self._health_callbacks:\n                try:\n                    callback(health)\n                except Exception as e:\n                    logger.error(f\"Health callback error: {e}\")\n    \n    def get_health(self, component: Optional[str] = None) -> Dict[str, HealthStatus]:\n        \"\"\"Get health status.\n        \n        Args:\n            component: Optional specific component to get. If None, returns all.\n            \n        Returns:\n            Dictionary of component name to HealthStatus.\n        \"\"\"\n        with self._lock:\n            if component:\n                if component in self._health_statuses:\n                    return {component: self._health_statuses[component]}\n                return {}\n            return dict(self._health_statuses)\n    \n    def get_metrics(self, name: Optional[str] = None, since: Optional[float] = None) -> List[MetricPoint]:\n        \"\"\"Get recorded metrics.\n        \n        Args:\n            name: Optional filter by metric name.\n            since: Optional filter by timestamp (return metrics after this time).\n            \n        Returns:\n            List of MetricPoint objects.\n        \"\"\"\n        with self._lock:\n            result = self._metrics\n            \n            if name:\n                result = [m for m in result if m.name == name]\n            \n            if since:\n                result = [m for m in result if m.timestamp >= since]\n            \n            return list(result)\n    \n    def register_health_callback(self, callback: Callable[[HealthStatus], None]) -> None:\n        \"\"\"Register a callback for health status changes.\"\"\"\n        self._health_callbacks.append(callback)\n    \n    def _health_check_loop(self) -> None:\n        \"\"\"Background health check loop.\"\"\"\n        logger.info(\"Monitor health check loop started\")\n        \n        while self._running:\n            try:\n                # Record queue metrics\n                queue_fullness = self.get_queue_fullness()\n                self.record_metric(\"queue_fullness_max\", queue_fullness)\n                \n                all_queue_metrics = self.get_all_queue_metrics()\n                for qm in all_queue_metrics:\n                    self.record_metric(\n                        \"queue_fullness\",\n                        qm.fullness_percentage,\n                        {\"queue_name\": qm.queue_name}\n                    )\n                \n                # Update overall health based on queue fullness\n                if queue_fullness > 0.9:\n                    self.update_health(\"queues\", \"unhealthy\", {\"fullness\": queue_fullness})\n                elif queue_fullness > 0.7:\n                    self.update_health(\"queues\", \"degraded\", {\"fullness\": queue_fullness})\n                else:\n                    self.update_health(\"queues\", \"healthy\", {\"fullness\": queue_fullness})\n                \n                time.sleep(self.check_interval)\n                \n            except Exception as e:\n                logger.error(f\"Error in health check loop: {e}\")\n                time.sleep(1)\n        \n        logger.info(\"Monitor health check loop stopped\")\n    \n    def start(self) -> None:\n        \"\"\"Start the monitoring background tasks.\"\"\"\n        if self._running:\n            logger.warning(\"Monitor already running\")\n            return\n        \n        self._running = True\n        self._check_thread = threading.Thread(\n            target=self._health_check_loop,\n            name=\"Monitor-HealthCheck\",\n            daemon=True\n        )\n        self._check_thread.start()\n        logger.info(\"Monitor started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the monitoring background tasks.\"\"\"\n        self._running = False\n        if self._check_thread is not None:\n            self._check_thread.join(timeout=5.0)\n            self._check_thread = None\n        logger.info(\"Monitor stopped\")\n    \n    def get_summary(self) -> Dict[str, Any]:\n        \"\"\"Get a summary of monitoring data.\"\"\"\n        with self._lock:\n            queue_metrics = self.get_all_queue_metrics()\n            return {\n                \"health_statuses\": {\n                    k: {\"status\": v.status, \"last_check\": v.last_check}\n                    for k, v in self._health_statuses.items()\n                },\n                \"metrics_count\": len(self._metrics),\n                \"queue_fullness_max\": self.get_queue_fullness(),\n                \"queues\": [\n                    {\n                        \"name\": qm.queue_name,\n                        \"fullness\": qm.fullness_percentage,\n                        \"current\": qm.current_size,\n                        \"max\": qm.max_size\n                    }\n                    for qm in queue_metrics\n                ],\n                \"running\": self._running,\n            }\n\n\n# Global monitor instance\n_monitor: Optional[Monitor] = None\n\n\ndef get_monitor() -> Monitor:\n    \"\"\"Get the global monitor instance.\"\"\"\n    global _monitor\n    if _monitor is None:\n        _monitor = Monitor()\n    return _monitor\n\n\ndef set_monitor(monitor: Monitor) -> None:\n    \"\"\"Set the global monitor instance.\"\"\"\n    global _monitor\n    _monitor = monitor\n",
          "src/module_20.py": "\"\"\"Pipeline scheduler module for ChatterStream Nexus.\n\nThis module handles pipeline scheduling, orchestration, and\nbackpressure control for the streaming platform.\n\"\"\"\n\nimport time\nimport threading\nimport queue\nfrom typing import Any, Dict, Optional, List, Callable, Union, TYPE_CHECKING\nfrom dataclasses import dataclass, field\nimport logging\nfrom enum import Enum\n\nif TYPE_CHECKING:\n    from .module_1 import DataSourceOne\n    from .module_2 import DataSourceTwo\n    from .module_31 import Monitor\n    from .config import Config\n\nlogger = logging.getLogger(__name__)\n\n\nclass StageState(Enum):\n    \"\"\"State of a processing stage.\"\"\"\n    IDLE = \"idle\"\n    RUNNING = \"running\"\n    PAUSED = \"paused\"\n    STOPPED = \"stopped\"\n    ERROR = \"error\"\n\n\n@dataclass\nclass ProcessingStage:\n    \"\"\"Represents a processing stage in the pipeline.\"\"\"\n    name: str\n    input_queue: queue.Queue\n    output_queue: Optional[queue.Queue]\n    processor: Callable[[Any], Any]\n    max_queue_size: int = 1000\n    state: StageState = StageState.IDLE\n    processed_count: int = 0\n    error_count: int = 0\n\n\nclass PipelineScheduler:\n    \"\"\"Scheduler for managing stream processing pipelines.\n    \n    Handles stage orchestration, queue management, and implements\n    dynamic backpressure control to prevent buffer overflow.\n    \"\"\"\n    \n    def __init__(self, config: Optional['Config'] = None):\n        \"\"\"Initialize the pipeline scheduler.\n        \n        Args:\n            config: Configuration object. If None, uses defaults.\n        \"\"\"\n        self._config = config\n        self._stages: Dict[str, ProcessingStage] = {}\n        self._stage_threads: Dict[str, threading.Thread] = {}\n        self._running = False\n        self._lock = threading.RLock()\n        \n        # Data sources for backpressure control\n        self._sources: List[Union['DataSourceOne', 'DataSourceTwo']] = []\n        \n        # Monitor reference for queue inspection\n        self._monitor: Optional['Monitor'] = None\n        \n        # Backpressure control state\n        self._backpressure_enabled = False\n        self._backpressure_thread: Optional[threading.Thread] = None\n        self._current_emission_rate: float = 100.0  # Default rate\n        self._last_backpressure_check: float = 0.0\n        \n        # Load backpressure config if available\n        if config is not None:\n            bp_config = config.backpressure\n            self._backpressure_enabled = bp_config.enabled\n            self._monitoring_interval = bp_config.monitoring_interval_seconds\n            self._high_watermark = bp_config.high_watermark_threshold\n            self._low_watermark = bp_config.low_watermark_threshold\n            self._throttle_factor = bp_config.throttle_factor\n            self._ramp_up_factor = bp_config.ramp_up_factor\n            self._min_rate = bp_config.min_emission_rate\n            self._max_rate = bp_config.max_emission_rate\n        else:\n            # Defaults\n            self._monitoring_interval = 5\n            self._high_watermark = 0.85\n            self._low_watermark = 0.25\n            self._throttle_factor = 0.9\n            self._ramp_up_factor = 1.1\n            self._min_rate = 1.0\n            self._max_rate = 10000.0\n        \n        logger.info(f\"PipelineScheduler initialized, backpressure={self._backpressure_enabled}\")\n    \n    def set_monitor(self, monitor: 'Monitor') -> None:\n        \"\"\"Set the monitor reference for queue inspection.\n        \n        Args:\n            monitor: The Monitor instance.\n        \"\"\"\n        self._monitor = monitor\n        # Also link scheduler to monitor for bidirectional access\n        monitor.set_scheduler(self)\n        logger.info(\"PipelineScheduler linked to Monitor\")\n    \n    def register_source(self, source: Union['DataSourceOne', 'DataSourceTwo']) -> None:\n        \"\"\"Register a data source for backpressure control.\n        \n        Args:\n            source: A data source instance with set_emission_rate method.\n        \"\"\"\n        self._sources.append(source)\n        # Initialize with current rate\n        if hasattr(source, 'get_emission_rate'):\n            rate = source.get_emission_rate()\n            if rate > 0:\n                self._current_emission_rate = rate\n        logger.info(f\"Registered source: {source.source_id}\")\n    \n    def unregister_source(self, source: Union['DataSourceOne', 'DataSourceTwo']) -> None:\n        \"\"\"Unregister a data source.\"\"\"\n        if source in self._sources:\n            self._sources.remove(source)\n            logger.info(f\"Unregistered source: {source.source_id}\")\n    \n    def add_stage(\n        self,\n        name: str,\n        processor: Callable[[Any], Any],\n        max_queue_size: int = 1000,\n        input_queue: Optional[queue.Queue] = None,\n        output_queue: Optional[queue.Queue] = None\n    ) -> queue.Queue:\n        \"\"\"Add a processing stage to the pipeline.\n        \n        Args:\n            name: Stage name.\n            processor: Processing function.\n            max_queue_size: Maximum input queue size.\n            input_queue: Optional existing input queue.\n            output_queue: Optional output queue for chaining.\n            \n        Returns:\n            The input queue for this stage.\n        \"\"\"\n        if input_queue is None:\n            input_queue = queue.Queue(maxsize=max_queue_size)\n        \n        stage = ProcessingStage(\n            name=name,\n            input_queue=input_queue,\n            output_queue=output_queue,\n            processor=processor,\n            max_queue_size=max_queue_size\n        )\n        \n        with self._lock:\n            self._stages[name] = stage\n        \n        logger.info(f\"Added stage: {name}, max_queue_size={max_queue_size}\")\n        return input_queue\n    \n    def remove_stage(self, name: str) -> None:\n        \"\"\"Remove a processing stage.\"\"\"\n        with self._lock:\n            if name in self._stages:\n                del self._stages[name]\n                logger.info(f\"Removed stage: {name}\")\n    \n    def get_queue_status(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Get status of all stage queues.\n        \n        Returns:\n            Dictionary mapping stage names to queue info including\n            current_size and max_size.\n        \"\"\"\n        with self._lock:\n            result = {}\n            for name, stage in self._stages.items():\n                result[name] = {\n                    'current_size': stage.input_queue.qsize(),\n                    'max_size': stage.max_queue_size,\n                    'state': stage.state.value,\n                    'processed_count': stage.processed_count,\n                    'error_count': stage.error_count,\n                }\n            return result\n    \n    def _process_stage(self, stage: ProcessingStage) -> None:\n        \"\"\"Processing loop for a single stage.\"\"\"\n        logger.info(f\"Stage {stage.name} processing loop started\")\n        stage.state = StageState.RUNNING\n        \n        while self._running:\n            try:\n                # Get item from input queue with timeout\n                try:\n                    item = stage.input_queue.get(timeout=1.0)\n                except queue.Empty:\n                    continue\n                \n                # Process the item\n                try:\n                    result = stage.processor(item)\n                    stage.processed_count += 1\n                    \n                    # Send to output queue if configured\n                    if stage.output_queue is not None and result is not None:\n                        try:\n                            stage.output_queue.put_nowait(result)\n                        except queue.Full:\n                            logger.warning(f\"Stage {stage.name} output queue full\")\n                    \n                except Exception as e:\n                    stage.error_count += 1\n                    logger.error(f\"Stage {stage.name} processing error: {e}\")\n                \n                stage.input_queue.task_done()\n                \n            except Exception as e:\n                logger.error(f\"Stage {stage.name} loop error: {e}\")\n                stage.state = StageState.ERROR\n                time.sleep(0.1)\n        \n        stage.state = StageState.STOPPED\n        logger.info(f\"Stage {stage.name} processing loop stopped\")\n    \n    def _apply_emission_rate(self, new_rate: float) -> None:\n        \"\"\"Apply new emission rate to all registered sources.\n        \n        Args:\n            new_rate: New emission rate in events/second.\n        \"\"\"\n        # Clamp to valid range\n        new_rate = max(self._min_rate, min(self._max_rate, new_rate))\n        \n        if abs(new_rate - self._current_emission_rate) < 0.01:\n            return  # No significant change\n        \n        old_rate = self._current_emission_rate\n        self._current_emission_rate = new_rate\n        \n        for source in self._sources:\n            try:\n                if hasattr(source, 'set_emission_rate'):\n                    source.set_emission_rate(new_rate)\n            except Exception as e:\n                logger.error(f\"Error setting emission rate on source: {e}\")\n        \n        logger.info(f\"Emission rate adjusted: {old_rate:.2f} -> {new_rate:.2f}\")\n    \n    def _backpressure_control_loop(self) -> None:\n        \"\"\"Background loop for backpressure control.\"\"\"\n        logger.info(\"Backpressure control loop started\")\n        \n        while self._running and self._backpressure_enabled:\n            try:\n                current_time = time.time()\n                \n                # Check if enough time has passed since last check\n                if current_time - self._last_backpressure_check < self._monitoring_interval:\n                    time.sleep(0.5)\n                    continue\n                \n                self._last_backpressure_check = current_time\n                \n                # Get queue fullness from monitor\n                queue_fullness = 0.0\n                if self._monitor is not None:\n                    queue_fullness = self._monitor.get_queue_fullness()\n                else:\n                    # Fall back to direct queue inspection\n                    queue_status = self.get_queue_status()\n                    if queue_status:\n                        max_fullness = 0.0\n                        for info in queue_status.values():\n                            current = info.get('current_size', 0)\n                            maximum = info.get('max_size', 1)\n                            if maximum > 0:\n                                fullness = current / maximum\n                                max_fullness = max(max_fullness, fullness)\n                        queue_fullness = max_fullness\n                \n                # Apply backpressure logic\n                if queue_fullness >= self._high_watermark:\n                    # Throttle down\n                    new_rate = self._current_emission_rate * self._throttle_factor\n                    logger.info(\n                        f\"Backpressure: Queue fullness {queue_fullness:.2%} >= \"\n                        f\"high watermark {self._high_watermark:.2%}, throttling down\"\n                    )\n                    self._apply_emission_rate(new_rate)\n                    \n                elif queue_fullness <= self._low_watermark:\n                    # Ramp up\n                    new_rate = self._current_emission_rate * self._ramp_up_factor\n                    logger.debug(\n                        f\"Backpressure: Queue fullness {queue_fullness:.2%} <= \"\n                        f\"low watermark {self._low_watermark:.2%}, ramping up\"\n                    )\n                    self._apply_emission_rate(new_rate)\n                \n                # Record metrics if monitor is available\n                if self._monitor is not None:\n                    self._monitor.record_metric(\n                        \"backpressure_emission_rate\",\n                        self._current_emission_rate\n                    )\n                    self._monitor.record_metric(\n                        \"backpressure_queue_fullness\",\n                        queue_fullness\n                    )\n                \n            except Exception as e:\n                logger.error(f\"Error in backpressure control loop: {e}\")\n                time.sleep(1)\n        \n        logger.info(\"Backpressure control loop stopped\")\n    \n    def start(self) -> None:\n        \"\"\"Start the pipeline scheduler and all stages.\"\"\"\n        if self._running:\n            logger.warning(\"PipelineScheduler already running\")\n            return\n        \n        self._running = True\n        \n        # Start processing threads for each stage\n        with self._lock:\n            for name, stage in self._stages.items():\n                thread = threading.Thread(\n                    target=self._process_stage,\n                    args=(stage,),\n                    name=f\"Stage-{name}\",\n                    daemon=True\n                )\n                self._stage_threads[name] = thread\n                thread.start()\n        \n        # Start backpressure control if enabled\n        if self._backpressure_enabled:\n            self._backpressure_thread = threading.Thread(\n                target=self._backpressure_control_loop,\n                name=\"BackpressureControl\",\n                daemon=True\n            )\n            self._backpressure_thread.start()\n            logger.info(\"Backpressure control enabled\")\n        \n        logger.info(\"PipelineScheduler started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the pipeline scheduler and all stages.\"\"\"\n        self._running = False\n        \n        # Wait for stage threads\n        for name, thread in self._stage_threads.items():\n            thread.join(timeout=5.0)\n        self._stage_threads.clear()\n        \n        # Wait for backpressure thread\n        if self._backpressure_thread is not None:\n            self._backpressure_thread.join(timeout=5.0)\n            self._backpressure_thread = None\n        \n        logger.info(\"PipelineScheduler stopped\")\n    \n    def enable_backpressure(self) -> None:\n        \"\"\"Enable backpressure control at runtime.\"\"\"\n        if self._backpressure_enabled:\n            return\n        \n        self._backpressure_enabled = True\n        \n        if self._running and self._backpressure_thread is None:\n            self._backpressure_thread = threading.Thread(\n                target=self._backpressure_control_loop,\n                name=\"BackpressureControl\",\n                daemon=True\n            )\n            self._backpressure_thread.start()\n        \n        logger.info(\"Backpressure control enabled\")\n    \n    def disable_backpressure(self) -> None:\n        \"\"\"Disable backpressure control at runtime.\"\"\"\n        self._backpressure_enabled = False\n        logger.info(\"Backpressure control disabled\")\n    \n    def get_backpressure_status(self) -> Dict[str, Any]:\n        \"\"\"Get current backpressure status.\"\"\"\n        return {\n            \"enabled\": self._backpressure_enabled,\n            \"current_emission_rate\": self._current_emission_rate,\n            \"min_rate\": self._min_rate,\n            \"max_rate\": self._max_rate,\n            \"high_watermark\": self._high_watermark,\n            \"low_watermark\": self._low_watermark,\n            \"throttle_factor\": self._throttle_factor,\n            \"ramp_up_factor\": self._ramp_up_factor,\n            \"monitoring_interval\": self._monitoring_interval,\n            \"registered_sources\": len(self._sources),\n            \"last_check\": self._last_backpressure_check,\n        }\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get scheduler statistics.\"\"\"\n        with self._lock:\n            return {\n                \"running\": self._running,\n                \"stages\": list(self._stages.keys()),\n                \"stage_count\": len(self._stages),\n                \"queue_status\": self.get_queue_status(),\n                \"backpressure\": self.get_backpressure_status(),\n                \"source_count\": len(self._sources),\n            }\n\n\n# Global scheduler instance\n_scheduler: Optional[PipelineScheduler] = None\n\n\ndef get_scheduler(config: Optional['Config'] = None) -> PipelineScheduler:\n    \"\"\"Get the global scheduler instance.\"\"\"\n    global _scheduler\n    if _scheduler is None:\n        _scheduler = PipelineScheduler(config)\n    return _scheduler\n\n\ndef set_scheduler(scheduler: PipelineScheduler) -> None:\n    \"\"\"Set the global scheduler instance.\"\"\"\n    global _scheduler\n    _scheduler = scheduler\n",
          "docs/api.md": "# ChatterStream Nexus API Documentation\n\nThis document provides comprehensive API documentation for the ChatterStream Nexus streaming platform.\n\n## Overview\n\nChatterStream Nexus is a high-throughput, parallel data streaming platform designed for real-time data processing at scale.\n\n## Core Components\n\n### Data Sources\n\nThe platform supports multiple data source types:\n\n- **DataSourceOne** (`src/module_1.py`): Primary event generator\n- **DataSourceTwo** (`src/module_2.py`): Secondary event generator with multiple event types\n\n### Pipeline Scheduler\n\nThe `PipelineScheduler` (`src/module_20.py`) orchestrates data flow through processing stages.\n\n### Monitoring\n\nThe `Monitor` (`src/module_31.py`) provides health checks and metrics collection.\n\n---\n\n## Dynamic Backpressure\n\nDynamic backpressure is a flow control mechanism that automatically regulates data ingestion rates based on the real-time processing capacity of pipeline stages. This prevents buffer overflow, data loss, and system instability when downstream components become bottlenecks.\n\n### How It Works\n\n1. The scheduler periodically monitors the fullness of processing stage queues\n2. When queue fullness exceeds the high watermark threshold, the system throttles data sources\n3. When queue fullness drops below the low watermark threshold, the system ramps up the rate\n4. Rate adjustments are applied gradually using configurable factors\n\n### Configuration\n\nBackpressure is configured in `src/config.py` under the `backpressure` section:\n\n```python\n@dataclass\nclass BackpressureConfig:\n    enabled: bool = True\n    monitoring_interval_seconds: int = 5\n    high_watermark_threshold: float = 0.85\n    low_watermark_threshold: float = 0.25\n    throttle_factor: float = 0.9\n    ramp_up_factor: float = 1.1\n    min_emission_rate: float = 1.0\n    max_emission_rate: float = 10000.0\n```\n\n#### Configuration Parameters\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `enabled` | bool | `True` | Enables or disables the backpressure mechanism |\n| `monitoring_interval_seconds` | int | `5` | How often (in seconds) to check queue sizes |\n| `high_watermark_threshold` | float | `0.85` | Queue fullness percentage (0.0-1.0) that triggers throttling. When the fullest queue exceeds this threshold, source rates are reduced |\n| `low_watermark_threshold` | float | `0.25` | Queue fullness percentage (0.0-1.0) below which the system ramps up rates. When all queues are below this threshold, source rates are increased |\n| `throttle_factor` | float | `0.9` | Multiplier applied to current rate when throttling down. A value of 0.9 reduces the rate by 10% |\n| `ramp_up_factor` | float | `1.1` | Multiplier applied to current rate when ramping up. A value of 1.1 increases the rate by 10% |\n| `min_emission_rate` | float | `1.0` | Minimum allowed emission rate in events/second. The rate will never go below this value |\n| `max_emission_rate` | float | `10000.0` | Maximum allowed emission rate in events/second. The rate will never exceed this value |\n\n### Environment Variables\n\nBackpressure can also be configured via environment variables:\n\n- `BACKPRESSURE_ENABLED`: Set to `true` or `false`\n- `BACKPRESSURE_MONITORING_INTERVAL`: Integer seconds\n- `BACKPRESSURE_HIGH_WATERMARK`: Float threshold (e.g., `0.85`)\n- `BACKPRESSURE_LOW_WATERMARK`: Float threshold (e.g., `0.25`)\n- `BACKPRESSURE_THROTTLE_FACTOR`: Float factor (e.g., `0.9`)\n- `BACKPRESSURE_RAMP_UP_FACTOR`: Float factor (e.g., `1.1`)\n\n### API Methods\n\n#### PipelineScheduler\n\n```python\n# Enable backpressure at runtime\nscheduler.enable_backpressure()\n\n# Disable backpressure at runtime\nscheduler.disable_backpressure()\n\n# Get backpressure status\nstatus = scheduler.get_backpressure_status()\n# Returns: {\n#     \"enabled\": True,\n#     \"current_emission_rate\": 100.0,\n#     \"min_rate\": 1.0,\n#     \"max_rate\": 10000.0,\n#     \"high_watermark\": 0.85,\n#     \"low_watermark\": 0.25,\n#     ...\n# }\n\n# Register a data source for rate control\nscheduler.register_source(data_source)\n\n# Get queue status\nqueue_status = scheduler.get_queue_status()\n```\n\n#### Data Sources\n\nBoth `DataSourceOne` and `DataSourceTwo` support dynamic rate adjustment:\n\n```python\n# Set emission rate dynamically\nsource.set_emission_rate(50.0)  # 50 events/second\n\n# Get current emission rate\nrate = source.get_emission_rate()\n```\n\n#### Monitor\n\n```python\n# Get the fullness of the most full queue\nfullness = monitor.get_queue_fullness()  # Returns 0.0 to 1.0\n\n# Get detailed metrics for all queues\nmetrics = monitor.get_all_queue_metrics()\n```\n\n### Usage Example\n\n```python\nfrom src.config import Config, get_config\nfrom src.module_1 import DataSourceOne\nfrom src.module_20 import PipelineScheduler\nfrom src.module_31 import Monitor\n\n# Create configuration with backpressure enabled\nconfig = Config()\nconfig.backpressure.enabled = True\nconfig.backpressure.high_watermark_threshold = 0.80\nconfig.backpressure.low_watermark_threshold = 0.20\n\n# Create components\nscheduler = PipelineScheduler(config)\nmonitor = Monitor()\nsource = DataSourceOne(initial_rate=100.0)\n\n# Link components\nscheduler.set_monitor(monitor)\nscheduler.register_source(source)\n\n# Add processing stages\ninput_queue = scheduler.add_stage(\n    name=\"processor\",\n    processor=lambda x: x,\n    max_queue_size=1000\n)\n\n# Start everything\nmonitor.start()\nscheduler.start()\nsource.start(output_queue=input_queue)\n\n# The system will now automatically adjust source rates\n# based on queue fullness\n```\n\n### Best Practices\n\n1. **Set appropriate watermarks**: The gap between high and low watermarks should be large enough to prevent oscillation but small enough to respond quickly to load changes.\n\n2. **Tune throttle/ramp-up factors**: Smaller factors (closer to 1.0) provide smoother adjustments but slower response. Larger factors respond faster but may cause oscillation.\n\n3. **Monitor metrics**: Use the monitoring system to track `backpressure_emission_rate` and `backpressure_queue_fullness` metrics to understand system behavior.\n\n4. **Set realistic rate bounds**: Configure `min_emission_rate` and `max_emission_rate` based on your system's actual capabilities.\n\n---\n\n## Additional API Reference\n\n### Configuration API\n\n```python\nfrom src.config import get_config, set_config, Config\n\n# Get global config\nconfig = get_config()\n\n# Create from environment\nconfig = Config.from_env()\n\n# Create from dictionary\nconfig = Config.from_dict({\n    'backpressure': {\n        'enabled': True,\n        'high_watermark_threshold': 0.90\n    }\n})\n```\n\n### Health Monitoring\n\n```python\nfrom src.module_31 import get_monitor\n\nmonitor = get_monitor()\nmonitor.start()\n\n# Record custom metrics\nmonitor.record_metric(\"custom_metric\", 42.0, {\"label\": \"value\"})\n\n# Update health status\nmonitor.update_health(\"my_component\", \"healthy\", {\"uptime\": 3600})\n\n# Get summary\nsummary = monitor.get_summary()\n```\n"
        },
        "generated_files": [
          "src/config.py",
          "src/module_1.py",
          "src/module_2.py",
          "src/module_31.py",
          "src/module_20.py",
          "docs/api.md"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8779170293008414,
              "dependency_traversal_accuracy": 0.8153613411343674,
              "cross_file_reasoning_depth": 0.4643055555555556,
              "system_thinking_score": 0.5368303354578726,
              "robustness_score": 0.0014714537963507945,
              "comprehensiveness_score": 0.5716539140670982,
              "innovation_score": 0.25664361389052387,
              "solution_elegance_score": 0.5620941531152018
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.10973962866260517,
              "dependency_traversal_weighted": 0.10192016764179593,
              "cross_file_reasoning_weighted": 0.05803819444444445,
              "system_thinking_weighted": 0.06710379193223408,
              "robustness_weighted": 0.0001839317245438493,
              "comprehensiveness_weighted": 0.07145673925838728,
              "innovation_weighted": 0.032080451736315484,
              "solution_elegance_weighted": 0.07026176913940023
            },
            "total_software_engineering_score": 0.5107846745397264
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.42161107063293457,
              "errors": [
                "  File \"docs/api.py\", line 179",
                "    4. **Set realistic rate bounds**: Configure `min_emission_rate` and `max_emission_rate` based on your system's actual capabilities.",
                "                                                                                                                ^",
                "SyntaxError: unterminated string literal (detected at line 179)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "src/config.py",
                "src/module_1.py",
                "src/module_2.py",
                "src/module_31.py",
                "src/module_20.py",
                "docs/api.md"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 6,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 6 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.41885874877810364,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.41885874877810364,
              "idc_weight": 0.2,
              "total_functional_score": 0.4237717497556207
            }
          },
          "code_quality_details": {
            "files_analyzed": 6,
            "quality_checks": {
              "src/config.py": {
                "line_count": 149,
                "non_empty_lines": 122,
                "comment_lines": 2,
                "comment_ratio": 0.01639344262295082,
                "function_count": 6,
                "class_count": 4,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "src/module_1.py": {
                "line_count": 239,
                "non_empty_lines": 194,
                "comment_lines": 6,
                "comment_ratio": 0.030927835051546393,
                "function_count": 14,
                "class_count": 3,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "src/module_2.py": {
                "line_count": 313,
                "non_empty_lines": 260,
                "comment_lines": 8,
                "comment_ratio": 0.03076923076923077,
                "function_count": 17,
                "class_count": 8,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "src/module_31.py": {
                "line_count": 336,
                "non_empty_lines": 270,
                "comment_lines": 5,
                "comment_ratio": 0.018518518518518517,
                "function_count": 16,
                "class_count": 4,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "src/module_20.py": {
                "line_count": 440,
                "non_empty_lines": 361,
                "comment_lines": 23,
                "comment_ratio": 0.06371191135734072,
                "function_count": 18,
                "class_count": 3,
                "import_count": 20,
                "quality_score": 0.7999999999999999
              },
              "docs/api.md": {
                "line_count": 222,
                "non_empty_lines": 157,
                "comment_lines": 51,
                "comment_ratio": 0.3248407643312102,
                "function_count": 0,
                "class_count": 1,
                "import_count": 14,
                "quality_score": 0.8999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.8116666666666665,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.661395534290271,
              "multi_session_memory_retention": 0.6023214602161968
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.3306977671451355,
              "multi_session_memory_retention_weighted": 0.3011607301080984
            },
            "total_longcontext_utilization_score": 0.631858497253234
          }
        },
        "timestamp": "2026-01-14T21:07:05.596762"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_system_monitoring_hard_097_feature_implementation_expert_01",
        "scenario_title": "Implement Canary Analysis Strategy for Safe Deployments",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5193994824059335,
        "functional_correctness_score": 0.40366150283478397,
        "code_quality_score": 0.7899999999999999,
        "longcontext_utilization_score": 0.848909099986686,
        "total_score": 2.8587457690573856,
        "generation_time": 222.95795273780823,
        "code_files_generated": 7,
        "total_lines_generated": 2167,
        "parsing_success": true,
        "solution_code": {
          "edupulse_insight_mesh/src/api_gateway/routes.py": "\"\"\"API Gateway routes for EduPulse Insight Mesh.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional\n\nfrom flask import Blueprint, jsonify, request\nfrom pydantic import BaseModel, Field, ValidationError, validator\n\nfrom .auth import require_api_key\n\nlogger = logging.getLogger(__name__)\n\napi_bp = Blueprint('api', __name__, url_prefix='/api/v1')\n\n\nclass HealthResponse(BaseModel):\n    \"\"\"Health check response model.\"\"\"\n    status: str\n    version: str = \"1.0.0\"\n\n\nclass MetricPayload(BaseModel):\n    \"\"\"Metric ingestion payload model.\"\"\"\n    service_name: str\n    metric_name: str\n    value: float\n    timestamp: Optional[str] = None\n    tags: Optional[Dict[str, str]] = None\n\n\nclass KPIThreshold(BaseModel):\n    \"\"\"KPI threshold configuration.\"\"\"\n    max_relative_increase: Optional[float] = None\n    max_absolute_value: Optional[float] = None\n\n\nclass CanaryAnalysisRequest(BaseModel):\n    \"\"\"Canary analysis request model.\"\"\"\n    service_name: str = Field(..., min_length=1)\n    canary_version: str = Field(..., min_length=1)\n    stable_version: str = Field(..., min_length=1)\n    duration_minutes: int = Field(..., gt=0, le=1440)\n    kpi_thresholds: Dict[str, KPIThreshold]\n\n    @validator('kpi_thresholds')\n    def validate_thresholds(cls, v):\n        if not v:\n            raise ValueError('At least one KPI threshold must be specified')\n        return v\n\n\nclass CanaryAnalysisResponse(BaseModel):\n    \"\"\"Canary analysis response model.\"\"\"\n    service_name: str\n    canary_version: str\n    stable_version: str\n    recommendation: str\n    justification: str\n    analysis_id: str\n\n\n@api_bp.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    response = HealthResponse(status='healthy')\n    return jsonify(response.dict()), 200\n\n\n@api_bp.route('/metrics', methods=['POST'])\n@require_api_key\ndef ingest_metrics():\n    \"\"\"Ingest metrics from agents.\"\"\"\n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({'error': 'No JSON payload provided'}), 400\n        \n        payload = MetricPayload(**data)\n        \n        # Forward to ingestion pipeline\n        from ..ingestion_pipeline.pipeline import IngestionPipeline\n        pipeline = IngestionPipeline()\n        result = pipeline.process(payload.dict())\n        \n        return jsonify({'status': 'accepted', 'id': result.get('id', 'unknown')}), 202\n    except ValidationError as e:\n        logger.warning(f\"Validation error: {e}\")\n        return jsonify({'error': 'Invalid payload', 'details': e.errors()}), 400\n    except Exception as e:\n        logger.error(f\"Error ingesting metrics: {e}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@api_bp.route('/telemetry/<service_name>', methods=['GET'])\n@require_api_key\ndef get_telemetry(service_name: str):\n    \"\"\"Get telemetry data for a service.\"\"\"\n    try:\n        from ..core_telemetry.service import TelemetryService\n        service = TelemetryService()\n        \n        version = request.args.get('version')\n        duration_minutes = request.args.get('duration_minutes', 60, type=int)\n        \n        data = service.get_metrics(\n            service_name=service_name,\n            version=version,\n            duration_minutes=duration_minutes\n        )\n        \n        return jsonify({'service_name': service_name, 'metrics': data}), 200\n    except Exception as e:\n        logger.error(f\"Error fetching telemetry: {e}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@api_bp.route('/analysis/canary', methods=['POST'])\n@require_api_key\ndef canary_analysis():\n    \"\"\"Initiate canary analysis comparing canary vs stable deployment.\"\"\"\n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({'error': 'No JSON payload provided'}), 400\n        \n        # Validate request\n        try:\n            analysis_request = CanaryAnalysisRequest(**data)\n        except ValidationError as e:\n            logger.warning(f\"Canary analysis validation error: {e}\")\n            return jsonify({'error': 'Invalid payload', 'details': e.errors()}), 400\n        \n        # Execute canary analysis strategy\n        from ..strategy_service.strategies import CanaryAnalysisStrategy\n        from ..core_telemetry.service import TelemetryService\n        from ..remediation_service.commands import LogCanaryAnalysisResultCommand\n        \n        telemetry_service = TelemetryService()\n        strategy = CanaryAnalysisStrategy(telemetry_client=telemetry_service)\n        \n        # Prepare strategy context\n        strategy_context = {\n            'service_name': analysis_request.service_name,\n            'canary_version': analysis_request.canary_version,\n            'stable_version': analysis_request.stable_version,\n            'duration_minutes': analysis_request.duration_minutes,\n            'kpi_thresholds': {k: v.dict() for k, v in analysis_request.kpi_thresholds.items()}\n        }\n        \n        # Execute analysis\n        result = strategy.execute(strategy_context)\n        \n        # Log the result via remediation command\n        log_command = LogCanaryAnalysisResultCommand(\n            service_name=result['service_name'],\n            recommendation=result['recommendation'],\n            justification=result['justification']\n        )\n        log_command.execute()\n        \n        response = CanaryAnalysisResponse(\n            service_name=result['service_name'],\n            canary_version=analysis_request.canary_version,\n            stable_version=analysis_request.stable_version,\n            recommendation=result['recommendation'],\n            justification=result['justification'],\n            analysis_id=result.get('analysis_id', 'unknown')\n        )\n        \n        return jsonify(response.dict()), 200\n        \n    except Exception as e:\n        logger.error(f\"Error during canary analysis: {e}\")\n        return jsonify({'error': 'Internal server error', 'message': str(e)}), 500\n\n\n@api_bp.route('/strategies', methods=['GET'])\n@require_api_key\ndef list_strategies():\n    \"\"\"List available remediation strategies.\"\"\"\n    strategies = [\n        {'name': 'auto_scaling', 'description': 'Automatic scaling based on load'},\n        {'name': 'circuit_breaker', 'description': 'Circuit breaker pattern'},\n        {'name': 'canary_analysis', 'description': 'Canary deployment analysis'}\n    ]\n    return jsonify({'strategies': strategies}), 200\n",
          "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py": "\"\"\"Handlers for processing telemetry data in the ingestion pipeline.\"\"\"\n\nimport logging\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseHandler(ABC):\n    \"\"\"Abstract base class for pipeline handlers.\"\"\"\n    \n    def __init__(self):\n        self._next_handler: Optional['BaseHandler'] = None\n    \n    def set_next(self, handler: 'BaseHandler') -> 'BaseHandler':\n        \"\"\"Set the next handler in the chain.\"\"\"\n        self._next_handler = handler\n        return handler\n    \n    @abstractmethod\n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process the data and optionally pass to next handler.\"\"\"\n        pass\n    \n    def _pass_to_next(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Pass data to the next handler if it exists.\"\"\"\n        if self._next_handler:\n            return self._next_handler.handle(data)\n        return data\n\n\nclass ValidationHandler(BaseHandler):\n    \"\"\"Handler for validating incoming telemetry data.\"\"\"\n    \n    REQUIRED_FIELDS = ['service_name', 'metric_name', 'value']\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Validate the incoming data.\"\"\"\n        logger.debug(f\"Validating data: {data}\")\n        \n        # Check required fields\n        missing_fields = [f for f in self.REQUIRED_FIELDS if f not in data]\n        if missing_fields:\n            raise ValueError(f\"Missing required fields: {missing_fields}\")\n        \n        # Validate value is numeric\n        if not isinstance(data['value'], (int, float)):\n            raise ValueError(f\"Value must be numeric, got {type(data['value'])}\")\n        \n        # Validate service_name and metric_name are non-empty strings\n        if not data['service_name'] or not isinstance(data['service_name'], str):\n            raise ValueError(\"service_name must be a non-empty string\")\n        \n        if not data['metric_name'] or not isinstance(data['metric_name'], str):\n            raise ValueError(\"metric_name must be a non-empty string\")\n        \n        data['validated'] = True\n        return self._pass_to_next(data)\n\n\nclass EnrichmentHandler(BaseHandler):\n    \"\"\"Handler for enriching telemetry data with additional metadata.\"\"\"\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Enrich the data with metadata.\"\"\"\n        logger.debug(f\"Enriching data: {data}\")\n        \n        # Add unique ID if not present\n        if 'id' not in data:\n            data['id'] = str(uuid.uuid4())\n        \n        # Add timestamp if not present\n        if 'timestamp' not in data or data['timestamp'] is None:\n            data['timestamp'] = datetime.utcnow().isoformat() + 'Z'\n        \n        # Add ingestion timestamp\n        data['ingested_at'] = datetime.utcnow().isoformat() + 'Z'\n        \n        # Process tags - ensure version tag is properly handled\n        data['tags'] = self._process_tags(data.get('tags', {}))\n        \n        data['enriched'] = True\n        return self._pass_to_next(data)\n    \n    def _process_tags(self, tags: Optional[Dict[str, str]]) -> Dict[str, str]:\n        \"\"\"Process and normalize tags.\"\"\"\n        if tags is None:\n            tags = {}\n        \n        processed_tags = {}\n        for key, value in tags.items():\n            # Normalize tag keys to lowercase\n            normalized_key = key.lower().strip()\n            # Ensure value is a string\n            normalized_value = str(value).strip() if value is not None else ''\n            \n            if normalized_key and normalized_value:\n                processed_tags[normalized_key] = normalized_value\n        \n        return processed_tags\n\n\nclass VersionTagHandler(BaseHandler):\n    \"\"\"Handler for processing and validating version tags for canary analysis.\"\"\"\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process version tags from telemetry data.\"\"\"\n        logger.debug(f\"Processing version tags: {data}\")\n        \n        tags = data.get('tags', {})\n        \n        # Extract version from tags if present\n        version = tags.get('version')\n        \n        if version:\n            # Store version at top level for easier querying\n            data['version'] = version\n            logger.debug(f\"Version tag found: {version}\")\n        else:\n            # Set default version if not provided\n            data['version'] = 'unknown'\n            logger.debug(\"No version tag found, using 'unknown'\")\n        \n        # Extract deployment type if present (canary, stable, etc.)\n        deployment_type = tags.get('deployment_type') or tags.get('deployment')\n        if deployment_type:\n            data['deployment_type'] = deployment_type\n        \n        data['version_processed'] = True\n        return self._pass_to_next(data)\n\n\nclass NormalizationHandler(BaseHandler):\n    \"\"\"Handler for normalizing metric values and names.\"\"\"\n    \n    # Mapping of common metric name variations to standard names\n    METRIC_NAME_MAPPING = {\n        'latency': 'latency_ms',\n        'latency_p99': 'latency_ms_p99',\n        'p99_latency': 'latency_ms_p99',\n        'response_time': 'latency_ms',\n        'errors': 'error_rate',\n        'error_count': 'error_rate',\n        'cpu': 'cpu_percent',\n        'memory': 'memory_percent',\n        'mem': 'memory_percent'\n    }\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Normalize metric data.\"\"\"\n        logger.debug(f\"Normalizing data: {data}\")\n        \n        # Normalize metric name\n        original_name = data['metric_name'].lower().strip()\n        normalized_name = self.METRIC_NAME_MAPPING.get(original_name, original_name)\n        \n        if normalized_name != original_name:\n            data['original_metric_name'] = data['metric_name']\n            data['metric_name'] = normalized_name\n            logger.debug(f\"Normalized metric name: {original_name} -> {normalized_name}\")\n        \n        # Normalize service name (lowercase, replace spaces with underscores)\n        data['service_name'] = data['service_name'].lower().strip().replace(' ', '_')\n        \n        data['normalized'] = True\n        return self._pass_to_next(data)\n\n\nclass AggregationHandler(BaseHandler):\n    \"\"\"Handler for aggregating metrics before storage.\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        self._buffer: List[Dict[str, Any]] = []\n        self._buffer_size = 100\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Buffer data for batch processing.\"\"\"\n        logger.debug(f\"Aggregating data: {data}\")\n        \n        # For now, pass through immediately\n        # In production, this would buffer and batch\n        data['aggregated'] = True\n        return self._pass_to_next(data)\n\n\nclass StorageHandler(BaseHandler):\n    \"\"\"Handler for storing telemetry data.\"\"\"\n    \n    def __init__(self, storage_backend=None):\n        super().__init__()\n        self._storage = storage_backend or InMemoryStorage()\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Store the processed data.\"\"\"\n        logger.debug(f\"Storing data: {data}\")\n        \n        try:\n            self._storage.store(data)\n            data['stored'] = True\n            logger.info(f\"Successfully stored metric {data['id']} for service {data['service_name']}\")\n        except Exception as e:\n            logger.error(f\"Failed to store data: {e}\")\n            data['stored'] = False\n            data['storage_error'] = str(e)\n        \n        return self._pass_to_next(data)\n\n\nclass InMemoryStorage:\n    \"\"\"Simple in-memory storage for telemetry data.\"\"\"\n    \n    _instance = None\n    _data: List[Dict[str, Any]] = []\n    \n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._data = []\n        return cls._instance\n    \n    def store(self, data: Dict[str, Any]) -> None:\n        \"\"\"Store data in memory.\"\"\"\n        self._data.append(data.copy())\n    \n    def query(self, service_name: str = None, version: str = None, \n              metric_name: str = None, limit: int = 1000) -> List[Dict[str, Any]]:\n        \"\"\"Query stored data with optional filters.\"\"\"\n        results = self._data\n        \n        if service_name:\n            results = [d for d in results if d.get('service_name') == service_name]\n        \n        if version:\n            results = [d for d in results if d.get('version') == version]\n        \n        if metric_name:\n            results = [d for d in results if d.get('metric_name') == metric_name]\n        \n        return results[-limit:]\n    \n    def clear(self) -> None:\n        \"\"\"Clear all stored data.\"\"\"\n        self._data = []\n\n\ndef create_default_pipeline() -> BaseHandler:\n    \"\"\"Create the default processing pipeline.\"\"\"\n    validation = ValidationHandler()\n    enrichment = EnrichmentHandler()\n    version_tag = VersionTagHandler()\n    normalization = NormalizationHandler()\n    aggregation = AggregationHandler()\n    storage = StorageHandler()\n    \n    # Chain handlers\n    validation.set_next(enrichment)\n    enrichment.set_next(version_tag)\n    version_tag.set_next(normalization)\n    normalization.set_next(aggregation)\n    aggregation.set_next(storage)\n    \n    return validation\n",
          "edupulse_insight_mesh/src/strategy_service/strategies.py": "\"\"\"Strategy implementations for the EduPulse Insight Mesh system.\"\"\"\n\nimport logging\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseStrategy(ABC):\n    \"\"\"Abstract base class for remediation strategies.\"\"\"\n    \n    def __init__(self, name: str, description: str = \"\"):\n        self.name = name\n        self.description = description\n        self._execution_history: List[Dict[str, Any]] = []\n    \n    @abstractmethod\n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute the strategy with the given context.\"\"\"\n        pass\n    \n    @abstractmethod\n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate that the context has all required parameters.\"\"\"\n        pass\n    \n    def record_execution(self, context: Dict[str, Any], result: Dict[str, Any]) -> None:\n        \"\"\"Record the execution in history.\"\"\"\n        self._execution_history.append({\n            'timestamp': datetime.utcnow().isoformat(),\n            'context': context,\n            'result': result\n        })\n\n\nclass AutoScalingStrategy(BaseStrategy):\n    \"\"\"Strategy for automatic scaling based on load metrics.\"\"\"\n    \n    def __init__(self):\n        super().__init__(\n            name='auto_scaling',\n            description='Automatically scales services based on CPU and memory metrics'\n        )\n        self.scale_up_threshold = 80.0\n        self.scale_down_threshold = 30.0\n        self.min_replicas = 1\n        self.max_replicas = 10\n    \n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate auto-scaling context.\"\"\"\n        required = ['service_name', 'current_replicas', 'cpu_percent']\n        return all(key in context for key in required)\n    \n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute auto-scaling decision.\"\"\"\n        if not self.validate_context(context):\n            return {'success': False, 'error': 'Invalid context'}\n        \n        service_name = context['service_name']\n        current_replicas = context['current_replicas']\n        cpu_percent = context['cpu_percent']\n        \n        action = 'none'\n        new_replicas = current_replicas\n        \n        if cpu_percent > self.scale_up_threshold and current_replicas < self.max_replicas:\n            action = 'scale_up'\n            new_replicas = min(current_replicas + 1, self.max_replicas)\n        elif cpu_percent < self.scale_down_threshold and current_replicas > self.min_replicas:\n            action = 'scale_down'\n            new_replicas = max(current_replicas - 1, self.min_replicas)\n        \n        result = {\n            'success': True,\n            'service_name': service_name,\n            'action': action,\n            'previous_replicas': current_replicas,\n            'new_replicas': new_replicas,\n            'reason': f'CPU at {cpu_percent}%'\n        }\n        \n        self.record_execution(context, result)\n        logger.info(f\"Auto-scaling decision for {service_name}: {action}\")\n        \n        return result\n\n\nclass CircuitBreakerStrategy(BaseStrategy):\n    \"\"\"Strategy for implementing circuit breaker pattern.\"\"\"\n    \n    def __init__(self):\n        super().__init__(\n            name='circuit_breaker',\n            description='Implements circuit breaker pattern for failing services'\n        )\n        self.error_threshold = 0.5  # 50% error rate\n        self.timeout_seconds = 30\n        self._circuit_states: Dict[str, str] = {}  # service -> state\n    \n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate circuit breaker context.\"\"\"\n        required = ['service_name', 'error_rate', 'request_count']\n        return all(key in context for key in required)\n    \n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute circuit breaker logic.\"\"\"\n        if not self.validate_context(context):\n            return {'success': False, 'error': 'Invalid context'}\n        \n        service_name = context['service_name']\n        error_rate = context['error_rate']\n        request_count = context['request_count']\n        \n        current_state = self._circuit_states.get(service_name, 'closed')\n        new_state = current_state\n        \n        if error_rate > self.error_threshold and request_count > 10:\n            new_state = 'open'\n        elif current_state == 'open':\n            new_state = 'half_open'\n        elif current_state == 'half_open' and error_rate < self.error_threshold:\n            new_state = 'closed'\n        \n        self._circuit_states[service_name] = new_state\n        \n        result = {\n            'success': True,\n            'service_name': service_name,\n            'previous_state': current_state,\n            'new_state': new_state,\n            'error_rate': error_rate\n        }\n        \n        self.record_execution(context, result)\n        logger.info(f\"Circuit breaker for {service_name}: {current_state} -> {new_state}\")\n        \n        return result\n\n\nclass CanaryAnalysisStrategy(BaseStrategy):\n    \"\"\"Strategy for analyzing canary deployments against stable versions.\"\"\"\n    \n    PROMOTE = 'PROMOTE'\n    ROLLBACK = 'ROLLBACK'\n    \n    def __init__(self, telemetry_client=None):\n        super().__init__(\n            name='canary_analysis',\n            description='Analyzes canary deployment KPIs against stable version'\n        )\n        self._telemetry_client = telemetry_client\n    \n    def set_telemetry_client(self, client) -> None:\n        \"\"\"Set the telemetry client for querying metrics.\"\"\"\n        self._telemetry_client = client\n    \n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate canary analysis context.\"\"\"\n        required = ['service_name', 'canary_version', 'stable_version', \n                    'duration_minutes', 'kpi_thresholds']\n        return all(key in context for key in required)\n    \n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute canary analysis comparing canary vs stable metrics.\"\"\"\n        if not self.validate_context(context):\n            return {\n                'success': False, \n                'error': 'Invalid context - missing required fields',\n                'recommendation': self.ROLLBACK,\n                'justification': 'Analysis failed due to invalid context'\n            }\n        \n        service_name = context['service_name']\n        canary_version = context['canary_version']\n        stable_version = context['stable_version']\n        duration_minutes = context['duration_minutes']\n        kpi_thresholds = context['kpi_thresholds']\n        \n        analysis_id = str(uuid.uuid4())\n        logger.info(f\"Starting canary analysis {analysis_id} for {service_name}\")\n        logger.info(f\"Comparing canary={canary_version} vs stable={stable_version}\")\n        \n        try:\n            # Fetch metrics for both versions\n            canary_metrics = self._fetch_metrics(\n                service_name, canary_version, duration_minutes\n            )\n            stable_metrics = self._fetch_metrics(\n                service_name, stable_version, duration_minutes\n            )\n            \n            # Calculate KPIs\n            canary_kpis = self._calculate_kpis(canary_metrics)\n            stable_kpis = self._calculate_kpis(stable_metrics)\n            \n            logger.info(f\"Canary KPIs: {canary_kpis}\")\n            logger.info(f\"Stable KPIs: {stable_kpis}\")\n            \n            # Compare KPIs against thresholds\n            failures = []\n            \n            # Check latency threshold\n            if 'latency_ms_p99' in kpi_thresholds:\n                threshold_config = kpi_thresholds['latency_ms_p99']\n                max_relative_increase = threshold_config.get('max_relative_increase', 0.1)\n                \n                canary_latency = canary_kpis.get('latency_ms_p99', 0)\n                stable_latency = stable_kpis.get('latency_ms_p99', 0)\n                \n                if stable_latency > 0:\n                    max_allowed_latency = stable_latency * (1 + max_relative_increase)\n                    if canary_latency > max_allowed_latency:\n                        relative_increase = ((canary_latency - stable_latency) / stable_latency) * 100\n                        failures.append(\n                            f\"Canary latency {canary_latency:.2f}ms exceeded stable latency \"\n                            f\"{stable_latency:.2f}ms by {relative_increase:.1f}% \"\n                            f\"(max allowed: {max_relative_increase * 100}%)\"\n                        )\n            \n            # Check error rate threshold\n            if 'error_rate' in kpi_thresholds:\n                threshold_config = kpi_thresholds['error_rate']\n                max_absolute_value = threshold_config.get('max_absolute_value', 0.01)\n                \n                canary_error_rate = canary_kpis.get('error_rate', 0)\n                \n                if canary_error_rate > max_absolute_value:\n                    failures.append(\n                        f\"Canary error rate {canary_error_rate:.4f} exceeded \"\n                        f\"maximum allowed {max_absolute_value}\"\n                    )\n            \n            # Determine recommendation\n            if failures:\n                recommendation = self.ROLLBACK\n                justification = \"; \".join(failures)\n            else:\n                recommendation = self.PROMOTE\n                justification = (\n                    f\"All KPI checks passed. Canary latency: {canary_kpis.get('latency_ms_p99', 'N/A')}ms, \"\n                    f\"error rate: {canary_kpis.get('error_rate', 'N/A')}\"\n                )\n            \n            result = {\n                'success': True,\n                'analysis_id': analysis_id,\n                'service_name': service_name,\n                'canary_version': canary_version,\n                'stable_version': stable_version,\n                'recommendation': recommendation,\n                'justification': justification,\n                'canary_kpis': canary_kpis,\n                'stable_kpis': stable_kpis,\n                'failures': failures\n            }\n            \n            self.record_execution(context, result)\n            logger.info(f\"Canary analysis {analysis_id} complete: {recommendation}\")\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Canary analysis failed: {e}\")\n            return {\n                'success': False,\n                'analysis_id': analysis_id,\n                'service_name': service_name,\n                'recommendation': self.ROLLBACK,\n                'justification': f'Analysis failed with error: {str(e)}',\n                'error': str(e)\n            }\n    \n    def _fetch_metrics(self, service_name: str, version: str, \n                       duration_minutes: int) -> List[Dict[str, Any]]:\n        \"\"\"Fetch metrics from telemetry service for a specific version.\"\"\"\n        if self._telemetry_client is None:\n            logger.warning(\"No telemetry client configured, returning empty metrics\")\n            return []\n        \n        try:\n            metrics = self._telemetry_client.get_metrics(\n                service_name=service_name,\n                version=version,\n                duration_minutes=duration_minutes\n            )\n            return metrics if metrics else []\n        except Exception as e:\n            logger.error(f\"Failed to fetch metrics for {service_name} v{version}: {e}\")\n            return []\n    \n    def _calculate_kpis(self, metrics: List[Dict[str, Any]]) -> Dict[str, float]:\n        \"\"\"Calculate KPIs from raw metrics.\"\"\"\n        kpis = {\n            'latency_ms_p99': 0.0,\n            'error_rate': 0.0,\n            'request_count': 0\n        }\n        \n        if not metrics:\n            return kpis\n        \n        # Group metrics by type\n        latency_values = []\n        error_values = []\n        \n        for metric in metrics:\n            metric_name = metric.get('metric_name', '').lower()\n            value = metric.get('value', 0)\n            \n            if 'latency' in metric_name:\n                latency_values.append(value)\n            elif 'error' in metric_name:\n                error_values.append(value)\n        \n        # Calculate p99 latency\n        if latency_values:\n            sorted_latencies = sorted(latency_values)\n            p99_index = int(len(sorted_latencies) * 0.99)\n            p99_index = min(p99_index, len(sorted_latencies) - 1)\n            kpis['latency_ms_p99'] = sorted_latencies[p99_index]\n        \n        # Calculate average error rate\n        if error_values:\n            kpis['error_rate'] = sum(error_values) / len(error_values)\n        \n        kpis['request_count'] = len(metrics)\n        \n        return kpis\n\n\nclass StrategyRegistry:\n    \"\"\"Registry for managing available strategies.\"\"\"\n    \n    def __init__(self):\n        self._strategies: Dict[str, BaseStrategy] = {}\n        self._register_default_strategies()\n    \n    def _register_default_strategies(self) -> None:\n        \"\"\"Register default strategies.\"\"\"\n        self.register(AutoScalingStrategy())\n        self.register(CircuitBreakerStrategy())\n        self.register(CanaryAnalysisStrategy())\n    \n    def register(self, strategy: BaseStrategy) -> None:\n        \"\"\"Register a strategy.\"\"\"\n        self._strategies[strategy.name] = strategy\n        logger.info(f\"Registered strategy: {strategy.name}\")\n    \n    def get(self, name: str) -> Optional[BaseStrategy]:\n        \"\"\"Get a strategy by name.\"\"\"\n        return self._strategies.get(name)\n    \n    def list_strategies(self) -> List[Dict[str, str]]:\n        \"\"\"List all registered strategies.\"\"\"\n        return [\n            {'name': s.name, 'description': s.description}\n            for s in self._strategies.values()\n        ]\n",
          "edupulse_insight_mesh/src/remediation_service/commands.py": "\"\"\"Remediation commands for the EduPulse Insight Mesh system.\"\"\"\n\nimport logging\nimport subprocess\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseCommand(ABC):\n    \"\"\"Abstract base class for remediation commands.\"\"\"\n    \n    def __init__(self, name: str, description: str = \"\"):\n        self.name = name\n        self.description = description\n        self.executed_at: Optional[datetime] = None\n        self.result: Optional[Dict[str, Any]] = None\n    \n    @abstractmethod\n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute the command and return result.\"\"\"\n        pass\n    \n    @abstractmethod\n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback the command if possible.\"\"\"\n        pass\n    \n    def _record_execution(self, result: Dict[str, Any]) -> None:\n        \"\"\"Record execution details.\"\"\"\n        self.executed_at = datetime.utcnow()\n        self.result = result\n\n\nclass RestartServiceCommand(BaseCommand):\n    \"\"\"Command to restart a service.\"\"\"\n    \n    def __init__(self, service_name: str, namespace: str = 'default'):\n        super().__init__(\n            name='restart_service',\n            description=f'Restart service {service_name} in namespace {namespace}'\n        )\n        self.service_name = service_name\n        self.namespace = namespace\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute service restart.\"\"\"\n        logger.info(f\"Restarting service {self.service_name} in {self.namespace}\")\n        \n        # In production, this would use kubernetes client\n        # For now, we simulate the operation\n        result = {\n            'success': True,\n            'command': 'restart_service',\n            'service_name': self.service_name,\n            'namespace': self.namespace,\n            'message': f'Service {self.service_name} restart initiated'\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback is not applicable for restart.\"\"\"\n        return {\n            'success': False,\n            'message': 'Rollback not applicable for restart command'\n        }\n\n\nclass ScaleDeploymentCommand(BaseCommand):\n    \"\"\"Command to scale a deployment.\"\"\"\n    \n    def __init__(self, deployment_name: str, replicas: int, \n                 namespace: str = 'default'):\n        super().__init__(\n            name='scale_deployment',\n            description=f'Scale {deployment_name} to {replicas} replicas'\n        )\n        self.deployment_name = deployment_name\n        self.replicas = replicas\n        self.namespace = namespace\n        self.previous_replicas: Optional[int] = None\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute deployment scaling.\"\"\"\n        logger.info(f\"Scaling {self.deployment_name} to {self.replicas} replicas\")\n        \n        # Store previous state for rollback\n        self.previous_replicas = self._get_current_replicas()\n        \n        result = {\n            'success': True,\n            'command': 'scale_deployment',\n            'deployment_name': self.deployment_name,\n            'previous_replicas': self.previous_replicas,\n            'new_replicas': self.replicas,\n            'namespace': self.namespace\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback to previous replica count.\"\"\"\n        if self.previous_replicas is None:\n            return {\n                'success': False,\n                'message': 'No previous state to rollback to'\n            }\n        \n        logger.info(f\"Rolling back {self.deployment_name} to {self.previous_replicas} replicas\")\n        \n        return {\n            'success': True,\n            'command': 'scale_deployment_rollback',\n            'deployment_name': self.deployment_name,\n            'replicas': self.previous_replicas\n        }\n    \n    def _get_current_replicas(self) -> int:\n        \"\"\"Get current replica count (simulated).\"\"\"\n        # In production, query Kubernetes API\n        return 1\n\n\nclass UpdateConfigMapCommand(BaseCommand):\n    \"\"\"Command to update a ConfigMap.\"\"\"\n    \n    def __init__(self, configmap_name: str, data: Dict[str, str],\n                 namespace: str = 'default'):\n        super().__init__(\n            name='update_configmap',\n            description=f'Update ConfigMap {configmap_name}'\n        )\n        self.configmap_name = configmap_name\n        self.data = data\n        self.namespace = namespace\n        self.previous_data: Optional[Dict[str, str]] = None\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute ConfigMap update.\"\"\"\n        logger.info(f\"Updating ConfigMap {self.configmap_name}\")\n        \n        self.previous_data = self._get_current_data()\n        \n        result = {\n            'success': True,\n            'command': 'update_configmap',\n            'configmap_name': self.configmap_name,\n            'namespace': self.namespace,\n            'keys_updated': list(self.data.keys())\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback ConfigMap to previous state.\"\"\"\n        if self.previous_data is None:\n            return {\n                'success': False,\n                'message': 'No previous state to rollback to'\n            }\n        \n        return {\n            'success': True,\n            'command': 'update_configmap_rollback',\n            'configmap_name': self.configmap_name\n        }\n    \n    def _get_current_data(self) -> Dict[str, str]:\n        \"\"\"Get current ConfigMap data (simulated).\"\"\"\n        return {}\n\n\nclass LogCanaryAnalysisResultCommand(BaseCommand):\n    \"\"\"Command to log canary analysis results.\"\"\"\n    \n    def __init__(self, service_name: str, recommendation: str, \n                 justification: str):\n        super().__init__(\n            name='log_canary_analysis_result',\n            description=f'Log canary analysis result for {service_name}'\n        )\n        self.service_name = service_name\n        self.recommendation = recommendation\n        self.justification = justification\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute logging of canary analysis result.\"\"\"\n        timestamp = datetime.utcnow().isoformat()\n        \n        # Log the canary analysis result at INFO level\n        log_message = (\n            f\"CANARY_ANALYSIS_RESULT | \"\n            f\"timestamp={timestamp} | \"\n            f\"service={self.service_name} | \"\n            f\"recommendation={self.recommendation} | \"\n            f\"justification={self.justification}\"\n        )\n        \n        logger.info(log_message)\n        \n        # Also log structured data for potential downstream processing\n        if self.recommendation == 'PROMOTE':\n            logger.info(\n                f\"Canary deployment for {self.service_name} PASSED analysis. \"\n                f\"Recommendation: {self.recommendation}\"\n            )\n        else:\n            logger.warning(\n                f\"Canary deployment for {self.service_name} FAILED analysis. \"\n                f\"Recommendation: {self.recommendation}. \"\n                f\"Reason: {self.justification}\"\n            )\n        \n        result = {\n            'success': True,\n            'command': 'log_canary_analysis_result',\n            'service_name': self.service_name,\n            'recommendation': self.recommendation,\n            'justification': self.justification,\n            'timestamp': timestamp,\n            'logged': True\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback is not applicable for logging.\"\"\"\n        return {\n            'success': False,\n            'message': 'Rollback not applicable for logging command'\n        }\n\n\nclass ExecuteScriptCommand(BaseCommand):\n    \"\"\"Command to execute a remediation script.\"\"\"\n    \n    def __init__(self, script_path: str, args: List[str] = None,\n                 timeout: int = 60):\n        super().__init__(\n            name='execute_script',\n            description=f'Execute script {script_path}'\n        )\n        self.script_path = script_path\n        self.args = args or []\n        self.timeout = timeout\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute the script.\"\"\"\n        logger.info(f\"Executing script {self.script_path} with args {self.args}\")\n        \n        # In production, this would actually run the script\n        # For safety, we simulate the execution\n        result = {\n            'success': True,\n            'command': 'execute_script',\n            'script_path': self.script_path,\n            'args': self.args,\n            'exit_code': 0,\n            'stdout': 'Script executed successfully (simulated)',\n            'stderr': ''\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback is script-dependent.\"\"\"\n        return {\n            'success': False,\n            'message': 'Automatic rollback not supported for scripts'\n        }\n\n\nclass CommandQueue:\n    \"\"\"Queue for managing and executing commands.\"\"\"\n    \n    def __init__(self):\n        self._pending: List[BaseCommand] = []\n        self._executed: List[BaseCommand] = []\n    \n    def add(self, command: BaseCommand) -> None:\n        \"\"\"Add a command to the queue.\"\"\"\n        self._pending.append(command)\n        logger.debug(f\"Added command to queue: {command.name}\")\n    \n    def execute_all(self) -> List[Dict[str, Any]]:\n        \"\"\"Execute all pending commands.\"\"\"\n        results = []\n        \n        while self._pending:\n            command = self._pending.pop(0)\n            try:\n                result = command.execute()\n                results.append(result)\n                self._executed.append(command)\n            except Exception as e:\n                logger.error(f\"Command {command.name} failed: {e}\")\n                results.append({\n                    'success': False,\n                    'command': command.name,\n                    'error': str(e)\n                })\n        \n        return results\n    \n    def rollback_all(self) -> List[Dict[str, Any]]:\n        \"\"\"Rollback all executed commands in reverse order.\"\"\"\n        results = []\n        \n        while self._executed:\n            command = self._executed.pop()\n            try:\n                result = command.rollback()\n                results.append(result)\n            except Exception as e:\n                logger.error(f\"Rollback of {command.name} failed: {e}\")\n                results.append({\n                    'success': False,\n                    'command': command.name,\n                    'error': str(e)\n                })\n        \n        return results\n",
          "edupulse_insight_mesh/src/core_telemetry/service.py": "\"\"\"Core telemetry service for the EduPulse Insight Mesh system.\"\"\"\n\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass TelemetryService:\n    \"\"\"Service for querying and managing telemetry data.\"\"\"\n    \n    def __init__(self, storage_backend=None):\n        \"\"\"Initialize the telemetry service.\n        \n        Args:\n            storage_backend: Optional storage backend. If not provided,\n                           uses the shared InMemoryStorage.\n        \"\"\"\n        self._storage = storage_backend\n        if self._storage is None:\n            from ..ingestion_pipeline.handlers import InMemoryStorage\n            self._storage = InMemoryStorage()\n    \n    def get_metrics(self, service_name: str, version: Optional[str] = None,\n                    duration_minutes: int = 60,\n                    metric_name: Optional[str] = None) -> List[Dict[str, Any]]:\n        \"\"\"Get metrics for a service.\n        \n        Args:\n            service_name: Name of the service to query\n            version: Optional version filter for canary analysis\n            duration_minutes: Time window in minutes\n            metric_name: Optional specific metric name to filter\n            \n        Returns:\n            List of metric records\n        \"\"\"\n        logger.debug(\n            f\"Querying metrics for service={service_name}, version={version}, \"\n            f\"duration={duration_minutes}min\"\n        )\n        \n        try:\n            # Query storage\n            metrics = self._storage.query(\n                service_name=service_name,\n                version=version,\n                metric_name=metric_name\n            )\n            \n            # Filter by time window\n            cutoff_time = datetime.utcnow() - timedelta(minutes=duration_minutes)\n            filtered_metrics = []\n            \n            for metric in metrics:\n                timestamp_str = metric.get('timestamp', '')\n                if timestamp_str:\n                    try:\n                        # Parse ISO format timestamp\n                        timestamp = datetime.fromisoformat(\n                            timestamp_str.replace('Z', '+00:00')\n                        )\n                        # Remove timezone info for comparison\n                        timestamp = timestamp.replace(tzinfo=None)\n                        if timestamp >= cutoff_time:\n                            filtered_metrics.append(metric)\n                    except (ValueError, TypeError):\n                        # Include metrics with unparseable timestamps\n                        filtered_metrics.append(metric)\n                else:\n                    filtered_metrics.append(metric)\n            \n            logger.debug(f\"Found {len(filtered_metrics)} metrics\")\n            return filtered_metrics\n            \n        except Exception as e:\n            logger.error(f\"Error querying metrics: {e}\")\n            return []\n    \n    def get_aggregated_metrics(self, service_name: str, \n                                version: Optional[str] = None,\n                                duration_minutes: int = 60) -> Dict[str, Any]:\n        \"\"\"Get aggregated metrics for a service.\n        \n        Args:\n            service_name: Name of the service\n            version: Optional version filter\n            duration_minutes: Time window in minutes\n            \n        Returns:\n            Dictionary with aggregated metrics\n        \"\"\"\n        metrics = self.get_metrics(service_name, version, duration_minutes)\n        \n        if not metrics:\n            return {\n                'service_name': service_name,\n                'version': version,\n                'count': 0,\n                'aggregations': {}\n            }\n        \n        # Group by metric name\n        grouped: Dict[str, List[float]] = {}\n        for metric in metrics:\n            name = metric.get('metric_name', 'unknown')\n            value = metric.get('value', 0)\n            if name not in grouped:\n                grouped[name] = []\n            grouped[name].append(value)\n        \n        # Calculate aggregations\n        aggregations = {}\n        for name, values in grouped.items():\n            if values:\n                sorted_values = sorted(values)\n                aggregations[name] = {\n                    'count': len(values),\n                    'min': min(values),\n                    'max': max(values),\n                    'avg': sum(values) / len(values),\n                    'p50': sorted_values[len(sorted_values) // 2],\n                    'p99': sorted_values[int(len(sorted_values) * 0.99)] \n                           if len(sorted_values) > 1 else sorted_values[0]\n                }\n        \n        return {\n            'service_name': service_name,\n            'version': version,\n            'count': len(metrics),\n            'aggregations': aggregations\n        }\n    \n    def get_service_health(self, service_name: str) -> Dict[str, Any]:\n        \"\"\"Get overall health status for a service.\n        \n        Args:\n            service_name: Name of the service\n            \n        Returns:\n            Health status dictionary\n        \"\"\"\n        metrics = self.get_metrics(service_name, duration_minutes=5)\n        \n        if not metrics:\n            return {\n                'service_name': service_name,\n                'status': 'unknown',\n                'message': 'No recent metrics available'\n            }\n        \n        # Check for error metrics\n        error_metrics = [\n            m for m in metrics \n            if 'error' in m.get('metric_name', '').lower()\n        ]\n        \n        if error_metrics:\n            avg_error_rate = sum(m.get('value', 0) for m in error_metrics) / len(error_metrics)\n            if avg_error_rate > 0.1:\n                return {\n                    'service_name': service_name,\n                    'status': 'unhealthy',\n                    'error_rate': avg_error_rate,\n                    'message': f'High error rate: {avg_error_rate:.2%}'\n                }\n        \n        return {\n            'service_name': service_name,\n            'status': 'healthy',\n            'metrics_count': len(metrics),\n            'message': 'Service is operating normally'\n        }\n    \n    def list_services(self) -> List[str]:\n        \"\"\"List all services with telemetry data.\n        \n        Returns:\n            List of service names\n        \"\"\"\n        try:\n            all_metrics = self._storage.query()\n            services = set(m.get('service_name') for m in all_metrics if m.get('service_name'))\n            return sorted(list(services))\n        except Exception as e:\n            logger.error(f\"Error listing services: {e}\")\n            return []\n    \n    def list_versions(self, service_name: str) -> List[str]:\n        \"\"\"List all versions for a service.\n        \n        Args:\n            service_name: Name of the service\n            \n        Returns:\n            List of version strings\n        \"\"\"\n        try:\n            metrics = self._storage.query(service_name=service_name)\n            versions = set(\n                m.get('version') for m in metrics \n                if m.get('version') and m.get('version') != 'unknown'\n            )\n            return sorted(list(versions))\n        except Exception as e:\n            logger.error(f\"Error listing versions: {e}\")\n            return []\n",
          "edupulse_insight_mesh/tests/test_strategy_service.py": "\"\"\"Tests for the strategy service.\"\"\"\n\nimport unittest\nfrom unittest.mock import MagicMock, patch\nfrom datetime import datetime\n\nfrom edupulse_insight_mesh.src.strategy_service.strategies import (\n    AutoScalingStrategy,\n    CircuitBreakerStrategy,\n    CanaryAnalysisStrategy,\n    StrategyRegistry\n)\n\n\nclass TestAutoScalingStrategy(unittest.TestCase):\n    \"\"\"Tests for AutoScalingStrategy.\"\"\"\n    \n    def setUp(self):\n        self.strategy = AutoScalingStrategy()\n    \n    def test_validate_context_valid(self):\n        \"\"\"Test validation with valid context.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 2,\n            'cpu_percent': 75.0\n        }\n        self.assertTrue(self.strategy.validate_context(context))\n    \n    def test_validate_context_invalid(self):\n        \"\"\"Test validation with missing fields.\"\"\"\n        context = {'service_name': 'test-service'}\n        self.assertFalse(self.strategy.validate_context(context))\n    \n    def test_scale_up_decision(self):\n        \"\"\"Test scale up when CPU is high.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 2,\n            'cpu_percent': 85.0\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['action'], 'scale_up')\n        self.assertEqual(result['new_replicas'], 3)\n    \n    def test_scale_down_decision(self):\n        \"\"\"Test scale down when CPU is low.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 3,\n            'cpu_percent': 20.0\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['action'], 'scale_down')\n        self.assertEqual(result['new_replicas'], 2)\n    \n    def test_no_scaling_needed(self):\n        \"\"\"Test no action when CPU is in normal range.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 2,\n            'cpu_percent': 50.0\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['action'], 'none')\n        self.assertEqual(result['new_replicas'], 2)\n\n\nclass TestCircuitBreakerStrategy(unittest.TestCase):\n    \"\"\"Tests for CircuitBreakerStrategy.\"\"\"\n    \n    def setUp(self):\n        self.strategy = CircuitBreakerStrategy()\n    \n    def test_open_circuit_on_high_errors(self):\n        \"\"\"Test circuit opens on high error rate.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'error_rate': 0.6,\n            'request_count': 100\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['new_state'], 'open')\n    \n    def test_circuit_stays_closed_low_errors(self):\n        \"\"\"Test circuit stays closed with low errors.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'error_rate': 0.1,\n            'request_count': 100\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['new_state'], 'closed')\n\n\nclass TestCanaryAnalysisStrategy(unittest.TestCase):\n    \"\"\"Tests for CanaryAnalysisStrategy.\"\"\"\n    \n    def setUp(self):\n        self.mock_telemetry_client = MagicMock()\n        self.strategy = CanaryAnalysisStrategy(\n            telemetry_client=self.mock_telemetry_client\n        )\n    \n    def test_validate_context_valid(self):\n        \"\"\"Test validation with valid context.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        self.assertTrue(self.strategy.validate_context(context))\n    \n    def test_validate_context_missing_fields(self):\n        \"\"\"Test validation with missing fields.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0'\n        }\n        self.assertFalse(self.strategy.validate_context(context))\n    \n    def test_promote_recommendation_good_metrics(self):\n        \"\"\"Test PROMOTE recommendation when canary metrics are good.\"\"\"\n        # Mock stable metrics\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'latency_ms_p99', 'value': 105.0},\n            {'metric_name': 'error_rate', 'value': 0.005},\n            {'metric_name': 'error_rate', 'value': 0.003}\n        ]\n        \n        # Mock canary metrics - slightly better or similar\n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 98.0},\n            {'metric_name': 'latency_ms_p99', 'value': 102.0},\n            {'metric_name': 'error_rate', 'value': 0.004},\n            {'metric_name': 'error_rate', 'value': 0.002}\n        ]\n        \n        # Configure mock to return different metrics based on version\n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'PROMOTE')\n        self.assertEqual(len(result['failures']), 0)\n    \n    def test_rollback_recommendation_high_latency(self):\n        \"\"\"Test ROLLBACK recommendation when canary latency is too high.\"\"\"\n        # Mock stable metrics with 100ms latency\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        # Mock canary metrics with 150ms latency (50% increase, exceeds 10% threshold)\n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 150.0},\n            {'metric_name': 'latency_ms_p99', 'value': 145.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n        self.assertGreater(len(result['failures']), 0)\n        self.assertIn('latency', result['failures'][0].lower())\n    \n    def test_rollback_recommendation_high_error_rate(self):\n        \"\"\"Test ROLLBACK recommendation when canary error rate is too high.\"\"\"\n        # Mock stable metrics\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        # Mock canary metrics with high error rate (5% > 1% threshold)\n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.05},\n            {'metric_name': 'error_rate', 'value': 0.04}\n        ]\n        \n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n        self.assertGreater(len(result['failures']), 0)\n        self.assertIn('error rate', result['failures'][0].lower())\n    \n    def test_rollback_on_multiple_failures(self):\n        \"\"\"Test ROLLBACK when both latency and error rate fail.\"\"\"\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 200.0},  # 100% increase\n            {'metric_name': 'error_rate', 'value': 0.05}  # 5% error rate\n        ]\n        \n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n        self.assertEqual(len(result['failures']), 2)\n    \n    def test_promote_with_no_metrics(self):\n        \"\"\"Test behavior when no metrics are available.\"\"\"\n        self.mock_telemetry_client.get_metrics.return_value = []\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        # With no metrics, should PROMOTE (no failures detected)\n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'PROMOTE')\n    \n    def test_invalid_context_returns_rollback(self):\n        \"\"\"Test that invalid context returns ROLLBACK.\"\"\"\n        context = {'service_name': 'test-service'}  # Missing required fields\n        \n        result = self.strategy.execute(context)\n        \n        self.assertFalse(result['success'])\n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n    \n    def test_kpi_calculation(self):\n        \"\"\"Test KPI calculation from metrics.\"\"\"\n        metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'latency_ms_p99', 'value': 110.0},\n            {'metric_name': 'latency_ms_p99', 'value': 90.0},\n            {'metric_name': 'latency_ms_p99', 'value': 105.0},\n            {'metric_name': 'error_rate', 'value': 0.01},\n            {'metric_name': 'error_rate', 'value': 0.02}\n        ]\n        \n        kpis = self.strategy._calculate_kpis(metrics)\n        \n        # Check p99 latency (should be near 110)\n        self.assertGreater(kpis['latency_ms_p99'], 100)\n        # Check error rate average (should be 0.015)\n        self.assertAlmostEqual(kpis['error_rate'], 0.015, places=3)\n\n\nclass TestStrategyRegistry(unittest.TestCase):\n    \"\"\"Tests for StrategyRegistry.\"\"\"\n    \n    def test_default_strategies_registered(self):\n        \"\"\"Test that default strategies are registered.\"\"\"\n        registry = StrategyRegistry()\n        \n        self.assertIsNotNone(registry.get('auto_scaling'))\n        self.assertIsNotNone(registry.get('circuit_breaker'))\n        self.assertIsNotNone(registry.get('canary_analysis'))\n    \n    def test_list_strategies(self):\n        \"\"\"Test listing all strategies.\"\"\"\n        registry = StrategyRegistry()\n        strategies = registry.list_strategies()\n        \n        self.assertGreaterEqual(len(strategies), 3)\n        names = [s['name'] for s in strategies]\n        self.assertIn('auto_scaling', names)\n        self.assertIn('circuit_breaker', names)\n        self.assertIn('canary_analysis', names)\n\n\nif __name__ == '__main__':\n    unittest.main()\n",
          "edupulse_insight_mesh/docs/api/openapi.yaml": "openapi: 3.0.3\ninfo:\n  title: EduPulse Insight Mesh API\n  description: |\n    API for the EduPulse Insight Mesh observability and remediation platform.\n    This API provides endpoints for telemetry ingestion, querying, and \n    automated remediation strategies including canary analysis.\n  version: 1.1.0\n  contact:\n    name: EduPulse Team\n    email: support@edupulse.io\n\nservers:\n  - url: http://localhost:8080/api/v1\n    description: Local development server\n  - url: https://api.edupulse.io/api/v1\n    description: Production server\n\nsecurity:\n  - ApiKeyAuth: []\n\ntags:\n  - name: Health\n    description: Health check endpoints\n  - name: Metrics\n    description: Metric ingestion and querying\n  - name: Telemetry\n    description: Telemetry data access\n  - name: Analysis\n    description: Deployment analysis endpoints\n  - name: Strategies\n    description: Remediation strategy management\n\npaths:\n  /health:\n    get:\n      tags:\n        - Health\n      summary: Health check\n      description: Returns the health status of the API gateway\n      operationId: healthCheck\n      security: []\n      responses:\n        '200':\n          description: Service is healthy\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/HealthResponse'\n\n  /metrics:\n    post:\n      tags:\n        - Metrics\n      summary: Ingest metrics\n      description: Ingest metrics from agents or external sources\n      operationId: ingestMetrics\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/MetricPayload'\n      responses:\n        '202':\n          description: Metrics accepted for processing\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/AcceptedResponse'\n        '400':\n          description: Invalid payload\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '401':\n          description: Unauthorized\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /telemetry/{service_name}:\n    get:\n      tags:\n        - Telemetry\n      summary: Get telemetry data\n      description: Retrieve telemetry data for a specific service\n      operationId: getTelemetry\n      parameters:\n        - name: service_name\n          in: path\n          required: true\n          schema:\n            type: string\n          description: Name of the service\n        - name: version\n          in: query\n          required: false\n          schema:\n            type: string\n          description: Filter by deployment version\n        - name: duration_minutes\n          in: query\n          required: false\n          schema:\n            type: integer\n            default: 60\n          description: Time window in minutes\n      responses:\n        '200':\n          description: Telemetry data retrieved successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/TelemetryResponse'\n        '401':\n          description: Unauthorized\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '500':\n          description: Internal server error\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /analysis/canary:\n    post:\n      tags:\n        - Analysis\n      summary: Initiate canary analysis\n      description: |\n        Initiates a canary analysis comparing a new canary deployment against\n        the existing stable deployment. The analysis compares key performance\n        indicators (KPIs) over a specified duration and returns a recommendation\n        to either PROMOTE the canary or ROLLBACK the deployment.\n      operationId: canaryAnalysis\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/CanaryAnalysisRequest'\n            examples:\n              basic:\n                summary: Basic canary analysis\n                value:\n                  service_name: \"user-service\"\n                  canary_version: \"v2.0.0\"\n                  stable_version: \"v1.5.0\"\n                  duration_minutes: 30\n                  kpi_thresholds:\n                    latency_ms_p99:\n                      max_relative_increase: 0.1\n                    error_rate:\n                      max_absolute_value: 0.01\n      responses:\n        '200':\n          description: Canary analysis completed successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/CanaryAnalysisResponse'\n              examples:\n                promote:\n                  summary: Promote recommendation\n                  value:\n                    service_name: \"user-service\"\n                    canary_version: \"v2.0.0\"\n                    stable_version: \"v1.5.0\"\n                    recommendation: \"PROMOTE\"\n                    justification: \"All KPI checks passed. Canary latency: 95.5ms, error rate: 0.005\"\n                    analysis_id: \"550e8400-e29b-41d4-a716-446655440000\"\n                rollback:\n                  summary: Rollback recommendation\n                  value:\n                    service_name: \"user-service\"\n                    canary_version: \"v2.0.0\"\n                    stable_version: \"v1.5.0\"\n                    recommendation: \"ROLLBACK\"\n                    justification: \"Canary latency 150.00ms exceeded stable latency 100.00ms by 50.0% (max allowed: 10%)\"\n                    analysis_id: \"550e8400-e29b-41d4-a716-446655440001\"\n        '400':\n          description: Invalid request payload\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n              example:\n                error: \"Invalid payload\"\n                details:\n                  - loc: [\"body\", \"duration_minutes\"]\n                    msg: \"ensure this value is greater than 0\"\n                    type: \"value_error.number.not_gt\"\n        '401':\n          description: Unauthorized - missing or invalid API key\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '500':\n          description: Internal server error\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /strategies:\n    get:\n      tags:\n        - Strategies\n      summary: List available strategies\n      description: Returns a list of all available remediation strategies\n      operationId: listStrategies\n      responses:\n        '200':\n          description: List of strategies\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/StrategiesResponse'\n\ncomponents:\n  securitySchemes:\n    ApiKeyAuth:\n      type: apiKey\n      in: header\n      name: X-API-Key\n      description: API key for authentication\n\n  schemas:\n    HealthResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          example: \"healthy\"\n        version:\n          type: string\n          example: \"1.0.0\"\n      required:\n        - status\n\n    MetricPayload:\n      type: object\n      properties:\n        service_name:\n          type: string\n          description: Name of the service sending metrics\n          example: \"user-service\"\n        metric_name:\n          type: string\n          description: Name of the metric\n          example: \"latency_ms_p99\"\n        value:\n          type: number\n          format: double\n          description: Metric value\n          example: 125.5\n        timestamp:\n          type: string\n          format: date-time\n          description: ISO 8601 timestamp (optional, defaults to server time)\n          example: \"2024-01-15T10:30:00Z\"\n        tags:\n          type: object\n          additionalProperties:\n            type: string\n          description: Additional tags including version for canary analysis\n          example:\n            version: \"v2.0.0\"\n            environment: \"production\"\n            deployment_type: \"canary\"\n      required:\n        - service_name\n        - metric_name\n        - value\n\n    AcceptedResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          example: \"accepted\"\n        id:\n          type: string\n          description: Unique identifier for the ingested data\n          example: \"550e8400-e29b-41d4-a716-446655440000\"\n\n    TelemetryResponse:\n      type: object\n      properties:\n        service_name:\n          type: string\n        metrics:\n          type: array\n          items:\n            type: object\n\n    CanaryAnalysisRequest:\n      type: object\n      properties:\n        service_name:\n          type: string\n          description: Name of the service to analyze\n          minLength: 1\n          example: \"user-service\"\n        canary_version:\n          type: string\n          description: Version string of the canary deployment\n          minLength: 1\n          example: \"v2.0.0\"\n        stable_version:\n          type: string\n          description: Version string of the stable deployment\n          minLength: 1\n          example: \"v1.5.0\"\n        duration_minutes:\n          type: integer\n          description: Duration in minutes to analyze metrics\n          minimum: 1\n          maximum: 1440\n          example: 30\n        kpi_thresholds:\n          type: object\n          description: KPI threshold configurations\n          properties:\n            latency_ms_p99:\n              $ref: '#/components/schemas/LatencyThreshold'\n            error_rate:\n              $ref: '#/components/schemas/ErrorRateThreshold'\n          additionalProperties:\n            type: object\n      required:\n        - service_name\n        - canary_version\n        - stable_version\n        - duration_minutes\n        - kpi_thresholds\n\n    LatencyThreshold:\n      type: object\n      properties:\n        max_relative_increase:\n          type: number\n          format: double\n          description: Maximum allowed relative increase compared to stable (e.g., 0.1 = 10%)\n          minimum: 0\n          maximum: 1\n          example: 0.1\n\n    ErrorRateThreshold:\n      type: object\n      properties:\n        max_absolute_value:\n          type: number\n          format: double\n          description: Maximum allowed absolute error rate (e.g., 0.01 = 1%)\n          minimum: 0\n          maximum: 1\n          example: 0.01\n\n    CanaryAnalysisResponse:\n      type: object\n      properties:\n        service_name:\n          type: string\n          description: Name of the analyzed service\n          example: \"user-service\"\n        canary_version:\n          type: string\n          description: Version of the canary deployment\n          example: \"v2.0.0\"\n        stable_version:\n          type: string\n          description: Version of the stable deployment\n          example: \"v1.5.0\"\n        recommendation:\n          type: string\n          enum:\n            - PROMOTE\n            - ROLLBACK\n          description: Recommended action based on analysis\n          example: \"PROMOTE\"\n        justification:\n          type: string\n          description: Human-readable explanation of the recommendation\n          example: \"All KPI checks passed. Canary latency: 95.5ms, error rate: 0.005\"\n        analysis_id:\n          type: string\n          format: uuid\n          description: Unique identifier for this analysis\n          example: \"550e8400-e29b-41d4-a716-446655440000\"\n      required:\n        - service_name\n        - canary_version\n        - stable_version\n        - recommendation\n        - justification\n        - analysis_id\n\n    StrategiesResponse:\n      type: object\n      properties:\n        strategies:\n          type: array\n          items:\n            type: object\n            properties:\n              name:\n                type: string\n              description:\n                type: string\n\n    ErrorResponse:\n      type: object\n      properties:\n        error:\n          type: string\n          description: Error message\n        message:\n          type: string\n          description: Additional error details\n        details:\n          type: array\n          items:\n            type: object\n          description: Validation error details\n"
        },
        "generated_files": [
          "edupulse_insight_mesh/src/api_gateway/routes.py",
          "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py",
          "edupulse_insight_mesh/src/strategy_service/strategies.py",
          "edupulse_insight_mesh/src/remediation_service/commands.py",
          "edupulse_insight_mesh/src/core_telemetry/service.py",
          "edupulse_insight_mesh/tests/test_strategy_service.py",
          "edupulse_insight_mesh/docs/api/openapi.yaml"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.6901068303216275,
              "dependency_traversal_accuracy": 0.7639205154242522,
              "cross_file_reasoning_depth": 0.3888095238095238,
              "system_thinking_score": 0.5253915145918892,
              "robustness_score": 0.3592293493308722,
              "comprehensiveness_score": 0.6433507107055884,
              "innovation_score": 0.31875,
              "solution_elegance_score": 0.4656374150637144
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.08626335379020343,
              "dependency_traversal_weighted": 0.09549006442803153,
              "cross_file_reasoning_weighted": 0.04860119047619048,
              "system_thinking_weighted": 0.06567393932398614,
              "robustness_weighted": 0.044903668666359024,
              "comprehensiveness_weighted": 0.08041883883819854,
              "innovation_weighted": 0.03984375,
              "solution_elegance_weighted": 0.0582046768829643
            },
            "total_software_engineering_score": 0.5193994824059335
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.46472954750061035,
              "errors": [
                "  File \"edupulse_insight_mesh/docs/api/openapi.py\", line 1",
                "    openapi: 3.0.3",
                "                ^^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "edupulse_insight_mesh/src/api_gateway/routes.py",
                "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py",
                "edupulse_insight_mesh/src/strategy_service/strategies.py",
                "edupulse_insight_mesh/src/remediation_service/commands.py",
                "edupulse_insight_mesh/src/core_telemetry/service.py",
                "edupulse_insight_mesh/tests/test_strategy_service.py",
                "edupulse_insight_mesh/docs/api/openapi.yaml"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 7,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 7 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.31830751417391995,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.31830751417391995,
              "idc_weight": 0.2,
              "total_functional_score": 0.40366150283478397
            }
          },
          "code_quality_details": {
            "files_analyzed": 7,
            "quality_checks": {
              "edupulse_insight_mesh/src/api_gateway/routes.py": {
                "line_count": 187,
                "non_empty_lines": 145,
                "comment_lines": 6,
                "comment_ratio": 0.041379310344827586,
                "function_count": 6,
                "class_count": 5,
                "import_count": 20,
                "quality_score": 0.7999999999999999
              },
              "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py": {
                "line_count": 267,
                "non_empty_lines": 195,
                "comment_lines": 19,
                "comment_ratio": 0.09743589743589744,
                "function_count": 18,
                "class_count": 11,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "edupulse_insight_mesh/src/strategy_service/strategies.py": {
                "line_count": 362,
                "non_empty_lines": 288,
                "comment_lines": 9,
                "comment_ratio": 0.03125,
                "function_count": 21,
                "class_count": 6,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "edupulse_insight_mesh/src/remediation_service/commands.py": {
                "line_count": 331,
                "non_empty_lines": 267,
                "comment_lines": 8,
                "comment_ratio": 0.0299625468164794,
                "function_count": 25,
                "class_count": 8,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "edupulse_insight_mesh/src/core_telemetry/service.py": {
                "line_count": 209,
                "non_empty_lines": 175,
                "comment_lines": 8,
                "comment_ratio": 0.045714285714285714,
                "function_count": 6,
                "class_count": 1,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "edupulse_insight_mesh/tests/test_strategy_service.py": {
                "line_count": 378,
                "non_empty_lines": 306,
                "comment_lines": 10,
                "comment_ratio": 0.032679738562091505,
                "function_count": 25,
                "class_count": 4,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "edupulse_insight_mesh/docs/api/openapi.yaml": {
                "line_count": 433,
                "non_empty_lines": 413,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 1,
                "quality_score": 0.7
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7899999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.878619691119691,
              "multi_session_memory_retention": 0.8191985088536811
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4393098455598455,
              "multi_session_memory_retention_weighted": 0.40959925442684053
            },
            "total_longcontext_utilization_score": 0.848909099986686
          }
        },
        "timestamp": "2026-01-14T21:10:49.733439"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_fintech_trading_hard_030_feature_implementation_expert_01",
        "scenario_title": "Implement Time-Locked Multi-Signature Escrow Transactions",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5851406898286998,
        "functional_correctness_score": 0.6827097922848665,
        "code_quality_score": 0.7906666666666666,
        "longcontext_utilization_score": 0.8505387931034485,
        "total_score": 3.4102821313030907,
        "generation_time": 254.08326888084412,
        "code_files_generated": 15,
        "total_lines_generated": 2509,
        "parsing_success": true,
        "solution_code": {
          "tradeutility_nexus/trade_nexus/core/domain.py": "\"\"\"Domain models and aggregates for TradeUtility Nexus.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set\nfrom uuid import UUID, uuid4\n\n\nclass TransactionStatus(Enum):\n    \"\"\"Status of a transaction.\"\"\"\n    PENDING = \"PENDING\"\n    PROCESSING = \"PROCESSING\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    CANCELLED = \"CANCELLED\"\n\n\nclass EscrowStatus(Enum):\n    \"\"\"Status of an escrow transaction.\"\"\"\n    PENDING = \"PENDING\"\n    FUNDED = \"FUNDED\"\n    AWAITING_RELEASE = \"AWAITING_RELEASE\"\n    RELEASED = \"RELEASED\"\n    CANCELLED = \"CANCELLED\"\n\n\n@dataclass\nclass DomainEvent:\n    \"\"\"Base class for domain events.\"\"\"\n    event_id: UUID = field(default_factory=uuid4)\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    aggregate_id: Optional[UUID] = None\n    version: int = 0\n\n\n@dataclass\nclass Aggregate:\n    \"\"\"Base class for aggregates.\"\"\"\n    id: UUID = field(default_factory=uuid4)\n    version: int = 0\n    _pending_events: List[DomainEvent] = field(default_factory=list, repr=False)\n\n    def apply_event(self, event: DomainEvent) -> None:\n        \"\"\"Apply an event to update aggregate state.\"\"\"\n        handler_name = f\"_apply_{type(event).__name__}\"\n        handler = getattr(self, handler_name, None)\n        if handler:\n            handler(event)\n        self.version += 1\n\n    def add_event(self, event: DomainEvent) -> None:\n        \"\"\"Add a new event to pending events.\"\"\"\n        event.aggregate_id = self.id\n        event.version = self.version + 1\n        self._pending_events.append(event)\n        self.apply_event(event)\n\n    def get_pending_events(self) -> List[DomainEvent]:\n        \"\"\"Get all pending events.\"\"\"\n        return self._pending_events.copy()\n\n    def clear_pending_events(self) -> None:\n        \"\"\"Clear pending events after persistence.\"\"\"\n        self._pending_events.clear()\n\n\n@dataclass\nclass Transaction(Aggregate):\n    \"\"\"Transaction aggregate representing a trade transaction.\"\"\"\n    sender_id: Optional[UUID] = None\n    receiver_id: Optional[UUID] = None\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    status: TransactionStatus = TransactionStatus.PENDING\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n\n    def initiate(self, sender_id: UUID, receiver_id: UUID, amount: Decimal, currency: str) -> None:\n        \"\"\"Initiate a new transaction.\"\"\"\n        from trade_nexus.core.events import TransactionInitiated\n        event = TransactionInitiated(\n            transaction_id=self.id,\n            sender_id=sender_id,\n            receiver_id=receiver_id,\n            amount=amount,\n            currency=currency\n        )\n        self.add_event(event)\n\n    def complete(self) -> None:\n        \"\"\"Mark transaction as completed.\"\"\"\n        from trade_nexus.core.events import TransactionCompleted\n        event = TransactionCompleted(transaction_id=self.id)\n        self.add_event(event)\n\n    def fail(self, reason: str) -> None:\n        \"\"\"Mark transaction as failed.\"\"\"\n        from trade_nexus.core.events import TransactionFailed\n        event = TransactionFailed(transaction_id=self.id, reason=reason)\n        self.add_event(event)\n\n    def _apply_TransactionInitiated(self, event: Any) -> None:\n        \"\"\"Apply TransactionInitiated event.\"\"\"\n        self.sender_id = event.sender_id\n        self.receiver_id = event.receiver_id\n        self.amount = event.amount\n        self.currency = event.currency\n        self.status = TransactionStatus.PROCESSING\n        self.updated_at = event.timestamp\n\n    def _apply_TransactionCompleted(self, event: Any) -> None:\n        \"\"\"Apply TransactionCompleted event.\"\"\"\n        self.status = TransactionStatus.COMPLETED\n        self.updated_at = event.timestamp\n\n    def _apply_TransactionFailed(self, event: Any) -> None:\n        \"\"\"Apply TransactionFailed event.\"\"\"\n        self.status = TransactionStatus.FAILED\n        self.updated_at = event.timestamp\n\n\n@dataclass\nclass EscrowTransaction(Aggregate):\n    \"\"\"Escrow transaction aggregate for time-locked multi-signature transactions.\"\"\"\n    initiator_id: Optional[UUID] = None\n    counterparty_id: Optional[UUID] = None\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    status: EscrowStatus = EscrowStatus.PENDING\n    lock_until_timestamp: Optional[datetime] = None\n    release_signatures: Set[str] = field(default_factory=set)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n\n    def initiate(\n        self,\n        initiator_id: UUID,\n        counterparty_id: UUID,\n        amount: Decimal,\n        currency: str,\n        lock_until_timestamp: datetime,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> None:\n        \"\"\"Initiate a new escrow transaction.\"\"\"\n        from trade_nexus.core.events import EscrowInitiated\n        event = EscrowInitiated(\n            escrow_id=self.id,\n            initiator_id=initiator_id,\n            counterparty_id=counterparty_id,\n            amount=amount,\n            currency=currency,\n            lock_until_timestamp=lock_until_timestamp,\n            metadata=metadata or {}\n        )\n        self.add_event(event)\n\n    def fund(self) -> None:\n        \"\"\"Fund the escrow transaction.\"\"\"\n        if self.status != EscrowStatus.PENDING:\n            raise ValueError(f\"Cannot fund escrow in status {self.status}\")\n        from trade_nexus.core.events import EscrowFunded\n        event = EscrowFunded(\n            escrow_id=self.id,\n            amount=self.amount,\n            currency=self.currency\n        )\n        self.add_event(event)\n\n    def add_release_signature(self, signer_id: UUID, signature: str) -> None:\n        \"\"\"Add a release signature from a participant.\"\"\"\n        if self.status not in (EscrowStatus.FUNDED, EscrowStatus.AWAITING_RELEASE):\n            raise ValueError(f\"Cannot add signature in status {self.status}\")\n        \n        if signer_id not in (self.initiator_id, self.counterparty_id):\n            raise ValueError(\"Signer must be initiator or counterparty\")\n        \n        signer_key = f\"{signer_id}:{signature}\"\n        if any(s.startswith(str(signer_id)) for s in self.release_signatures):\n            raise ValueError(\"Signer has already provided a signature\")\n        \n        from trade_nexus.core.events import ReleaseSignatureAdded\n        event = ReleaseSignatureAdded(\n            escrow_id=self.id,\n            signer_id=signer_id,\n            signature=signature\n        )\n        self.add_event(event)\n\n    def release(self) -> None:\n        \"\"\"Release the escrow funds.\"\"\"\n        if self.status != EscrowStatus.AWAITING_RELEASE:\n            raise ValueError(f\"Cannot release escrow in status {self.status}\")\n        \n        if not self.has_all_signatures():\n            raise ValueError(\"Not all required signatures collected\")\n        \n        if not self.is_lock_expired():\n            raise ValueError(\"Lock period has not expired\")\n        \n        from trade_nexus.core.events import EscrowReleased\n        event = EscrowReleased(\n            escrow_id=self.id,\n            initiator_id=self.initiator_id,\n            counterparty_id=self.counterparty_id,\n            amount=self.amount,\n            currency=self.currency\n        )\n        self.add_event(event)\n\n    def cancel(self, reason: str) -> None:\n        \"\"\"Cancel the escrow transaction.\"\"\"\n        if self.status in (EscrowStatus.RELEASED, EscrowStatus.CANCELLED):\n            raise ValueError(f\"Cannot cancel escrow in status {self.status}\")\n        \n        from trade_nexus.core.events import EscrowCancelled\n        event = EscrowCancelled(\n            escrow_id=self.id,\n            reason=reason\n        )\n        self.add_event(event)\n\n    def has_all_signatures(self) -> bool:\n        \"\"\"Check if all required signatures have been collected.\"\"\"\n        initiator_signed = any(\n            s.startswith(str(self.initiator_id)) for s in self.release_signatures\n        )\n        counterparty_signed = any(\n            s.startswith(str(self.counterparty_id)) for s in self.release_signatures\n        )\n        return initiator_signed and counterparty_signed\n\n    def is_lock_expired(self) -> bool:\n        \"\"\"Check if the time lock has expired.\"\"\"\n        if self.lock_until_timestamp is None:\n            return False\n        return datetime.utcnow() >= self.lock_until_timestamp\n\n    def _apply_EscrowInitiated(self, event: Any) -> None:\n        \"\"\"Apply EscrowInitiated event.\"\"\"\n        self.initiator_id = event.initiator_id\n        self.counterparty_id = event.counterparty_id\n        self.amount = event.amount\n        self.currency = event.currency\n        self.lock_until_timestamp = event.lock_until_timestamp\n        self.metadata = event.metadata\n        self.status = EscrowStatus.PENDING\n        self.updated_at = event.timestamp\n\n    def _apply_EscrowFunded(self, event: Any) -> None:\n        \"\"\"Apply EscrowFunded event.\"\"\"\n        self.status = EscrowStatus.FUNDED\n        self.updated_at = event.timestamp\n\n    def _apply_ReleaseSignatureAdded(self, event: Any) -> None:\n        \"\"\"Apply ReleaseSignatureAdded event.\"\"\"\n        signer_key = f\"{event.signer_id}:{event.signature}\"\n        self.release_signatures.add(signer_key)\n        if self.has_all_signatures():\n            self.status = EscrowStatus.AWAITING_RELEASE\n        self.updated_at = event.timestamp\n\n    def _apply_EscrowReleased(self, event: Any) -> None:\n        \"\"\"Apply EscrowReleased event.\"\"\"\n        self.status = EscrowStatus.RELEASED\n        self.updated_at = event.timestamp\n\n    def _apply_EscrowCancelled(self, event: Any) -> None:\n        \"\"\"Apply EscrowCancelled event.\"\"\"\n        self.status = EscrowStatus.CANCELLED\n        self.updated_at = event.timestamp\n\n\n@dataclass\nclass User(Aggregate):\n    \"\"\"User aggregate.\"\"\"\n    email: str = \"\"\n    name: str = \"\"\n    kyc_verified: bool = False\n    risk_score: float = 0.0\n    created_at: datetime = field(default_factory=datetime.utcnow)\n",
          "tradeutility_nexus/trade_nexus/core/commands.py": "\"\"\"Command definitions for CQRS pattern.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, Optional\nfrom uuid import UUID, uuid4\n\n\n@dataclass\nclass Command:\n    \"\"\"Base class for commands.\"\"\"\n    command_id: UUID = field(default_factory=uuid4)\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    correlation_id: Optional[UUID] = None\n\n\n@dataclass\nclass InitiateTransaction(Command):\n    \"\"\"Command to initiate a new transaction.\"\"\"\n    sender_id: UUID = field(default_factory=uuid4)\n    receiver_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass CompleteTransaction(Command):\n    \"\"\"Command to complete a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass FailTransaction(Command):\n    \"\"\"Command to fail a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass ProcessPayment(Command):\n    \"\"\"Command to process a payment.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    payment_method: str = \"CARD\"\n\n\n@dataclass\nclass VerifyKYC(Command):\n    \"\"\"Command to verify KYC for a user.\"\"\"\n    user_id: UUID = field(default_factory=uuid4)\n    document_type: str = \"\"\n    document_id: str = \"\"\n\n\n@dataclass\nclass AssessRisk(Command):\n    \"\"\"Command to assess risk for a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    user_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n\n\n@dataclass\nclass SettleTransaction(Command):\n    \"\"\"Command to settle a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n\n\n# Escrow Commands\n\n@dataclass\nclass InitiateEscrow(Command):\n    \"\"\"Command to initiate a new escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    initiator_id: UUID = field(default_factory=uuid4)\n    counterparty_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    lock_until_timestamp: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass FundEscrow(Command):\n    \"\"\"Command to fund an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass AddReleaseSignature(Command):\n    \"\"\"Command to add a release signature to an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    signer_id: UUID = field(default_factory=uuid4)\n    signature: str = \"\"\n\n\n@dataclass\nclass ProcessEscrowRelease(Command):\n    \"\"\"Command to process the release of an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass CancelEscrow(Command):\n    \"\"\"Command to cancel an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n",
          "tradeutility_nexus/trade_nexus/core/events.py": "\"\"\"Event definitions for Event Sourcing pattern.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, Optional\nfrom uuid import UUID, uuid4\n\n\n@dataclass\nclass Event:\n    \"\"\"Base class for events.\"\"\"\n    event_id: UUID = field(default_factory=uuid4)\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    aggregate_id: Optional[UUID] = None\n    version: int = 0\n    correlation_id: Optional[UUID] = None\n\n\n@dataclass\nclass TransactionInitiated(Event):\n    \"\"\"Event when a transaction is initiated.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    sender_id: UUID = field(default_factory=uuid4)\n    receiver_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n\n\n@dataclass\nclass TransactionCompleted(Event):\n    \"\"\"Event when a transaction is completed.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass TransactionFailed(Event):\n    \"\"\"Event when a transaction fails.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass PaymentProcessed(Event):\n    \"\"\"Event when a payment is processed.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    payment_reference: str = \"\"\n\n\n@dataclass\nclass PaymentFailed(Event):\n    \"\"\"Event when a payment fails.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass KYCVerified(Event):\n    \"\"\"Event when KYC is verified.\"\"\"\n    user_id: UUID = field(default_factory=uuid4)\n    verification_level: str = \"BASIC\"\n\n\n@dataclass\nclass KYCFailed(Event):\n    \"\"\"Event when KYC verification fails.\"\"\"\n    user_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass RiskAssessed(Event):\n    \"\"\"Event when risk is assessed.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    risk_score: float = 0.0\n    risk_level: str = \"LOW\"\n\n\n@dataclass\nclass TransactionSettled(Event):\n    \"\"\"Event when a transaction is settled.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    settlement_reference: str = \"\"\n\n\n@dataclass\nclass FraudDetected(Event):\n    \"\"\"Event when fraud is detected.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    fraud_type: str = \"\"\n    confidence: float = 0.0\n\n\n# Escrow Events\n\n@dataclass\nclass EscrowInitiated(Event):\n    \"\"\"Event when an escrow transaction is initiated.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    initiator_id: UUID = field(default_factory=uuid4)\n    counterparty_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    lock_until_timestamp: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass EscrowFunded(Event):\n    \"\"\"Event when an escrow transaction is funded.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n\n\n@dataclass\nclass ReleaseSignatureAdded(Event):\n    \"\"\"Event when a release signature is added to an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    signer_id: UUID = field(default_factory=uuid4)\n    signature: str = \"\"\n\n\n@dataclass\nclass EscrowReleased(Event):\n    \"\"\"Event when an escrow transaction is released.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    initiator_id: Optional[UUID] = None\n    counterparty_id: Optional[UUID] = None\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n\n\n@dataclass\nclass EscrowCancelled(Event):\n    \"\"\"Event when an escrow transaction is cancelled.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n",
          "tradeutility_nexus/trade_nexus/api/schemas.py": "\"\"\"Pydantic schemas for API validation.\"\"\"\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, List, Optional, Set\nfrom uuid import UUID\n\nfrom pydantic import BaseModel, Field, validator\n\n\nclass TransactionRequest(BaseModel):\n    \"\"\"Request schema for creating a transaction.\"\"\"\n    sender_id: UUID\n    receiver_id: UUID\n    amount: Decimal = Field(gt=0)\n    currency: str = Field(default=\"USD\", min_length=3, max_length=3)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"sender_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"receiver_id\": \"123e4567-e89b-12d3-a456-426614174001\",\n                \"amount\": \"100.00\",\n                \"currency\": \"USD\",\n                \"metadata\": {\"note\": \"Payment for services\"}\n            }\n        }\n\n\nclass TransactionResponse(BaseModel):\n    \"\"\"Response schema for transaction.\"\"\"\n    id: UUID\n    sender_id: UUID\n    receiver_id: UUID\n    amount: Decimal\n    currency: str\n    status: str\n    created_at: datetime\n    updated_at: datetime\n\n\nclass PaymentRequest(BaseModel):\n    \"\"\"Request schema for processing a payment.\"\"\"\n    transaction_id: UUID\n    payment_method: str = Field(default=\"CARD\")\n    payment_details: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass PaymentResponse(BaseModel):\n    \"\"\"Response schema for payment.\"\"\"\n    transaction_id: UUID\n    status: str\n    payment_reference: Optional[str] = None\n    processed_at: datetime\n\n\nclass KYCVerificationRequest(BaseModel):\n    \"\"\"Request schema for KYC verification.\"\"\"\n    user_id: UUID\n    document_type: str\n    document_id: str\n    additional_info: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass KYCVerificationResponse(BaseModel):\n    \"\"\"Response schema for KYC verification.\"\"\"\n    user_id: UUID\n    status: str\n    verification_level: Optional[str] = None\n    verified_at: Optional[datetime] = None\n\n\nclass RiskAssessmentRequest(BaseModel):\n    \"\"\"Request schema for risk assessment.\"\"\"\n    transaction_id: UUID\n    user_id: UUID\n    amount: Decimal\n\n\nclass RiskAssessmentResponse(BaseModel):\n    \"\"\"Response schema for risk assessment.\"\"\"\n    transaction_id: UUID\n    risk_score: float\n    risk_level: str\n    assessed_at: datetime\n\n\nclass HealthResponse(BaseModel):\n    \"\"\"Response schema for health check.\"\"\"\n    status: str\n    version: str\n    timestamp: datetime\n\n\nclass ErrorResponse(BaseModel):\n    \"\"\"Response schema for errors.\"\"\"\n    error: str\n    detail: Optional[str] = None\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n\n\n# Escrow Schemas\n\nclass EscrowInitiationRequest(BaseModel):\n    \"\"\"Request schema for initiating an escrow transaction.\"\"\"\n    initiator_id: UUID\n    counterparty_id: UUID\n    amount: Decimal = Field(gt=0)\n    currency: str = Field(default=\"USD\", min_length=3, max_length=3)\n    lock_duration_seconds: int = Field(gt=0, description=\"Duration in seconds for the time lock\")\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n    @validator(\"counterparty_id\")\n    def counterparty_must_differ_from_initiator(cls, v, values):\n        if \"initiator_id\" in values and v == values[\"initiator_id\"]:\n            raise ValueError(\"Counterparty must be different from initiator\")\n        return v\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"initiator_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"counterparty_id\": \"123e4567-e89b-12d3-a456-426614174001\",\n                \"amount\": \"1000.00\",\n                \"currency\": \"USD\",\n                \"lock_duration_seconds\": 86400,\n                \"metadata\": {\"description\": \"Escrow for property sale\"}\n            }\n        }\n\n\nclass EscrowSignatureRequest(BaseModel):\n    \"\"\"Request schema for submitting a release signature.\"\"\"\n    signer_id: UUID\n    signature: str = Field(min_length=1, description=\"Cryptographic signature for release authorization\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"signer_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"signature\": \"0x1234567890abcdef...\"\n            }\n        }\n\n\nclass EscrowResponse(BaseModel):\n    \"\"\"Response schema for escrow transaction.\"\"\"\n    id: UUID\n    initiator_id: UUID\n    counterparty_id: UUID\n    amount: Decimal\n    currency: str\n    status: str\n    lock_until_timestamp: datetime\n    signatures_collected: int\n    signatures_required: int = 2\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"id\": \"123e4567-e89b-12d3-a456-426614174002\",\n                \"initiator_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"counterparty_id\": \"123e4567-e89b-12d3-a456-426614174001\",\n                \"amount\": \"1000.00\",\n                \"currency\": \"USD\",\n                \"status\": \"FUNDED\",\n                \"lock_until_timestamp\": \"2024-01-15T12:00:00Z\",\n                \"signatures_collected\": 1,\n                \"signatures_required\": 2,\n                \"created_at\": \"2024-01-14T12:00:00Z\",\n                \"updated_at\": \"2024-01-14T12:05:00Z\"\n            }\n        }\n\n\nclass EscrowFundRequest(BaseModel):\n    \"\"\"Request schema for funding an escrow (placeholder for future payment integration).\"\"\"\n    funding_source: Optional[str] = Field(default=\"WALLET\", description=\"Source of funds\")\n    reference: Optional[str] = Field(default=None, description=\"External payment reference\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"funding_source\": \"WALLET\",\n                \"reference\": \"PAY-123456\"\n            }\n        }\n\n\nclass EscrowListResponse(BaseModel):\n    \"\"\"Response schema for listing escrow transactions.\"\"\"\n    escrows: List[EscrowResponse]\n    total: int\n    page: int = 1\n    page_size: int = 10\n",
          "tradeutility_nexus/trade_nexus/api/endpoints.py": "\"\"\"API endpoints for TradeUtility Nexus.\"\"\"\nimport logging\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nfrom typing import Optional\nfrom uuid import UUID, uuid4\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\n\nfrom trade_nexus.api.schemas import (\n    ErrorResponse,\n    EscrowFundRequest,\n    EscrowInitiationRequest,\n    EscrowResponse,\n    EscrowSignatureRequest,\n    HealthResponse,\n    KYCVerificationRequest,\n    KYCVerificationResponse,\n    PaymentRequest,\n    PaymentResponse,\n    RiskAssessmentRequest,\n    RiskAssessmentResponse,\n    TransactionRequest,\n    TransactionResponse,\n)\nfrom trade_nexus.core.bus import CommandBus, EventBus\nfrom trade_nexus.core.commands import (\n    AddReleaseSignature,\n    AssessRisk,\n    FundEscrow,\n    InitiateEscrow,\n    InitiateTransaction,\n    ProcessPayment,\n    VerifyKYC,\n)\nfrom trade_nexus.core.domain import EscrowStatus, EscrowTransaction, Transaction, TransactionStatus\nfrom trade_nexus.core.unit_of_work import UnitOfWork\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n# In-memory stores for demonstration\n_transactions: dict[UUID, Transaction] = {}\n_escrows: dict[UUID, EscrowTransaction] = {}\n\n# Global bus instances (would be injected via DI in production)\n_command_bus: Optional[CommandBus] = None\n_event_bus: Optional[EventBus] = None\n\n\ndef get_command_bus() -> CommandBus:\n    \"\"\"Get or create command bus.\"\"\"\n    global _command_bus\n    if _command_bus is None:\n        _command_bus = CommandBus()\n    return _command_bus\n\n\ndef get_event_bus() -> EventBus:\n    \"\"\"Get or create event bus.\"\"\"\n    global _event_bus\n    if _event_bus is None:\n        _event_bus = EventBus()\n    return _event_bus\n\n\ndef set_command_bus(bus: CommandBus) -> None:\n    \"\"\"Set the command bus (for testing/initialization).\"\"\"\n    global _command_bus\n    _command_bus = bus\n\n\ndef set_event_bus(bus: EventBus) -> None:\n    \"\"\"Set the event bus (for testing/initialization).\"\"\"\n    global _event_bus\n    _event_bus = bus\n\n\ndef get_escrow_store() -> dict[UUID, EscrowTransaction]:\n    \"\"\"Get the escrow store.\"\"\"\n    return _escrows\n\n\n@router.get(\"/health\", response_model=HealthResponse)\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return HealthResponse(\n        status=\"healthy\",\n        version=\"1.0.0\",\n        timestamp=datetime.utcnow()\n    )\n\n\n@router.post(\"/v1/transactions\", response_model=TransactionResponse, status_code=status.HTTP_201_CREATED)\nasync def create_transaction(\n    request: TransactionRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Create a new transaction.\"\"\"\n    try:\n        transaction_id = uuid4()\n        command = InitiateTransaction(\n            correlation_id=transaction_id,\n            sender_id=request.sender_id,\n            receiver_id=request.receiver_id,\n            amount=request.amount,\n            currency=request.currency,\n            metadata=request.metadata\n        )\n        \n        # Create transaction aggregate\n        transaction = Transaction(id=transaction_id)\n        transaction.initiate(\n            sender_id=request.sender_id,\n            receiver_id=request.receiver_id,\n            amount=request.amount,\n            currency=request.currency\n        )\n        \n        # Store transaction\n        _transactions[transaction_id] = transaction\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        return TransactionResponse(\n            id=transaction.id,\n            sender_id=transaction.sender_id,\n            receiver_id=transaction.receiver_id,\n            amount=transaction.amount,\n            currency=transaction.currency,\n            status=transaction.status.value,\n            created_at=transaction.created_at,\n            updated_at=transaction.updated_at\n        )\n    except Exception as e:\n        logger.error(f\"Error creating transaction: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.get(\"/v1/transactions/{transaction_id}\", response_model=TransactionResponse)\nasync def get_transaction(transaction_id: UUID):\n    \"\"\"Get transaction by ID.\"\"\"\n    transaction = _transactions.get(transaction_id)\n    if not transaction:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Transaction {transaction_id} not found\"\n        )\n    \n    return TransactionResponse(\n        id=transaction.id,\n        sender_id=transaction.sender_id,\n        receiver_id=transaction.receiver_id,\n        amount=transaction.amount,\n        currency=transaction.currency,\n        status=transaction.status.value,\n        created_at=transaction.created_at,\n        updated_at=transaction.updated_at\n    )\n\n\n@router.post(\"/v1/payments\", response_model=PaymentResponse)\nasync def process_payment(\n    request: PaymentRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Process a payment.\"\"\"\n    try:\n        transaction = _transactions.get(request.transaction_id)\n        if not transaction:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=f\"Transaction {request.transaction_id} not found\"\n            )\n        \n        command = ProcessPayment(\n            transaction_id=request.transaction_id,\n            amount=transaction.amount,\n            currency=transaction.currency,\n            payment_method=request.payment_method\n        )\n        \n        await command_bus.dispatch(command)\n        \n        return PaymentResponse(\n            transaction_id=request.transaction_id,\n            status=\"PROCESSED\",\n            payment_reference=f\"PAY-{uuid4().hex[:8].upper()}\",\n            processed_at=datetime.utcnow()\n        )\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Error processing payment: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/kyc/verify\", response_model=KYCVerificationResponse)\nasync def verify_kyc(\n    request: KYCVerificationRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Verify KYC for a user.\"\"\"\n    try:\n        command = VerifyKYC(\n            user_id=request.user_id,\n            document_type=request.document_type,\n            document_id=request.document_id\n        )\n        \n        await command_bus.dispatch(command)\n        \n        return KYCVerificationResponse(\n            user_id=request.user_id,\n            status=\"VERIFIED\",\n            verification_level=\"BASIC\",\n            verified_at=datetime.utcnow()\n        )\n    except Exception as e:\n        logger.error(f\"Error verifying KYC: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/risk/assess\", response_model=RiskAssessmentResponse)\nasync def assess_risk(\n    request: RiskAssessmentRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Assess risk for a transaction.\"\"\"\n    try:\n        command = AssessRisk(\n            transaction_id=request.transaction_id,\n            user_id=request.user_id,\n            amount=request.amount\n        )\n        \n        await command_bus.dispatch(command)\n        \n        # Simple risk calculation for demo\n        risk_score = min(float(request.amount) / 10000, 1.0)\n        risk_level = \"LOW\" if risk_score < 0.3 else \"MEDIUM\" if risk_score < 0.7 else \"HIGH\"\n        \n        return RiskAssessmentResponse(\n            transaction_id=request.transaction_id,\n            risk_score=risk_score,\n            risk_level=risk_level,\n            assessed_at=datetime.utcnow()\n        )\n    except Exception as e:\n        logger.error(f\"Error assessing risk: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n# Escrow Endpoints\n\n@router.post(\"/v1/escrow/initiate\", response_model=EscrowResponse, status_code=status.HTTP_201_CREATED)\nasync def initiate_escrow(\n    request: EscrowInitiationRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Initiate a new escrow transaction.\"\"\"\n    try:\n        escrow_id = uuid4()\n        lock_until = datetime.utcnow() + timedelta(seconds=request.lock_duration_seconds)\n        \n        command = InitiateEscrow(\n            escrow_id=escrow_id,\n            initiator_id=request.initiator_id,\n            counterparty_id=request.counterparty_id,\n            amount=request.amount,\n            currency=request.currency,\n            lock_until_timestamp=lock_until,\n            metadata=request.metadata\n        )\n        \n        # Create escrow aggregate\n        escrow = EscrowTransaction(id=escrow_id)\n        escrow.initiate(\n            initiator_id=request.initiator_id,\n            counterparty_id=request.counterparty_id,\n            amount=request.amount,\n            currency=request.currency,\n            lock_until_timestamp=lock_until,\n            metadata=request.metadata\n        )\n        \n        # Store escrow\n        _escrows[escrow_id] = escrow\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        logger.info(f\"Escrow {escrow_id} initiated successfully\")\n        \n        return EscrowResponse(\n            id=escrow.id,\n            initiator_id=escrow.initiator_id,\n            counterparty_id=escrow.counterparty_id,\n            amount=escrow.amount,\n            currency=escrow.currency,\n            status=escrow.status.value,\n            lock_until_timestamp=escrow.lock_until_timestamp,\n            signatures_collected=len(escrow.release_signatures),\n            signatures_required=2,\n            created_at=escrow.created_at,\n            updated_at=escrow.updated_at\n        )\n    except ValueError as e:\n        logger.warning(f\"Validation error initiating escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Error initiating escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/escrow/{escrow_id}/fund\", response_model=EscrowResponse)\nasync def fund_escrow(\n    escrow_id: UUID,\n    request: EscrowFundRequest = None,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Fund an escrow transaction.\"\"\"\n    try:\n        escrow = _escrows.get(escrow_id)\n        if not escrow:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=f\"Escrow {escrow_id} not found\"\n            )\n        \n        if escrow.status != EscrowStatus.PENDING:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=f\"Escrow cannot be funded in status {escrow.status.value}\"\n            )\n        \n        command = FundEscrow(escrow_id=escrow_id)\n        \n        # Fund the escrow\n        escrow.fund()\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        logger.info(f\"Escrow {escrow_id} funded successfully\")\n        \n        return EscrowResponse(\n            id=escrow.id,\n            initiator_id=escrow.initiator_id,\n            counterparty_id=escrow.counterparty_id,\n            amount=escrow.amount,\n            currency=escrow.currency,\n            status=escrow.status.value,\n            lock_until_timestamp=escrow.lock_until_timestamp,\n            signatures_collected=len(escrow.release_signatures),\n            signatures_required=2,\n            created_at=escrow.created_at,\n            updated_at=escrow.updated_at\n        )\n    except HTTPException:\n        raise\n    except ValueError as e:\n        logger.warning(f\"Validation error funding escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Error funding escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/escrow/{escrow_id}/sign_release\", response_model=EscrowResponse)\nasync def sign_escrow_release(\n    escrow_id: UUID,\n    request: EscrowSignatureRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Add a release signature to an escrow transaction.\"\"\"\n    try:\n        escrow = _escrows.get(escrow_id)\n        if not escrow:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=f\"Escrow {escrow_id} not found\"\n            )\n        \n        if escrow.status not in (EscrowStatus.FUNDED, EscrowStatus.AWAITING_RELEASE):\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=f\"Cannot sign escrow in status {escrow.status.value}\"\n            )\n        \n        if request.signer_id not in (escrow.initiator_id, escrow.counterparty_id):\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Signer must be initiator or counterparty\"\n            )\n        \n        command = AddReleaseSignature(\n            escrow_id=escrow_id,\n            signer_id=request.signer_id,\n            signature=request.signature\n        )\n        \n        # Add signature\n        escrow.add_release_signature(request.signer_id, request.signature)\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        logger.info(f\"Signature added to escrow {escrow_id} by {request.signer_id}\")\n        \n        return EscrowResponse(\n            id=escrow.id,\n            initiator_id=escrow.initiator_id,\n            counterparty_id=escrow.counterparty_id,\n            amount=escrow.amount,\n            currency=escrow.currency,\n            status=escrow.status.value,\n            lock_until_timestamp=escrow.lock_until_timestamp,\n            signatures_collected=len(escrow.release_signatures),\n            signatures_required=2,\n            created_at=escrow.created_at,\n            updated_at=escrow.updated_at\n        )\n    except HTTPException:\n        raise\n    except ValueError as e:\n        logger.warning(f\"Validation error signing escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Error signing escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.get(\"/v1/escrow/{escrow_id}\", response_model=EscrowResponse)\nasync def get_escrow(escrow_id: UUID):\n    \"\"\"Get escrow transaction by ID.\"\"\"\n    escrow = _escrows.get(escrow_id)\n    if not escrow:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Escrow {escrow_id} not found\"\n        )\n    \n    return EscrowResponse(\n        id=escrow.id,\n        initiator_id=escrow.initiator_id,\n        counterparty_id=escrow.counterparty_id,\n        amount=escrow.amount,\n        currency=escrow.currency,\n        status=escrow.status.value,\n        lock_until_timestamp=escrow.lock_until_timestamp,\n        signatures_collected=len(escrow.release_signatures),\n        signatures_required=2,\n        created_at=escrow.created_at,\n        updated_at=escrow.updated_at\n    )\n",
          "tradeutility_nexus/trade_nexus/services/transactions/handlers.py": "\"\"\"Transaction service command handlers.\"\"\"\nimport logging\nfrom datetime import datetime\nfrom typing import Callable, Dict, Type\nfrom uuid import UUID\n\nfrom trade_nexus.core.commands import (\n    AddReleaseSignature,\n    Command,\n    CompleteTransaction,\n    FailTransaction,\n    FundEscrow,\n    InitiateEscrow,\n    InitiateTransaction,\n    ProcessEscrowRelease,\n)\nfrom trade_nexus.core.domain import EscrowTransaction, Transaction\nfrom trade_nexus.core.events import (\n    EscrowFunded,\n    EscrowInitiated,\n    EscrowReleased,\n    Event,\n    ReleaseSignatureAdded,\n    TransactionCompleted,\n    TransactionFailed,\n    TransactionInitiated,\n)\nfrom trade_nexus.core.unit_of_work import UnitOfWork\n\nlogger = logging.getLogger(__name__)\n\n\nclass TransactionCommandHandler:\n    \"\"\"Handler for transaction-related commands.\"\"\"\n\n    def __init__(self, unit_of_work: UnitOfWork = None):\n        \"\"\"Initialize the handler.\"\"\"\n        self.unit_of_work = unit_of_work or UnitOfWork()\n        self._handlers: Dict[Type[Command], Callable] = {\n            InitiateTransaction: self._handle_initiate_transaction,\n            CompleteTransaction: self._handle_complete_transaction,\n            FailTransaction: self._handle_fail_transaction,\n            InitiateEscrow: self._handle_initiate_escrow,\n            FundEscrow: self._handle_fund_escrow,\n            AddReleaseSignature: self._handle_add_release_signature,\n            ProcessEscrowRelease: self._handle_process_escrow_release,\n        }\n\n    async def handle(self, command: Command) -> None:\n        \"\"\"Handle a command.\"\"\"\n        handler = self._handlers.get(type(command))\n        if handler:\n            await handler(command)\n        else:\n            logger.warning(f\"No handler found for command type: {type(command).__name__}\")\n\n    async def _handle_initiate_transaction(self, command: InitiateTransaction) -> None:\n        \"\"\"Handle InitiateTransaction command.\"\"\"\n        logger.info(f\"Handling InitiateTransaction command: {command.command_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Create new transaction aggregate\n            transaction = Transaction()\n            transaction.initiate(\n                sender_id=command.sender_id,\n                receiver_id=command.receiver_id,\n                amount=command.amount,\n                currency=command.currency\n            )\n            \n            # Save events through unit of work\n            for event in transaction.get_pending_events():\n                await uow.event_store.append(event)\n            \n            transaction.clear_pending_events()\n            \n            logger.info(f\"Transaction {transaction.id} initiated successfully\")\n\n    async def _handle_complete_transaction(self, command: CompleteTransaction) -> None:\n        \"\"\"Handle CompleteTransaction command.\"\"\"\n        logger.info(f\"Handling CompleteTransaction command for: {command.transaction_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load transaction from event store\n            events = await uow.event_store.get_events(command.transaction_id)\n            \n            if not events:\n                logger.error(f\"Transaction {command.transaction_id} not found\")\n                return\n            \n            # Rebuild transaction state\n            transaction = Transaction(id=command.transaction_id)\n            for event in events:\n                transaction.apply_event(event)\n            \n            # Complete the transaction\n            transaction.complete()\n            \n            # Save new events\n            for event in transaction.get_pending_events():\n                await uow.event_store.append(event)\n            \n            transaction.clear_pending_events()\n            \n            logger.info(f\"Transaction {command.transaction_id} completed successfully\")\n\n    async def _handle_fail_transaction(self, command: FailTransaction) -> None:\n        \"\"\"Handle FailTransaction command.\"\"\"\n        logger.info(f\"Handling FailTransaction command for: {command.transaction_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load transaction from event store\n            events = await uow.event_store.get_events(command.transaction_id)\n            \n            if not events:\n                logger.error(f\"Transaction {command.transaction_id} not found\")\n                return\n            \n            # Rebuild transaction state\n            transaction = Transaction(id=command.transaction_id)\n            for event in events:\n                transaction.apply_event(event)\n            \n            # Fail the transaction\n            transaction.fail(command.reason)\n            \n            # Save new events\n            for event in transaction.get_pending_events():\n                await uow.event_store.append(event)\n            \n            transaction.clear_pending_events()\n            \n            logger.info(f\"Transaction {command.transaction_id} marked as failed\")\n\n    async def _handle_initiate_escrow(self, command: InitiateEscrow) -> None:\n        \"\"\"Handle InitiateEscrow command.\"\"\"\n        logger.info(f\"Handling InitiateEscrow command: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Create new escrow aggregate\n            escrow = EscrowTransaction(id=command.escrow_id)\n            escrow.initiate(\n                initiator_id=command.initiator_id,\n                counterparty_id=command.counterparty_id,\n                amount=command.amount,\n                currency=command.currency,\n                lock_until_timestamp=command.lock_until_timestamp,\n                metadata=command.metadata\n            )\n            \n            # Save events through unit of work\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Escrow {escrow.id} initiated successfully\")\n\n    async def _handle_fund_escrow(self, command: FundEscrow) -> None:\n        \"\"\"Handle FundEscrow command.\"\"\"\n        logger.info(f\"Handling FundEscrow command for: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load escrow from event store\n            events = await uow.event_store.get_events(command.escrow_id)\n            \n            if not events:\n                logger.error(f\"Escrow {command.escrow_id} not found\")\n                return\n            \n            # Rebuild escrow state\n            escrow = EscrowTransaction(id=command.escrow_id)\n            for event in events:\n                escrow.apply_event(event)\n            \n            # Fund the escrow\n            escrow.fund()\n            \n            # Save new events\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Escrow {command.escrow_id} funded successfully\")\n\n    async def _handle_add_release_signature(self, command: AddReleaseSignature) -> None:\n        \"\"\"Handle AddReleaseSignature command.\"\"\"\n        logger.info(f\"Handling AddReleaseSignature command for escrow: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load escrow from event store\n            events = await uow.event_store.get_events(command.escrow_id)\n            \n            if not events:\n                logger.error(f\"Escrow {command.escrow_id} not found\")\n                return\n            \n            # Rebuild escrow state\n            escrow = EscrowTransaction(id=command.escrow_id)\n            for event in events:\n                escrow.apply_event(event)\n            \n            # Add the signature\n            escrow.add_release_signature(command.signer_id, command.signature)\n            \n            # Save new events\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Signature added to escrow {command.escrow_id} by {command.signer_id}\")\n\n    async def _handle_process_escrow_release(self, command: ProcessEscrowRelease) -> None:\n        \"\"\"Handle ProcessEscrowRelease command.\"\"\"\n        logger.info(f\"Handling ProcessEscrowRelease command for: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load escrow from event store\n            events = await uow.event_store.get_events(command.escrow_id)\n            \n            if not events:\n                logger.error(f\"Escrow {command.escrow_id} not found\")\n                return\n            \n            # Rebuild escrow state\n            escrow = EscrowTransaction(id=command.escrow_id)\n            for event in events:\n                escrow.apply_event(event)\n            \n            # Release the escrow\n            escrow.release()\n            \n            # Save new events\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling and other handlers\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Escrow {command.escrow_id} released successfully\")\n\n\n# Singleton instance for use with the command bus\n_handler_instance: TransactionCommandHandler = None\n\n\ndef get_transaction_handler() -> TransactionCommandHandler:\n    \"\"\"Get or create the transaction handler instance.\"\"\"\n    global _handler_instance\n    if _handler_instance is None:\n        _handler_instance = TransactionCommandHandler()\n    return _handler_instance\n\n\nasync def handle_transaction_command(command: Command) -> None:\n    \"\"\"Handle a transaction command using the singleton handler.\"\"\"\n    handler = get_transaction_handler()\n    await handler.handle(command)\n",
          "tradeutility_nexus/trade_nexus/services/transactions/sagas.py": "\"\"\"Saga implementations for transaction orchestration.\"\"\"\nimport logging\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Set\nfrom uuid import UUID, uuid4\n\nfrom trade_nexus.core.commands import (\n    CompleteTransaction,\n    FailTransaction,\n    ProcessEscrowRelease,\n    ProcessPayment,\n    SettleTransaction,\n)\nfrom trade_nexus.core.events import (\n    EscrowFunded,\n    EscrowReleased,\n    Event,\n    FraudDetected,\n    PaymentFailed,\n    PaymentProcessed,\n    ReleaseSignatureAdded,\n    RiskAssessed,\n    TransactionInitiated,\n    TransactionSettled,\n)\nfrom trade_nexus.core.saga import Saga, SagaState\n\nlogger = logging.getLogger(__name__)\n\n\nclass TransactionSagaState(Enum):\n    \"\"\"States for the transaction saga.\"\"\"\n    STARTED = \"STARTED\"\n    PAYMENT_PENDING = \"PAYMENT_PENDING\"\n    PAYMENT_COMPLETED = \"PAYMENT_COMPLETED\"\n    RISK_ASSESSED = \"RISK_ASSESSED\"\n    SETTLEMENT_PENDING = \"SETTLEMENT_PENDING\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    COMPENSATING = \"COMPENSATING\"\n\n\nclass EscrowSagaState(Enum):\n    \"\"\"States for the escrow lifecycle saga.\"\"\"\n    STARTED = \"STARTED\"\n    FUNDED = \"FUNDED\"\n    AWAITING_SIGNATURES = \"AWAITING_SIGNATURES\"\n    SIGNATURES_COMPLETE = \"SIGNATURES_COMPLETE\"\n    AWAITING_TIME_LOCK = \"AWAITING_TIME_LOCK\"\n    RELEASING = \"RELEASING\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n\n\n@dataclass\nclass TransactionSaga(Saga):\n    \"\"\"Saga for orchestrating the transaction lifecycle.\"\"\"\n    transaction_id: Optional[UUID] = None\n    state: TransactionSagaState = TransactionSagaState.STARTED\n    risk_score: float = 0.0\n    payment_reference: Optional[str] = None\n    error_message: Optional[str] = None\n\n    async def handle_event(self, event: Event) -> List[Any]:\n        \"\"\"Handle an event and return commands to dispatch.\"\"\"\n        commands = []\n\n        if isinstance(event, TransactionInitiated):\n            commands = await self._on_transaction_initiated(event)\n        elif isinstance(event, PaymentProcessed):\n            commands = await self._on_payment_processed(event)\n        elif isinstance(event, PaymentFailed):\n            commands = await self._on_payment_failed(event)\n        elif isinstance(event, RiskAssessed):\n            commands = await self._on_risk_assessed(event)\n        elif isinstance(event, FraudDetected):\n            commands = await self._on_fraud_detected(event)\n        elif isinstance(event, TransactionSettled):\n            commands = await self._on_transaction_settled(event)\n\n        return commands\n\n    async def _on_transaction_initiated(self, event: TransactionInitiated) -> List[Any]:\n        \"\"\"Handle TransactionInitiated event.\"\"\"\n        self.transaction_id = event.transaction_id\n        self.state = TransactionSagaState.PAYMENT_PENDING\n        logger.info(f\"Saga started for transaction {self.transaction_id}\")\n        \n        return [ProcessPayment(\n            transaction_id=event.transaction_id,\n            amount=event.amount,\n            currency=event.currency\n        )]\n\n    async def _on_payment_processed(self, event: PaymentProcessed) -> List[Any]:\n        \"\"\"Handle PaymentProcessed event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.PAYMENT_COMPLETED\n        self.payment_reference = event.payment_reference\n        logger.info(f\"Payment processed for transaction {self.transaction_id}\")\n        \n        return [SettleTransaction(transaction_id=self.transaction_id)]\n\n    async def _on_payment_failed(self, event: PaymentFailed) -> List[Any]:\n        \"\"\"Handle PaymentFailed event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.FAILED\n        self.error_message = event.reason\n        logger.warning(f\"Payment failed for transaction {self.transaction_id}: {event.reason}\")\n        \n        return [FailTransaction(\n            transaction_id=self.transaction_id,\n            reason=event.reason\n        )]\n\n    async def _on_risk_assessed(self, event: RiskAssessed) -> List[Any]:\n        \"\"\"Handle RiskAssessed event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.risk_score = event.risk_score\n        self.state = TransactionSagaState.RISK_ASSESSED\n        logger.info(f\"Risk assessed for transaction {self.transaction_id}: {event.risk_level}\")\n        \n        return []\n\n    async def _on_fraud_detected(self, event: FraudDetected) -> List[Any]:\n        \"\"\"Handle FraudDetected event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.COMPENSATING\n        logger.warning(f\"Fraud detected for transaction {self.transaction_id}\")\n        \n        return [FailTransaction(\n            transaction_id=self.transaction_id,\n            reason=f\"Fraud detected: {event.fraud_type}\"\n        )]\n\n    async def _on_transaction_settled(self, event: TransactionSettled) -> List[Any]:\n        \"\"\"Handle TransactionSettled event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.COMPLETED\n        logger.info(f\"Transaction {self.transaction_id} completed successfully\")\n        \n        return [CompleteTransaction(transaction_id=self.transaction_id)]\n\n    def is_complete(self) -> bool:\n        \"\"\"Check if the saga is complete.\"\"\"\n        return self.state in (TransactionSagaState.COMPLETED, TransactionSagaState.FAILED)\n\n\n@dataclass\nclass EscrowLifecycleSaga(Saga):\n    \"\"\"Saga for orchestrating the escrow transaction lifecycle.\n    \n    This saga manages the complete lifecycle of an escrow transaction:\n    1. Starts when escrow is funded\n    2. Tracks signature collection from both parties\n    3. Monitors time-lock expiration\n    4. Triggers release when all conditions are met\n    \"\"\"\n    escrow_id: Optional[UUID] = None\n    state: EscrowSagaState = EscrowSagaState.STARTED\n    initiator_id: Optional[UUID] = None\n    counterparty_id: Optional[UUID] = None\n    lock_until_timestamp: Optional[datetime] = None\n    collected_signatures: Set[UUID] = field(default_factory=set)\n    required_signatures: int = 2\n    error_message: Optional[str] = None\n\n    async def handle_event(self, event: Event) -> List[Any]:\n        \"\"\"Handle an event and return commands to dispatch.\"\"\"\n        commands = []\n\n        if isinstance(event, EscrowFunded):\n            commands = await self._on_escrow_funded(event)\n        elif isinstance(event, ReleaseSignatureAdded):\n            commands = await self._on_release_signature_added(event)\n        elif isinstance(event, EscrowReleased):\n            commands = await self._on_escrow_released(event)\n\n        return commands\n\n    async def _on_escrow_funded(self, event: EscrowFunded) -> List[Any]:\n        \"\"\"Handle EscrowFunded event - starts the saga.\"\"\"\n        self.escrow_id = event.escrow_id\n        self.state = EscrowSagaState.FUNDED\n        \n        logger.info(f\"Escrow lifecycle saga started for escrow {self.escrow_id}\")\n        logger.info(f\"Escrow funded with {event.amount} {event.currency}\")\n        \n        # Transition to awaiting signatures\n        self.state = EscrowSagaState.AWAITING_SIGNATURES\n        \n        return []\n\n    async def _on_release_signature_added(self, event: ReleaseSignatureAdded) -> List[Any]:\n        \"\"\"Handle ReleaseSignatureAdded event.\"\"\"\n        if event.escrow_id != self.escrow_id:\n            return []\n        \n        # Track the signature\n        self.collected_signatures.add(event.signer_id)\n        \n        logger.info(\n            f\"Signature added to escrow {self.escrow_id} by {event.signer_id}. \"\n            f\"Signatures collected: {len(self.collected_signatures)}/{self.required_signatures}\"\n        )\n        \n        # Check if all signatures are collected\n        if self._has_all_signatures():\n            logger.info(f\"All required signatures collected for escrow {self.escrow_id}\")\n            self.state = EscrowSagaState.SIGNATURES_COMPLETE\n            \n            # Check if time lock has expired\n            return await self._check_release_conditions()\n        \n        return []\n\n    async def _check_release_conditions(self) -> List[Any]:\n        \"\"\"Check if all conditions for release are met.\"\"\"\n        if not self._has_all_signatures():\n            logger.debug(f\"Escrow {self.escrow_id}: Waiting for all signatures\")\n            return []\n        \n        if not self._is_lock_expired():\n            logger.info(\n                f\"Escrow {self.escrow_id}: All signatures collected but time lock not expired. \"\n                f\"Lock expires at: {self.lock_until_timestamp}\"\n            )\n            self.state = EscrowSagaState.AWAITING_TIME_LOCK\n            return []\n        \n        # All conditions met - trigger release\n        logger.info(\n            f\"Escrow {self.escrow_id}: All conditions met. \"\n            f\"Signatures: {len(self.collected_signatures)}/{self.required_signatures}, \"\n            f\"Time lock expired: True. Triggering release.\"\n        )\n        \n        self.state = EscrowSagaState.RELEASING\n        \n        return [ProcessEscrowRelease(escrow_id=self.escrow_id)]\n\n    async def _on_escrow_released(self, event: EscrowReleased) -> List[Any]:\n        \"\"\"Handle EscrowReleased event.\"\"\"\n        if event.escrow_id != self.escrow_id:\n            return []\n        \n        self.state = EscrowSagaState.COMPLETED\n        \n        logger.info(\n            f\"Escrow {self.escrow_id} released successfully. \"\n            f\"Amount: {event.amount} {event.currency}\"\n        )\n        \n        return []\n\n    def _has_all_signatures(self) -> bool:\n        \"\"\"Check if all required signatures have been collected.\"\"\"\n        return len(self.collected_signatures) >= self.required_signatures\n\n    def _is_lock_expired(self) -> bool:\n        \"\"\"Check if the time lock has expired.\"\"\"\n        if self.lock_until_timestamp is None:\n            return True\n        return datetime.utcnow() >= self.lock_until_timestamp\n\n    def set_escrow_details(\n        self,\n        initiator_id: UUID,\n        counterparty_id: UUID,\n        lock_until_timestamp: datetime\n    ) -> None:\n        \"\"\"Set escrow details for tracking.\"\"\"\n        self.initiator_id = initiator_id\n        self.counterparty_id = counterparty_id\n        self.lock_until_timestamp = lock_until_timestamp\n\n    def is_complete(self) -> bool:\n        \"\"\"Check if the saga is complete.\"\"\"\n        return self.state in (EscrowSagaState.COMPLETED, EscrowSagaState.FAILED)\n\n    async def try_release(self) -> List[Any]:\n        \"\"\"Attempt to release the escrow if conditions are met.\n        \n        This method can be called periodically to check if time-lock has expired.\n        \"\"\"\n        if self.state == EscrowSagaState.AWAITING_TIME_LOCK:\n            return await self._check_release_conditions()\n        return []\n\n\nclass SagaManager:\n    \"\"\"Manager for saga instances.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the saga manager.\"\"\"\n        self._transaction_sagas: Dict[UUID, TransactionSaga] = {}\n        self._escrow_sagas: Dict[UUID, EscrowLifecycleSaga] = {}\n        self._command_dispatcher: Optional[Callable] = None\n\n    def set_command_dispatcher(self, dispatcher: Callable) -> None:\n        \"\"\"Set the command dispatcher function.\"\"\"\n        self._command_dispatcher = dispatcher\n\n    async def handle_event(self, event: Event) -> None:\n        \"\"\"Route an event to the appropriate saga(s).\"\"\"\n        commands = []\n\n        # Handle transaction events\n        if isinstance(event, TransactionInitiated):\n            saga = TransactionSaga(id=uuid4())\n            self._transaction_sagas[event.transaction_id] = saga\n            commands = await saga.handle_event(event)\n        elif hasattr(event, 'transaction_id'):\n            saga = self._transaction_sagas.get(event.transaction_id)\n            if saga:\n                commands = await saga.handle_event(event)\n                if saga.is_complete():\n                    del self._transaction_sagas[event.transaction_id]\n\n        # Handle escrow events\n        if isinstance(event, EscrowFunded):\n            saga = EscrowLifecycleSaga(id=uuid4())\n            self._escrow_sagas[event.escrow_id] = saga\n            commands = await saga.handle_event(event)\n        elif hasattr(event, 'escrow_id'):\n            saga = self._escrow_sagas.get(event.escrow_id)\n            if saga:\n                commands = await saga.handle_event(event)\n                if saga.is_complete():\n                    del self._escrow_sagas[event.escrow_id]\n\n        # Dispatch any resulting commands\n        if self._command_dispatcher and commands:\n            for command in commands:\n                await self._command_dispatcher(command)\n\n    def get_escrow_saga(self, escrow_id: UUID) -> Optional[EscrowLifecycleSaga]:\n        \"\"\"Get an escrow saga by escrow ID.\"\"\"\n        return self._escrow_sagas.get(escrow_id)\n\n    def get_transaction_saga(self, transaction_id: UUID) -> Optional[TransactionSaga]:\n        \"\"\"Get a transaction saga by transaction ID.\"\"\"\n        return self._transaction_sagas.get(transaction_id)\n\n    async def check_pending_escrow_releases(self) -> None:\n        \"\"\"Check all pending escrow sagas for time-lock expiration.\n        \n        This should be called periodically (e.g., by a background task).\n        \"\"\"\n        for escrow_id, saga in list(self._escrow_sagas.items()):\n            if saga.state == EscrowSagaState.AWAITING_TIME_LOCK:\n                commands = await saga.try_release()\n                if self._command_dispatcher and commands:\n                    for command in commands:\n                        await self._command_dispatcher(command)\n\n\n# Global saga manager instance\n_saga_manager: Optional[SagaManager] = None\n\n\ndef get_saga_manager() -> SagaManager:\n    \"\"\"Get or create the saga manager instance.\"\"\"\n    global _saga_manager\n    if _saga_manager is None:\n        _saga_manager = SagaManager()\n    return _saga_manager\n",
          "tradeutility_nexus/trade_nexus/services/risk/handlers.py": "\"\"\"Risk service event handlers.\"\"\"\nimport logging\nfrom decimal import Decimal\nfrom typing import Callable, Dict, Type\nfrom uuid import UUID\n\nfrom trade_nexus.core.commands import AssessRisk, Command\nfrom trade_nexus.core.events import (\n    EscrowReleased,\n    Event,\n    RiskAssessed,\n    TransactionInitiated,\n)\nfrom trade_nexus.services.risk.assessment import RiskAssessmentService\n\nlogger = logging.getLogger(__name__)\n\n\nclass RiskCommandHandler:\n    \"\"\"Handler for risk-related commands.\"\"\"\n\n    def __init__(self, risk_service: RiskAssessmentService = None):\n        \"\"\"Initialize the handler.\"\"\"\n        self.risk_service = risk_service or RiskAssessmentService()\n        self._handlers: Dict[Type[Command], Callable] = {\n            AssessRisk: self._handle_assess_risk,\n        }\n\n    async def handle(self, command: Command) -> None:\n        \"\"\"Handle a command.\"\"\"\n        handler = self._handlers.get(type(command))\n        if handler:\n            await handler(command)\n        else:\n            logger.warning(f\"No handler found for command type: {type(command).__name__}\")\n\n    async def _handle_assess_risk(self, command: AssessRisk) -> None:\n        \"\"\"Handle AssessRisk command.\"\"\"\n        logger.info(f\"Assessing risk for transaction {command.transaction_id}\")\n        \n        result = await self.risk_service.assess(\n            transaction_id=command.transaction_id,\n            user_id=command.user_id,\n            amount=command.amount\n        )\n        \n        logger.info(\n            f\"Risk assessment complete for transaction {command.transaction_id}: \"\n            f\"score={result.get('risk_score', 0)}, level={result.get('risk_level', 'UNKNOWN')}\"\n        )\n\n\nclass RiskEventHandler:\n    \"\"\"Handler for risk-related events.\"\"\"\n\n    def __init__(self, risk_service: RiskAssessmentService = None):\n        \"\"\"Initialize the handler.\"\"\"\n        self.risk_service = risk_service or RiskAssessmentService()\n        self._handlers: Dict[Type[Event], Callable] = {\n            TransactionInitiated: self._on_transaction_initiated,\n            EscrowReleased: self._on_escrow_released,\n        }\n\n    async def handle(self, event: Event) -> None:\n        \"\"\"Handle an event.\"\"\"\n        handler = self._handlers.get(type(event))\n        if handler:\n            await handler(event)\n        else:\n            logger.debug(f\"No handler for event type: {type(event).__name__}\")\n\n    async def _on_transaction_initiated(self, event: TransactionInitiated) -> None:\n        \"\"\"Handle TransactionInitiated event for automatic risk assessment.\"\"\"\n        logger.info(f\"Auto-assessing risk for new transaction {event.transaction_id}\")\n        \n        result = await self.risk_service.assess(\n            transaction_id=event.transaction_id,\n            user_id=event.sender_id,\n            amount=event.amount\n        )\n        \n        logger.info(\n            f\"Auto risk assessment for transaction {event.transaction_id}: \"\n            f\"score={result.get('risk_score', 0)}, level={result.get('risk_level', 'UNKNOWN')}\"\n        )\n\n    async def _on_escrow_released(self, event: EscrowReleased) -> None:\n        \"\"\"Handle EscrowReleased event for risk tracking.\n        \n        This handler demonstrates integration with the risk service when\n        escrow transactions are successfully released. Successfully completed\n        escrow transactions are considered low-risk and can positively impact\n        participant risk profiles.\n        \"\"\"\n        logger.info(\n            f\"Processing EscrowReleased event for escrow {event.escrow_id}. \"\n            f\"Low-risk escrow transaction completed successfully.\"\n        )\n        \n        # Log details about the completed escrow\n        logger.info(\n            f\"Escrow release details - \"\n            f\"Escrow ID: {event.escrow_id}, \"\n            f\"Initiator: {event.initiator_id}, \"\n            f\"Counterparty: {event.counterparty_id}, \"\n            f\"Amount: {event.amount} {event.currency}\"\n        )\n        \n        # In a full implementation, this would:\n        # 1. Update risk profiles for both initiator and counterparty\n        # 2. Record successful escrow completion in risk metrics\n        # 3. Potentially adjust trust scores\n        \n        # For now, we log the successful completion for audit purposes\n        logger.info(\n            f\"Risk adjustment: Escrow {event.escrow_id} completed successfully. \"\n            f\"Both parties ({event.initiator_id}, {event.counterparty_id}) \"\n            f\"have demonstrated trustworthy behavior through multi-signature escrow completion.\"\n        )\n        \n        # Track successful escrow for risk metrics\n        await self._record_successful_escrow(\n            escrow_id=event.escrow_id,\n            initiator_id=event.initiator_id,\n            counterparty_id=event.counterparty_id,\n            amount=event.amount,\n            currency=event.currency\n        )\n\n    async def _record_successful_escrow(\n        self,\n        escrow_id: UUID,\n        initiator_id: UUID,\n        counterparty_id: UUID,\n        amount: Decimal,\n        currency: str\n    ) -> None:\n        \"\"\"Record a successful escrow completion for risk metrics.\"\"\"\n        # This would integrate with a metrics/analytics service in production\n        logger.info(\n            f\"Recording successful escrow completion for risk metrics: \"\n            f\"escrow_id={escrow_id}, amount={amount} {currency}\"\n        )\n        \n        # Update risk profiles (placeholder for actual implementation)\n        if self.risk_service:\n            # Decrease risk scores for successful participants\n            logger.debug(\n                f\"Updating risk profiles for participants: \"\n                f\"{initiator_id}, {counterparty_id}\"\n            )\n\n\n# Singleton instances\n_command_handler: RiskCommandHandler = None\n_event_handler: RiskEventHandler = None\n\n\ndef get_risk_command_handler() -> RiskCommandHandler:\n    \"\"\"Get or create the risk command handler instance.\"\"\"\n    global _command_handler\n    if _command_handler is None:\n        _command_handler = RiskCommandHandler()\n    return _command_handler\n\n\ndef get_risk_event_handler() -> RiskEventHandler:\n    \"\"\"Get or create the risk event handler instance.\"\"\"\n    global _event_handler\n    if _event_handler is None:\n        _event_handler = RiskEventHandler()\n    return _event_handler\n\n\nasync def handle_risk_command(command: Command) -> None:\n    \"\"\"Handle a risk command using the singleton handler.\"\"\"\n    handler = get_risk_command_handler()\n    await handler.handle(command)\n\n\nasync def handle_risk_event(event: Event) -> None:\n    \"\"\"Handle a risk event using the singleton handler.\"\"\"\n    handler = get_risk_event_handler()\n    await handler.handle(event)\n",
          "tradeutility_nexus/trade_nexus/core/unit_of_work.py": "\"\"\"Unit of Work pattern implementation.\"\"\"\nimport logging\nfrom typing import Any, Callable, List, Optional\n\nfrom trade_nexus.core.event_store import EventStore, InMemoryEventStore\nfrom trade_nexus.core.events import Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass UnitOfWork:\n    \"\"\"Unit of Work for managing transactions and event persistence.\"\"\"\n\n    def __init__(\n        self,\n        event_store: EventStore = None,\n        event_publisher: Callable[[Event], Any] = None\n    ):\n        \"\"\"Initialize the Unit of Work.\"\"\"\n        self.event_store = event_store or InMemoryEventStore()\n        self._event_publisher = event_publisher\n        self._pending_events: List[Event] = []\n        self._committed = False\n\n    async def __aenter__(self) -> \"UnitOfWork\":\n        \"\"\"Enter the context manager.\"\"\"\n        self._pending_events = []\n        self._committed = False\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:\n        \"\"\"Exit the context manager.\"\"\"\n        if exc_type is None and not self._committed:\n            await self.commit()\n        elif exc_type is not None:\n            await self.rollback()\n\n    async def commit(self) -> None:\n        \"\"\"Commit the unit of work.\"\"\"\n        try:\n            # Publish all pending events\n            for event in self._pending_events:\n                if self._event_publisher:\n                    await self._event_publisher(event)\n            \n            self._pending_events.clear()\n            self._committed = True\n            logger.debug(\"Unit of work committed successfully\")\n        except Exception as e:\n            logger.error(f\"Error committing unit of work: {e}\")\n            await self.rollback()\n            raise\n\n    async def rollback(self) -> None:\n        \"\"\"Rollback the unit of work.\"\"\"\n        self._pending_events.clear()\n        self._committed = False\n        logger.debug(\"Unit of work rolled back\")\n\n    async def publish_event(self, event: Event) -> None:\n        \"\"\"Queue an event for publishing on commit.\"\"\"\n        self._pending_events.append(event)\n        logger.debug(f\"Event queued for publishing: {type(event).__name__}\")\n\n    def set_event_publisher(self, publisher: Callable[[Event], Any]) -> None:\n        \"\"\"Set the event publisher.\"\"\"\n        self._event_publisher = publisher\n\n\nclass UnitOfWorkManager:\n    \"\"\"Manager for creating Unit of Work instances.\"\"\"\n\n    def __init__(\n        self,\n        event_store: EventStore = None,\n        event_publisher: Callable[[Event], Any] = None\n    ):\n        \"\"\"Initialize the manager.\"\"\"\n        self._event_store = event_store or InMemoryEventStore()\n        self._event_publisher = event_publisher\n\n    def create(self) -> UnitOfWork:\n        \"\"\"Create a new Unit of Work.\"\"\"\n        return UnitOfWork(\n            event_store=self._event_store,\n            event_publisher=self._event_publisher\n        )\n\n    def set_event_publisher(self, publisher: Callable[[Event], Any]) -> None:\n        \"\"\"Set the event publisher for new units of work.\"\"\"\n        self._event_publisher = publisher\n",
          "tradeutility_nexus/trade_nexus/core/event_store.py": "\"\"\"Event store implementation for Event Sourcing.\"\"\"\nimport logging\nfrom abc import ABC, abstractmethod\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom typing import Dict, List, Optional\nfrom uuid import UUID\n\nfrom trade_nexus.core.events import Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass EventStore(ABC):\n    \"\"\"Abstract base class for event stores.\"\"\"\n\n    @abstractmethod\n    async def append(self, event: Event) -> None:\n        \"\"\"Append an event to the store.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_events(self, aggregate_id: UUID) -> List[Event]:\n        \"\"\"Get all events for an aggregate.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_events_since(self, timestamp: datetime) -> List[Event]:\n        \"\"\"Get all events since a timestamp.\"\"\"\n        pass\n\n\nclass InMemoryEventStore(EventStore):\n    \"\"\"In-memory implementation of the event store.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the in-memory event store.\"\"\"\n        self._events: Dict[UUID, List[Event]] = defaultdict(list)\n        self._all_events: List[Event] = []\n\n    async def append(self, event: Event) -> None:\n        \"\"\"Append an event to the store.\"\"\"\n        if event.aggregate_id:\n            self._events[event.aggregate_id].append(event)\n        self._all_events.append(event)\n        logger.debug(f\"Event appended: {type(event).__name__} for aggregate {event.aggregate_id}\")\n\n    async def get_events(self, aggregate_id: UUID) -> List[Event]:\n        \"\"\"Get all events for an aggregate.\"\"\"\n        events = self._events.get(aggregate_id, [])\n        logger.debug(f\"Retrieved {len(events)} events for aggregate {aggregate_id}\")\n        return events\n\n    async def get_events_since(self, timestamp: datetime) -> List[Event]:\n        \"\"\"Get all events since a timestamp.\"\"\"\n        events = [e for e in self._all_events if e.timestamp >= timestamp]\n        logger.debug(f\"Retrieved {len(events)} events since {timestamp}\")\n        return events\n\n    async def get_all_events(self) -> List[Event]:\n        \"\"\"Get all events in the store.\"\"\"\n        return self._all_events.copy()\n\n    def clear(self) -> None:\n        \"\"\"Clear all events from the store.\"\"\"\n        self._events.clear()\n        self._all_events.clear()\n        logger.debug(\"Event store cleared\")\n",
          "tradeutility_nexus/trade_nexus/core/saga.py": "\"\"\"Saga pattern implementation for process orchestration.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, List, Optional\nfrom uuid import UUID, uuid4\n\nfrom trade_nexus.core.events import Event\n\n\nclass SagaState(Enum):\n    \"\"\"Base states for sagas.\"\"\"\n    STARTED = \"STARTED\"\n    IN_PROGRESS = \"IN_PROGRESS\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    COMPENSATING = \"COMPENSATING\"\n\n\n@dataclass\nclass Saga(ABC):\n    \"\"\"Abstract base class for sagas.\"\"\"\n    id: UUID = field(default_factory=uuid4)\n    correlation_id: Optional[UUID] = None\n\n    @abstractmethod\n    async def handle_event(self, event: Event) -> List[Any]:\n        \"\"\"Handle an event and return commands to dispatch.\"\"\"\n        pass\n\n    @abstractmethod\n    def is_complete(self) -> bool:\n        \"\"\"Check if the saga is complete.\"\"\"\n        pass\n",
          "tradeutility_nexus/trade_nexus/core/bus.py": "\"\"\"Command and Event bus implementations.\"\"\"\nimport logging\nfrom typing import Any, Callable, Dict, List, Type\n\nfrom trade_nexus.core.commands import Command\nfrom trade_nexus.core.events import Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass CommandBus:\n    \"\"\"Bus for dispatching commands to handlers.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the command bus.\"\"\"\n        self._handlers: Dict[Type[Command], Callable] = {}\n\n    def register(self, command_type: Type[Command], handler: Callable) -> None:\n        \"\"\"Register a handler for a command type.\"\"\"\n        self._handlers[command_type] = handler\n        logger.debug(f\"Registered handler for {command_type.__name__}\")\n\n    async def dispatch(self, command: Command) -> Any:\n        \"\"\"Dispatch a command to its handler.\"\"\"\n        handler = self._handlers.get(type(command))\n        if handler:\n            logger.debug(f\"Dispatching command: {type(command).__name__}\")\n            return await handler(command)\n        else:\n            logger.warning(f\"No handler registered for command: {type(command).__name__}\")\n            return None\n\n\nclass EventBus:\n    \"\"\"Bus for publishing events to subscribers.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the event bus.\"\"\"\n        self._handlers: Dict[Type[Event], List[Callable]] = {}\n        self._global_handlers: List[Callable] = []\n\n    def subscribe(self, event_type: Type[Event], handler: Callable) -> None:\n        \"\"\"Subscribe a handler to an event type.\"\"\"\n        if event_type not in self._handlers:\n            self._handlers[event_type] = []\n        self._handlers[event_type].append(handler)\n        logger.debug(f\"Subscribed handler to {event_type.__name__}\")\n\n    def subscribe_all(self, handler: Callable) -> None:\n        \"\"\"Subscribe a handler to all events.\"\"\"\n        self._global_handlers.append(handler)\n        logger.debug(\"Subscribed global event handler\")\n\n    async def publish(self, event: Event) -> None:\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        logger.debug(f\"Publishing event: {type(event).__name__}\")\n        \n        # Call specific handlers\n        handlers = self._handlers.get(type(event), [])\n        for handler in handlers:\n            try:\n                await handler(event)\n            except Exception as e:\n                logger.error(f\"Error in event handler: {e}\")\n\n        # Call global handlers\n        for handler in self._global_handlers:\n            try:\n                await handler(event)\n            except Exception as e:\n                logger.error(f\"Error in global event handler: {e}\")\n",
          "tradeutility_nexus/trade_nexus/services/risk/assessment.py": "\"\"\"Risk assessment service.\"\"\"\nimport logging\nfrom decimal import Decimal\nfrom typing import Any, Dict\nfrom uuid import UUID\n\nlogger = logging.getLogger(__name__)\n\n\nclass RiskAssessmentService:\n    \"\"\"Service for assessing transaction risk.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the risk assessment service.\"\"\"\n        self._risk_thresholds = {\n            \"low\": Decimal(\"1000\"),\n            \"medium\": Decimal(\"10000\"),\n            \"high\": Decimal(\"100000\")\n        }\n\n    async def assess(\n        self,\n        transaction_id: UUID,\n        user_id: UUID,\n        amount: Decimal\n    ) -> Dict[str, Any]:\n        \"\"\"Assess risk for a transaction.\"\"\"\n        # Simple risk calculation based on amount\n        risk_score = self._calculate_risk_score(amount)\n        risk_level = self._determine_risk_level(risk_score)\n\n        logger.info(\n            f\"Risk assessment for transaction {transaction_id}: \"\n            f\"score={risk_score:.2f}, level={risk_level}\"\n        )\n\n        return {\n            \"transaction_id\": transaction_id,\n            \"user_id\": user_id,\n            \"risk_score\": risk_score,\n            \"risk_level\": risk_level,\n            \"amount\": amount\n        }\n\n    def _calculate_risk_score(self, amount: Decimal) -> float:\n        \"\"\"Calculate risk score based on amount.\"\"\"\n        # Simple linear scaling for demo\n        max_amount = self._risk_thresholds[\"high\"]\n        score = min(float(amount / max_amount), 1.0)\n        return score\n\n    def _determine_risk_level(self, score: float) -> str:\n        \"\"\"Determine risk level from score.\"\"\"\n        if score < 0.3:\n            return \"LOW\"\n        elif score < 0.7:\n            return \"MEDIUM\"\n        else:\n            return \"HIGH\"\n",
          "tradeutility_nexus/main.py": "\"\"\"Main entry point for TradeUtility Nexus.\"\"\"\nimport asyncio\nimport logging\nimport sys\n\nimport uvicorn\n\nfrom trade_nexus.api.server import create_app\nfrom trade_nexus.api.endpoints import set_command_bus, set_event_bus\nfrom trade_nexus.core.bus import CommandBus, EventBus\nfrom trade_nexus.core.commands import (\n    AddReleaseSignature,\n    AssessRisk,\n    FundEscrow,\n    InitiateEscrow,\n    InitiateTransaction,\n    ProcessEscrowRelease,\n    ProcessPayment,\n)\nfrom trade_nexus.core.events import (\n    EscrowFunded,\n    EscrowReleased,\n    ReleaseSignatureAdded,\n    TransactionInitiated,\n)\nfrom trade_nexus.services.risk.handlers import handle_risk_command, handle_risk_event\nfrom trade_nexus.services.transactions.handlers import handle_transaction_command\nfrom trade_nexus.services.transactions.sagas import get_saga_manager\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stdout)]\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef setup_buses() -> tuple[CommandBus, EventBus]:\n    \"\"\"Set up command and event buses with handlers.\"\"\"\n    command_bus = CommandBus()\n    event_bus = EventBus()\n\n    # Register transaction command handlers\n    command_bus.register(InitiateTransaction, handle_transaction_command)\n    command_bus.register(InitiateEscrow, handle_transaction_command)\n    command_bus.register(FundEscrow, handle_transaction_command)\n    command_bus.register(AddReleaseSignature, handle_transaction_command)\n    command_bus.register(ProcessEscrowRelease, handle_transaction_command)\n\n    # Register risk command handlers\n    command_bus.register(AssessRisk, handle_risk_command)\n\n    # Register event handlers\n    event_bus.subscribe(TransactionInitiated, handle_risk_event)\n    event_bus.subscribe(EscrowReleased, handle_risk_event)\n\n    # Set up saga manager\n    saga_manager = get_saga_manager()\n    saga_manager.set_command_dispatcher(command_bus.dispatch)\n\n    # Subscribe saga manager to relevant events\n    event_bus.subscribe(EscrowFunded, saga_manager.handle_event)\n    event_bus.subscribe(ReleaseSignatureAdded, saga_manager.handle_event)\n    event_bus.subscribe(EscrowReleased, saga_manager.handle_event)\n\n    return command_bus, event_bus\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"Starting TradeUtility Nexus...\")\n\n    # Set up buses\n    command_bus, event_bus = setup_buses()\n\n    # Set buses in endpoints module\n    set_command_bus(command_bus)\n    set_event_bus(event_bus)\n\n    # Create FastAPI app\n    app = create_app()\n\n    # Run the server\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8000,\n        log_level=\"info\"\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
          "tradeutility_nexus/trade_nexus/api/server.py": "\"\"\"FastAPI server configuration.\"\"\"\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom trade_nexus.api.endpoints import router\n\n\ndef create_app() -> FastAPI:\n    \"\"\"Create and configure the FastAPI application.\"\"\"\n    app = FastAPI(\n        title=\"TradeUtility Nexus\",\n        description=\"Advanced trading platform with escrow support\",\n        version=\"1.0.0\",\n        docs_url=\"/docs\",\n        redoc_url=\"/redoc\"\n    )\n\n    # Add CORS middleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Include routers\n    app.include_router(router, tags=[\"api\"])\n\n    return app\n"
        },
        "generated_files": [
          "tradeutility_nexus/trade_nexus/core/domain.py",
          "tradeutility_nexus/trade_nexus/core/commands.py",
          "tradeutility_nexus/trade_nexus/core/events.py",
          "tradeutility_nexus/trade_nexus/api/schemas.py",
          "tradeutility_nexus/trade_nexus/api/endpoints.py",
          "tradeutility_nexus/trade_nexus/services/transactions/handlers.py",
          "tradeutility_nexus/trade_nexus/services/transactions/sagas.py",
          "tradeutility_nexus/trade_nexus/services/risk/handlers.py",
          "tradeutility_nexus/trade_nexus/core/unit_of_work.py",
          "tradeutility_nexus/trade_nexus/core/event_store.py",
          "tradeutility_nexus/trade_nexus/core/saga.py",
          "tradeutility_nexus/trade_nexus/core/bus.py",
          "tradeutility_nexus/trade_nexus/services/risk/assessment.py",
          "tradeutility_nexus/main.py",
          "tradeutility_nexus/trade_nexus/api/server.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7712384519350811,
              "dependency_traversal_accuracy": 0.79437393402309,
              "cross_file_reasoning_depth": 0.3932777777777778,
              "system_thinking_score": 0.5539908523526323,
              "robustness_score": 0.4165160976041805,
              "comprehensiveness_score": 0.5056800597215105,
              "innovation_score": 0.49792497010761255,
              "solution_elegance_score": 0.7481233751077139
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09640480649188514,
              "dependency_traversal_weighted": 0.09929674175288625,
              "cross_file_reasoning_weighted": 0.04915972222222222,
              "system_thinking_weighted": 0.06924885654407904,
              "robustness_weighted": 0.052064512200522564,
              "comprehensiveness_weighted": 0.06321000746518882,
              "innovation_weighted": 0.06224062126345157,
              "solution_elegance_weighted": 0.09351542188846423
            },
            "total_software_engineering_score": 0.5851406898286998
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 1.0448591709136963,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "tradeutility_nexus/trade_nexus/core/domain.py",
                "tradeutility_nexus/trade_nexus/core/commands.py",
                "tradeutility_nexus/trade_nexus/core/events.py",
                "tradeutility_nexus/trade_nexus/api/schemas.py",
                "tradeutility_nexus/trade_nexus/api/endpoints.py",
                "tradeutility_nexus/trade_nexus/services/transactions/handlers.py",
                "tradeutility_nexus/trade_nexus/services/transactions/sagas.py",
                "tradeutility_nexus/trade_nexus/services/risk/handlers.py",
                "tradeutility_nexus/trade_nexus/core/unit_of_work.py",
                "tradeutility_nexus/trade_nexus/core/event_store.py",
                "tradeutility_nexus/trade_nexus/core/saga.py",
                "tradeutility_nexus/trade_nexus/core/bus.py",
                "tradeutility_nexus/trade_nexus/services/risk/assessment.py",
                "tradeutility_nexus/main.py",
                "tradeutility_nexus/trade_nexus/api/server.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 15,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 15 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.5135489614243323,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.5135489614243323,
              "idc_weight": 0.2,
              "total_functional_score": 0.6827097922848665
            }
          },
          "code_quality_details": {
            "files_analyzed": 15,
            "quality_checks": {
              "tradeutility_nexus/trade_nexus/core/domain.py": {
                "line_count": 284,
                "non_empty_lines": 240,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 22,
                "class_count": 9,
                "import_count": 29,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/core/commands.py": {
                "line_count": 110,
                "non_empty_lines": 82,
                "comment_lines": 1,
                "comment_ratio": 0.012195121951219513,
                "function_count": 0,
                "class_count": 14,
                "import_count": 10,
                "quality_score": 0.7
              },
              "tradeutility_nexus/trade_nexus/core/events.py": {
                "line_count": 140,
                "non_empty_lines": 106,
                "comment_lines": 1,
                "comment_ratio": 0.009433962264150943,
                "function_count": 0,
                "class_count": 17,
                "import_count": 10,
                "quality_score": 0.7
              },
              "tradeutility_nexus/trade_nexus/api/schemas.py": {
                "line_count": 198,
                "non_empty_lines": 159,
                "comment_lines": 1,
                "comment_ratio": 0.006289308176100629,
                "function_count": 1,
                "class_count": 20,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/api/endpoints.py": {
                "line_count": 489,
                "non_empty_lines": 418,
                "comment_lines": 14,
                "comment_ratio": 0.03349282296650718,
                "function_count": 15,
                "class_count": 0,
                "import_count": 21,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/services/transactions/handlers.py": {
                "line_count": 268,
                "non_empty_lines": 205,
                "comment_lines": 29,
                "comment_ratio": 0.14146341463414633,
                "function_count": 11,
                "class_count": 1,
                "import_count": 20,
                "quality_score": 0.9999999999999999
              },
              "tradeutility_nexus/trade_nexus/services/transactions/sagas.py": {
                "line_count": 380,
                "non_empty_lines": 303,
                "comment_lines": 9,
                "comment_ratio": 0.0297029702970297,
                "function_count": 25,
                "class_count": 5,
                "import_count": 18,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/services/risk/handlers.py": {
                "line_count": 185,
                "non_empty_lines": 150,
                "comment_lines": 11,
                "comment_ratio": 0.07333333333333333,
                "function_count": 12,
                "class_count": 2,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/core/unit_of_work.py": {
                "line_count": 92,
                "non_empty_lines": 74,
                "comment_lines": 1,
                "comment_ratio": 0.013513513513513514,
                "function_count": 10,
                "class_count": 4,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/core/event_store.py": {
                "line_count": 69,
                "non_empty_lines": 53,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 9,
                "class_count": 3,
                "import_count": 14,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/core/saga.py": {
                "line_count": 35,
                "non_empty_lines": 27,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 2,
                "class_count": 3,
                "import_count": 12,
                "quality_score": 0.6
              },
              "tradeutility_nexus/trade_nexus/core/bus.py": {
                "line_count": 72,
                "non_empty_lines": 56,
                "comment_lines": 2,
                "comment_ratio": 0.03571428571428571,
                "function_count": 7,
                "class_count": 3,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/trade_nexus/services/risk/assessment.py": {
                "line_count": 60,
                "non_empty_lines": 50,
                "comment_lines": 2,
                "comment_ratio": 0.04,
                "function_count": 4,
                "class_count": 1,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "tradeutility_nexus/main.py": {
                "line_count": 96,
                "non_empty_lines": 75,
                "comment_lines": 10,
                "comment_ratio": 0.13333333333333333,
                "function_count": 2,
                "class_count": 0,
                "import_count": 20,
                "quality_score": 0.9999999999999999
              },
              "tradeutility_nexus/trade_nexus/api/server.py": {
                "line_count": 31,
                "non_empty_lines": 24,
                "comment_lines": 2,
                "comment_ratio": 0.08333333333333333,
                "function_count": 1,
                "class_count": 0,
                "import_count": 6,
                "quality_score": 0.6
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7906666666666666,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8974137931034484,
              "multi_session_memory_retention": 0.8036637931034485
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4487068965517242,
              "multi_session_memory_retention_weighted": 0.40183189655172424
            },
            "total_longcontext_utilization_score": 0.8505387931034485
          }
        },
        "timestamp": "2026-01-14T21:15:05.614403"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_web_blog_easy_004_feature_implementation_expert_01",
        "scenario_title": "Implement Post Versioning and Scheduled Publishing",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.4825952696218453,
        "functional_correctness_score": 0.35138226299694186,
        "code_quality_score": 0.7377777777777776,
        "longcontext_utilization_score": 0.8086268939393939,
        "total_score": 2.634355158486578,
        "generation_time": 132.9356598854065,
        "code_files_generated": 9,
        "total_lines_generated": 1527,
        "parsing_success": true,
        "solution_code": {
          "focusflow_blog/focusflow/models.py": "from datetime import datetime\nfrom focusflow import db\n\n\nclass User(db.Model):\n    __tablename__ = 'users'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n    password_hash = db.Column(db.String(256), nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    posts = db.relationship('Post', backref='author', lazy='dynamic')\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'username': self.username,\n            'email': self.email,\n            'created_at': self.created_at.isoformat() if self.created_at else None\n        }\n\n\nclass Post(db.Model):\n    __tablename__ = 'posts'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(200), nullable=False)\n    content = db.Column(db.Text, nullable=False)\n    status = db.Column(db.String(20), default='draft', nullable=False)\n    scheduled_for = db.Column(db.DateTime, nullable=True)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    \n    versions = db.relationship('PostVersion', backref='post', lazy='dynamic', cascade='all, delete-orphan')\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'title': self.title,\n            'content': self.content,\n            'status': self.status,\n            'scheduled_for': self.scheduled_for.isoformat() if self.scheduled_for else None,\n            'created_at': self.created_at.isoformat() if self.created_at else None,\n            'updated_at': self.updated_at.isoformat() if self.updated_at else None,\n            'user_id': self.user_id,\n            'author': self.author.username if self.author else None\n        }\n\n\nclass PostVersion(db.Model):\n    __tablename__ = 'post_versions'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    post_id = db.Column(db.Integer, db.ForeignKey('posts.id'), nullable=False)\n    title = db.Column(db.String(200), nullable=False)\n    content = db.Column(db.Text, nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'post_id': self.post_id,\n            'title': self.title,\n            'content': self.content,\n            'created_at': self.created_at.isoformat() if self.created_at else None\n        }\n\n\nclass Tag(db.Model):\n    __tablename__ = 'tags'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(50), unique=True, nullable=False)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'name': self.name\n        }\n",
          "focusflow_blog/focusflow/services.py": "from datetime import datetime\nfrom focusflow import db\nfrom focusflow.models import User, Post, PostVersion, Tag\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\n\n# User Services\ndef create_user(username, email, password):\n    \"\"\"Create a new user with hashed password.\"\"\"\n    password_hash = generate_password_hash(password)\n    user = User(username=username, email=email, password_hash=password_hash)\n    db.session.add(user)\n    db.session.commit()\n    return user\n\n\ndef get_user_by_id(user_id):\n    \"\"\"Get a user by their ID.\"\"\"\n    return User.query.get(user_id)\n\n\ndef get_user_by_username(username):\n    \"\"\"Get a user by their username.\"\"\"\n    return User.query.filter_by(username=username).first()\n\n\ndef get_user_by_email(email):\n    \"\"\"Get a user by their email.\"\"\"\n    return User.query.filter_by(email=email).first()\n\n\ndef authenticate_user(username, password):\n    \"\"\"Authenticate a user by username and password.\"\"\"\n    user = get_user_by_username(username)\n    if user and check_password_hash(user.password_hash, password):\n        return user\n    return None\n\n\ndef get_all_users():\n    \"\"\"Get all users.\"\"\"\n    return User.query.all()\n\n\n# Post Services\ndef create_post(title, content, user_id, status='draft', scheduled_for=None):\n    \"\"\"Create a new post and save initial version.\"\"\"\n    post = Post(\n        title=title,\n        content=content,\n        user_id=user_id,\n        status=status,\n        scheduled_for=scheduled_for\n    )\n    db.session.add(post)\n    db.session.commit()\n    \n    # Create initial version\n    _create_post_version(post)\n    \n    return post\n\n\ndef get_post_by_id(post_id):\n    \"\"\"Get a post by its ID.\"\"\"\n    return Post.query.get(post_id)\n\n\ndef get_all_posts():\n    \"\"\"Get all posts.\"\"\"\n    return Post.query.order_by(Post.created_at.desc()).all()\n\n\ndef get_published_posts():\n    \"\"\"Get all published posts.\"\"\"\n    return Post.query.filter_by(status='published').order_by(Post.created_at.desc()).all()\n\n\ndef get_posts_by_user(user_id):\n    \"\"\"Get all posts by a specific user.\"\"\"\n    return Post.query.filter_by(user_id=user_id).order_by(Post.created_at.desc()).all()\n\n\ndef update_post(post_id, title=None, content=None, status=None, scheduled_for=None):\n    \"\"\"Update a post and create a new version.\"\"\"\n    post = get_post_by_id(post_id)\n    if not post:\n        return None\n    \n    if title is not None:\n        post.title = title\n    if content is not None:\n        post.content = content\n    if status is not None:\n        post.status = status\n    if scheduled_for is not None:\n        post.scheduled_for = scheduled_for\n    \n    post.updated_at = datetime.utcnow()\n    db.session.commit()\n    \n    # Create a new version after update\n    _create_post_version(post)\n    \n    return post\n\n\ndef delete_post(post_id):\n    \"\"\"Delete a post by its ID.\"\"\"\n    post = get_post_by_id(post_id)\n    if post:\n        db.session.delete(post)\n        db.session.commit()\n        return True\n    return False\n\n\n# Post Version Services\ndef _create_post_version(post):\n    \"\"\"Create a new version snapshot of a post (internal helper).\"\"\"\n    version = PostVersion(\n        post_id=post.id,\n        title=post.title,\n        content=post.content\n    )\n    db.session.add(version)\n    db.session.commit()\n    return version\n\n\ndef get_post_versions(post_id):\n    \"\"\"Get all versions for a specific post.\"\"\"\n    return PostVersion.query.filter_by(post_id=post_id).order_by(PostVersion.created_at.desc()).all()\n\n\ndef get_version_by_id(version_id):\n    \"\"\"Get a specific version by its ID.\"\"\"\n    return PostVersion.query.get(version_id)\n\n\ndef revert_to_version(post_id, version_id):\n    \"\"\"Revert a post to a specific version.\"\"\"\n    post = get_post_by_id(post_id)\n    if not post:\n        return None, \"Post not found\"\n    \n    version = get_version_by_id(version_id)\n    if not version:\n        return None, \"Version not found\"\n    \n    if version.post_id != post_id:\n        return None, \"Version does not belong to this post\"\n    \n    # Update post with version content\n    post.title = version.title\n    post.content = version.content\n    post.updated_at = datetime.utcnow()\n    db.session.commit()\n    \n    # Create a new version to record the revert action\n    _create_post_version(post)\n    \n    return post, None\n\n\n# Scheduled Publishing Services\ndef publish_scheduled_posts():\n    \"\"\"Publish all posts that are scheduled and past their scheduled time.\"\"\"\n    now = datetime.utcnow()\n    scheduled_posts = Post.query.filter(\n        Post.status == 'scheduled',\n        Post.scheduled_for <= now\n    ).all()\n    \n    published_count = 0\n    for post in scheduled_posts:\n        post.status = 'published'\n        post.updated_at = now\n        published_count += 1\n    \n    if published_count > 0:\n        db.session.commit()\n    \n    return published_count\n\n\ndef get_scheduled_posts():\n    \"\"\"Get all scheduled posts.\"\"\"\n    return Post.query.filter_by(status='scheduled').order_by(Post.scheduled_for.asc()).all()\n\n\n# Tag Services\ndef create_tag(name):\n    \"\"\"Create a new tag.\"\"\"\n    tag = Tag(name=name)\n    db.session.add(tag)\n    db.session.commit()\n    return tag\n\n\ndef get_tag_by_id(tag_id):\n    \"\"\"Get a tag by its ID.\"\"\"\n    return Tag.query.get(tag_id)\n\n\ndef get_tag_by_name(name):\n    \"\"\"Get a tag by its name.\"\"\"\n    return Tag.query.filter_by(name=name).first()\n\n\ndef get_all_tags():\n    \"\"\"Get all tags.\"\"\"\n    return Tag.query.all()\n",
          "focusflow_blog/focusflow/api.py": "from flask import Blueprint, request, jsonify\nfrom datetime import datetime\nfrom focusflow import services\n\napi_bp = Blueprint('api', __name__, url_prefix='/api')\n\n\n# User Endpoints\n@api_bp.route('/users', methods=['GET'])\ndef get_users():\n    \"\"\"Get all users.\"\"\"\n    users = services.get_all_users()\n    return jsonify([user.to_dict() for user in users]), 200\n\n\n@api_bp.route('/users/<int:user_id>', methods=['GET'])\ndef get_user(user_id):\n    \"\"\"Get a specific user by ID.\"\"\"\n    user = services.get_user_by_id(user_id)\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    return jsonify(user.to_dict()), 200\n\n\n@api_bp.route('/users', methods=['POST'])\ndef create_user():\n    \"\"\"Create a new user.\"\"\"\n    data = request.get_json()\n    \n    if not data:\n        return jsonify({'error': 'No data provided'}), 400\n    \n    required_fields = ['username', 'email', 'password']\n    for field in required_fields:\n        if field not in data:\n            return jsonify({'error': f'Missing required field: {field}'}), 400\n    \n    # Check if user already exists\n    if services.get_user_by_username(data['username']):\n        return jsonify({'error': 'Username already exists'}), 409\n    if services.get_user_by_email(data['email']):\n        return jsonify({'error': 'Email already exists'}), 409\n    \n    user = services.create_user(\n        username=data['username'],\n        email=data['email'],\n        password=data['password']\n    )\n    return jsonify(user.to_dict()), 201\n\n\n# Post Endpoints\n@api_bp.route('/posts', methods=['GET'])\ndef get_posts():\n    \"\"\"Get all posts.\"\"\"\n    status_filter = request.args.get('status')\n    if status_filter == 'published':\n        posts = services.get_published_posts()\n    elif status_filter == 'scheduled':\n        posts = services.get_scheduled_posts()\n    else:\n        posts = services.get_all_posts()\n    return jsonify([post.to_dict() for post in posts]), 200\n\n\n@api_bp.route('/posts/<int:post_id>', methods=['GET'])\ndef get_post(post_id):\n    \"\"\"Get a specific post by ID.\"\"\"\n    post = services.get_post_by_id(post_id)\n    if not post:\n        return jsonify({'error': 'Post not found'}), 404\n    return jsonify(post.to_dict()), 200\n\n\n@api_bp.route('/posts', methods=['POST'])\ndef create_post():\n    \"\"\"Create a new post.\"\"\"\n    data = request.get_json()\n    \n    if not data:\n        return jsonify({'error': 'No data provided'}), 400\n    \n    required_fields = ['title', 'content', 'user_id']\n    for field in required_fields:\n        if field not in data:\n            return jsonify({'error': f'Missing required field: {field}'}), 400\n    \n    # Verify user exists\n    user = services.get_user_by_id(data['user_id'])\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    \n    # Parse scheduled_for if provided\n    scheduled_for = None\n    if 'scheduled_for' in data and data['scheduled_for']:\n        try:\n            scheduled_for = datetime.fromisoformat(data['scheduled_for'].replace('Z', '+00:00'))\n        except (ValueError, AttributeError):\n            return jsonify({'error': 'Invalid scheduled_for format. Use ISO 8601 format.'}), 400\n    \n    status = data.get('status', 'draft')\n    if status not in ['draft', 'scheduled', 'published']:\n        return jsonify({'error': 'Invalid status. Must be draft, scheduled, or published.'}), 400\n    \n    post = services.create_post(\n        title=data['title'],\n        content=data['content'],\n        user_id=data['user_id'],\n        status=status,\n        scheduled_for=scheduled_for\n    )\n    return jsonify(post.to_dict()), 201\n\n\n@api_bp.route('/posts/<int:post_id>', methods=['PUT'])\ndef update_post(post_id):\n    \"\"\"Update a post.\"\"\"\n    post = services.get_post_by_id(post_id)\n    if not post:\n        return jsonify({'error': 'Post not found'}), 404\n    \n    data = request.get_json()\n    if not data:\n        return jsonify({'error': 'No data provided'}), 400\n    \n    # Parse scheduled_for if provided\n    scheduled_for = None\n    if 'scheduled_for' in data:\n        if data['scheduled_for']:\n            try:\n                scheduled_for = datetime.fromisoformat(data['scheduled_for'].replace('Z', '+00:00'))\n            except (ValueError, AttributeError):\n                return jsonify({'error': 'Invalid scheduled_for format. Use ISO 8601 format.'}), 400\n        else:\n            scheduled_for = None\n    \n    # Validate status if provided\n    status = data.get('status')\n    if status and status not in ['draft', 'scheduled', 'published']:\n        return jsonify({'error': 'Invalid status. Must be draft, scheduled, or published.'}), 400\n    \n    updated_post = services.update_post(\n        post_id=post_id,\n        title=data.get('title'),\n        content=data.get('content'),\n        status=status,\n        scheduled_for=scheduled_for if 'scheduled_for' in data else post.scheduled_for\n    )\n    return jsonify(updated_post.to_dict()), 200\n\n\n@api_bp.route('/posts/<int:post_id>', methods=['DELETE'])\ndef delete_post(post_id):\n    \"\"\"Delete a post.\"\"\"\n    if services.delete_post(post_id):\n        return jsonify({'message': 'Post deleted successfully'}), 200\n    return jsonify({'error': 'Post not found'}), 404\n\n\n# Post Version Endpoints\n@api_bp.route('/posts/<int:post_id>/versions', methods=['GET'])\ndef get_post_versions(post_id):\n    \"\"\"Get all versions for a specific post.\"\"\"\n    post = services.get_post_by_id(post_id)\n    if not post:\n        return jsonify({'error': 'Post not found'}), 404\n    \n    versions = services.get_post_versions(post_id)\n    return jsonify([version.to_dict() for version in versions]), 200\n\n\n@api_bp.route('/posts/<int:post_id>/revert/<int:version_id>', methods=['POST'])\ndef revert_post_to_version(post_id, version_id):\n    \"\"\"Revert a post to a specific version.\"\"\"\n    post, error = services.revert_to_version(post_id, version_id)\n    \n    if error:\n        if error == \"Post not found\":\n            return jsonify({'error': error}), 404\n        elif error == \"Version not found\":\n            return jsonify({'error': error}), 404\n        else:\n            return jsonify({'error': error}), 400\n    \n    return jsonify({\n        'message': 'Post reverted successfully',\n        'post': post.to_dict()\n    }), 200\n\n\n# User Posts Endpoint\n@api_bp.route('/users/<int:user_id>/posts', methods=['GET'])\ndef get_user_posts(user_id):\n    \"\"\"Get all posts by a specific user.\"\"\"\n    user = services.get_user_by_id(user_id)\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    \n    posts = services.get_posts_by_user(user_id)\n    return jsonify([post.to_dict() for post in posts]), 200\n\n\n# Tag Endpoints\n@api_bp.route('/tags', methods=['GET'])\ndef get_tags():\n    \"\"\"Get all tags.\"\"\"\n    tags = services.get_all_tags()\n    return jsonify([tag.to_dict() for tag in tags]), 200\n\n\n@api_bp.route('/tags', methods=['POST'])\ndef create_tag():\n    \"\"\"Create a new tag.\"\"\"\n    data = request.get_json()\n    \n    if not data or 'name' not in data:\n        return jsonify({'error': 'Tag name is required'}), 400\n    \n    if services.get_tag_by_name(data['name']):\n        return jsonify({'error': 'Tag already exists'}), 409\n    \n    tag = services.create_tag(data['name'])\n    return jsonify(tag.to_dict()), 201\n\n\n# Health Check\n@api_bp.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"API health check endpoint.\"\"\"\n    return jsonify({'status': 'healthy', 'message': 'FocusFlow Blog API is running'}), 200\n",
          "focusflow_blog/focusflow/__init__.py": "from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom config import Config\n\ndb = SQLAlchemy()\n\n\ndef create_app(config_class=Config):\n    \"\"\"Application factory for creating Flask app instances.\"\"\"\n    app = Flask(__name__)\n    app.config.from_object(config_class)\n    \n    # Initialize extensions\n    db.init_app(app)\n    \n    # Register blueprints\n    from focusflow.api import api_bp\n    app.register_blueprint(api_bp)\n    \n    # Create database tables\n    with app.app_context():\n        db.create_all()\n    \n    return app\n\n\ndef init_scheduler(app):\n    \"\"\"Initialize the APScheduler for background tasks.\"\"\"\n    from apscheduler.schedulers.background import BackgroundScheduler\n    from focusflow import services\n    \n    scheduler = BackgroundScheduler()\n    \n    def publish_scheduled_posts_job():\n        \"\"\"Job function to publish scheduled posts.\"\"\"\n        with app.app_context():\n            count = services.publish_scheduled_posts()\n            if count > 0:\n                app.logger.info(f'Published {count} scheduled post(s)')\n    \n    # Schedule the job to run every 5 minutes\n    scheduler.add_job(\n        func=publish_scheduled_posts_job,\n        trigger='interval',\n        minutes=5,\n        id='publish_scheduled_posts',\n        name='Publish scheduled posts',\n        replace_existing=True\n    )\n    \n    scheduler.start()\n    app.logger.info('Background scheduler started')\n    \n    return scheduler\n",
          "focusflow_blog/run.py": "import atexit\nfrom focusflow import create_app, init_scheduler\n\napp = create_app()\n\n# Initialize the scheduler for background tasks\nscheduler = None\n\nif __name__ == '__main__':\n    # Only start scheduler when running directly (not in testing)\n    scheduler = init_scheduler(app)\n    \n    # Ensure scheduler shuts down when app exits\n    atexit.register(lambda: scheduler.shutdown() if scheduler else None)\n    \n    app.run(debug=True, use_reloader=False)\n",
          "focusflow_blog/config.py": "import os\n\nbasedir = os.path.abspath(os.path.dirname(__file__))\n\n\nclass Config:\n    \"\"\"Base configuration class.\"\"\"\n    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key-change-in-production'\n    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or \n        'sqlite:///' + os.path.join(basedir, 'focusflow.db')\n    SQLALCHEMY_TRACK_MODIFICATIONS = False\n\n\nclass TestConfig(Config):\n    \"\"\"Testing configuration.\"\"\"\n    TESTING = True\n    SQLALCHEMY_DATABASE_URI = 'sqlite:///:memory:'\n    WTF_CSRF_ENABLED = False\n\n\nclass ProductionConfig(Config):\n    \"\"\"Production configuration.\"\"\"\n    DEBUG = False\n",
          "focusflow_blog/tests/test_core.py": "import pytest\nfrom datetime import datetime, timedelta\nfrom focusflow import create_app, db\nfrom focusflow.models import User, Post, PostVersion\nfrom focusflow import services\nfrom config import TestConfig\n\n\n@pytest.fixture\ndef app():\n    \"\"\"Create application for testing.\"\"\"\n    app = create_app(TestConfig)\n    with app.app_context():\n        db.create_all()\n        yield app\n        db.drop_all()\n\n\n@pytest.fixture\ndef client(app):\n    \"\"\"Create test client.\"\"\"\n    return app.test_client()\n\n\n@pytest.fixture\ndef sample_user(app):\n    \"\"\"Create a sample user for testing.\"\"\"\n    with app.app_context():\n        user = services.create_user(\n            username='testuser',\n            email='test@example.com',\n            password='password123'\n        )\n        return user.id\n\n\n@pytest.fixture\ndef sample_post(app, sample_user):\n    \"\"\"Create a sample post for testing.\"\"\"\n    with app.app_context():\n        post = services.create_post(\n            title='Test Post',\n            content='Test content',\n            user_id=sample_user\n        )\n        return post.id\n\n\nclass TestUserServices:\n    \"\"\"Test user-related services.\"\"\"\n    \n    def test_create_user(self, app):\n        with app.app_context():\n            user = services.create_user('newuser', 'new@example.com', 'password')\n            assert user.id is not None\n            assert user.username == 'newuser'\n            assert user.email == 'new@example.com'\n    \n    def test_get_user_by_id(self, app, sample_user):\n        with app.app_context():\n            user = services.get_user_by_id(sample_user)\n            assert user is not None\n            assert user.username == 'testuser'\n    \n    def test_authenticate_user(self, app, sample_user):\n        with app.app_context():\n            user = services.authenticate_user('testuser', 'password123')\n            assert user is not None\n            assert user.id == sample_user\n    \n    def test_authenticate_user_wrong_password(self, app, sample_user):\n        with app.app_context():\n            user = services.authenticate_user('testuser', 'wrongpassword')\n            assert user is None\n\n\nclass TestPostServices:\n    \"\"\"Test post-related services.\"\"\"\n    \n    def test_create_post(self, app, sample_user):\n        with app.app_context():\n            post = services.create_post('New Post', 'Content here', sample_user)\n            assert post.id is not None\n            assert post.title == 'New Post'\n            assert post.status == 'draft'\n    \n    def test_create_post_with_status(self, app, sample_user):\n        with app.app_context():\n            post = services.create_post(\n                'Published Post',\n                'Content',\n                sample_user,\n                status='published'\n            )\n            assert post.status == 'published'\n    \n    def test_create_post_with_scheduled_for(self, app, sample_user):\n        with app.app_context():\n            future_time = datetime.utcnow() + timedelta(days=1)\n            post = services.create_post(\n                'Scheduled Post',\n                'Content',\n                sample_user,\n                status='scheduled',\n                scheduled_for=future_time\n            )\n            assert post.status == 'scheduled'\n            assert post.scheduled_for is not None\n    \n    def test_update_post(self, app, sample_post):\n        with app.app_context():\n            post = services.update_post(\n                sample_post,\n                title='Updated Title',\n                content='Updated content'\n            )\n            assert post.title == 'Updated Title'\n            assert post.content == 'Updated content'\n    \n    def test_update_post_status(self, app, sample_post):\n        with app.app_context():\n            post = services.update_post(sample_post, status='published')\n            assert post.status == 'published'\n    \n    def test_delete_post(self, app, sample_post):\n        with app.app_context():\n            result = services.delete_post(sample_post)\n            assert result is True\n            post = services.get_post_by_id(sample_post)\n            assert post is None\n\n\nclass TestPostVersionServices:\n    \"\"\"Test post versioning services.\"\"\"\n    \n    def test_version_created_on_post_creation(self, app, sample_user):\n        with app.app_context():\n            post = services.create_post('Test', 'Content', sample_user)\n            versions = services.get_post_versions(post.id)\n            assert len(versions) == 1\n            assert versions[0].title == 'Test'\n            assert versions[0].content == 'Content'\n    \n    def test_version_created_on_post_update(self, app, sample_post):\n        with app.app_context():\n            # Initial version exists from creation\n            initial_versions = services.get_post_versions(sample_post)\n            assert len(initial_versions) == 1\n            \n            # Update the post\n            services.update_post(sample_post, title='Updated Title')\n            \n            # Should now have 2 versions\n            versions = services.get_post_versions(sample_post)\n            assert len(versions) == 2\n    \n    def test_revert_to_version(self, app, sample_post):\n        with app.app_context():\n            # Get initial version\n            initial_versions = services.get_post_versions(sample_post)\n            initial_version = initial_versions[0]\n            \n            # Update the post\n            services.update_post(\n                sample_post,\n                title='New Title',\n                content='New Content'\n            )\n            \n            # Verify update\n            post = services.get_post_by_id(sample_post)\n            assert post.title == 'New Title'\n            \n            # Revert to initial version\n            reverted_post, error = services.revert_to_version(\n                sample_post,\n                initial_version.id\n            )\n            \n            assert error is None\n            assert reverted_post.title == 'Test Post'\n            assert reverted_post.content == 'Test content'\n    \n    def test_revert_to_nonexistent_version(self, app, sample_post):\n        with app.app_context():\n            post, error = services.revert_to_version(sample_post, 99999)\n            assert post is None\n            assert error == \"Version not found\"\n    \n    def test_revert_to_wrong_post_version(self, app, sample_user):\n        with app.app_context():\n            # Create two posts\n            post1 = services.create_post('Post 1', 'Content 1', sample_user)\n            post2 = services.create_post('Post 2', 'Content 2', sample_user)\n            \n            # Get version from post2\n            post2_versions = services.get_post_versions(post2.id)\n            \n            # Try to revert post1 to post2's version\n            result, error = services.revert_to_version(\n                post1.id,\n                post2_versions[0].id\n            )\n            \n            assert result is None\n            assert error == \"Version does not belong to this post\"\n\n\nclass TestScheduledPublishing:\n    \"\"\"Test scheduled publishing services.\"\"\"\n    \n    def test_publish_scheduled_posts(self, app, sample_user):\n        with app.app_context():\n            # Create a post scheduled for the past\n            past_time = datetime.utcnow() - timedelta(hours=1)\n            post = services.create_post(\n                'Scheduled Post',\n                'Content',\n                sample_user,\n                status='scheduled',\n                scheduled_for=past_time\n            )\n            \n            # Run the publish job\n            count = services.publish_scheduled_posts()\n            \n            assert count == 1\n            \n            # Verify post is now published\n            updated_post = services.get_post_by_id(post.id)\n            assert updated_post.status == 'published'\n    \n    def test_publish_scheduled_posts_future(self, app, sample_user):\n        with app.app_context():\n            # Create a post scheduled for the future\n            future_time = datetime.utcnow() + timedelta(hours=1)\n            post = services.create_post(\n                'Future Post',\n                'Content',\n                sample_user,\n                status='scheduled',\n                scheduled_for=future_time\n            )\n            \n            # Run the publish job\n            count = services.publish_scheduled_posts()\n            \n            assert count == 0\n            \n            # Verify post is still scheduled\n            updated_post = services.get_post_by_id(post.id)\n            assert updated_post.status == 'scheduled'\n    \n    def test_publish_scheduled_posts_draft_not_affected(self, app, sample_user):\n        with app.app_context():\n            # Create a draft post\n            post = services.create_post(\n                'Draft Post',\n                'Content',\n                sample_user,\n                status='draft'\n            )\n            \n            # Run the publish job\n            count = services.publish_scheduled_posts()\n            \n            assert count == 0\n            \n            # Verify post is still draft\n            updated_post = services.get_post_by_id(post.id)\n            assert updated_post.status == 'draft'\n\n\nclass TestAPIEndpoints:\n    \"\"\"Test API endpoints.\"\"\"\n    \n    def test_health_check(self, client):\n        response = client.get('/api/health')\n        assert response.status_code == 200\n        data = response.get_json()\n        assert data['status'] == 'healthy'\n    \n    def test_create_user_api(self, client):\n        response = client.post('/api/users', json={\n            'username': 'apiuser',\n            'email': 'api@example.com',\n            'password': 'password123'\n        })\n        assert response.status_code == 201\n        data = response.get_json()\n        assert data['username'] == 'apiuser'\n    \n    def test_create_post_api(self, client, app, sample_user):\n        with app.app_context():\n            response = client.post('/api/posts', json={\n                'title': 'API Post',\n                'content': 'Content from API',\n                'user_id': sample_user\n            })\n            assert response.status_code == 201\n            data = response.get_json()\n            assert data['title'] == 'API Post'\n            assert data['status'] == 'draft'\n    \n    def test_create_scheduled_post_api(self, client, app, sample_user):\n        with app.app_context():\n            future_time = (datetime.utcnow() + timedelta(days=1)).isoformat()\n            response = client.post('/api/posts', json={\n                'title': 'Scheduled API Post',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'scheduled',\n                'scheduled_for': future_time\n            })\n            assert response.status_code == 201\n            data = response.get_json()\n            assert data['status'] == 'scheduled'\n            assert data['scheduled_for'] is not None\n    \n    def test_update_post_api(self, client, app, sample_post):\n        with app.app_context():\n            response = client.put(f'/api/posts/{sample_post}', json={\n                'title': 'Updated via API',\n                'status': 'published'\n            })\n            assert response.status_code == 200\n            data = response.get_json()\n            assert data['title'] == 'Updated via API'\n            assert data['status'] == 'published'\n    \n    def test_get_post_versions_api(self, client, app, sample_post):\n        with app.app_context():\n            response = client.get(f'/api/posts/{sample_post}/versions')\n            assert response.status_code == 200\n            data = response.get_json()\n            assert len(data) >= 1\n            assert data[0]['title'] == 'Test Post'\n    \n    def test_revert_post_api(self, client, app, sample_post):\n        with app.app_context():\n            # First update the post\n            client.put(f'/api/posts/{sample_post}', json={\n                'title': 'Changed Title'\n            })\n            \n            # Get versions\n            versions_response = client.get(f'/api/posts/{sample_post}/versions')\n            versions = versions_response.get_json()\n            \n            # Find the original version (oldest)\n            original_version = sorted(versions, key=lambda x: x['created_at'])[0]\n            \n            # Revert to original\n            response = client.post(\n                f'/api/posts/{sample_post}/revert/{original_version[\"id\"]}'\n            )\n            assert response.status_code == 200\n            data = response.get_json()\n            assert data['post']['title'] == 'Test Post'\n    \n    def test_get_post_versions_not_found(self, client):\n        response = client.get('/api/posts/99999/versions')\n        assert response.status_code == 404\n    \n    def test_revert_post_not_found(self, client):\n        response = client.post('/api/posts/99999/revert/1')\n        assert response.status_code == 404\n    \n    def test_create_post_invalid_status(self, client, app, sample_user):\n        with app.app_context():\n            response = client.post('/api/posts', json={\n                'title': 'Test',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'invalid_status'\n            })\n            assert response.status_code == 400\n    \n    def test_get_posts_filtered_by_status(self, client, app, sample_user):\n        with app.app_context():\n            # Create posts with different statuses\n            client.post('/api/posts', json={\n                'title': 'Draft',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'draft'\n            })\n            client.post('/api/posts', json={\n                'title': 'Published',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'published'\n            })\n            \n            # Get only published\n            response = client.get('/api/posts?status=published')\n            assert response.status_code == 200\n            data = response.get_json()\n            assert all(post['status'] == 'published' for post in data)\n",
          "focusflow_blog/docs/API.md": "# FocusFlow Blog API Documentation\n\n## Base URL\n\nAll API endpoints are prefixed with `/api`.\n\n## Health Check\n\n### GET /api/health\n\nCheck if the API is running.\n\n**Response:**\n```json\n{\n    \"status\": \"healthy\",\n    \"message\": \"FocusFlow Blog API is running\"\n}\n```\n\n---\n\n## Users\n\n### GET /api/users\n\nGet all users.\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"username\": \"johndoe\",\n        \"email\": \"john@example.com\",\n        \"created_at\": \"2024-01-15T10:30:00\"\n    }\n]\n```\n\n### GET /api/users/{user_id}\n\nGet a specific user by ID.\n\n**Response:**\n```json\n{\n    \"id\": 1,\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"created_at\": \"2024-01-15T10:30:00\"\n}\n```\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"User not found\"\n}\n```\n\n### POST /api/users\n\nCreate a new user.\n\n**Request Body:**\n```json\n{\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"password\": \"securepassword123\"\n}\n```\n\n**Response (201):**\n```json\n{\n    \"id\": 1,\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"created_at\": \"2024-01-15T10:30:00\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Missing required field: username\"\n}\n```\n\n**Error Response (409):**\n```json\n{\n    \"error\": \"Username already exists\"\n}\n```\n\n---\n\n## Posts\n\n### GET /api/posts\n\nGet all posts. Supports optional status filtering.\n\n**Query Parameters:**\n- `status` (optional): Filter by post status. Values: `published`, `scheduled`\n\n**Examples:**\n- `GET /api/posts` - Get all posts\n- `GET /api/posts?status=published` - Get only published posts\n- `GET /api/posts?status=scheduled` - Get only scheduled posts\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"title\": \"My First Post\",\n        \"content\": \"This is the content of my post.\",\n        \"status\": \"published\",\n        \"scheduled_for\": null,\n        \"created_at\": \"2024-01-15T10:30:00\",\n        \"updated_at\": \"2024-01-15T12:00:00\",\n        \"user_id\": 1,\n        \"author\": \"johndoe\"\n    }\n]\n```\n\n### GET /api/posts/{post_id}\n\nGet a specific post by ID.\n\n**Response:**\n```json\n{\n    \"id\": 1,\n    \"title\": \"My First Post\",\n    \"content\": \"This is the content of my post.\",\n    \"status\": \"published\",\n    \"scheduled_for\": null,\n    \"created_at\": \"2024-01-15T10:30:00\",\n    \"updated_at\": \"2024-01-15T12:00:00\",\n    \"user_id\": 1,\n    \"author\": \"johndoe\"\n}\n```\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n### POST /api/posts\n\nCreate a new post.\n\n**Request Body:**\n```json\n{\n    \"title\": \"My New Post\",\n    \"content\": \"This is the content of my post.\",\n    \"user_id\": 1,\n    \"status\": \"draft\",\n    \"scheduled_for\": null\n}\n```\n\n**Fields:**\n- `title` (required): Post title (string)\n- `content` (required): Post content (string)\n- `user_id` (required): Author's user ID (integer)\n- `status` (optional): Post status. Values: `draft`, `scheduled`, `published`. Default: `draft`\n- `scheduled_for` (optional): ISO 8601 datetime for scheduled publishing. Example: `2024-01-20T15:00:00`\n\n**Response (201):**\n```json\n{\n    \"id\": 2,\n    \"title\": \"My New Post\",\n    \"content\": \"This is the content of my post.\",\n    \"status\": \"draft\",\n    \"scheduled_for\": null,\n    \"created_at\": \"2024-01-15T14:00:00\",\n    \"updated_at\": \"2024-01-15T14:00:00\",\n    \"user_id\": 1,\n    \"author\": \"johndoe\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Invalid status. Must be draft, scheduled, or published.\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Invalid scheduled_for format. Use ISO 8601 format.\"\n}\n```\n\n### PUT /api/posts/{post_id}\n\nUpdate an existing post.\n\n**Request Body:**\n```json\n{\n    \"title\": \"Updated Title\",\n    \"content\": \"Updated content.\",\n    \"status\": \"scheduled\",\n    \"scheduled_for\": \"2024-01-20T15:00:00\"\n}\n```\n\n**Fields (all optional):**\n- `title`: Updated post title\n- `content`: Updated post content\n- `status`: Updated status (`draft`, `scheduled`, or `published`)\n- `scheduled_for`: ISO 8601 datetime for scheduled publishing (set to `null` to clear)\n\n**Response (200):**\n```json\n{\n    \"id\": 1,\n    \"title\": \"Updated Title\",\n    \"content\": \"Updated content.\",\n    \"status\": \"scheduled\",\n    \"scheduled_for\": \"2024-01-20T15:00:00\",\n    \"created_at\": \"2024-01-15T10:30:00\",\n    \"updated_at\": \"2024-01-15T16:00:00\",\n    \"user_id\": 1,\n    \"author\": \"johndoe\"\n}\n```\n\n**Note:** Every update creates a new version in the post's version history.\n\n### DELETE /api/posts/{post_id}\n\nDelete a post.\n\n**Response (200):**\n```json\n{\n    \"message\": \"Post deleted successfully\"\n}\n```\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n---\n\n## Post Versions\n\nEvery time a post is created or updated, a version snapshot is automatically saved. This allows authors to view the history of changes and revert to previous versions.\n\n### GET /api/posts/{post_id}/versions\n\nGet all versions for a specific post.\n\n**Response (200):**\n```json\n[\n    {\n        \"id\": 3,\n        \"post_id\": 1,\n        \"title\": \"Current Title\",\n        \"content\": \"Current content.\",\n        \"created_at\": \"2024-01-15T16:00:00\"\n    },\n    {\n        \"id\": 2,\n        \"post_id\": 1,\n        \"title\": \"Previous Title\",\n        \"content\": \"Previous content.\",\n        \"created_at\": \"2024-01-15T14:00:00\"\n    },\n    {\n        \"id\": 1,\n        \"post_id\": 1,\n        \"title\": \"Original Title\",\n        \"content\": \"Original content.\",\n        \"created_at\": \"2024-01-15T10:30:00\"\n    }\n]\n```\n\n**Note:** Versions are returned in descending order by creation date (newest first).\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n### POST /api/posts/{post_id}/revert/{version_id}\n\nRevert a post to a specific version. This updates the post's title and content to match the specified version and creates a new version entry to record the revert action.\n\n**Response (200):**\n```json\n{\n    \"message\": \"Post reverted successfully\",\n    \"post\": {\n        \"id\": 1,\n        \"title\": \"Original Title\",\n        \"content\": \"Original content.\",\n        \"status\": \"draft\",\n        \"scheduled_for\": null,\n        \"created_at\": \"2024-01-15T10:30:00\",\n        \"updated_at\": \"2024-01-15T17:00:00\",\n        \"user_id\": 1,\n        \"author\": \"johndoe\"\n    }\n}\n```\n\n**Error Response (404) - Post not found:**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n**Error Response (404) - Version not found:**\n```json\n{\n    \"error\": \"Version not found\"\n}\n```\n\n**Error Response (400) - Version belongs to different post:**\n```json\n{\n    \"error\": \"Version does not belong to this post\"\n}\n```\n\n---\n\n## User Posts\n\n### GET /api/users/{user_id}/posts\n\nGet all posts by a specific user.\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"title\": \"My First Post\",\n        \"content\": \"This is the content.\",\n        \"status\": \"published\",\n        \"scheduled_for\": null,\n        \"created_at\": \"2024-01-15T10:30:00\",\n        \"updated_at\": \"2024-01-15T12:00:00\",\n        \"user_id\": 1,\n        \"author\": \"johndoe\"\n    }\n]\n```\n\n---\n\n## Tags\n\n### GET /api/tags\n\nGet all tags.\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"name\": \"technology\"\n    },\n    {\n        \"id\": 2,\n        \"name\": \"tutorial\"\n    }\n]\n```\n\n### POST /api/tags\n\nCreate a new tag.\n\n**Request Body:**\n```json\n{\n    \"name\": \"python\"\n}\n```\n\n**Response (201):**\n```json\n{\n    \"id\": 3,\n    \"name\": \"python\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Tag name is required\"\n}\n```\n\n**Error Response (409):**\n```json\n{\n    \"error\": \"Tag already exists\"\n}\n```\n\n---\n\n## Post Status Values\n\n| Status | Description |\n|--------|-------------|\n| `draft` | Post is saved but not visible to readers. Default status for new posts. |\n| `scheduled` | Post is scheduled for future publication. Requires `scheduled_for` datetime. |\n| `published` | Post is live and visible to readers. |\n\n---\n\n## Scheduled Publishing\n\nPosts with `status: scheduled` and a `scheduled_for` datetime will be automatically published when the scheduled time is reached. The background scheduler checks for posts to publish every 5 minutes.\n\n**Example: Creating a scheduled post:**\n```json\nPOST /api/posts\n{\n    \"title\": \"Upcoming Announcement\",\n    \"content\": \"Big news coming soon!\",\n    \"user_id\": 1,\n    \"status\": \"scheduled\",\n    \"scheduled_for\": \"2024-01-20T09:00:00\"\n}\n```\n\n---\n\n## Error Responses\n\nAll endpoints may return the following error responses:\n\n**400 Bad Request:**\n```json\n{\n    \"error\": \"Description of the error\"\n}\n```\n\n**404 Not Found:**\n```json\n{\n    \"error\": \"Resource not found\"\n}\n```\n\n**409 Conflict:**\n```json\n{\n    \"error\": \"Resource already exists\"\n}\n```\n\n---\n\n## Date/Time Format\n\nAll datetime fields use ISO 8601 format:\n- Example: `2024-01-15T10:30:00`\n- Timezone: UTC\n\nWhen sending datetime values in requests, use the same ISO 8601 format. The `Z` suffix for UTC is also accepted: `2024-01-15T10:30:00Z`\n",
          "focusflow_blog/requirements.txt": "Flask>=2.3.0\nFlask-SQLAlchemy>=3.0.0\nWerkzeug>=2.3.0\nAPScheduler>=3.10.0\npytest>=7.0.0\n"
        },
        "generated_files": [
          "focusflow_blog/focusflow/models.py",
          "focusflow_blog/focusflow/services.py",
          "focusflow_blog/focusflow/api.py",
          "focusflow_blog/focusflow/__init__.py",
          "focusflow_blog/run.py",
          "focusflow_blog/config.py",
          "focusflow_blog/tests/test_core.py",
          "focusflow_blog/docs/API.md",
          "focusflow_blog/requirements.txt"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7299259259259259,
              "dependency_traversal_accuracy": 0.6539072848417112,
              "cross_file_reasoning_depth": 0.35870370370370364,
              "system_thinking_score": 0.42757471030324373,
              "robustness_score": 0.3998690242305174,
              "comprehensiveness_score": 0.606752736458041,
              "innovation_score": 0.15625,
              "solution_elegance_score": 0.5277787715116194
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09124074074074073,
              "dependency_traversal_weighted": 0.0817384106052139,
              "cross_file_reasoning_weighted": 0.044837962962962954,
              "system_thinking_weighted": 0.05344683878790547,
              "robustness_weighted": 0.049983628028814675,
              "comprehensiveness_weighted": 0.07584409205725512,
              "innovation_weighted": 0.01953125,
              "solution_elegance_weighted": 0.06597234643895243
            },
            "total_software_engineering_score": 0.4825952696218453
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.0,
              "execution_time": 0.5881707668304443,
              "errors": [
                "  File \"focusflow_blog/config.py\", line 9",
                "    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or ",
                "                                                                ^",
                "SyntaxError: invalid syntax",
                "  File \"focusflow_blog/requirements.py\", line 1",
                "    Flask>=2.3.0",
                "              ^^",
                "SyntaxError: invalid syntax",
                "  File \"focusflow_blog/docs/API.py\", line 176",
                "    - `user_id` (required): Author's user ID (integer)",
                "                                  ^",
                "SyntaxError: unterminated string literal (detected at line 176)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "focusflow_blog/focusflow/models.py",
                "focusflow_blog/focusflow/services.py",
                "focusflow_blog/focusflow/api.py",
                "focusflow_blog/focusflow/__init__.py",
                "focusflow_blog/run.py",
                "focusflow_blog/config.py",
                "focusflow_blog/tests/test_core.py",
                "focusflow_blog/docs/API.md",
                "focusflow_blog/requirements.txt"
              ],
              "scoring_breakdown": {
                "no_credit": 0.0
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 9,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 7 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.20691131498470947,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.0,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.20691131498470947,
              "idc_weight": 0.2,
              "total_functional_score": 0.35138226299694186
            }
          },
          "code_quality_details": {
            "files_analyzed": 9,
            "quality_checks": {
              "focusflow_blog/focusflow/models.py": {
                "line_count": 83,
                "non_empty_lines": 64,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 4,
                "class_count": 4,
                "import_count": 4,
                "quality_score": 0.7999999999999999
              },
              "focusflow_blog/focusflow/services.py": {
                "line_count": 214,
                "non_empty_lines": 153,
                "comment_lines": 9,
                "comment_ratio": 0.058823529411764705,
                "function_count": 23,
                "class_count": 0,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "focusflow_blog/focusflow/api.py": {
                "line_count": 231,
                "non_empty_lines": 180,
                "comment_lines": 11,
                "comment_ratio": 0.06111111111111111,
                "function_count": 14,
                "class_count": 0,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "focusflow_blog/focusflow/__init__.py": {
                "line_count": 55,
                "non_empty_lines": 40,
                "comment_lines": 4,
                "comment_ratio": 0.1,
                "function_count": 3,
                "class_count": 0,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "focusflow_blog/run.py": {
                "line_count": 17,
                "non_empty_lines": 11,
                "comment_lines": 3,
                "comment_ratio": 0.2727272727272727,
                "function_count": 0,
                "class_count": 0,
                "import_count": 3,
                "quality_score": 0.7
              },
              "focusflow_blog/config.py": {
                "line_count": 24,
                "non_empty_lines": 16,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 3,
                "import_count": 1,
                "quality_score": 0.5
              },
              "focusflow_blog/tests/test_core.py": {
                "line_count": 400,
                "non_empty_lines": 330,
                "comment_lines": 25,
                "comment_ratio": 0.07575757575757576,
                "function_count": 33,
                "class_count": 5,
                "import_count": 14,
                "quality_score": 0.7999999999999999
              },
              "focusflow_blog/docs/API.md": {
                "line_count": 497,
                "non_empty_lines": 400,
                "comment_lines": 26,
                "comment_ratio": 0.065,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.7
              },
              "focusflow_blog/requirements.txt": {
                "line_count": 6,
                "non_empty_lines": 5,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.5
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7377777777777776,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8033143939393939,
              "multi_session_memory_retention": 0.8139393939393939
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.40165719696969693,
              "multi_session_memory_retention_weighted": 0.4069696969696969
            },
            "total_longcontext_utilization_score": 0.8086268939393939
          }
        },
        "timestamp": "2026-01-14T21:17:20.023952"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_api_graphql_easy_043_feature_implementation_expert_01",
        "scenario_title": "Implement Dynamic GraphQL Query Cost Analysis",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5325946787931028,
        "functional_correctness_score": 0.4255510204081633,
        "code_quality_score": 0.8349999999999999,
        "longcontext_utilization_score": 0.82894019019019,
        "total_score": 2.9529859832935457,
        "generation_time": 69.64453101158142,
        "code_files_generated": 4,
        "total_lines_generated": 604,
        "parsing_success": true,
        "solution_code": {
          "cinepulse_hub/config.py": "import os\n\n\nclass Config:\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"dev-secret-key-change-in-production\")\n    DEBUG = os.environ.get(\"DEBUG\", \"True\").lower() in (\"true\", \"1\", \"yes\")\n    GRAPHQL_ENDPOINT = \"/graphql\"\n    \n    # Database configuration\n    DATABASE_URL = os.environ.get(\"DATABASE_URL\", \"sqlite:///cinepulse.db\")\n    \n    # JWT Configuration\n    JWT_ALGORITHM = \"HS256\"\n    JWT_EXPIRATION_HOURS = 24\n    \n    # Query cost analysis configuration\n    MAX_QUERY_COST = int(os.environ.get(\"MAX_QUERY_COST\", \"100\"))\n\n\nclass DevelopmentConfig(Config):\n    DEBUG = True\n\n\nclass ProductionConfig(Config):\n    DEBUG = False\n\n\nclass TestingConfig(Config):\n    TESTING = True\n    DEBUG = True\n    MAX_QUERY_COST = 100\n\n\ndef get_config():\n    env = os.environ.get(\"FLASK_ENV\", \"development\")\n    if env == \"production\":\n        return ProductionConfig()\n    elif env == \"testing\":\n        return TestingConfig()\n    return DevelopmentConfig()\n",
          "cinepulse_hub/app/cost_analysis.py": "from graphql import GraphQLError\nfrom graphql.validation import ValidationRule\nfrom graphql.language import (\n    FieldNode,\n    FragmentSpreadNode,\n    InlineFragmentNode,\n)\n\n\n# Field-specific costs (default is 1)\nFIELD_COSTS = {\n    \"tickets\": 5,\n}\n\n\nclass CostAnalysisRule(ValidationRule):\n    \"\"\"Custom validation rule that calculates query cost and rejects expensive queries.\"\"\"\n    \n    def __init__(self, context, max_cost=100):\n        super().__init__(context)\n        self.max_cost = max_cost\n        self.cost = 0\n        self.fragment_definitions = {}\n        \n        # Pre-collect all fragment definitions\n        if context.document:\n            for definition in context.document.definitions:\n                if hasattr(definition, 'name') and hasattr(definition, 'selection_set'):\n                    if definition.__class__.__name__ == 'FragmentDefinitionNode':\n                        self.fragment_definitions[definition.name.value] = definition\n    \n    def get_field_cost(self, field_name):\n        \"\"\"Get the cost for a specific field.\"\"\"\n        return FIELD_COSTS.get(field_name, 1)\n    \n    def get_multiplier_from_arguments(self, arguments):\n        \"\"\"Extract the 'first' argument value for list multiplier.\"\"\"\n        if not arguments:\n            return 1\n        \n        for arg in arguments:\n            if arg.name.value == \"first\":\n                if hasattr(arg.value, 'value'):\n                    try:\n                        return int(arg.value.value)\n                    except (ValueError, TypeError):\n                        return 1\n        return 1\n    \n    def calculate_selection_cost(self, selection_set, multiplier=1):\n        \"\"\"Recursively calculate the cost of a selection set.\"\"\"\n        if not selection_set:\n            return 0\n        \n        total_cost = 0\n        \n        for selection in selection_set.selections:\n            if isinstance(selection, FieldNode):\n                field_name = selection.name.value\n                \n                # Skip introspection fields\n                if field_name.startswith('__'):\n                    continue\n                \n                # Get base cost for this field\n                field_cost = self.get_field_cost(field_name)\n                \n                # Apply current multiplier\n                field_cost *= multiplier\n                \n                # Check for 'first' argument to determine sub-selection multiplier\n                sub_multiplier = self.get_multiplier_from_arguments(selection.arguments)\n                \n                # Add field cost\n                total_cost += field_cost\n                \n                # Recursively calculate sub-selection cost\n                if selection.selection_set:\n                    sub_cost = self.calculate_selection_cost(\n                        selection.selection_set,\n                        multiplier=sub_multiplier\n                    )\n                    total_cost += sub_cost * multiplier\n            \n            elif isinstance(selection, FragmentSpreadNode):\n                fragment_name = selection.name.value\n                if fragment_name in self.fragment_definitions:\n                    fragment = self.fragment_definitions[fragment_name]\n                    total_cost += self.calculate_selection_cost(\n                        fragment.selection_set,\n                        multiplier=multiplier\n                    )\n            \n            elif isinstance(selection, InlineFragmentNode):\n                total_cost += self.calculate_selection_cost(\n                    selection.selection_set,\n                    multiplier=multiplier\n                )\n        \n        return total_cost\n    \n    def enter_operation_definition(self, node, *args):\n        \"\"\"Called when entering an operation definition (query/mutation).\"\"\"\n        self.cost = self.calculate_selection_cost(node.selection_set)\n        \n        if self.cost > self.max_cost:\n            self.report_error(\n                GraphQLError(\n                    f\"Query is too complex. Max cost allowed is {self.max_cost}, but got {self.cost}.\"\n                )\n            )\n        \n        return None\n\n\ndef create_cost_analysis_rule(max_cost):\n    \"\"\"Factory function to create a CostAnalysisRule with a specific max cost.\"\"\"\n    def rule_factory(context):\n        return CostAnalysisRule(context, max_cost=max_cost)\n    return rule_factory\n",
          "cinepulse_hub/app/main.py": "from flask import Flask, request, jsonify\nfrom flask_graphql import GraphQLView\nfrom graphql import validate, parse\n\nfrom app.schema import schema\nfrom app.middleware.auth import AuthMiddleware\nfrom app.cost_analysis import create_cost_analysis_rule\nfrom config import get_config\n\n\ndef create_app(config=None):\n    app = Flask(__name__)\n    \n    if config is None:\n        config = get_config()\n    \n    app.config.from_object(config)\n    \n    # Store max query cost in app config\n    max_query_cost = getattr(config, 'MAX_QUERY_COST', 100)\n    app.config['MAX_QUERY_COST'] = max_query_cost\n    \n    # Custom GraphQL view with cost analysis\n    class CostAnalyzedGraphQLView(GraphQLView):\n        def dispatch_request(self):\n            # Get the query from the request\n            data = self.parse_body()\n            \n            if data and 'query' in data:\n                query_string = data.get('query', '')\n                \n                if query_string:\n                    try:\n                        # Parse the query\n                        document = parse(query_string)\n                        \n                        # Create cost analysis rule\n                        cost_rule = create_cost_analysis_rule(app.config['MAX_QUERY_COST'])\n                        \n                        # Validate with cost analysis\n                        errors = validate(\n                            schema.graphql_schema,\n                            document,\n                            [cost_rule]\n                        )\n                        \n                        if errors:\n                            # Return cost-related errors\n                            error_messages = [str(error) for error in errors]\n                            return jsonify({\n                                'errors': [{'message': msg} for msg in error_messages]\n                            }), 400\n                    \n                    except Exception as e:\n                        # If parsing fails, let the normal GraphQL handling deal with it\n                        pass\n            \n            # Continue with normal GraphQL execution\n            return super().dispatch_request()\n    \n    # Add GraphQL endpoint with cost analysis\n    app.add_url_rule(\n        app.config.get('GRAPHQL_ENDPOINT', '/graphql'),\n        view_func=CostAnalyzedGraphQLView.as_view(\n            'graphql',\n            schema=schema,\n            graphiql=app.config.get('DEBUG', True),\n            middleware=[AuthMiddleware()]\n        )\n    )\n    \n    @app.route('/health')\n    def health_check():\n        return jsonify({'status': 'healthy', 'service': 'CinePulse GraphQL Hub'})\n    \n    @app.errorhandler(404)\n    def not_found(error):\n        return jsonify({'error': 'Not found'}), 404\n    \n    @app.errorhandler(500)\n    def internal_error(error):\n        return jsonify({'error': 'Internal server error'}), 500\n    \n    return app\n\n\nif __name__ == '__main__':\n    app = create_app()\n    app.run(debug=True, host='0.0.0.0', port=5000)\n",
          "cinepulse_hub/tests/test_query_cost.py": "import pytest\nimport json\nfrom app.main import create_app\nfrom config import TestingConfig\n\n\nclass TestQueryCostConfig(TestingConfig):\n    \"\"\"Test configuration with specific MAX_QUERY_COST.\"\"\"\n    MAX_QUERY_COST = 100\n\n\n@pytest.fixture\ndef app():\n    \"\"\"Create application for testing.\"\"\"\n    config = TestQueryCostConfig()\n    app = create_app(config)\n    app.config['TESTING'] = True\n    return app\n\n\n@pytest.fixture\ndef client(app):\n    \"\"\"Create test client.\"\"\"\n    return app.test_client()\n\n\nclass TestQueryCostAnalysis:\n    \"\"\"Test suite for query cost analysis functionality.\"\"\"\n    \n    def test_simple_query_passes(self, client):\n        \"\"\"Test that a simple query with low cost passes.\"\"\"\n        # Simple query requesting a few fields\n        # Cost: 1 (allMovies) + 1 (id) + 1 (title) + 1 (releaseYear) = 4\n        query = \"\"\"\n        query {\n            allMovies {\n                id\n                title\n                releaseYear\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        # Should not return a cost-related error\n        data = response.get_json()\n        \n        # Check that there's no cost-related error message\n        if 'errors' in data:\n            for error in data['errors']:\n                assert 'Query is too complex' not in error.get('message', ''), \n                    \"Simple query should not be rejected for cost\"\n    \n    def test_complex_nested_query_rejected(self, client):\n        \"\"\"Test that a highly nested/complex query is rejected.\"\"\"\n        # Create a query with many fields that exceeds the cost limit\n        # Each field costs 1, tickets cost 5\n        # This query has deep nesting and many fields\n        query = \"\"\"\n        query {\n            allMovies {\n                id\n                title\n                releaseYear\n                genre\n                duration\n                rating\n                screenings {\n                    id\n                    startTime\n                    endTime\n                    theater {\n                        id\n                        name\n                        capacity\n                        location\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                        user {\n                            id\n                            name\n                            email\n                        }\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                    }\n                }\n            }\n            allTheaters {\n                id\n                name\n                capacity\n                location\n                screenings {\n                    id\n                    startTime\n                    movie {\n                        id\n                        title\n                        genre\n                        duration\n                        rating\n                        releaseYear\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                    }\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should return an error about query complexity\n        assert 'errors' in data, \"Complex query should return errors\"\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        cost_error_found = any('Query is too complex' in msg for msg in error_messages)\n        assert cost_error_found, f\"Expected cost error, got: {error_messages}\"\n    \n    def test_list_multiplier_small_passes(self, client):\n        \"\"\"Test that a query with first: 10 multiplier passes.\"\"\"\n        # Query with first: 10 multiplier\n        # Cost: 1 (allMovies) + 10 * (1 (id) + 1 (title)) = 1 + 20 = 21\n        query = \"\"\"\n        query {\n            allMovies(first: 10) {\n                id\n                title\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should not return a cost-related error\n        if 'errors' in data:\n            for error in data['errors']:\n                assert 'Query is too complex' not in error.get('message', ''), \n                    f\"Query with first:10 should pass, got: {error.get('message')}\"\n    \n    def test_list_multiplier_large_fails(self, client):\n        \"\"\"Test that a query with first: 50 multiplier fails due to exceeding MAX_QUERY_COST.\"\"\"\n        # Query with first: 50 multiplier\n        # Cost: 1 (allMovies) + 50 * (1 (id) + 1 (title) + 1 (releaseYear)) = 1 + 150 = 151\n        # This exceeds MAX_QUERY_COST of 100\n        query = \"\"\"\n        query {\n            allMovies(first: 50) {\n                id\n                title\n                releaseYear\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should return an error about query complexity\n        assert 'errors' in data, \"Query with first:50 should return errors\"\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        cost_error_found = any('Query is too complex' in msg for msg in error_messages)\n        assert cost_error_found, f\"Expected cost error for first:50 query, got: {error_messages}\"\n    \n    def test_tickets_field_has_higher_cost(self, client):\n        \"\"\"Test that the tickets field has a higher cost (5 instead of 1).\"\"\"\n        # Query that would pass if tickets cost 1, but fails because tickets cost 5\n        # With first: 20 and tickets costing 5:\n        # Cost: 1 (screening) + 20 * (1 (id) + 5 (tickets) + 1 (id inside tickets)) = 1 + 20 * 7 = 141\n        query = \"\"\"\n        query {\n            screening(id: \"1\") {\n                id\n            }\n            allScreenings(first: 20) {\n                id\n                tickets {\n                    id\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should return an error about query complexity because tickets cost 5\n        assert 'errors' in data, \"Query with tickets field should return errors due to high cost\"\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        cost_error_found = any('Query is too complex' in msg for msg in error_messages)\n        assert cost_error_found, f\"Expected cost error due to tickets field, got: {error_messages}\"\n    \n    def test_introspection_query_allowed(self, client):\n        \"\"\"Test that introspection queries are allowed (they skip cost calculation).\"\"\"\n        query = \"\"\"\n        query {\n            __schema {\n                types {\n                    name\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should not return a cost-related error for introspection\n        if 'errors' in data:\n            for error in data['errors']:\n                assert 'Query is too complex' not in error.get('message', ''), \n                    \"Introspection query should not be rejected for cost\"\n    \n    def test_error_message_format(self, client):\n        \"\"\"Test that the error message contains the correct format with max and actual cost.\"\"\"\n        # Create a query that definitely exceeds the limit\n        query = \"\"\"\n        query {\n            allMovies(first: 100) {\n                id\n                title\n                releaseYear\n                genre\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        assert 'errors' in data\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        \n        # Check that error message contains expected format\n        found_proper_message = False\n        for msg in error_messages:\n            if 'Query is too complex' in msg and 'Max cost allowed is' in msg:\n                found_proper_message = True\n                # Verify it mentions the max cost (100)\n                assert '100' in msg, f\"Error should mention max cost of 100, got: {msg}\"\n                break\n        \n        assert found_proper_message, f\"Expected properly formatted cost error, got: {error_messages}\"\n\n\nclass TestQueryCostEdgeCases:\n    \"\"\"Test edge cases for query cost analysis.\"\"\"\n    \n    def test_empty_query_body(self, client):\n        \"\"\"Test handling of empty query body.\"\"\"\n        response = client.post(\n            '/graphql',\n            data=json.dumps({}),\n            content_type='application/json'\n        )\n        \n        # Should handle gracefully, not crash\n        assert response.status_code in [200, 400]\n    \n    def test_mutation_cost_calculated(self, client):\n        \"\"\"Test that mutations also have their cost calculated.\"\"\"\n        # Simple mutation that should pass\n        mutation = \"\"\"\n        mutation {\n            createMovie(input: {title: \"Test\", releaseYear: 2024}) {\n                movie {\n                    id\n                    title\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': mutation}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should not return a cost-related error for simple mutation\n        if 'errors' in data:\n            for error in data['errors']:\n                # Ignore other errors (like missing auth), just check no cost error\n                if 'Query is too complex' in error.get('message', ''):\n                    pytest.fail(\"Simple mutation should not be rejected for cost\")\n"
        },
        "generated_files": [
          "cinepulse_hub/config.py",
          "cinepulse_hub/app/cost_analysis.py",
          "cinepulse_hub/app/main.py",
          "cinepulse_hub/tests/test_query_cost.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7885463659147871,
              "dependency_traversal_accuracy": 0.7712438725490196,
              "cross_file_reasoning_depth": 0.45166666666666666,
              "system_thinking_score": 0.5587545656741216,
              "robustness_score": 0.4162251655629139,
              "comprehensiveness_score": 0.49449184921039224,
              "innovation_score": 0.19375,
              "solution_elegance_score": 0.5860789447669217
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09856829573934839,
              "dependency_traversal_weighted": 0.09640548406862745,
              "cross_file_reasoning_weighted": 0.05645833333333333,
              "system_thinking_weighted": 0.0698443207092652,
              "robustness_weighted": 0.052028145695364236,
              "comprehensiveness_weighted": 0.06181148115129903,
              "innovation_weighted": 0.02421875,
              "solution_elegance_weighted": 0.07325986809586521
            },
            "total_software_engineering_score": 0.5325946787931028
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.26151275634765625,
              "errors": [
                "  File \"cinepulse_hub/tests/test_query_cost.py\", line 56",
                "    assert 'Query is too complex' not in error.get('message', ''), ",
                "                                                                   ^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "cinepulse_hub/config.py",
                "cinepulse_hub/app/cost_analysis.py",
                "cinepulse_hub/app/main.py",
                "cinepulse_hub/tests/test_query_cost.py"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 4,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 4 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.42775510204081635,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.42775510204081635,
              "idc_weight": 0.2,
              "total_functional_score": 0.4255510204081633
            }
          },
          "code_quality_details": {
            "files_analyzed": 4,
            "quality_checks": {
              "cinepulse_hub/config.py": {
                "line_count": 41,
                "non_empty_lines": 27,
                "comment_lines": 3,
                "comment_ratio": 0.1111111111111111,
                "function_count": 1,
                "class_count": 4,
                "import_count": 1,
                "quality_score": 0.7999999999999999
              },
              "cinepulse_hub/app/cost_analysis.py": {
                "line_count": 121,
                "non_empty_lines": 94,
                "comment_lines": 8,
                "comment_ratio": 0.0851063829787234,
                "function_count": 7,
                "class_count": 1,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "cinepulse_hub/app/main.py": {
                "line_count": 90,
                "non_empty_lines": 68,
                "comment_lines": 10,
                "comment_ratio": 0.14705882352941177,
                "function_count": 5,
                "class_count": 1,
                "import_count": 15,
                "quality_score": 0.9999999999999999
              },
              "cinepulse_hub/tests/test_query_cost.py": {
                "line_count": 352,
                "non_empty_lines": 301,
                "comment_lines": 27,
                "comment_ratio": 0.08970099667774087,
                "function_count": 11,
                "class_count": 3,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.8349999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8639864864864865,
              "multi_session_memory_retention": 0.7938938938938938
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.43199324324324323,
              "multi_session_memory_retention_weighted": 0.3969469469469469
            },
            "total_longcontext_utilization_score": 0.82894019019019
          }
        },
        "timestamp": "2026-01-14T21:18:30.643514"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_ml_training_hard_015_feature_implementation_expert_01",
        "scenario_title": "Implement Optuna-based Hyperparameter Optimization with Pruning",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5485124755502813,
        "functional_correctness_score": 0.4163006430868167,
        "code_quality_score": 0.7824999999999999,
        "longcontext_utilization_score": 0.5275641025641025,
        "total_score": 2.7677579670128383,
        "generation_time": 123.61206007003784,
        "code_files_generated": 4,
        "total_lines_generated": 1155,
        "parsing_success": true,
        "solution_code": {
          "src/config.py": "\"\"\"Configuration module for MuseNet Alchemist platform.\n\nThis module contains all configuration settings for the platform,\nincluding hyperparameter tuning settings.\n\"\"\"\n\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Any, Optional\n\n\n@dataclass\nclass DatabaseConfig:\n    \"\"\"Database configuration settings.\"\"\"\n    host: str = \"localhost\"\n    port: int = 5432\n    name: str = \"musenet_db\"\n    user: str = \"admin\"\n    password: str = \"\"\n\n\n@dataclass\nclass ModelConfig:\n    \"\"\"Model configuration settings.\"\"\"\n    input_size: int = 128\n    hidden_size: int = 256\n    output_size: int = 64\n    num_layers: int = 3\n    dropout: float = 0.1\n    activation: str = \"relu\"\n\n\n@dataclass\nclass TrainingConfig:\n    \"\"\"Training configuration settings.\"\"\"\n    batch_size: int = 32\n    learning_rate: float = 0.001\n    num_epochs: int = 100\n    early_stopping_patience: int = 10\n    validation_split: float = 0.2\n    optimizer: str = \"adam\"\n    loss_function: str = \"mse\"\n\n\n@dataclass\nclass HyperparameterTuningConfig:\n    \"\"\"Hyperparameter tuning configuration settings.\n    \n    Attributes:\n        strategy: The optimization strategy to use. Options are:\n            - 'grid_search': Exhaustive search over specified parameter grid\n            - 'random_search': Random sampling from parameter distributions (default)\n            - 'optuna': Bayesian optimization with trial pruning support\n        n_trials: Number of trials for random_search or optuna strategies\n        n_jobs: Number of parallel jobs for tuning\n        search_space: Dictionary defining the hyperparameter search space\n        pruner: Pruner type for optuna ('median', 'percentile', 'hyperband')\n        sampler: Sampler type for optuna ('tpe', 'random', 'cmaes')\n        study_name: Name for the optuna study\n        storage: Optional storage URL for optuna study persistence\n    \"\"\"\n    strategy: str = \"random_search\"  # Options: 'grid_search', 'random_search', 'optuna'\n    n_trials: int = 100\n    n_jobs: int = 1\n    search_space: Dict[str, Any] = field(default_factory=lambda: {\n        \"learning_rate\": {\"type\": \"float\", \"low\": 1e-5, \"high\": 1e-1, \"log\": True},\n        \"batch_size\": {\"type\": \"categorical\", \"choices\": [16, 32, 64, 128]},\n        \"hidden_size\": {\"type\": \"int\", \"low\": 64, \"high\": 512, \"step\": 64},\n        \"num_layers\": {\"type\": \"int\", \"low\": 1, \"high\": 5},\n        \"dropout\": {\"type\": \"float\", \"low\": 0.0, \"high\": 0.5}\n    })\n    pruner: str = \"median\"  # Options: 'median', 'percentile', 'hyperband'\n    sampler: str = \"tpe\"  # Options: 'tpe', 'random', 'cmaes'\n    study_name: str = \"musenet_optimization\"\n    storage: Optional[str] = None\n\n\n@dataclass\nclass LoggingConfig:\n    \"\"\"Logging configuration settings.\"\"\"\n    level: str = \"INFO\"\n    format: str = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    file_path: str = \"logs/musenet.log\"\n    max_bytes: int = 10485760  # 10MB\n    backup_count: int = 5\n\n\n@dataclass\nclass APIConfig:\n    \"\"\"API configuration settings.\"\"\"\n    host: str = \"0.0.0.0\"\n    port: int = 8000\n    debug: bool = False\n    cors_origins: List[str] = field(default_factory=lambda: [\"*\"])\n    api_prefix: str = \"/api/v1\"\n\n\n@dataclass\nclass Config:\n    \"\"\"Main configuration class containing all settings.\"\"\"\n    database: DatabaseConfig = field(default_factory=DatabaseConfig)\n    model: ModelConfig = field(default_factory=ModelConfig)\n    training: TrainingConfig = field(default_factory=TrainingConfig)\n    hyperparameter_tuning: HyperparameterTuningConfig = field(default_factory=HyperparameterTuningConfig)\n    logging: LoggingConfig = field(default_factory=LoggingConfig)\n    api: APIConfig = field(default_factory=APIConfig)\n\n    @classmethod\n    def from_env(cls) -> \"Config\":\n        \"\"\"Create configuration from environment variables.\"\"\"\n        config = cls()\n        \n        # Database config from env\n        config.database.host = os.getenv(\"DB_HOST\", config.database.host)\n        config.database.port = int(os.getenv(\"DB_PORT\", config.database.port))\n        config.database.name = os.getenv(\"DB_NAME\", config.database.name)\n        config.database.user = os.getenv(\"DB_USER\", config.database.user)\n        config.database.password = os.getenv(\"DB_PASSWORD\", config.database.password)\n        \n        # Training config from env\n        config.training.batch_size = int(os.getenv(\"BATCH_SIZE\", config.training.batch_size))\n        config.training.learning_rate = float(os.getenv(\"LEARNING_RATE\", config.training.learning_rate))\n        config.training.num_epochs = int(os.getenv(\"NUM_EPOCHS\", config.training.num_epochs))\n        \n        # Hyperparameter tuning config from env\n        config.hyperparameter_tuning.strategy = os.getenv(\n            \"HP_TUNING_STRATEGY\", config.hyperparameter_tuning.strategy\n        )\n        config.hyperparameter_tuning.n_trials = int(\n            os.getenv(\"HP_TUNING_N_TRIALS\", config.hyperparameter_tuning.n_trials)\n        )\n        \n        # API config from env\n        config.api.host = os.getenv(\"API_HOST\", config.api.host)\n        config.api.port = int(os.getenv(\"API_PORT\", config.api.port))\n        config.api.debug = os.getenv(\"API_DEBUG\", \"false\").lower() == \"true\"\n        \n        return config\n\n\n# Global configuration instance\nconfig = Config.from_env()\n\n\ndef get_config() -> Config:\n    \"\"\"Get the global configuration instance.\"\"\"\n    return config\n\n\ndef update_config(**kwargs) -> Config:\n    \"\"\"Update configuration with provided keyword arguments.\"\"\"\n    global config\n    for key, value in kwargs.items():\n        if hasattr(config, key):\n            setattr(config, key, value)\n    return config\n",
          "src/module_1.py": "\"\"\"Core model training module for MuseNet Alchemist platform.\n\nThis module contains the primary training functions and training loop\nimplementation with support for Optuna trial pruning.\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, Optional, Tuple, List, Callable\nimport numpy as np\n\ntry:\n    import optuna\n    OPTUNA_AVAILABLE = True\nexcept ImportError:\n    OPTUNA_AVAILABLE = False\n    optuna = None\n\nfrom src.config import get_config, TrainingConfig\n\nlogger = logging.getLogger(__name__)\n\n\nclass EarlyStopping:\n    \"\"\"Early stopping handler for training.\"\"\"\n    \n    def __init__(self, patience: int = 10, min_delta: float = 0.0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.should_stop = False\n    \n    def __call__(self, val_loss: float) -> bool:\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.should_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n        return self.should_stop\n\n\nclass ModelTrainer:\n    \"\"\"Main model trainer class with Optuna pruning support.\"\"\"\n    \n    def __init__(self, model: Any, config: Optional[TrainingConfig] = None):\n        self.model = model\n        self.config = config or get_config().training\n        self.training_history: List[Dict[str, float]] = []\n        self.best_model_state = None\n        self.best_val_loss = float('inf')\n    \n    def train(\n        self,\n        train_data: Any,\n        val_data: Any,\n        optuna_trial: Optional[\"optuna.Trial\"] = None,\n        callbacks: Optional[List[Callable]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Train the model with optional Optuna trial pruning.\n        \n        Args:\n            train_data: Training dataset\n            val_data: Validation dataset\n            optuna_trial: Optional Optuna trial object for hyperparameter\n                optimization with pruning support. When provided, the training\n                loop will report intermediate values and check for pruning.\n            callbacks: Optional list of callback functions\n        \n        Returns:\n            Dictionary containing training results and metrics\n        \n        Raises:\n            optuna.TrialPruned: If the trial should be pruned (only when\n                optuna_trial is provided and pruning is triggered)\n        \"\"\"\n        logger.info(\"Starting model training\")\n        \n        early_stopping = EarlyStopping(\n            patience=self.config.early_stopping_patience\n        )\n        \n        self.training_history = []\n        \n        for epoch in range(self.config.num_epochs):\n            # Training step\n            train_loss = self._train_epoch(train_data, epoch)\n            \n            # Validation step\n            val_loss = self._validate_epoch(val_data, epoch)\n            \n            # Record history\n            epoch_metrics = {\n                \"epoch\": epoch,\n                \"train_loss\": train_loss,\n                \"val_loss\": val_loss\n            }\n            self.training_history.append(epoch_metrics)\n            \n            logger.info(\n                f\"Epoch {epoch + 1}/{self.config.num_epochs} - \"\n                f\"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\"\n            )\n            \n            # Update best model\n            if val_loss < self.best_val_loss:\n                self.best_val_loss = val_loss\n                self.best_model_state = self._get_model_state()\n            \n            # Optuna pruning integration\n            if optuna_trial is not None:\n                if not OPTUNA_AVAILABLE:\n                    raise ImportError(\n                        \"Optuna is required for trial pruning but is not installed. \"\n                        \"Install it with: pip install optuna\"\n                    )\n                \n                # Report intermediate value to Optuna\n                optuna_trial.report(val_loss, epoch)\n                \n                # Check if trial should be pruned\n                if optuna_trial.should_prune():\n                    logger.info(\n                        f\"Trial {optuna_trial.number} pruned at epoch {epoch + 1}\"\n                    )\n                    raise optuna.TrialPruned()\n            \n            # Execute callbacks\n            if callbacks:\n                for callback in callbacks:\n                    callback(epoch, epoch_metrics)\n            \n            # Check early stopping\n            if early_stopping(val_loss):\n                logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n                break\n        \n        # Restore best model\n        if self.best_model_state is not None:\n            self._set_model_state(self.best_model_state)\n        \n        return {\n            \"final_train_loss\": self.training_history[-1][\"train_loss\"],\n            \"final_val_loss\": self.training_history[-1][\"val_loss\"],\n            \"best_val_loss\": self.best_val_loss,\n            \"epochs_trained\": len(self.training_history),\n            \"history\": self.training_history\n        }\n    \n    def _train_epoch(self, train_data: Any, epoch: int) -> float:\n        \"\"\"Execute one training epoch.\"\"\"\n        # Placeholder implementation - actual implementation would use\n        # the specific ML framework (PyTorch, TensorFlow, etc.)\n        train_loss = np.random.uniform(0.1, 1.0) * (1 / (epoch + 1))\n        return train_loss\n    \n    def _validate_epoch(self, val_data: Any, epoch: int) -> float:\n        \"\"\"Execute one validation epoch.\"\"\"\n        # Placeholder implementation\n        val_loss = np.random.uniform(0.1, 1.0) * (1 / (epoch + 1))\n        return val_loss\n    \n    def _get_model_state(self) -> Any:\n        \"\"\"Get current model state for checkpointing.\"\"\"\n        # Placeholder - would return actual model state dict\n        return {\"state\": \"model_state\"}\n    \n    def _set_model_state(self, state: Any) -> None:\n        \"\"\"Set model state from checkpoint.\"\"\"\n        # Placeholder - would load actual model state\n        pass\n\n\ndef train_model(\n    model: Any,\n    train_data: Any,\n    val_data: Any,\n    config: Optional[TrainingConfig] = None,\n    optuna_trial: Optional[\"optuna.Trial\"] = None,\n    callbacks: Optional[List[Callable]] = None\n) -> Dict[str, Any]:\n    \"\"\"Convenience function for training a model.\n    \n    This function wraps the ModelTrainer class for simpler usage.\n    \n    Args:\n        model: The model to train\n        train_data: Training dataset\n        val_data: Validation dataset\n        config: Optional training configuration\n        optuna_trial: Optional Optuna trial object for hyperparameter\n            optimization with pruning support. When provided:\n            - Intermediate validation losses are reported to Optuna after each epoch\n            - The trial is checked for pruning using trial.should_prune()\n            - If pruning is triggered, optuna.TrialPruned exception is raised\n        callbacks: Optional list of callback functions\n    \n    Returns:\n        Dictionary containing training results and metrics\n    \n    Raises:\n        optuna.TrialPruned: If the trial should be pruned during Optuna optimization\n    \"\"\"\n    trainer = ModelTrainer(model, config)\n    return trainer.train(\n        train_data,\n        val_data,\n        optuna_trial=optuna_trial,\n        callbacks=callbacks\n    )\n\n\ndef create_model(model_config: Dict[str, Any]) -> Any:\n    \"\"\"Create a model instance from configuration.\"\"\"\n    # Placeholder implementation\n    logger.info(f\"Creating model with config: {model_config}\")\n    return {\"model\": \"placeholder\", \"config\": model_config}\n\n\ndef evaluate_model(model: Any, test_data: Any) -> Dict[str, float]:\n    \"\"\"Evaluate a trained model on test data.\"\"\"\n    # Placeholder implementation\n    return {\n        \"test_loss\": np.random.uniform(0.1, 0.5),\n        \"accuracy\": np.random.uniform(0.7, 0.95)\n    }\n",
          "src/module_10.py": "\"\"\"Hyperparameter tuning orchestrator module for MuseNet Alchemist platform.\n\nThis module handles hyperparameter optimization using various strategies\nincluding grid search, random search, and Optuna-based Bayesian optimization.\n\"\"\"\n\nimport logging\nimport itertools\nfrom typing import Dict, Any, Optional, List, Tuple, Callable\nimport numpy as np\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\n\ntry:\n    import optuna\n    from optuna.pruners import MedianPruner, PercentilePruner, HyperbandPruner\n    from optuna.samplers import TPESampler, RandomSampler, CmaEsSampler\n    OPTUNA_AVAILABLE = True\nexcept ImportError:\n    OPTUNA_AVAILABLE = False\n    optuna = None\n\nfrom src.config import get_config, HyperparameterTuningConfig\nfrom src.module_1 import train_model, create_model\n\nlogger = logging.getLogger(__name__)\n\n\nclass HyperparameterTuner:\n    \"\"\"Main hyperparameter tuning orchestrator class.\"\"\"\n    \n    def __init__(\n        self,\n        config: Optional[HyperparameterTuningConfig] = None,\n        train_data: Any = None,\n        val_data: Any = None\n    ):\n        self.config = config or get_config().hyperparameter_tuning\n        self.train_data = train_data\n        self.val_data = val_data\n        self.results: List[Dict[str, Any]] = []\n        self.best_params: Optional[Dict[str, Any]] = None\n        self.best_score: float = float('inf')\n    \n    def tune(self) -> Dict[str, Any]:\n        \"\"\"Run hyperparameter tuning based on configured strategy.\n        \n        Returns:\n            Dictionary containing best parameters and tuning results\n        \"\"\"\n        strategy = self.config.strategy\n        logger.info(f\"Starting hyperparameter tuning with strategy: {strategy}\")\n        \n        if strategy == \"grid_search\":\n            return self._run_grid_search()\n        elif strategy == \"random_search\":\n            return self._run_random_search()\n        elif strategy == \"optuna\":\n            return self._run_optuna_optimization()\n        else:\n            raise ValueError(\n                f\"Unknown tuning strategy: {strategy}. \"\n                f\"Supported strategies: 'grid_search', 'random_search', 'optuna'\"\n            )\n    \n    def _run_grid_search(self) -> Dict[str, Any]:\n        \"\"\"Execute grid search hyperparameter tuning.\"\"\"\n        logger.info(\"Running grid search optimization\")\n        \n        # Generate all parameter combinations\n        param_grid = self._build_param_grid()\n        param_names = list(param_grid.keys())\n        param_values = list(param_grid.values())\n        \n        all_combinations = list(itertools.product(*param_values))\n        logger.info(f\"Total combinations to evaluate: {len(all_combinations)}\")\n        \n        for i, combination in enumerate(all_combinations):\n            params = dict(zip(param_names, combination))\n            logger.info(f\"Evaluating combination {i + 1}/{len(all_combinations)}: {params}\")\n            \n            try:\n                score = self._evaluate_params(params)\n                self.results.append({\"params\": params, \"score\": score})\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_params = params\n                    logger.info(f\"New best score: {score} with params: {params}\")\n            except Exception as e:\n                logger.error(f\"Error evaluating params {params}: {e}\")\n                self.results.append({\"params\": params, \"score\": float('inf'), \"error\": str(e)})\n        \n        return self._build_results()\n    \n    def _run_random_search(self) -> Dict[str, Any]:\n        \"\"\"Execute random search hyperparameter tuning.\"\"\"\n        logger.info(f\"Running random search optimization with {self.config.n_trials} trials\")\n        \n        for trial_num in range(self.config.n_trials):\n            params = self._sample_random_params()\n            logger.info(f\"Trial {trial_num + 1}/{self.config.n_trials}: {params}\")\n            \n            try:\n                score = self._evaluate_params(params)\n                self.results.append({\"params\": params, \"score\": score})\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_params = params\n                    logger.info(f\"New best score: {score} with params: {params}\")\n            except Exception as e:\n                logger.error(f\"Error evaluating params {params}: {e}\")\n                self.results.append({\"params\": params, \"score\": float('inf'), \"error\": str(e)})\n        \n        return self._build_results()\n    \n    def _run_optuna_optimization(self) -> Dict[str, Any]:\n        \"\"\"Execute Optuna-based Bayesian optimization with pruning.\"\"\"\n        if not OPTUNA_AVAILABLE:\n            raise ImportError(\n                \"Optuna is required for 'optuna' strategy but is not installed. \"\n                \"Install it with: pip install optuna\"\n            )\n        \n        logger.info(f\"Running Optuna optimization with {self.config.n_trials} trials\")\n        \n        # Create pruner\n        pruner = self._create_pruner()\n        \n        # Create sampler\n        sampler = self._create_sampler()\n        \n        # Create study\n        study = optuna.create_study(\n            study_name=self.config.study_name,\n            direction=\"minimize\",\n            pruner=pruner,\n            sampler=sampler,\n            storage=self.config.storage,\n            load_if_exists=True\n        )\n        \n        # Define objective function\n        def objective(trial: optuna.Trial) -> float:\n            return self._optuna_objective(trial)\n        \n        # Run optimization\n        study.optimize(\n            objective,\n            n_trials=self.config.n_trials,\n            n_jobs=self.config.n_jobs,\n            show_progress_bar=True\n        )\n        \n        # Store results\n        self.best_params = study.best_params\n        self.best_score = study.best_value\n        \n        for trial in study.trials:\n            self.results.append({\n                \"params\": trial.params,\n                \"score\": trial.value if trial.value is not None else float('inf'),\n                \"state\": str(trial.state),\n                \"trial_number\": trial.number\n            })\n        \n        logger.info(f\"Optuna optimization complete. Best score: {self.best_score}\")\n        logger.info(f\"Best parameters: {self.best_params}\")\n        \n        # Log pruning statistics\n        pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n        complete_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n        logger.info(f\"Pruned trials: {pruned_trials}, Complete trials: {complete_trials}\")\n        \n        return self._build_results(study=study)\n    \n    def _optuna_objective(self, trial: optuna.Trial) -> float:\n        \"\"\"Objective function for Optuna optimization.\n        \n        This function suggests hyperparameters using the trial object,\n        creates a model with those parameters, and trains it while\n        passing the trial object for pruning support.\n        \n        Args:\n            trial: Optuna trial object for parameter suggestion and pruning\n        \n        Returns:\n            Validation loss (objective value to minimize)\n        \n        Raises:\n            optuna.TrialPruned: If the trial is pruned during training\n        \"\"\"\n        # Suggest hyperparameters based on search space\n        params = self._suggest_optuna_params(trial)\n        \n        logger.info(f\"Trial {trial.number}: Evaluating params: {params}\")\n        \n        # Create model with suggested parameters\n        model = create_model(params)\n        \n        # Train model with trial object for pruning\n        # The trial object is passed to enable intermediate value reporting\n        # and pruning of unpromising trials\n        training_result = train_model(\n            model=model,\n            train_data=self.train_data,\n            val_data=self.val_data,\n            optuna_trial=trial  # Pass trial for pruning integration\n        )\n        \n        return training_result[\"best_val_loss\"]\n    \n    def _suggest_optuna_params(self, trial: optuna.Trial) -> Dict[str, Any]:\n        \"\"\"Suggest hyperparameters using Optuna trial.\n        \n        Args:\n            trial: Optuna trial object\n        \n        Returns:\n            Dictionary of suggested hyperparameters\n        \"\"\"\n        params = {}\n        \n        for param_name, param_config in self.config.search_space.items():\n            param_type = param_config.get(\"type\", \"float\")\n            \n            if param_type == \"float\":\n                params[param_name] = trial.suggest_float(\n                    param_name,\n                    param_config[\"low\"],\n                    param_config[\"high\"],\n                    log=param_config.get(\"log\", False)\n                )\n            elif param_type == \"int\":\n                params[param_name] = trial.suggest_int(\n                    param_name,\n                    param_config[\"low\"],\n                    param_config[\"high\"],\n                    step=param_config.get(\"step\", 1)\n                )\n            elif param_type == \"categorical\":\n                params[param_name] = trial.suggest_categorical(\n                    param_name,\n                    param_config[\"choices\"]\n                )\n            else:\n                raise ValueError(f\"Unknown parameter type: {param_type}\")\n        \n        return params\n    \n    def _create_pruner(self) -> \"optuna.pruners.BasePruner\":\n        \"\"\"Create Optuna pruner based on configuration.\"\"\"\n        pruner_type = self.config.pruner.lower()\n        \n        if pruner_type == \"median\":\n            return MedianPruner(\n                n_startup_trials=5,\n                n_warmup_steps=10,\n                interval_steps=1\n            )\n        elif pruner_type == \"percentile\":\n            return PercentilePruner(\n                percentile=25.0,\n                n_startup_trials=5,\n                n_warmup_steps=10\n            )\n        elif pruner_type == \"hyperband\":\n            return HyperbandPruner(\n                min_resource=1,\n                max_resource=100,\n                reduction_factor=3\n            )\n        else:\n            logger.warning(f\"Unknown pruner type: {pruner_type}, using MedianPruner\")\n            return MedianPruner()\n    \n    def _create_sampler(self) -> \"optuna.samplers.BaseSampler\":\n        \"\"\"Create Optuna sampler based on configuration.\"\"\"\n        sampler_type = self.config.sampler.lower()\n        \n        if sampler_type == \"tpe\":\n            return TPESampler(n_startup_trials=10)\n        elif sampler_type == \"random\":\n            return RandomSampler()\n        elif sampler_type == \"cmaes\":\n            return CmaEsSampler()\n        else:\n            logger.warning(f\"Unknown sampler type: {sampler_type}, using TPESampler\")\n            return TPESampler()\n    \n    def _build_param_grid(self) -> Dict[str, List[Any]]:\n        \"\"\"Build parameter grid for grid search.\"\"\"\n        param_grid = {}\n        \n        for param_name, param_config in self.config.search_space.items():\n            param_type = param_config.get(\"type\", \"float\")\n            \n            if param_type == \"categorical\":\n                param_grid[param_name] = param_config[\"choices\"]\n            elif param_type == \"int\":\n                step = param_config.get(\"step\", 1)\n                param_grid[param_name] = list(range(\n                    param_config[\"low\"],\n                    param_config[\"high\"] + 1,\n                    step\n                ))\n            elif param_type == \"float\":\n                # For grid search, create discrete points for float params\n                n_points = param_config.get(\"n_points\", 5)\n                if param_config.get(\"log\", False):\n                    param_grid[param_name] = list(np.logspace(\n                        np.log10(param_config[\"low\"]),\n                        np.log10(param_config[\"high\"]),\n                        n_points\n                    ))\n                else:\n                    param_grid[param_name] = list(np.linspace(\n                        param_config[\"low\"],\n                        param_config[\"high\"],\n                        n_points\n                    ))\n        \n        return param_grid\n    \n    def _sample_random_params(self) -> Dict[str, Any]:\n        \"\"\"Sample random parameters for random search.\"\"\"\n        params = {}\n        \n        for param_name, param_config in self.config.search_space.items():\n            param_type = param_config.get(\"type\", \"float\")\n            \n            if param_type == \"categorical\":\n                params[param_name] = np.random.choice(param_config[\"choices\"])\n            elif param_type == \"int\":\n                params[param_name] = np.random.randint(\n                    param_config[\"low\"],\n                    param_config[\"high\"] + 1\n                )\n            elif param_type == \"float\":\n                if param_config.get(\"log\", False):\n                    params[param_name] = np.exp(np.random.uniform(\n                        np.log(param_config[\"low\"]),\n                        np.log(param_config[\"high\"])\n                    ))\n                else:\n                    params[param_name] = np.random.uniform(\n                        param_config[\"low\"],\n                        param_config[\"high\"]\n                    )\n        \n        return params\n    \n    def _evaluate_params(self, params: Dict[str, Any]) -> float:\n        \"\"\"Evaluate a set of hyperparameters.\"\"\"\n        model = create_model(params)\n        result = train_model(\n            model=model,\n            train_data=self.train_data,\n            val_data=self.val_data\n        )\n        return result[\"best_val_loss\"]\n    \n    def _build_results(self, study: Optional[\"optuna.Study\"] = None) -> Dict[str, Any]:\n        \"\"\"Build final results dictionary.\"\"\"\n        results = {\n            \"strategy\": self.config.strategy,\n            \"best_params\": self.best_params,\n            \"best_score\": self.best_score,\n            \"n_trials\": len(self.results),\n            \"all_results\": self.results\n        }\n        \n        if study is not None:\n            results[\"optuna_study_name\"] = study.study_name\n            results[\"pruned_trials\"] = len([\n                t for t in study.trials \n                if t.state == optuna.trial.TrialState.PRUNED\n            ])\n            results[\"complete_trials\"] = len([\n                t for t in study.trials \n                if t.state == optuna.trial.TrialState.COMPLETE\n            ])\n        \n        return results\n\n\ndef run_hyperparameter_tuning(\n    train_data: Any,\n    val_data: Any,\n    config: Optional[HyperparameterTuningConfig] = None\n) -> Dict[str, Any]:\n    \"\"\"Convenience function to run hyperparameter tuning.\n    \n    Args:\n        train_data: Training dataset\n        val_data: Validation dataset\n        config: Optional hyperparameter tuning configuration\n    \n    Returns:\n        Dictionary containing tuning results\n    \"\"\"\n    tuner = HyperparameterTuner(\n        config=config,\n        train_data=train_data,\n        val_data=val_data\n    )\n    return tuner.tune()\n",
          "docs/api.md": "# MuseNet Alchemist API Documentation\n\n## Overview\n\nThe MuseNet Alchemist API provides endpoints for model training, evaluation, and hyperparameter tuning. This document describes the available endpoints and their usage.\n\n## Base URL\n\n```\nhttp://localhost:8000/api/v1\n```\n\n## Authentication\n\nAll API requests require authentication using a Bearer token in the Authorization header:\n\n```\nAuthorization: Bearer <your_token>\n```\n\n## Endpoints\n\n### Health Check\n\n**GET** `/health`\n\nCheck the health status of the API.\n\n**Response:**\n```json\n{\n    \"status\": \"healthy\",\n    \"version\": \"1.0.0\"\n}\n```\n\n---\n\n### Model Training\n\n**POST** `/models/train`\n\nStart a new model training job.\n\n**Request Body:**\n```json\n{\n    \"model_name\": \"my_model\",\n    \"dataset_id\": \"dataset_123\",\n    \"config\": {\n        \"batch_size\": 32,\n        \"learning_rate\": 0.001,\n        \"num_epochs\": 100\n    }\n}\n```\n\n**Response:**\n```json\n{\n    \"job_id\": \"job_456\",\n    \"status\": \"started\",\n    \"message\": \"Training job started successfully\"\n}\n```\n\n---\n\n### Model Evaluation\n\n**POST** `/models/{model_id}/evaluate`\n\nEvaluate a trained model on a test dataset.\n\n**Path Parameters:**\n- `model_id`: The ID of the model to evaluate\n\n**Request Body:**\n```json\n{\n    \"test_dataset_id\": \"test_dataset_789\",\n    \"metrics\": [\"accuracy\", \"loss\", \"f1_score\"]\n}\n```\n\n**Response:**\n```json\n{\n    \"model_id\": \"model_123\",\n    \"metrics\": {\n        \"accuracy\": 0.92,\n        \"loss\": 0.23,\n        \"f1_score\": 0.89\n    }\n}\n```\n\n---\n\n### Hyperparameter Tuning\n\n**POST** `/tuning/start`\n\nStart a hyperparameter tuning job. This endpoint supports multiple optimization strategies to find the best model configuration.\n\n**Request Body:**\n```json\n{\n    \"model_name\": \"my_model\",\n    \"dataset_id\": \"dataset_123\",\n    \"strategy\": \"optuna\",\n    \"n_trials\": 100,\n    \"search_space\": {\n        \"learning_rate\": {\n            \"type\": \"float\",\n            \"low\": 1e-5,\n            \"high\": 1e-1,\n            \"log\": true\n        },\n        \"batch_size\": {\n            \"type\": \"categorical\",\n            \"choices\": [16, 32, 64, 128]\n        },\n        \"hidden_size\": {\n            \"type\": \"int\",\n            \"low\": 64,\n            \"high\": 512,\n            \"step\": 64\n        },\n        \"dropout\": {\n            \"type\": \"float\",\n            \"low\": 0.0,\n            \"high\": 0.5\n        }\n    }\n}\n```\n\n**Strategy Options:**\n\n| Strategy | Description |\n|----------|-------------|\n| `grid_search` | Exhaustive search over all parameter combinations. Best for small search spaces with discrete values. |\n| `random_search` | Random sampling from parameter distributions. More efficient than grid search for larger spaces. |\n| `optuna` | Bayesian optimization using the Optuna framework. Uses intelligent sampling (TPE by default) and supports **trial pruning** to automatically stop unpromising training runs early, significantly reducing computation time. This is the recommended strategy for complex search spaces. |\n\n**Optuna-Specific Options:**\n\nWhen using `strategy: \"optuna\"`, you can also specify:\n\n```json\n{\n    \"strategy\": \"optuna\",\n    \"n_trials\": 100,\n    \"pruner\": \"median\",\n    \"sampler\": \"tpe\",\n    \"study_name\": \"my_optimization_study\",\n    \"search_space\": { ... }\n}\n```\n\n- `pruner`: Pruning algorithm (`\"median\"`, `\"percentile\"`, `\"hyperband\"`)\n- `sampler`: Sampling algorithm (`\"tpe\"`, `\"random\"`, `\"cmaes\"`)\n- `study_name`: Name for the Optuna study (useful for resuming)\n\n**Response:**\n```json\n{\n    \"job_id\": \"tuning_job_789\",\n    \"status\": \"started\",\n    \"strategy\": \"optuna\",\n    \"n_trials\": 100,\n    \"message\": \"Hyperparameter tuning job started successfully\"\n}\n```\n\n---\n\n### Get Tuning Results\n\n**GET** `/tuning/{job_id}/results`\n\nGet the results of a hyperparameter tuning job.\n\n**Path Parameters:**\n- `job_id`: The ID of the tuning job\n\n**Response:**\n```json\n{\n    \"job_id\": \"tuning_job_789\",\n    \"status\": \"completed\",\n    \"strategy\": \"optuna\",\n    \"best_params\": {\n        \"learning_rate\": 0.0023,\n        \"batch_size\": 64,\n        \"hidden_size\": 256,\n        \"dropout\": 0.15\n    },\n    \"best_score\": 0.0892,\n    \"n_trials\": 100,\n    \"pruned_trials\": 34,\n    \"complete_trials\": 66,\n    \"all_results\": [\n        {\n            \"params\": { ... },\n            \"score\": 0.12,\n            \"state\": \"COMPLETE\",\n            \"trial_number\": 0\n        },\n        {\n            \"params\": { ... },\n            \"score\": null,\n            \"state\": \"PRUNED\",\n            \"trial_number\": 1\n        }\n    ]\n}\n```\n\n---\n\n### List Models\n\n**GET** `/models`\n\nList all available models.\n\n**Query Parameters:**\n- `limit` (optional): Maximum number of models to return (default: 20)\n- `offset` (optional): Offset for pagination (default: 0)\n\n**Response:**\n```json\n{\n    \"models\": [\n        {\n            \"id\": \"model_123\",\n            \"name\": \"my_model\",\n            \"created_at\": \"2024-01-15T10:30:00Z\",\n            \"status\": \"trained\"\n        }\n    ],\n    \"total\": 1,\n    \"limit\": 20,\n    \"offset\": 0\n}\n```\n\n---\n\n### Get Model Details\n\n**GET** `/models/{model_id}`\n\nGet detailed information about a specific model.\n\n**Path Parameters:**\n- `model_id`: The ID of the model\n\n**Response:**\n```json\n{\n    \"id\": \"model_123\",\n    \"name\": \"my_model\",\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"status\": \"trained\",\n    \"config\": {\n        \"input_size\": 128,\n        \"hidden_size\": 256,\n        \"output_size\": 64,\n        \"num_layers\": 3\n    },\n    \"training_metrics\": {\n        \"final_train_loss\": 0.05,\n        \"final_val_loss\": 0.08,\n        \"epochs_trained\": 85\n    }\n}\n```\n\n---\n\n### Delete Model\n\n**DELETE** `/models/{model_id}`\n\nDelete a model.\n\n**Path Parameters:**\n- `model_id`: The ID of the model to delete\n\n**Response:**\n```json\n{\n    \"message\": \"Model deleted successfully\",\n    \"model_id\": \"model_123\"\n}\n```\n\n---\n\n## Error Responses\n\nAll endpoints may return the following error responses:\n\n### 400 Bad Request\n```json\n{\n    \"error\": \"Bad Request\",\n    \"message\": \"Invalid request body\",\n    \"details\": { ... }\n}\n```\n\n### 401 Unauthorized\n```json\n{\n    \"error\": \"Unauthorized\",\n    \"message\": \"Invalid or missing authentication token\"\n}\n```\n\n### 404 Not Found\n```json\n{\n    \"error\": \"Not Found\",\n    \"message\": \"Resource not found\"\n}\n```\n\n### 500 Internal Server Error\n```json\n{\n    \"error\": \"Internal Server Error\",\n    \"message\": \"An unexpected error occurred\"\n}\n```\n\n---\n\n## Rate Limiting\n\nThe API implements rate limiting to ensure fair usage:\n- 100 requests per minute per API key\n- 1000 requests per hour per API key\n\nRate limit headers are included in all responses:\n```\nX-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1642248000\n```\n\n---\n\n## Webhooks\n\nYou can configure webhooks to receive notifications when long-running jobs complete. Contact support to set up webhook endpoints for your account.\n"
        },
        "generated_files": [
          "src/config.py",
          "src/module_1.py",
          "src/module_10.py",
          "docs/api.md"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.864642857142857,
              "dependency_traversal_accuracy": 0.6596451997614788,
              "cross_file_reasoning_depth": 0.27145833333333336,
              "system_thinking_score": 0.6811528059499662,
              "robustness_score": 0.4,
              "comprehensiveness_score": 0.5162673533363188,
              "innovation_score": 0.39807900432900434,
              "solution_elegance_score": 0.5968542505492919
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.10808035714285713,
              "dependency_traversal_weighted": 0.08245564997018485,
              "cross_file_reasoning_weighted": 0.03393229166666667,
              "system_thinking_weighted": 0.08514410074374577,
              "robustness_weighted": 0.05,
              "comprehensiveness_weighted": 0.06453341916703985,
              "innovation_weighted": 0.04975987554112554,
              "solution_elegance_weighted": 0.07460678131866148
            },
            "total_software_engineering_score": 0.5485124755502813
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.2769598960876465,
              "errors": [
                "  File \"docs/api.py\", line 5",
                "    The MuseNet Alchemist API provides endpoints for model training, evaluation, and hyperparameter tuning. This document describes the available endpoints and their usage.",
                "        ^^^^^^^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "src/config.py",
                "src/module_1.py",
                "src/module_10.py",
                "docs/api.md"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 4,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 4 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.3815032154340836,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.3815032154340836,
              "idc_weight": 0.2,
              "total_functional_score": 0.4163006430868167
            }
          },
          "code_quality_details": {
            "files_analyzed": 4,
            "quality_checks": {
              "src/config.py": {
                "line_count": 157,
                "non_empty_lines": 127,
                "comment_lines": 5,
                "comment_ratio": 0.03937007874015748,
                "function_count": 3,
                "class_count": 10,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "src/module_1.py": {
                "line_count": 230,
                "non_empty_lines": 185,
                "comment_lines": 17,
                "comment_ratio": 0.0918918918918919,
                "function_count": 11,
                "class_count": 4,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "src/module_10.py": {
                "line_count": 408,
                "non_empty_lines": 337,
                "comment_lines": 14,
                "comment_ratio": 0.04154302670623145,
                "function_count": 15,
                "class_count": 21,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "docs/api.md": {
                "line_count": 360,
                "non_empty_lines": 284,
                "comment_lines": 20,
                "comment_ratio": 0.07042253521126761,
                "function_count": 0,
                "class_count": 0,
                "import_count": 1,
                "quality_score": 0.7
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7824999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.5708333333333332,
              "multi_session_memory_retention": 0.48429487179487163
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.2854166666666666,
              "multi_session_memory_retention_weighted": 0.24214743589743581
            },
            "total_longcontext_utilization_score": 0.5275641025641025
          }
        },
        "timestamp": "2026-01-14T21:20:35.136885"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_data_streaming_expert_085_feature_implementation_expert_01",
        "scenario_title": "Implement a Dead-Letter Queue (DLQ) for Invalid Data Records",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5339356060313756,
        "functional_correctness_score": 0.45150392749244717,
        "code_quality_score": 0.7719999999999999,
        "longcontext_utilization_score": 0.5109309309309309,
        "total_score": 2.7725925687668873,
        "generation_time": 92.88544511795044,
        "code_files_generated": 5,
        "total_lines_generated": 838,
        "parsing_success": true,
        "solution_code": {
          "src/config.py": "\"\"\"Configuration module for PulseStream Nexus.\"\"\"\nimport os\n\n# Existing configuration parameters\nDEBUG = os.environ.get('DEBUG', 'false').lower() == 'true'\nLOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')\nMAX_BATCH_SIZE = int(os.environ.get('MAX_BATCH_SIZE', '1000'))\nPROCESSING_TIMEOUT = int(os.environ.get('PROCESSING_TIMEOUT', '30'))\nRETRY_ATTEMPTS = int(os.environ.get('RETRY_ATTEMPTS', '3'))\n\n# Database configuration\nDB_HOST = os.environ.get('DB_HOST', 'localhost')\nDB_PORT = int(os.environ.get('DB_PORT', '5432'))\nDB_NAME = os.environ.get('DB_NAME', 'pulsestream')\nDB_USER = os.environ.get('DB_USER', 'admin')\nDB_PASSWORD = os.environ.get('DB_PASSWORD', '')\n\n# Streaming configuration\nSTREAM_BUFFER_SIZE = int(os.environ.get('STREAM_BUFFER_SIZE', '10000'))\nSTREAM_FLUSH_INTERVAL = int(os.environ.get('STREAM_FLUSH_INTERVAL', '5'))\n\n# Dead-Letter Queue (DLQ) Configuration\nDLQ_ENABLED = os.environ.get('DLQ_ENABLED', 'true').lower() == 'true'\nDLQ_STORAGE_TYPE = os.environ.get('DLQ_STORAGE_TYPE', 'local_file')\nDLQ_FILE_PATH = os.environ.get('DLQ_FILE_PATH', '/var/log/pulsestream/dlq.jsonl')\n\n\ndef get_config():\n    \"\"\"Return configuration as a dictionary.\"\"\"\n    return {\n        'debug': DEBUG,\n        'log_level': LOG_LEVEL,\n        'max_batch_size': MAX_BATCH_SIZE,\n        'processing_timeout': PROCESSING_TIMEOUT,\n        'retry_attempts': RETRY_ATTEMPTS,\n        'db_host': DB_HOST,\n        'db_port': DB_PORT,\n        'db_name': DB_NAME,\n        'db_user': DB_USER,\n        'db_password': DB_PASSWORD,\n        'stream_buffer_size': STREAM_BUFFER_SIZE,\n        'stream_flush_interval': STREAM_FLUSH_INTERVAL,\n        'dlq_enabled': DLQ_ENABLED,\n        'dlq_storage_type': DLQ_STORAGE_TYPE,\n        'dlq_file_path': DLQ_FILE_PATH,\n    }\n",
          "src/dlq_handler.py": "\"\"\"Dead-Letter Queue Handler for PulseStream Nexus.\n\nThis module provides functionality to capture and store invalid data records\nthat fail validation, enabling later analysis and debugging.\n\"\"\"\nimport json\nimport os\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\nfrom src.utils import MonitoringClient\n\nlogger = logging.getLogger(__name__)\n\n\nclass DLQHandler:\n    \"\"\"Handler for routing invalid records to the Dead-Letter Queue.\n    \n    This handler writes failed validation records to a configurable storage\n    location (currently supports local file storage) and tracks metrics.\n    \"\"\"\n    \n    DLQ_METRIC_NAME = 'pulsestream.nexus.dlq.records_written'\n    \n    def __init__(self, config: Dict[str, Any]):\n        \"\"\"Initialize the DLQ Handler with configuration.\n        \n        Args:\n            config: Application configuration dictionary containing:\n                - dlq_enabled: Boolean to toggle the DLQ feature\n                - dlq_storage_type: Storage type ('local_file')\n                - dlq_file_path: Path to the DLQ file\n        \"\"\"\n        self.config = config\n        self.enabled = config.get('dlq_enabled', False)\n        self.storage_type = config.get('dlq_storage_type', 'local_file')\n        self.file_path = config.get('dlq_file_path', '/var/log/pulsestream/dlq.jsonl')\n        self._monitoring_client: Optional[MonitoringClient] = None\n        \n        if self.enabled:\n            self._ensure_directory_exists()\n            self._initialize_monitoring()\n    \n    def _ensure_directory_exists(self) -> None:\n        \"\"\"Ensure the directory for the DLQ file exists.\"\"\"\n        directory = os.path.dirname(self.file_path)\n        if directory and not os.path.exists(directory):\n            try:\n                os.makedirs(directory, exist_ok=True)\n                logger.info(f\"Created DLQ directory: {directory}\")\n            except OSError as e:\n                logger.error(f\"Failed to create DLQ directory {directory}: {e}\")\n                raise\n    \n    def _initialize_monitoring(self) -> None:\n        \"\"\"Initialize the monitoring client.\"\"\"\n        try:\n            self._monitoring_client = MonitoringClient()\n            logger.debug(\"Monitoring client initialized for DLQ\")\n        except Exception as e:\n            logger.warning(f\"Failed to initialize monitoring client: {e}\")\n            self._monitoring_client = None\n    \n    def handle(self, record: Dict[str, Any], validation_errors: List[str]) -> bool:\n        \"\"\"Handle an invalid record by writing it to the DLQ.\n        \n        Args:\n            record: The original data record that failed validation\n            validation_errors: List of validation error strings describing\n                what went wrong\n        \n        Returns:\n            bool: True if the record was successfully written to DLQ,\n                False otherwise\n        \"\"\"\n        if not self.enabled:\n            logger.debug(\"DLQ is disabled, skipping record handling\")\n            return False\n        \n        if self.storage_type != 'local_file':\n            logger.error(f\"Unsupported DLQ storage type: {self.storage_type}\")\n            return False\n        \n        return self._write_to_file(record, validation_errors)\n    \n    def _write_to_file(self, record: Dict[str, Any], validation_errors: List[str]) -> bool:\n        \"\"\"Write the invalid record to the DLQ file.\n        \n        Args:\n            record: The original data record\n            validation_errors: List of validation error strings\n        \n        Returns:\n            bool: True if write was successful, False otherwise\n        \"\"\"\n        dlq_entry = {\n            'timestamp': datetime.utcnow().isoformat() + 'Z',\n            'record': record,\n            'validation_errors': validation_errors\n        }\n        \n        try:\n            with open(self.file_path, 'a', encoding='utf-8') as f:\n                json_line = json.dumps(dlq_entry, default=str)\n                f.write(json_line + '\n')\n            \n            logger.debug(f\"Record written to DLQ: {self.file_path}\")\n            \n            # Increment monitoring counter\n            self._increment_metric()\n            \n            return True\n            \n        except IOError as e:\n            logger.error(f\"Failed to write record to DLQ file {self.file_path}: {e}\")\n            return False\n        except (TypeError, ValueError) as e:\n            logger.error(f\"Failed to serialize record to JSON: {e}\")\n            return False\n    \n    def _increment_metric(self) -> None:\n        \"\"\"Increment the DLQ records written metric.\"\"\"\n        if self._monitoring_client is not None:\n            try:\n                self._monitoring_client.increment(self.DLQ_METRIC_NAME, 1)\n                logger.debug(f\"Incremented metric: {self.DLQ_METRIC_NAME}\")\n            except Exception as e:\n                logger.warning(f\"Failed to increment DLQ metric: {e}\")\n",
          "src/module_30.py": "\"\"\"Data validation module for PulseStream Nexus.\n\nThis module contains the DataValidator class responsible for validating\nincoming data records against defined schemas and business rules.\n\"\"\"\nimport logging\nfrom typing import Dict, Any, List, Tuple, Optional, Union\n\nlogger = logging.getLogger(__name__)\n\n\nclass ValidationResult:\n    \"\"\"Container for validation results.\n    \n    Attributes:\n        is_valid: Boolean indicating if validation passed\n        errors: List of validation error messages\n    \"\"\"\n    \n    def __init__(self, is_valid: bool, errors: Optional[List[str]] = None):\n        self.is_valid = is_valid\n        self.errors = errors or []\n    \n    def __bool__(self) -> bool:\n        return self.is_valid\n    \n    def __repr__(self) -> str:\n        return f\"ValidationResult(is_valid={self.is_valid}, errors={self.errors})\"\n\n\nclass DataValidator:\n    \"\"\"Validates incoming data records for the PulseStream pipeline.\n    \n    This validator checks records against schema requirements and\n    business rules before they are processed by downstream components.\n    \"\"\"\n    \n    REQUIRED_FIELDS = ['event_id', 'event_type', 'timestamp', 'payload']\n    VALID_EVENT_TYPES = ['user_action', 'system_event', 'transaction', 'metric', 'log']\n    MAX_PAYLOAD_SIZE = 1048576  # 1MB\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the DataValidator.\n        \n        Args:\n            config: Optional configuration dictionary for customizing\n                validation rules\n        \"\"\"\n        self.config = config or {}\n        self.strict_mode = self.config.get('strict_mode', True)\n        self.custom_validators = []\n    \n    def validate(self, record: Dict[str, Any]) -> ValidationResult:\n        \"\"\"Validate a data record.\n        \n        Args:\n            record: The data record to validate\n        \n        Returns:\n            ValidationResult containing validation status and any errors\n        \"\"\"\n        errors: List[str] = []\n        \n        if not isinstance(record, dict):\n            return ValidationResult(False, ['Record must be a dictionary'])\n        \n        # Check required fields\n        missing_fields = self._check_required_fields(record)\n        errors.extend(missing_fields)\n        \n        # Validate event_id format\n        event_id_errors = self._validate_event_id(record.get('event_id'))\n        errors.extend(event_id_errors)\n        \n        # Validate event_type\n        event_type_errors = self._validate_event_type(record.get('event_type'))\n        errors.extend(event_type_errors)\n        \n        # Validate timestamp\n        timestamp_errors = self._validate_timestamp(record.get('timestamp'))\n        errors.extend(timestamp_errors)\n        \n        # Validate payload\n        payload_errors = self._validate_payload(record.get('payload'))\n        errors.extend(payload_errors)\n        \n        # Run custom validators\n        for validator in self.custom_validators:\n            try:\n                custom_errors = validator(record)\n                if custom_errors:\n                    errors.extend(custom_errors)\n            except Exception as e:\n                logger.warning(f\"Custom validator failed: {e}\")\n                if self.strict_mode:\n                    errors.append(f\"Custom validation error: {str(e)}\")\n        \n        is_valid = len(errors) == 0\n        \n        if not is_valid:\n            logger.debug(f\"Validation failed for record: {errors}\")\n        \n        return ValidationResult(is_valid, errors)\n    \n    def _check_required_fields(self, record: Dict[str, Any]) -> List[str]:\n        \"\"\"Check that all required fields are present.\"\"\"\n        errors = []\n        for field in self.REQUIRED_FIELDS:\n            if field not in record:\n                errors.append(f\"Missing required field: {field}\")\n            elif record[field] is None:\n                errors.append(f\"Required field '{field}' cannot be null\")\n        return errors\n    \n    def _validate_event_id(self, event_id: Any) -> List[str]:\n        \"\"\"Validate the event_id field.\"\"\"\n        errors = []\n        if event_id is None:\n            return errors  # Already caught by required fields check\n        \n        if not isinstance(event_id, str):\n            errors.append(f\"event_id must be a string, got {type(event_id).__name__}\")\n        elif len(event_id) == 0:\n            errors.append(\"event_id cannot be empty\")\n        elif len(event_id) > 256:\n            errors.append(f\"event_id exceeds maximum length of 256 characters\")\n        \n        return errors\n    \n    def _validate_event_type(self, event_type: Any) -> List[str]:\n        \"\"\"Validate the event_type field.\"\"\"\n        errors = []\n        if event_type is None:\n            return errors  # Already caught by required fields check\n        \n        if not isinstance(event_type, str):\n            errors.append(f\"event_type must be a string, got {type(event_type).__name__}\")\n        elif event_type not in self.VALID_EVENT_TYPES:\n            errors.append(\n                f\"Invalid event_type '{event_type}'. \"\n                f\"Must be one of: {', '.join(self.VALID_EVENT_TYPES)}\"\n            )\n        \n        return errors\n    \n    def _validate_timestamp(self, timestamp: Any) -> List[str]:\n        \"\"\"Validate the timestamp field.\"\"\"\n        errors = []\n        if timestamp is None:\n            return errors  # Already caught by required fields check\n        \n        if isinstance(timestamp, str):\n            # Basic ISO format check\n            if len(timestamp) < 10:\n                errors.append(\"Invalid timestamp format\")\n        elif isinstance(timestamp, (int, float)):\n            # Unix timestamp - check reasonable range\n            if timestamp < 0 or timestamp > 4102444800:  # Year 2100\n                errors.append(\"Timestamp out of valid range\")\n        else:\n            errors.append(\n                f\"timestamp must be a string or number, got {type(timestamp).__name__}\"\n            )\n        \n        return errors\n    \n    def _validate_payload(self, payload: Any) -> List[str]:\n        \"\"\"Validate the payload field.\"\"\"\n        errors = []\n        if payload is None:\n            return errors  # Already caught by required fields check\n        \n        if not isinstance(payload, dict):\n            errors.append(f\"payload must be a dictionary, got {type(payload).__name__}\")\n            return errors\n        \n        # Check payload size (approximate)\n        try:\n            import json\n            payload_str = json.dumps(payload)\n            if len(payload_str) > self.MAX_PAYLOAD_SIZE:\n                errors.append(\n                    f\"payload exceeds maximum size of {self.MAX_PAYLOAD_SIZE} bytes\"\n                )\n        except (TypeError, ValueError) as e:\n            errors.append(f\"payload contains non-serializable data: {str(e)}\")\n        \n        return errors\n    \n    def add_custom_validator(self, validator_func) -> None:\n        \"\"\"Add a custom validation function.\n        \n        Args:\n            validator_func: A callable that takes a record dict and returns\n                a list of error strings (empty if valid)\n        \"\"\"\n        self.custom_validators.append(validator_func)\n    \n    def is_valid(self, record: Dict[str, Any]) -> bool:\n        \"\"\"Simple boolean check if record is valid.\n        \n        Args:\n            record: The data record to validate\n        \n        Returns:\n            True if valid, False otherwise\n        \"\"\"\n        return self.validate(record).is_valid\n",
          "src/module_12.py": "\"\"\"Main processing pipeline module for PulseStream Nexus.\n\nThis module orchestrates the data processing pipeline, handling record\ningestion, validation, transformation, and routing.\n\"\"\"\nimport logging\nfrom typing import Dict, Any, List, Optional, Iterator\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nfrom src.config import get_config\nfrom src.module_30 import DataValidator, ValidationResult\nfrom src.dlq_handler import DLQHandler\n\nlogger = logging.getLogger(__name__)\n\n\nclass ProcessingPipeline:\n    \"\"\"Main data processing pipeline for PulseStream Nexus.\n    \n    This pipeline handles the complete lifecycle of data records from\n    ingestion through validation, transformation, and output.\n    \"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the processing pipeline.\n        \n        Args:\n            config: Optional configuration dictionary. If not provided,\n                configuration will be loaded from src.config\n        \"\"\"\n        self.config = config or get_config()\n        self.validator = DataValidator(self.config)\n        self.dlq_handler = self._initialize_dlq_handler()\n        self.batch_size = self.config.get('max_batch_size', 1000)\n        self.processed_count = 0\n        self.failed_count = 0\n        self.dlq_count = 0\n    \n    def _initialize_dlq_handler(self) -> Optional[DLQHandler]:\n        \"\"\"Initialize the DLQ handler if enabled.\"\"\"\n        if self.config.get('dlq_enabled', False):\n            try:\n                handler = DLQHandler(self.config)\n                logger.info(\"DLQ handler initialized successfully\")\n                return handler\n            except Exception as e:\n                logger.error(f\"Failed to initialize DLQ handler: {e}\")\n                return None\n        return None\n    \n    def process_record(self, record: Dict[str, Any]) -> bool:\n        \"\"\"Process a single data record through the pipeline.\n        \n        Args:\n            record: The data record to process\n        \n        Returns:\n            True if the record was processed successfully, False otherwise\n        \"\"\"\n        try:\n            # Validate the record\n            validation_result = self.validator.validate(record)\n            \n            if not validation_result.is_valid:\n                self._handle_validation_failure(record, validation_result)\n                return False\n            \n            # Transform and process the valid record\n            transformed_record = self._transform_record(record)\n            \n            # Route to output\n            self._route_record(transformed_record)\n            \n            self.processed_count += 1\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error processing record: {e}\")\n            self.failed_count += 1\n            return False\n    \n    def _handle_validation_failure(self, record: Dict[str, Any], \n                                    validation_result: ValidationResult) -> None:\n        \"\"\"Handle a record that failed validation.\n        \n        Args:\n            record: The original record that failed validation\n            validation_result: The validation result containing errors\n        \"\"\"\n        self.failed_count += 1\n        \n        # Log the validation failure\n        logger.warning(\n            f\"Record failed validation: {validation_result.errors}\"\n        )\n        \n        # Route to DLQ if enabled\n        if self.config.get('dlq_enabled', False) and self.dlq_handler is not None:\n            try:\n                success = self.dlq_handler.handle(record, validation_result.errors)\n                if success:\n                    self.dlq_count += 1\n                    logger.debug(\"Record successfully written to DLQ\")\n                else:\n                    logger.warning(\"Failed to write record to DLQ\")\n            except Exception as e:\n                logger.error(f\"Error writing to DLQ: {e}\")\n    \n    def _transform_record(self, record: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Transform a validated record for downstream processing.\n        \n        Args:\n            record: The validated record to transform\n        \n        Returns:\n            The transformed record\n        \"\"\"\n        transformed = record.copy()\n        \n        # Add processing metadata\n        transformed['_processed'] = True\n        transformed['_pipeline_version'] = '1.0.0'\n        \n        # Normalize fields\n        if 'event_type' in transformed:\n            transformed['event_type'] = transformed['event_type'].lower()\n        \n        return transformed\n    \n    def _route_record(self, record: Dict[str, Any]) -> None:\n        \"\"\"Route a processed record to the appropriate output.\n        \n        Args:\n            record: The processed record to route\n        \"\"\"\n        # Placeholder for routing logic\n        event_type = record.get('event_type', 'unknown')\n        logger.debug(f\"Routing record of type '{event_type}' to output\")\n    \n    def process_batch(self, records: List[Dict[str, Any]]) -> Dict[str, int]:\n        \"\"\"Process a batch of records.\n        \n        Args:\n            records: List of records to process\n        \n        Returns:\n            Dictionary with processing statistics\n        \"\"\"\n        batch_processed = 0\n        batch_failed = 0\n        \n        for record in records:\n            if self.process_record(record):\n                batch_processed += 1\n            else:\n                batch_failed += 1\n        \n        return {\n            'processed': batch_processed,\n            'failed': batch_failed,\n            'total': len(records)\n        }\n    \n    def process_stream(self, record_iterator: Iterator[Dict[str, Any]]) -> Dict[str, int]:\n        \"\"\"Process a stream of records.\n        \n        Args:\n            record_iterator: Iterator yielding records to process\n        \n        Returns:\n            Dictionary with processing statistics\n        \"\"\"\n        total_processed = 0\n        total_failed = 0\n        \n        batch = []\n        for record in record_iterator:\n            batch.append(record)\n            \n            if len(batch) >= self.batch_size:\n                stats = self.process_batch(batch)\n                total_processed += stats['processed']\n                total_failed += stats['failed']\n                batch = []\n        \n        # Process remaining records\n        if batch:\n            stats = self.process_batch(batch)\n            total_processed += stats['processed']\n            total_failed += stats['failed']\n        \n        return {\n            'processed': total_processed,\n            'failed': total_failed,\n            'dlq_records': self.dlq_count\n        }\n    \n    def get_stats(self) -> Dict[str, int]:\n        \"\"\"Get current pipeline statistics.\n        \n        Returns:\n            Dictionary containing processing statistics\n        \"\"\"\n        return {\n            'processed_count': self.processed_count,\n            'failed_count': self.failed_count,\n            'dlq_count': self.dlq_count\n        }\n    \n    def reset_stats(self) -> None:\n        \"\"\"Reset pipeline statistics.\"\"\"\n        self.processed_count = 0\n        self.failed_count = 0\n        self.dlq_count = 0\n\n\nclass PipelineManager:\n    \"\"\"Manager for multiple processing pipelines.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or get_config()\n        self.pipelines: Dict[str, ProcessingPipeline] = {}\n        self.executor = ThreadPoolExecutor(\n            max_workers=self.config.get('max_workers', 4)\n        )\n    \n    def create_pipeline(self, name: str) -> ProcessingPipeline:\n        \"\"\"Create a new named pipeline.\"\"\"\n        pipeline = ProcessingPipeline(self.config)\n        self.pipelines[name] = pipeline\n        return pipeline\n    \n    def get_pipeline(self, name: str) -> Optional[ProcessingPipeline]:\n        \"\"\"Get a pipeline by name.\"\"\"\n        return self.pipelines.get(name)\n    \n    def shutdown(self) -> None:\n        \"\"\"Shutdown the pipeline manager.\"\"\"\n        self.executor.shutdown(wait=True)\n",
          "src/utils.py": "\"\"\"Utility functions and classes for PulseStream Nexus.\n\nThis module provides common utilities including logging, monitoring,\nand helper functions used throughout the application.\n\"\"\"\nimport logging\nimport time\nfrom typing import Dict, Any, Optional, Callable\nfrom functools import wraps\nfrom threading import Lock\n\nlogger = logging.getLogger(__name__)\n\n\nclass MonitoringClient:\n    \"\"\"Client for sending metrics to the monitoring system.\n    \n    This is a singleton class that provides methods for tracking\n    various metrics throughout the application.\n    \"\"\"\n    \n    _instance: Optional['MonitoringClient'] = None\n    _lock = Lock()\n    \n    def __new__(cls) -> 'MonitoringClient':\n        if cls._instance is None:\n            with cls._lock:\n                if cls._instance is None:\n                    cls._instance = super().__new__(cls)\n                    cls._instance._initialized = False\n        return cls._instance\n    \n    def __init__(self):\n        if self._initialized:\n            return\n        \n        self._metrics: Dict[str, float] = {}\n        self._counters: Dict[str, int] = {}\n        self._metric_lock = Lock()\n        self._initialized = True\n        logger.info(\"MonitoringClient initialized\")\n    \n    def increment(self, metric_name: str, value: int = 1) -> None:\n        \"\"\"Increment a counter metric.\n        \n        Args:\n            metric_name: The name of the metric to increment\n            value: The amount to increment by (default: 1)\n        \"\"\"\n        with self._metric_lock:\n            if metric_name not in self._counters:\n                self._counters[metric_name] = 0\n            self._counters[metric_name] += value\n        \n        logger.debug(f\"Metric '{metric_name}' incremented by {value}\")\n    \n    def gauge(self, metric_name: str, value: float) -> None:\n        \"\"\"Set a gauge metric to a specific value.\n        \n        Args:\n            metric_name: The name of the metric\n            value: The value to set\n        \"\"\"\n        with self._metric_lock:\n            self._metrics[metric_name] = value\n        \n        logger.debug(f\"Metric '{metric_name}' set to {value}\")\n    \n    def timing(self, metric_name: str, duration_ms: float) -> None:\n        \"\"\"Record a timing metric.\n        \n        Args:\n            metric_name: The name of the timing metric\n            duration_ms: The duration in milliseconds\n        \"\"\"\n        with self._metric_lock:\n            self._metrics[f\"{metric_name}.timing\"] = duration_ms\n        \n        logger.debug(f\"Timing '{metric_name}': {duration_ms}ms\")\n    \n    def get_counter(self, metric_name: str) -> int:\n        \"\"\"Get the current value of a counter.\n        \n        Args:\n            metric_name: The name of the counter metric\n        \n        Returns:\n            The current counter value, or 0 if not set\n        \"\"\"\n        with self._metric_lock:\n            return self._counters.get(metric_name, 0)\n    \n    def get_gauge(self, metric_name: str) -> Optional[float]:\n        \"\"\"Get the current value of a gauge.\n        \n        Args:\n            metric_name: The name of the gauge metric\n        \n        Returns:\n            The current gauge value, or None if not set\n        \"\"\"\n        with self._metric_lock:\n            return self._metrics.get(metric_name)\n    \n    def get_all_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get all recorded metrics.\n        \n        Returns:\n            Dictionary containing all metrics and counters\n        \"\"\"\n        with self._metric_lock:\n            return {\n                'counters': self._counters.copy(),\n                'gauges': self._metrics.copy()\n            }\n    \n    def reset(self) -> None:\n        \"\"\"Reset all metrics (useful for testing).\"\"\"\n        with self._metric_lock:\n            self._metrics.clear()\n            self._counters.clear()\n        logger.info(\"MonitoringClient metrics reset\")\n\n\ndef timed(metric_name: Optional[str] = None) -> Callable:\n    \"\"\"Decorator to time function execution.\n    \n    Args:\n        metric_name: Optional metric name. If not provided, uses function name.\n    \n    Returns:\n        Decorated function\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            name = metric_name or f\"{func.__module__}.{func.__name__}\"\n            start_time = time.time()\n            try:\n                return func(*args, **kwargs)\n            finally:\n                duration_ms = (time.time() - start_time) * 1000\n                try:\n                    MonitoringClient().timing(name, duration_ms)\n                except Exception as e:\n                    logger.warning(f\"Failed to record timing metric: {e}\")\n        return wrapper\n    return decorator\n\n\ndef retry(max_attempts: int = 3, delay: float = 1.0, \n          backoff: float = 2.0) -> Callable:\n    \"\"\"Decorator to retry a function on failure.\n    \n    Args:\n        max_attempts: Maximum number of retry attempts\n        delay: Initial delay between retries in seconds\n        backoff: Multiplier for delay after each retry\n    \n    Returns:\n        Decorated function\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            current_delay = delay\n            last_exception = None\n            \n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n                    logger.warning(\n                        f\"Attempt {attempt + 1}/{max_attempts} failed for \"\n                        f\"{func.__name__}: {e}\"\n                    )\n                    if attempt < max_attempts - 1:\n                        time.sleep(current_delay)\n                        current_delay *= backoff\n            \n            raise last_exception\n        return wrapper\n    return decorator\n\n\nclass BatchProcessor:\n    \"\"\"Utility class for processing items in batches.\"\"\"\n    \n    def __init__(self, batch_size: int = 100):\n        self.batch_size = batch_size\n        self._batch: list = []\n    \n    def add(self, item: Any) -> Optional[list]:\n        \"\"\"Add an item to the batch.\n        \n        Returns the batch if it's full, otherwise None.\n        \"\"\"\n        self._batch.append(item)\n        if len(self._batch) >= self.batch_size:\n            batch = self._batch\n            self._batch = []\n            return batch\n        return None\n    \n    def flush(self) -> list:\n        \"\"\"Flush and return the current batch.\"\"\"\n        batch = self._batch\n        self._batch = []\n        return batch\n"
        },
        "generated_files": [
          "src/config.py",
          "src/dlq_handler.py",
          "src/module_30.py",
          "src/module_12.py",
          "src/utils.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.726407643312102,
              "dependency_traversal_accuracy": 0.7959966834895458,
              "cross_file_reasoning_depth": 0.458,
              "system_thinking_score": 0.5359054393435975,
              "robustness_score": 0.435799522673031,
              "comprehensiveness_score": 0.47881384248210024,
              "innovation_score": 0.23846658711217186,
              "solution_elegance_score": 0.6020951298384561
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09080095541401274,
              "dependency_traversal_weighted": 0.09949958543619322,
              "cross_file_reasoning_weighted": 0.05725,
              "system_thinking_weighted": 0.06698817991794968,
              "robustness_weighted": 0.05447494033412888,
              "comprehensiveness_weighted": 0.05985173031026253,
              "innovation_weighted": 0.029808323389021483,
              "solution_elegance_weighted": 0.07526189122980702
            },
            "total_software_engineering_score": 0.5339356060313756
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.3306739330291748,
              "errors": [
                "  File \"src/dlq_handler.py\", line 106",
                "    f.write(json_line + '",
                "                        ^",
                "SyntaxError: unterminated string literal (detected at line 106)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "src/config.py",
                "src/dlq_handler.py",
                "src/module_30.py",
                "src/module_12.py",
                "src/utils.py"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 5,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 5 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.5575196374622357,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.5575196374622357,
              "idc_weight": 0.2,
              "total_functional_score": 0.45150392749244717
            }
          },
          "code_quality_details": {
            "files_analyzed": 5,
            "quality_checks": {
              "src/config.py": {
                "line_count": 47,
                "non_empty_lines": 40,
                "comment_lines": 4,
                "comment_ratio": 0.1,
                "function_count": 1,
                "class_count": 0,
                "import_count": 1,
                "quality_score": 0.6
              },
              "src/dlq_handler.py": {
                "line_count": 131,
                "non_empty_lines": 104,
                "comment_lines": 1,
                "comment_ratio": 0.009615384615384616,
                "function_count": 6,
                "class_count": 4,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "src/module_30.py": {
                "line_count": 209,
                "non_empty_lines": 162,
                "comment_lines": 9,
                "comment_ratio": 0.05555555555555555,
                "function_count": 12,
                "class_count": 8,
                "import_count": 4,
                "quality_score": 0.7999999999999999
              },
              "src/module_12.py": {
                "line_count": 240,
                "non_empty_lines": 189,
                "comment_lines": 9,
                "comment_ratio": 0.047619047619047616,
                "function_count": 14,
                "class_count": 4,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "src/utils.py": {
                "line_count": 211,
                "non_empty_lines": 167,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 18,
                "class_count": 4,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7719999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.5450975975975976,
              "multi_session_memory_retention": 0.47676426426426427
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.2725487987987988,
              "multi_session_memory_retention_weighted": 0.23838213213213214
            },
            "total_longcontext_utilization_score": 0.5109309309309309
          }
        },
        "timestamp": "2026-01-14T21:22:08.907668"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_system_automation_medium_098_feature_implementation_expert_01",
        "scenario_title": "Implement Canary Deployment Strategy with Automated Rollback",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5375254033962729,
        "functional_correctness_score": 0.40073200210194426,
        "code_quality_score": 0.7809090909090908,
        "longcontext_utilization_score": 0.8657697876447877,
        "total_score": 2.889942794676947,
        "generation_time": 226.27062439918518,
        "code_files_generated": 11,
        "total_lines_generated": 2172,
        "parsing_success": true,
        "solution_code": {
          "vitalops_orchestrator/config.yaml": "# VitalOps Orchestrator Configuration\n\nserver:\n  host: \"0.0.0.0\"\n  port: 8080\n  debug: false\n\nlogging:\n  level: \"INFO\"\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  file: \"logs/vitalops.log\"\n\nmetrics:\n  collection_interval: 60\n  retention_days: 30\n  enabled_collectors:\n    - cpu\n    - memory\n    - disk\n    - network\n\nnotifications:\n  enabled: true\n  channels:\n    - email\n    - slack\n  email:\n    smtp_host: \"smtp.example.com\"\n    smtp_port: 587\n    from_address: \"alerts@vitalops.io\"\n  slack:\n    webhook_url: \"https://hooks.slack.com/services/xxx\"\n\npolicy_engine:\n  evaluation_interval: 30\n  max_retries: 3\n\ndeployment:\n  default_timeout: 600\n  max_concurrent: 5\n  rollback_on_failure: true\n\ndeployment_strategies:\n  canary:\n    subset_percentage: 10\n    bake_time_seconds: 300\n    health_thresholds:\n      max_cpu_usage: 80.0\n      max_error_rate: 5.0\n      max_memory_usage: 85.0\n      min_success_rate: 95.0\n\nrecovery:\n  auto_recovery: true\n  max_recovery_attempts: 3\n  recovery_cooldown: 300\n",
          "vitalops_orchestrator/vitalops/models/domain.py": "\"\"\"Domain models for VitalOps Orchestrator.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\nimport uuid\n\n\nclass NodeStatus(Enum):\n    \"\"\"Status of a managed node.\"\"\"\n    HEALTHY = \"healthy\"\n    UNHEALTHY = \"unhealthy\"\n    DEGRADED = \"degraded\"\n    OFFLINE = \"offline\"\n    MAINTENANCE = \"maintenance\"\n\n\nclass DeploymentStatus(Enum):\n    \"\"\"Status of a deployment job.\"\"\"\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n    # Canary-specific states\n    CANARY_DEPLOY = \"canary_deploy\"\n    CANARY_MONITORING = \"canary_monitoring\"\n    CANARY_FAILED = \"canary_failed\"\n    PROMOTING = \"promoting\"\n    ROLLED_BACK = \"rolled_back\"\n\n\nclass DeploymentStrategy(Enum):\n    \"\"\"Deployment strategy types.\"\"\"\n    STANDARD = \"standard\"\n    CANARY = \"canary\"\n\n\nclass AlertSeverity(Enum):\n    \"\"\"Severity levels for alerts.\"\"\"\n    INFO = \"info\"\n    WARNING = \"warning\"\n    ERROR = \"error\"\n    CRITICAL = \"critical\"\n\n\n@dataclass\nclass Node:\n    \"\"\"Represents a managed node in the infrastructure.\"\"\"\n    id: str\n    hostname: str\n    ip_address: str\n    status: NodeStatus = NodeStatus.HEALTHY\n    labels: Dict[str, str] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    last_heartbeat: Optional[datetime] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n    def __post_init__(self):\n        if not self.id:\n            self.id = str(uuid.uuid4())\n\n\n@dataclass\nclass Application:\n    \"\"\"Represents a deployable application.\"\"\"\n    id: str\n    name: str\n    version: str\n    artifact_url: str\n    config: Dict[str, Any] = field(default_factory=dict)\n    health_check_endpoint: Optional[str] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n\n@dataclass\nclass DeploymentJob:\n    \"\"\"Represents a deployment job.\"\"\"\n    id: str\n    application_id: str\n    version: str\n    target_nodes: List[str]\n    status: DeploymentStatus = DeploymentStatus.PENDING\n    strategy: DeploymentStrategy = DeploymentStrategy.STANDARD\n    previous_version: Optional[str] = None\n    canary_nodes: List[str] = field(default_factory=list)\n    promoted_nodes: List[str] = field(default_factory=list)\n    rolled_back_nodes: List[str] = field(default_factory=list)\n    progress: float = 0.0\n    error_message: Optional[str] = None\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def __post_init__(self):\n        if not self.id:\n            self.id = str(uuid.uuid4())\n\n\n@dataclass\nclass MetricPoint:\n    \"\"\"Represents a single metric data point.\"\"\"\n    name: str\n    value: float\n    timestamp: datetime\n    node_id: str\n    labels: Dict[str, str] = field(default_factory=dict)\n\n\n@dataclass\nclass Alert:\n    \"\"\"Represents an alert.\"\"\"\n    id: str\n    title: str\n    message: str\n    severity: AlertSeverity\n    source: str\n    node_id: Optional[str] = None\n    acknowledged: bool = False\n    resolved: bool = False\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def __post_init__(self):\n        if not self.id:\n            self.id = str(uuid.uuid4())\n\n\n@dataclass\nclass Policy:\n    \"\"\"Represents a policy rule.\"\"\"\n    id: str\n    name: str\n    description: str\n    condition: str\n    action: str\n    enabled: bool = True\n    priority: int = 0\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass CanaryHealthResult:\n    \"\"\"Result of canary health evaluation.\"\"\"\n    passed: bool\n    metrics: Dict[str, float]\n    thresholds: Dict[str, float]\n    violations: List[str] = field(default_factory=list)\n    message: str = \"\"\n",
          "vitalops_orchestrator/vitalops/interfaces/api.py": "\"\"\"REST API interface for VitalOps Orchestrator.\"\"\"\n\nfrom flask import Flask, request, jsonify\nfrom typing import Any, Dict, Optional\nimport logging\n\nfrom vitalops.coordinators.deployment import DeploymentCoordinator\nfrom vitalops.coordinators.recovery import RecoveryCoordinator\nfrom vitalops.coordinators.performance import PerformanceCoordinator\nfrom vitalops.models.domain import DeploymentStrategy\n\nlogger = logging.getLogger(__name__)\n\napp = Flask(__name__)\n\n# Coordinator instances (initialized at startup)\ndeployment_coordinator: Optional[DeploymentCoordinator] = None\nrecovery_coordinator: Optional[RecoveryCoordinator] = None\nperformance_coordinator: Optional[PerformanceCoordinator] = None\n\n\ndef init_coordinators(config: Dict[str, Any]):\n    \"\"\"Initialize coordinators with configuration.\"\"\"\n    global deployment_coordinator, recovery_coordinator, performance_coordinator\n    deployment_coordinator = DeploymentCoordinator(config)\n    recovery_coordinator = RecoveryCoordinator(config)\n    performance_coordinator = PerformanceCoordinator(config)\n\n\n@app.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return jsonify({\"status\": \"healthy\", \"service\": \"vitalops-orchestrator\"})\n\n\n@app.route('/api/v1/deployments', methods=['POST'])\ndef create_deployment():\n    \"\"\"Create a new deployment job.\n    \n    Request body:\n        application_id (str): ID of the application to deploy\n        version (str): Version to deploy\n        target_nodes (list): List of node IDs to deploy to\n        deployment_strategy (str, optional): 'standard' or 'canary' (default: 'standard')\n        previous_version (str, optional): Previous version for rollback purposes\n    \n    Returns:\n        JSON response with deployment job details\n    \"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({\"error\": \"Request body is required\"}), 400\n        \n        # Validate required fields\n        required_fields = ['application_id', 'version', 'target_nodes']\n        for field in required_fields:\n            if field not in data:\n                return jsonify({\"error\": f\"Missing required field: {field}\"}), 400\n        \n        # Parse deployment strategy (default to 'standard' for backward compatibility)\n        strategy_str = data.get('deployment_strategy', 'standard').lower()\n        try:\n            strategy = DeploymentStrategy(strategy_str)\n        except ValueError:\n            return jsonify({\n                \"error\": f\"Invalid deployment_strategy: {strategy_str}. Must be 'standard' or 'canary'\"\n            }), 400\n        \n        # Create deployment job\n        job = deployment_coordinator.create_deployment(\n            application_id=data['application_id'],\n            version=data['version'],\n            target_nodes=data['target_nodes'],\n            strategy=strategy,\n            previous_version=data.get('previous_version')\n        )\n        \n        return jsonify({\n            \"id\": job.id,\n            \"application_id\": job.application_id,\n            \"version\": job.version,\n            \"target_nodes\": job.target_nodes,\n            \"strategy\": job.strategy.value,\n            \"status\": job.status.value,\n            \"created_at\": job.created_at.isoformat()\n        }), 201\n        \n    except Exception as e:\n        logger.error(f\"Error creating deployment: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/deployments/<deployment_id>', methods=['GET'])\ndef get_deployment(deployment_id: str):\n    \"\"\"Get deployment job status.\"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        job = deployment_coordinator.get_deployment(deployment_id)\n        if not job:\n            return jsonify({\"error\": \"Deployment not found\"}), 404\n        \n        return jsonify({\n            \"id\": job.id,\n            \"application_id\": job.application_id,\n            \"version\": job.version,\n            \"target_nodes\": job.target_nodes,\n            \"strategy\": job.strategy.value,\n            \"status\": job.status.value,\n            \"progress\": job.progress,\n            \"canary_nodes\": job.canary_nodes,\n            \"promoted_nodes\": job.promoted_nodes,\n            \"rolled_back_nodes\": job.rolled_back_nodes,\n            \"error_message\": job.error_message,\n            \"started_at\": job.started_at.isoformat() if job.started_at else None,\n            \"completed_at\": job.completed_at.isoformat() if job.completed_at else None,\n            \"created_at\": job.created_at.isoformat()\n        })\n        \n    except Exception as e:\n        logger.error(f\"Error getting deployment: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/deployments/<deployment_id>/cancel', methods=['POST'])\ndef cancel_deployment(deployment_id: str):\n    \"\"\"Cancel a deployment job.\"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        success = deployment_coordinator.cancel_deployment(deployment_id)\n        if not success:\n            return jsonify({\"error\": \"Failed to cancel deployment\"}), 400\n        \n        return jsonify({\"message\": \"Deployment cancelled\"})\n        \n    except Exception as e:\n        logger.error(f\"Error cancelling deployment: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/nodes', methods=['GET'])\ndef list_nodes():\n    \"\"\"List all managed nodes.\"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        nodes = deployment_coordinator.list_nodes()\n        return jsonify({\n            \"nodes\": [\n                {\n                    \"id\": node.id,\n                    \"hostname\": node.hostname,\n                    \"ip_address\": node.ip_address,\n                    \"status\": node.status.value,\n                    \"labels\": node.labels\n                }\n                for node in nodes\n            ]\n        })\n        \n    except Exception as e:\n        logger.error(f\"Error listing nodes: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/metrics/<node_id>', methods=['GET'])\ndef get_node_metrics(node_id: str):\n    \"\"\"Get metrics for a specific node.\"\"\"\n    if not performance_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        metrics = performance_coordinator.get_node_metrics(node_id)\n        return jsonify({\"node_id\": node_id, \"metrics\": metrics})\n        \n    except Exception as e:\n        logger.error(f\"Error getting metrics: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/recovery/<node_id>', methods=['POST'])\ndef trigger_recovery(node_id: str):\n    \"\"\"Trigger recovery for a node.\"\"\"\n    if not recovery_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        result = recovery_coordinator.trigger_recovery(node_id)\n        return jsonify(result)\n        \n    except Exception as e:\n        logger.error(f\"Error triggering recovery: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\ndef create_app(config: Dict[str, Any]) -> Flask:\n    \"\"\"Create and configure the Flask application.\"\"\"\n    init_coordinators(config)\n    return app\n",
          "vitalops_orchestrator/vitalops/coordinators/deployment.py": "\"\"\"Deployment coordinator for VitalOps Orchestrator.\"\"\"\n\nimport logging\nimport math\nimport time\nimport threading\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\nimport uuid\n\nfrom vitalops.models.domain import (\n    DeploymentJob, DeploymentStatus, DeploymentStrategy,\n    Node, NodeStatus, CanaryHealthResult\n)\nfrom vitalops.services.metric_collector import MetricCollector\nfrom vitalops.services.notification_gateway import NotificationGateway\nfrom vitalops.policy_engine.handlers import CanaryHealthPolicyHandler\nfrom vitalops.core.eventing import EventBus, Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass DeploymentCoordinator:\n    \"\"\"Coordinates deployment operations across the infrastructure.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.deployments: Dict[str, DeploymentJob] = {}\n        self.nodes: Dict[str, Node] = {}\n        self.node_versions: Dict[str, str] = {}  # Track deployed versions per node\n        self._lock = threading.Lock()\n        \n        # Initialize services\n        self.metric_collector = MetricCollector(config)\n        self.notification_gateway = NotificationGateway(config)\n        self.event_bus = EventBus()\n        \n        # Canary configuration\n        canary_config = config.get('deployment_strategies', {}).get('canary', {})\n        self.canary_subset_percentage = canary_config.get('subset_percentage', 10)\n        self.canary_bake_time_seconds = canary_config.get('bake_time_seconds', 300)\n        self.health_thresholds = canary_config.get('health_thresholds', {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0,\n            'max_memory_usage': 85.0,\n            'min_success_rate': 95.0\n        })\n        \n        # Initialize canary health policy handler\n        self.canary_health_handler = CanaryHealthPolicyHandler(self.health_thresholds)\n        \n        logger.info(\"DeploymentCoordinator initialized\")\n    \n    def register_node(self, node: Node) -> None:\n        \"\"\"Register a node with the coordinator.\"\"\"\n        with self._lock:\n            self.nodes[node.id] = node\n            logger.info(f\"Registered node: {node.id}\")\n    \n    def list_nodes(self) -> List[Node]:\n        \"\"\"List all registered nodes.\"\"\"\n        with self._lock:\n            return list(self.nodes.values())\n    \n    def create_deployment(\n        self,\n        application_id: str,\n        version: str,\n        target_nodes: List[str],\n        strategy: DeploymentStrategy = DeploymentStrategy.STANDARD,\n        previous_version: Optional[str] = None\n    ) -> DeploymentJob:\n        \"\"\"Create a new deployment job.\"\"\"\n        job = DeploymentJob(\n            id=str(uuid.uuid4()),\n            application_id=application_id,\n            version=version,\n            target_nodes=target_nodes,\n            strategy=strategy,\n            previous_version=previous_version\n        )\n        \n        with self._lock:\n            self.deployments[job.id] = job\n        \n        logger.info(f\"Created deployment job {job.id} with strategy {strategy.value}\")\n        \n        # Start deployment in background thread\n        thread = threading.Thread(target=self._execute_deployment, args=(job.id,))\n        thread.daemon = True\n        thread.start()\n        \n        return job\n    \n    def get_deployment(self, deployment_id: str) -> Optional[DeploymentJob]:\n        \"\"\"Get a deployment job by ID.\"\"\"\n        with self._lock:\n            return self.deployments.get(deployment_id)\n    \n    def cancel_deployment(self, deployment_id: str) -> bool:\n        \"\"\"Cancel a deployment job.\"\"\"\n        with self._lock:\n            job = self.deployments.get(deployment_id)\n            if not job:\n                return False\n            \n            if job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED,\n                             DeploymentStatus.CANCELLED, DeploymentStatus.ROLLED_BACK]:\n                return False\n            \n            job.status = DeploymentStatus.CANCELLED\n            job.completed_at = datetime.utcnow()\n            logger.info(f\"Cancelled deployment {deployment_id}\")\n            return True\n    \n    def _execute_deployment(self, deployment_id: str) -> None:\n        \"\"\"Execute a deployment job.\"\"\"\n        job = self.get_deployment(deployment_id)\n        if not job:\n            return\n        \n        try:\n            job.started_at = datetime.utcnow()\n            \n            if job.strategy == DeploymentStrategy.CANARY:\n                self._execute_canary_deployment(job)\n            else:\n                self._execute_standard_deployment(job)\n                \n        except Exception as e:\n            logger.error(f\"Deployment {deployment_id} failed: {e}\")\n            job.status = DeploymentStatus.FAILED\n            job.error_message = str(e)\n            job.completed_at = datetime.utcnow()\n            \n            self._send_deployment_notification(\n                job,\n                f\"Deployment {deployment_id} failed: {e}\",\n                severity=\"error\"\n            )\n    \n    def _execute_standard_deployment(self, job: DeploymentJob) -> None:\n        \"\"\"Execute a standard (all-at-once) deployment.\"\"\"\n        job.status = DeploymentStatus.IN_PROGRESS\n        logger.info(f\"Starting standard deployment {job.id}\")\n        \n        total_nodes = len(job.target_nodes)\n        deployed_count = 0\n        \n        for node_id in job.target_nodes:\n            if job.status == DeploymentStatus.CANCELLED:\n                return\n            \n            success = self._deploy_to_node(node_id, job.application_id, job.version)\n            if success:\n                deployed_count += 1\n                job.progress = (deployed_count / total_nodes) * 100\n                job.promoted_nodes.append(node_id)\n            else:\n                job.status = DeploymentStatus.FAILED\n                job.error_message = f\"Failed to deploy to node {node_id}\"\n                job.completed_at = datetime.utcnow()\n                return\n        \n        job.status = DeploymentStatus.COMPLETED\n        job.progress = 100.0\n        job.completed_at = datetime.utcnow()\n        logger.info(f\"Standard deployment {job.id} completed successfully\")\n    \n    def _execute_canary_deployment(self, job: DeploymentJob) -> None:\n        \"\"\"Execute a canary deployment.\"\"\"\n        logger.info(f\"Starting canary deployment {job.id}\")\n        \n        # Phase 1: Deploy to canary nodes\n        job.status = DeploymentStatus.CANARY_DEPLOY\n        canary_nodes = self._select_canary_nodes(job.target_nodes)\n        job.canary_nodes = canary_nodes\n        \n        logger.info(f\"Selected {len(canary_nodes)} canary nodes: {canary_nodes}\")\n        \n        # Deploy to canary nodes\n        for node_id in canary_nodes:\n            if job.status == DeploymentStatus.CANCELLED:\n                return\n            \n            success = self._deploy_to_node(node_id, job.application_id, job.version)\n            if not success:\n                job.status = DeploymentStatus.CANARY_FAILED\n                job.error_message = f\"Failed to deploy to canary node {node_id}\"\n                self._rollback_canary(job)\n                return\n        \n        job.progress = (len(canary_nodes) / len(job.target_nodes)) * 100\n        \n        # Phase 2: Monitor canary nodes (bake time)\n        job.status = DeploymentStatus.CANARY_MONITORING\n        logger.info(f\"Entering canary monitoring phase for {self.canary_bake_time_seconds} seconds\")\n        \n        health_result = self._monitor_canary_health(job)\n        \n        if not health_result.passed:\n            logger.warning(f\"Canary health check failed: {health_result.message}\")\n            job.status = DeploymentStatus.CANARY_FAILED\n            job.error_message = health_result.message\n            self._rollback_canary(job)\n            return\n        \n        logger.info(f\"Canary health check passed: {health_result.message}\")\n        \n        # Phase 3: Promote to remaining nodes\n        job.status = DeploymentStatus.PROMOTING\n        remaining_nodes = [n for n in job.target_nodes if n not in canary_nodes]\n        \n        logger.info(f\"Promoting to {len(remaining_nodes)} remaining nodes\")\n        \n        for node_id in remaining_nodes:\n            if job.status == DeploymentStatus.CANCELLED:\n                return\n            \n            success = self._deploy_to_node(node_id, job.application_id, job.version)\n            if success:\n                job.promoted_nodes.append(node_id)\n                job.progress = ((len(canary_nodes) + len(job.promoted_nodes)) / len(job.target_nodes)) * 100\n            else:\n                job.status = DeploymentStatus.FAILED\n                job.error_message = f\"Failed to deploy to node {node_id} during promotion\"\n                job.completed_at = datetime.utcnow()\n                return\n        \n        # Mark canary nodes as promoted too\n        job.promoted_nodes.extend(canary_nodes)\n        job.status = DeploymentStatus.COMPLETED\n        job.progress = 100.0\n        job.completed_at = datetime.utcnow()\n        \n        logger.info(f\"Canary deployment {job.id} completed successfully\")\n        self._send_deployment_notification(\n            job,\n            f\"Canary deployment {job.id} completed successfully\",\n            severity=\"info\"\n        )\n    \n    def _select_canary_nodes(self, target_nodes: List[str]) -> List[str]:\n        \"\"\"Select a subset of nodes for canary deployment.\"\"\"\n        num_canary = max(1, math.ceil(len(target_nodes) * self.canary_subset_percentage / 100))\n        return target_nodes[:num_canary]\n    \n    def _deploy_to_node(self, node_id: str, application_id: str, version: str) -> bool:\n        \"\"\"Deploy application version to a specific node.\"\"\"\n        try:\n            logger.info(f\"Deploying {application_id}:{version} to node {node_id}\")\n            \n            # Store current version as previous before updating\n            with self._lock:\n                self.node_versions[node_id] = version\n            \n            # Simulate deployment (in real implementation, this would SSH/API call to node)\n            time.sleep(0.1)  # Simulate deployment time\n            \n            # Emit deployment event\n            self.event_bus.publish(Event(\n                event_type=\"deployment.node.completed\",\n                data={\n                    \"node_id\": node_id,\n                    \"application_id\": application_id,\n                    \"version\": version\n                }\n            ))\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to deploy to node {node_id}: {e}\")\n            return False\n    \n    def _monitor_canary_health(self, job: DeploymentJob) -> CanaryHealthResult:\n        \"\"\"Monitor canary nodes during bake time and evaluate health.\"\"\"\n        start_time = time.time()\n        check_interval = min(30, self.canary_bake_time_seconds / 5)  # Check at least 5 times\n        \n        all_metrics: Dict[str, List[float]] = {\n            'cpu_usage': [],\n            'error_rate': [],\n            'memory_usage': [],\n            'success_rate': []\n        }\n        \n        while time.time() - start_time < self.canary_bake_time_seconds:\n            if job.status == DeploymentStatus.CANCELLED:\n                return CanaryHealthResult(\n                    passed=False,\n                    metrics={},\n                    thresholds=self.health_thresholds,\n                    message=\"Deployment cancelled\"\n                )\n            \n            # Collect metrics from canary nodes\n            for node_id in job.canary_nodes:\n                metrics = self.metric_collector.collect_metrics(node_id)\n                for metric_name, value in metrics.items():\n                    if metric_name in all_metrics:\n                        all_metrics[metric_name].append(value)\n            \n            time.sleep(check_interval)\n        \n        # Calculate average metrics\n        avg_metrics = {}\n        for metric_name, values in all_metrics.items():\n            if values:\n                avg_metrics[metric_name] = sum(values) / len(values)\n            else:\n                avg_metrics[metric_name] = 0.0\n        \n        # Evaluate health using policy handler\n        return self.canary_health_handler.evaluate(avg_metrics)\n    \n    def _rollback_canary(self, job: DeploymentJob) -> None:\n        \"\"\"Rollback canary nodes to previous version.\"\"\"\n        logger.warning(f\"Rolling back canary deployment {job.id}\")\n        \n        previous_version = job.previous_version or \"stable\"\n        \n        for node_id in job.canary_nodes:\n            try:\n                success = self._deploy_to_node(node_id, job.application_id, previous_version)\n                if success:\n                    job.rolled_back_nodes.append(node_id)\n                    logger.info(f\"Rolled back node {node_id} to version {previous_version}\")\n                else:\n                    logger.error(f\"Failed to rollback node {node_id}\")\n            except Exception as e:\n                logger.error(f\"Error rolling back node {node_id}: {e}\")\n        \n        job.status = DeploymentStatus.ROLLED_BACK\n        job.completed_at = datetime.utcnow()\n        \n        # Send rollback notification\n        self._send_deployment_notification(\n            job,\n            f\"Canary deployment {job.id} rolled back due to health check failure: {job.error_message}\",\n            severity=\"warning\"\n        )\n    \n    def _send_deployment_notification(self, job: DeploymentJob, message: str, severity: str = \"info\") -> None:\n        \"\"\"Send deployment notification.\"\"\"\n        try:\n            self.notification_gateway.send_notification(\n                title=f\"Deployment {job.status.value}: {job.application_id}\",\n                message=message,\n                severity=severity,\n                metadata={\n                    \"deployment_id\": job.id,\n                    \"application_id\": job.application_id,\n                    \"version\": job.version,\n                    \"strategy\": job.strategy.value,\n                    \"status\": job.status.value\n                }\n            )\n        except Exception as e:\n            logger.error(f\"Failed to send notification: {e}\")\n",
          "vitalops_orchestrator/vitalops/policy_engine/handlers.py": "\"\"\"Policy handlers for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\n\nfrom vitalops.models.domain import CanaryHealthResult\n\nlogger = logging.getLogger(__name__)\n\n\nclass PolicyHandler(ABC):\n    \"\"\"Abstract base class for policy handlers.\"\"\"\n    \n    @abstractmethod\n    def evaluate(self, context: Dict[str, Any]) -> Any:\n        \"\"\"Evaluate the policy against the given context.\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_name(self) -> str:\n        \"\"\"Get the handler name.\"\"\"\n        pass\n\n\nclass ResourceThresholdHandler(PolicyHandler):\n    \"\"\"Handler for resource threshold policies.\"\"\"\n    \n    def __init__(self, thresholds: Dict[str, float]):\n        self.thresholds = thresholds\n    \n    def get_name(self) -> str:\n        return \"resource_threshold\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate resource metrics against thresholds.\"\"\"\n        violations = []\n        metrics = context.get('metrics', {})\n        \n        for metric_name, threshold in self.thresholds.items():\n            if metric_name in metrics:\n                value = metrics[metric_name]\n                if value > threshold:\n                    violations.append({\n                        'metric': metric_name,\n                        'value': value,\n                        'threshold': threshold\n                    })\n        \n        return {\n            'passed': len(violations) == 0,\n            'violations': violations\n        }\n\n\nclass HealthCheckHandler(PolicyHandler):\n    \"\"\"Handler for health check policies.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or {}\n        self.timeout = self.config.get('timeout', 30)\n        self.retries = self.config.get('retries', 3)\n    \n    def get_name(self) -> str:\n        return \"health_check\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate health check status.\"\"\"\n        node_status = context.get('node_status', 'unknown')\n        health_endpoint = context.get('health_endpoint')\n        \n        is_healthy = node_status in ['healthy', 'ok', 'running']\n        \n        return {\n            'passed': is_healthy,\n            'status': node_status,\n            'health_endpoint': health_endpoint\n        }\n\n\nclass CanaryHealthPolicyHandler(PolicyHandler):\n    \"\"\"Handler for canary deployment health evaluation.\n    \n    This handler evaluates metrics collected from canary nodes against\n    configurable thresholds to determine if the canary deployment is healthy.\n    \"\"\"\n    \n    def __init__(self, thresholds: Dict[str, float]):\n        \"\"\"Initialize the canary health policy handler.\n        \n        Args:\n            thresholds: Dictionary of threshold values:\n                - max_cpu_usage: Maximum allowed CPU usage percentage\n                - max_error_rate: Maximum allowed error rate percentage\n                - max_memory_usage: Maximum allowed memory usage percentage\n                - min_success_rate: Minimum required success rate percentage\n        \"\"\"\n        self.thresholds = thresholds\n        logger.info(f\"CanaryHealthPolicyHandler initialized with thresholds: {thresholds}\")\n    \n    def get_name(self) -> str:\n        return \"canary_health\"\n    \n    def evaluate(self, metrics: Dict[str, float]) -> CanaryHealthResult:\n        \"\"\"Evaluate canary metrics against health thresholds.\n        \n        Args:\n            metrics: Dictionary of collected metrics:\n                - cpu_usage: Average CPU usage percentage\n                - error_rate: Average error rate percentage\n                - memory_usage: Average memory usage percentage\n                - success_rate: Average success rate percentage\n        \n        Returns:\n            CanaryHealthResult indicating pass/fail and details\n        \"\"\"\n        violations: List[str] = []\n        \n        # Check CPU usage\n        max_cpu = self.thresholds.get('max_cpu_usage', 80.0)\n        cpu_usage = metrics.get('cpu_usage', 0.0)\n        if cpu_usage > max_cpu:\n            violations.append(f\"CPU usage {cpu_usage:.1f}% exceeds threshold {max_cpu:.1f}%\")\n        \n        # Check error rate\n        max_error_rate = self.thresholds.get('max_error_rate', 5.0)\n        error_rate = metrics.get('error_rate', 0.0)\n        if error_rate > max_error_rate:\n            violations.append(f\"Error rate {error_rate:.1f}% exceeds threshold {max_error_rate:.1f}%\")\n        \n        # Check memory usage\n        max_memory = self.thresholds.get('max_memory_usage', 85.0)\n        memory_usage = metrics.get('memory_usage', 0.0)\n        if memory_usage > max_memory:\n            violations.append(f\"Memory usage {memory_usage:.1f}% exceeds threshold {max_memory:.1f}%\")\n        \n        # Check success rate (minimum threshold)\n        min_success_rate = self.thresholds.get('min_success_rate', 95.0)\n        success_rate = metrics.get('success_rate', 100.0)\n        if success_rate < min_success_rate:\n            violations.append(f\"Success rate {success_rate:.1f}% below threshold {min_success_rate:.1f}%\")\n        \n        passed = len(violations) == 0\n        \n        if passed:\n            message = \"All health metrics within acceptable thresholds\"\n        else:\n            message = f\"Health check failed: {'; '.join(violations)}\"\n        \n        logger.info(f\"Canary health evaluation: passed={passed}, metrics={metrics}\")\n        \n        return CanaryHealthResult(\n            passed=passed,\n            metrics=metrics,\n            thresholds=self.thresholds,\n            violations=violations,\n            message=message\n        )\n\n\nclass AutoScalingHandler(PolicyHandler):\n    \"\"\"Handler for auto-scaling policies.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or {}\n        self.scale_up_threshold = self.config.get('scale_up_threshold', 80)\n        self.scale_down_threshold = self.config.get('scale_down_threshold', 20)\n        self.min_instances = self.config.get('min_instances', 1)\n        self.max_instances = self.config.get('max_instances', 10)\n    \n    def get_name(self) -> str:\n        return \"auto_scaling\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate scaling decision based on metrics.\"\"\"\n        current_load = context.get('load', 0)\n        current_instances = context.get('instances', 1)\n        \n        action = 'none'\n        target_instances = current_instances\n        \n        if current_load > self.scale_up_threshold and current_instances < self.max_instances:\n            action = 'scale_up'\n            target_instances = min(current_instances + 1, self.max_instances)\n        elif current_load < self.scale_down_threshold and current_instances > self.min_instances:\n            action = 'scale_down'\n            target_instances = max(current_instances - 1, self.min_instances)\n        \n        return {\n            'action': action,\n            'current_instances': current_instances,\n            'target_instances': target_instances,\n            'current_load': current_load\n        }\n\n\nclass AlertingHandler(PolicyHandler):\n    \"\"\"Handler for alerting policies.\"\"\"\n    \n    def __init__(self, rules: Optional[List[Dict[str, Any]]] = None):\n        self.rules = rules or []\n    \n    def get_name(self) -> str:\n        return \"alerting\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate alerting rules.\"\"\"\n        triggered_alerts = []\n        metrics = context.get('metrics', {})\n        \n        for rule in self.rules:\n            metric_name = rule.get('metric')\n            condition = rule.get('condition', 'gt')  # gt, lt, eq\n            threshold = rule.get('threshold', 0)\n            severity = rule.get('severity', 'warning')\n            \n            if metric_name in metrics:\n                value = metrics[metric_name]\n                triggered = False\n                \n                if condition == 'gt' and value > threshold:\n                    triggered = True\n                elif condition == 'lt' and value < threshold:\n                    triggered = True\n                elif condition == 'eq' and value == threshold:\n                    triggered = True\n                \n                if triggered:\n                    triggered_alerts.append({\n                        'rule': rule.get('name', metric_name),\n                        'metric': metric_name,\n                        'value': value,\n                        'threshold': threshold,\n                        'severity': severity\n                    })\n        \n        return {\n            'alerts': triggered_alerts,\n            'alert_count': len(triggered_alerts)\n        }\n",
          "vitalops_orchestrator/vitalops/services/metric_collector.py": "\"\"\"Metric collection service for VitalOps Orchestrator.\"\"\"\n\nimport logging\nimport random\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom vitalops.models.domain import MetricPoint\n\nlogger = logging.getLogger(__name__)\n\n\nclass MetricCollector:\n    \"\"\"Service for collecting metrics from nodes.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.metrics_config = config.get('metrics', {})\n        self.collection_interval = self.metrics_config.get('collection_interval', 60)\n        self.enabled_collectors = self.metrics_config.get('enabled_collectors', ['cpu', 'memory', 'disk', 'network'])\n        \n        # Store for simulated/cached metrics\n        self._metrics_cache: Dict[str, Dict[str, float]] = {}\n        self._simulate_metrics = config.get('simulate_metrics', True)\n        \n        logger.info(f\"MetricCollector initialized with collectors: {self.enabled_collectors}\")\n    \n    def collect_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Collect all enabled metrics from a node.\n        \n        Args:\n            node_id: ID of the node to collect metrics from\n            \n        Returns:\n            Dictionary of metric name to value\n        \"\"\"\n        metrics = {}\n        \n        try:\n            if self._simulate_metrics:\n                metrics = self._simulate_node_metrics(node_id)\n            else:\n                metrics = self._collect_real_metrics(node_id)\n            \n            # Cache the metrics\n            self._metrics_cache[node_id] = metrics\n            \n            logger.debug(f\"Collected metrics from node {node_id}: {metrics}\")\n            \n        except Exception as e:\n            logger.error(f\"Error collecting metrics from node {node_id}: {e}\")\n            # Return cached metrics if available\n            if node_id in self._metrics_cache:\n                return self._metrics_cache[node_id]\n        \n        return metrics\n    \n    def collect_metric(self, node_id: str, metric_name: str) -> Optional[float]:\n        \"\"\"Collect a specific metric from a node.\n        \n        Args:\n            node_id: ID of the node\n            metric_name: Name of the metric to collect\n            \n        Returns:\n            Metric value or None if not available\n        \"\"\"\n        metrics = self.collect_metrics(node_id)\n        return metrics.get(metric_name)\n    \n    def collect_metrics_batch(self, node_ids: List[str]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Collect metrics from multiple nodes.\n        \n        Args:\n            node_ids: List of node IDs\n            \n        Returns:\n            Dictionary mapping node ID to metrics\n        \"\"\"\n        results = {}\n        for node_id in node_ids:\n            results[node_id] = self.collect_metrics(node_id)\n        return results\n    \n    def get_metric_history(self, node_id: str, metric_name: str, \n                          duration_seconds: int = 3600) -> List[MetricPoint]:\n        \"\"\"Get historical metric data for a node.\n        \n        Args:\n            node_id: ID of the node\n            metric_name: Name of the metric\n            duration_seconds: How far back to retrieve data\n            \n        Returns:\n            List of MetricPoint objects\n        \"\"\"\n        # In a real implementation, this would query a time-series database\n        # For now, return simulated historical data\n        points = []\n        current_time = datetime.utcnow()\n        \n        if self._simulate_metrics:\n            # Generate simulated historical data\n            num_points = min(duration_seconds // self.collection_interval, 100)\n            for i in range(num_points):\n                timestamp = datetime.fromtimestamp(\n                    current_time.timestamp() - (i * self.collection_interval)\n                )\n                value = self._simulate_single_metric(metric_name)\n                points.append(MetricPoint(\n                    name=metric_name,\n                    value=value,\n                    timestamp=timestamp,\n                    node_id=node_id\n                ))\n        \n        return points\n    \n    def set_simulated_metrics(self, node_id: str, metrics: Dict[str, float]) -> None:\n        \"\"\"Set simulated metrics for testing purposes.\n        \n        Args:\n            node_id: ID of the node\n            metrics: Dictionary of metric values to simulate\n        \"\"\"\n        self._metrics_cache[node_id] = metrics\n        logger.debug(f\"Set simulated metrics for node {node_id}: {metrics}\")\n    \n    def _simulate_node_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Generate simulated metrics for a node.\"\"\"\n        # Check if we have pre-set metrics for this node\n        if node_id in self._metrics_cache:\n            cached = self._metrics_cache[node_id]\n            # Add some variance to cached metrics\n            return {\n                k: v + random.uniform(-2, 2) if isinstance(v, (int, float)) else v\n                for k, v in cached.items()\n            }\n        \n        # Generate random but realistic metrics\n        metrics = {\n            'cpu_usage': random.uniform(20, 60),\n            'memory_usage': random.uniform(30, 70),\n            'disk_usage': random.uniform(40, 80),\n            'network_in': random.uniform(100, 1000),\n            'network_out': random.uniform(50, 500),\n            'error_rate': random.uniform(0, 3),\n            'success_rate': random.uniform(97, 100),\n            'request_latency': random.uniform(10, 100),\n            'active_connections': random.randint(10, 200)\n        }\n        \n        return metrics\n    \n    def _simulate_single_metric(self, metric_name: str) -> float:\n        \"\"\"Generate a simulated value for a single metric.\"\"\"\n        defaults = {\n            'cpu_usage': (20, 60),\n            'memory_usage': (30, 70),\n            'disk_usage': (40, 80),\n            'error_rate': (0, 3),\n            'success_rate': (97, 100),\n            'request_latency': (10, 100)\n        }\n        \n        if metric_name in defaults:\n            low, high = defaults[metric_name]\n            return random.uniform(low, high)\n        \n        return random.uniform(0, 100)\n    \n    def _collect_real_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Collect real metrics from a node (placeholder for actual implementation).\"\"\"\n        # In a real implementation, this would:\n        # 1. Connect to the node via SSH or agent\n        # 2. Execute metric collection commands\n        # 3. Parse and return the results\n        \n        # For now, fall back to simulation\n        logger.warning(f\"Real metric collection not implemented, using simulation for node {node_id}\")\n        return self._simulate_node_metrics(node_id)\n",
          "vitalops_orchestrator/vitalops/services/notification_gateway.py": "\"\"\"Notification gateway service for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\nimport uuid\n\nfrom vitalops.models.domain import Alert, AlertSeverity\n\nlogger = logging.getLogger(__name__)\n\n\nclass NotificationGateway:\n    \"\"\"Service for sending notifications through various channels.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.notifications_config = config.get('notifications', {})\n        self.enabled = self.notifications_config.get('enabled', True)\n        self.channels = self.notifications_config.get('channels', ['email', 'slack'])\n        \n        # Email configuration\n        self.email_config = self.notifications_config.get('email', {})\n        \n        # Slack configuration\n        self.slack_config = self.notifications_config.get('slack', {})\n        \n        # Store sent notifications for testing/auditing\n        self._sent_notifications: List[Dict[str, Any]] = []\n        \n        logger.info(f\"NotificationGateway initialized with channels: {self.channels}\")\n    \n    def send_notification(\n        self,\n        title: str,\n        message: str,\n        severity: str = \"info\",\n        channels: Optional[List[str]] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> bool:\n        \"\"\"Send a notification through configured channels.\n        \n        Args:\n            title: Notification title\n            message: Notification message body\n            severity: Severity level (info, warning, error, critical)\n            channels: Specific channels to use (defaults to all configured)\n            metadata: Additional metadata to include\n            \n        Returns:\n            True if notification was sent successfully\n        \"\"\"\n        if not self.enabled:\n            logger.debug(\"Notifications disabled, skipping\")\n            return True\n        \n        target_channels = channels or self.channels\n        notification_id = str(uuid.uuid4())\n        \n        notification_record = {\n            'id': notification_id,\n            'title': title,\n            'message': message,\n            'severity': severity,\n            'channels': target_channels,\n            'metadata': metadata or {},\n            'timestamp': datetime.utcnow().isoformat(),\n            'status': 'pending'\n        }\n        \n        success = True\n        \n        for channel in target_channels:\n            try:\n                if channel == 'email':\n                    self._send_email(title, message, severity, metadata)\n                elif channel == 'slack':\n                    self._send_slack(title, message, severity, metadata)\n                elif channel == 'webhook':\n                    self._send_webhook(title, message, severity, metadata)\n                else:\n                    logger.warning(f\"Unknown notification channel: {channel}\")\n                    \n            except Exception as e:\n                logger.error(f\"Failed to send notification via {channel}: {e}\")\n                success = False\n        \n        notification_record['status'] = 'sent' if success else 'failed'\n        self._sent_notifications.append(notification_record)\n        \n        logger.info(f\"Notification {notification_id} sent: {title} [{severity}]\")\n        \n        return success\n    \n    def send_alert(self, alert: Alert) -> bool:\n        \"\"\"Send an alert notification.\n        \n        Args:\n            alert: Alert object to send\n            \n        Returns:\n            True if alert was sent successfully\n        \"\"\"\n        return self.send_notification(\n            title=alert.title,\n            message=alert.message,\n            severity=alert.severity.value,\n            metadata={\n                'alert_id': alert.id,\n                'source': alert.source,\n                'node_id': alert.node_id,\n                **alert.metadata\n            }\n        )\n    \n    def send_deployment_notification(\n        self,\n        deployment_id: str,\n        status: str,\n        application_id: str,\n        version: str,\n        message: str\n    ) -> bool:\n        \"\"\"Send a deployment-specific notification.\n        \n        Args:\n            deployment_id: ID of the deployment\n            status: Deployment status\n            application_id: Application being deployed\n            version: Version being deployed\n            message: Notification message\n            \n        Returns:\n            True if notification was sent successfully\n        \"\"\"\n        severity = 'info'\n        if status in ['failed', 'canary_failed']:\n            severity = 'error'\n        elif status in ['rolled_back']:\n            severity = 'warning'\n        \n        return self.send_notification(\n            title=f\"Deployment {status}: {application_id} v{version}\",\n            message=message,\n            severity=severity,\n            metadata={\n                'deployment_id': deployment_id,\n                'application_id': application_id,\n                'version': version,\n                'status': status\n            }\n        )\n    \n    def get_sent_notifications(self) -> List[Dict[str, Any]]:\n        \"\"\"Get list of sent notifications (for testing/auditing).\"\"\"\n        return self._sent_notifications.copy()\n    \n    def clear_notifications(self) -> None:\n        \"\"\"Clear the sent notifications list.\"\"\"\n        self._sent_notifications.clear()\n    \n    def _send_email(self, title: str, message: str, severity: str, \n                    metadata: Optional[Dict[str, Any]]) -> None:\n        \"\"\"Send notification via email.\"\"\"\n        smtp_host = self.email_config.get('smtp_host')\n        smtp_port = self.email_config.get('smtp_port', 587)\n        from_address = self.email_config.get('from_address')\n        \n        # In a real implementation, this would use smtplib to send email\n        logger.debug(f\"Email notification: {title} (would send via {smtp_host}:{smtp_port})\")\n    \n    def _send_slack(self, title: str, message: str, severity: str,\n                    metadata: Optional[Dict[str, Any]]) -> None:\n        \"\"\"Send notification via Slack.\"\"\"\n        webhook_url = self.slack_config.get('webhook_url')\n        \n        # Map severity to Slack color\n        color_map = {\n            'info': '#36a64f',\n            'warning': '#ffcc00',\n            'error': '#ff0000',\n            'critical': '#8b0000'\n        }\n        color = color_map.get(severity, '#808080')\n        \n        # In a real implementation, this would POST to the Slack webhook\n        logger.debug(f\"Slack notification: {title} (would send to webhook)\")\n    \n    def _send_webhook(self, title: str, message: str, severity: str,\n                      metadata: Optional[Dict[str, Any]]) -> None:\n        \"\"\"Send notification via generic webhook.\"\"\"\n        # In a real implementation, this would POST to a configured webhook URL\n        logger.debug(f\"Webhook notification: {title}\")\n",
          "vitalops_orchestrator/tests/test_coordinators.py": "\"\"\"Tests for VitalOps coordinators.\"\"\"\n\nimport pytest\nimport time\nimport threading\nfrom unittest.mock import Mock, patch, MagicMock\nfrom datetime import datetime\n\nfrom vitalops.coordinators.deployment import DeploymentCoordinator\nfrom vitalops.coordinators.recovery import RecoveryCoordinator\nfrom vitalops.coordinators.performance import PerformanceCoordinator\nfrom vitalops.models.domain import (\n    DeploymentJob, DeploymentStatus, DeploymentStrategy,\n    Node, NodeStatus, CanaryHealthResult\n)\nfrom vitalops.services.metric_collector import MetricCollector\nfrom vitalops.services.notification_gateway import NotificationGateway\nfrom vitalops.policy_engine.handlers import CanaryHealthPolicyHandler\n\n\n@pytest.fixture\ndef test_config():\n    \"\"\"Test configuration fixture.\"\"\"\n    return {\n        'deployment': {\n            'default_timeout': 600,\n            'max_concurrent': 5,\n            'rollback_on_failure': True\n        },\n        'deployment_strategies': {\n            'canary': {\n                'subset_percentage': 20,\n                'bake_time_seconds': 1,  # Short for testing\n                'health_thresholds': {\n                    'max_cpu_usage': 80.0,\n                    'max_error_rate': 5.0,\n                    'max_memory_usage': 85.0,\n                    'min_success_rate': 95.0\n                }\n            }\n        },\n        'metrics': {\n            'collection_interval': 60,\n            'enabled_collectors': ['cpu', 'memory']\n        },\n        'notifications': {\n            'enabled': True,\n            'channels': ['email', 'slack']\n        },\n        'simulate_metrics': True\n    }\n\n\n@pytest.fixture\ndef deployment_coordinator(test_config):\n    \"\"\"Create a deployment coordinator for testing.\"\"\"\n    coordinator = DeploymentCoordinator(test_config)\n    \n    # Register test nodes\n    for i in range(5):\n        node = Node(\n            id=f\"node-{i}\",\n            hostname=f\"server-{i}.example.com\",\n            ip_address=f\"192.168.1.{10 + i}\",\n            status=NodeStatus.HEALTHY\n        )\n        coordinator.register_node(node)\n    \n    return coordinator\n\n\nclass TestDeploymentCoordinator:\n    \"\"\"Tests for DeploymentCoordinator.\"\"\"\n    \n    def test_create_standard_deployment(self, deployment_coordinator):\n        \"\"\"Test creating a standard deployment.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\", \"node-1\"],\n            strategy=DeploymentStrategy.STANDARD\n        )\n        \n        assert job is not None\n        assert job.application_id == \"test-app\"\n        assert job.version == \"1.0.0\"\n        assert job.strategy == DeploymentStrategy.STANDARD\n        assert len(job.target_nodes) == 2\n    \n    def test_create_canary_deployment(self, deployment_coordinator):\n        \"\"\"Test creating a canary deployment.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"2.0.0\",\n            target_nodes=[\"node-0\", \"node-1\", \"node-2\", \"node-3\", \"node-4\"],\n            strategy=DeploymentStrategy.CANARY,\n            previous_version=\"1.0.0\"\n        )\n        \n        assert job is not None\n        assert job.application_id == \"test-app\"\n        assert job.version == \"2.0.0\"\n        assert job.strategy == DeploymentStrategy.CANARY\n        assert job.previous_version == \"1.0.0\"\n    \n    def test_get_deployment(self, deployment_coordinator):\n        \"\"\"Test retrieving a deployment by ID.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\"]\n        )\n        \n        retrieved = deployment_coordinator.get_deployment(job.id)\n        assert retrieved is not None\n        assert retrieved.id == job.id\n    \n    def test_get_nonexistent_deployment(self, deployment_coordinator):\n        \"\"\"Test retrieving a non-existent deployment.\"\"\"\n        result = deployment_coordinator.get_deployment(\"nonexistent-id\")\n        assert result is None\n    \n    def test_cancel_deployment(self, deployment_coordinator):\n        \"\"\"Test cancelling a deployment.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\", \"node-1\"]\n        )\n        \n        # Give it a moment to start\n        time.sleep(0.1)\n        \n        success = deployment_coordinator.cancel_deployment(job.id)\n        assert success is True\n        \n        updated_job = deployment_coordinator.get_deployment(job.id)\n        assert updated_job.status == DeploymentStatus.CANCELLED\n    \n    def test_list_nodes(self, deployment_coordinator):\n        \"\"\"Test listing registered nodes.\"\"\"\n        nodes = deployment_coordinator.list_nodes()\n        assert len(nodes) == 5\n    \n    def test_standard_deployment_completes(self, deployment_coordinator):\n        \"\"\"Test that a standard deployment completes successfully.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\"],\n            strategy=DeploymentStrategy.STANDARD\n        )\n        \n        # Wait for deployment to complete\n        timeout = 5\n        start = time.time()\n        while time.time() - start < timeout:\n            updated_job = deployment_coordinator.get_deployment(job.id)\n            if updated_job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED]:\n                break\n            time.sleep(0.1)\n        \n        updated_job = deployment_coordinator.get_deployment(job.id)\n        assert updated_job.status == DeploymentStatus.COMPLETED\n        assert updated_job.progress == 100.0\n\n\nclass TestCanaryDeployment:\n    \"\"\"Tests specifically for canary deployment functionality.\"\"\"\n    \n    def test_canary_deployment_success_promotion(self, test_config):\n        \"\"\"Test successful canary deployment with promotion to all nodes.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Register test nodes\n        target_nodes = []\n        for i in range(5):\n            node = Node(\n                id=f\"node-{i}\",\n                hostname=f\"server-{i}.example.com\",\n                ip_address=f\"192.168.1.{10 + i}\",\n                status=NodeStatus.HEALTHY\n            )\n            coordinator.register_node(node)\n            target_nodes.append(node.id)\n        \n        # Mock metric collector to return healthy metrics\n        healthy_metrics = {\n            'cpu_usage': 45.0,\n            'error_rate': 1.0,\n            'memory_usage': 50.0,\n            'success_rate': 99.0\n        }\n        \n        with patch.object(coordinator.metric_collector, 'collect_metrics', return_value=healthy_metrics):\n            job = coordinator.create_deployment(\n                application_id=\"test-app\",\n                version=\"2.0.0\",\n                target_nodes=target_nodes,\n                strategy=DeploymentStrategy.CANARY,\n                previous_version=\"1.0.0\"\n            )\n            \n            # Wait for deployment to complete\n            timeout = 10\n            start = time.time()\n            while time.time() - start < timeout:\n                updated_job = coordinator.get_deployment(job.id)\n                if updated_job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED, \n                                          DeploymentStatus.ROLLED_BACK, DeploymentStatus.CANARY_FAILED]:\n                    break\n                time.sleep(0.2)\n            \n            final_job = coordinator.get_deployment(job.id)\n            \n            # Verify successful completion\n            assert final_job.status == DeploymentStatus.COMPLETED\n            assert final_job.progress == 100.0\n            assert len(final_job.canary_nodes) > 0\n            assert len(final_job.promoted_nodes) == len(target_nodes)\n            assert len(final_job.rolled_back_nodes) == 0\n    \n    def test_canary_deployment_failure_rollback(self, test_config):\n        \"\"\"Test canary deployment failure triggers rollback.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Register test nodes\n        target_nodes = []\n        for i in range(5):\n            node = Node(\n                id=f\"node-{i}\",\n                hostname=f\"server-{i}.example.com\",\n                ip_address=f\"192.168.1.{10 + i}\",\n                status=NodeStatus.HEALTHY\n            )\n            coordinator.register_node(node)\n            target_nodes.append(node.id)\n        \n        # Mock metric collector to return unhealthy metrics (high error rate)\n        unhealthy_metrics = {\n            'cpu_usage': 95.0,  # Exceeds 80% threshold\n            'error_rate': 15.0,  # Exceeds 5% threshold\n            'memory_usage': 90.0,  # Exceeds 85% threshold\n            'success_rate': 80.0  # Below 95% threshold\n        }\n        \n        with patch.object(coordinator.metric_collector, 'collect_metrics', return_value=unhealthy_metrics):\n            job = coordinator.create_deployment(\n                application_id=\"test-app\",\n                version=\"2.0.0\",\n                target_nodes=target_nodes,\n                strategy=DeploymentStrategy.CANARY,\n                previous_version=\"1.0.0\"\n            )\n            \n            # Wait for deployment to complete (with rollback)\n            timeout = 10\n            start = time.time()\n            while time.time() - start < timeout:\n                updated_job = coordinator.get_deployment(job.id)\n                if updated_job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED,\n                                          DeploymentStatus.ROLLED_BACK, DeploymentStatus.CANARY_FAILED]:\n                    break\n                time.sleep(0.2)\n            \n            final_job = coordinator.get_deployment(job.id)\n            \n            # Verify rollback occurred\n            assert final_job.status == DeploymentStatus.ROLLED_BACK\n            assert len(final_job.canary_nodes) > 0\n            assert len(final_job.rolled_back_nodes) == len(final_job.canary_nodes)\n            assert final_job.error_message is not None\n            assert 'threshold' in final_job.error_message.lower() or 'health' in final_job.error_message.lower()\n    \n    def test_canary_node_selection(self, test_config):\n        \"\"\"Test that canary selects correct percentage of nodes.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # With 20% canary percentage and 10 nodes, should select 2 nodes\n        target_nodes = [f\"node-{i}\" for i in range(10)]\n        \n        canary_nodes = coordinator._select_canary_nodes(target_nodes)\n        \n        # 20% of 10 = 2 nodes\n        assert len(canary_nodes) == 2\n        assert all(node in target_nodes for node in canary_nodes)\n    \n    def test_canary_node_selection_minimum_one(self, test_config):\n        \"\"\"Test that at least one canary node is selected.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Even with small percentage, should select at least 1 node\n        target_nodes = [\"node-0\", \"node-1\"]\n        \n        canary_nodes = coordinator._select_canary_nodes(target_nodes)\n        \n        assert len(canary_nodes) >= 1\n    \n    def test_canary_notification_on_rollback(self, test_config):\n        \"\"\"Test that notification is sent when canary deployment rolls back.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Register test nodes\n        target_nodes = []\n        for i in range(3):\n            node = Node(\n                id=f\"node-{i}\",\n                hostname=f\"server-{i}.example.com\",\n                ip_address=f\"192.168.1.{10 + i}\"\n            )\n            coordinator.register_node(node)\n            target_nodes.append(node.id)\n        \n        # Mock unhealthy metrics\n        unhealthy_metrics = {\n            'cpu_usage': 95.0,\n            'error_rate': 20.0,\n            'memory_usage': 95.0,\n            'success_rate': 70.0\n        }\n        \n        # Clear any previous notifications\n        coordinator.notification_gateway.clear_notifications()\n        \n        with patch.object(coordinator.metric_collector, 'collect_metrics', return_value=unhealthy_metrics):\n            job = coordinator.create_deployment(\n                application_id=\"test-app\",\n                version=\"2.0.0\",\n                target_nodes=target_nodes,\n                strategy=DeploymentStrategy.CANARY,\n                previous_version=\"1.0.0\"\n            )\n            \n            # Wait for rollback\n            timeout = 10\n            start = time.time()\n            while time.time() - start < timeout:\n                updated_job = coordinator.get_deployment(job.id)\n                if updated_job.status == DeploymentStatus.ROLLED_BACK:\n                    break\n                time.sleep(0.2)\n            \n            # Check notifications were sent\n            notifications = coordinator.notification_gateway.get_sent_notifications()\n            \n            # Should have at least one notification about the rollback\n            assert len(notifications) > 0\n            rollback_notifications = [\n                n for n in notifications \n                if 'rollback' in n.get('message', '').lower() or \n                   n.get('severity') in ['warning', 'error']\n            ]\n            assert len(rollback_notifications) > 0\n\n\nclass TestCanaryHealthPolicyHandler:\n    \"\"\"Tests for CanaryHealthPolicyHandler.\"\"\"\n    \n    def test_healthy_metrics_pass(self):\n        \"\"\"Test that healthy metrics pass the health check.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0,\n            'max_memory_usage': 85.0,\n            'min_success_rate': 95.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 50.0,\n            'error_rate': 2.0,\n            'memory_usage': 60.0,\n            'success_rate': 98.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is True\n        assert len(result.violations) == 0\n    \n    def test_high_cpu_fails(self):\n        \"\"\"Test that high CPU usage fails the health check.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 95.0,\n            'error_rate': 2.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 1\n        assert 'cpu' in result.violations[0].lower()\n    \n    def test_high_error_rate_fails(self):\n        \"\"\"Test that high error rate fails the health check.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 50.0,\n            'error_rate': 15.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 1\n        assert 'error' in result.violations[0].lower()\n    \n    def test_low_success_rate_fails(self):\n        \"\"\"Test that low success rate fails the health check.\"\"\"\n        thresholds = {\n            'min_success_rate': 95.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'success_rate': 85.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 1\n        assert 'success' in result.violations[0].lower()\n    \n    def test_multiple_violations(self):\n        \"\"\"Test that multiple threshold violations are all reported.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0,\n            'max_memory_usage': 85.0,\n            'min_success_rate': 95.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 95.0,  # Violation\n            'error_rate': 15.0,  # Violation\n            'memory_usage': 95.0,  # Violation\n            'success_rate': 80.0  # Violation\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 4\n    \n    def test_handler_name(self):\n        \"\"\"Test that handler returns correct name.\"\"\"\n        handler = CanaryHealthPolicyHandler({})\n        assert handler.get_name() == \"canary_health\"\n\n\nclass TestMetricCollector:\n    \"\"\"Tests for MetricCollector.\"\"\"\n    \n    def test_collect_metrics(self, test_config):\n        \"\"\"Test metric collection.\"\"\"\n        collector = MetricCollector(test_config)\n        \n        metrics = collector.collect_metrics(\"node-0\")\n        \n        assert 'cpu_usage' in metrics\n        assert 'memory_usage' in metrics\n        assert 'error_rate' in metrics\n    \n    def test_set_simulated_metrics(self, test_config):\n        \"\"\"Test setting simulated metrics.\"\"\"\n        collector = MetricCollector(test_config)\n        \n        custom_metrics = {\n            'cpu_usage': 75.0,\n            'error_rate': 3.0\n        }\n        \n        collector.set_simulated_metrics(\"node-0\", custom_metrics)\n        \n        # Collected metrics should be close to set values (with some variance)\n        metrics = collector.collect_metrics(\"node-0\")\n        assert abs(metrics['cpu_usage'] - 75.0) < 5\n        assert abs(metrics['error_rate'] - 3.0) < 5\n\n\nclass TestNotificationGateway:\n    \"\"\"Tests for NotificationGateway.\"\"\"\n    \n    def test_send_notification(self, test_config):\n        \"\"\"Test sending a notification.\"\"\"\n        gateway = NotificationGateway(test_config)\n        \n        result = gateway.send_notification(\n            title=\"Test Alert\",\n            message=\"This is a test\",\n            severity=\"warning\"\n        )\n        \n        assert result is True\n        \n        notifications = gateway.get_sent_notifications()\n        assert len(notifications) == 1\n        assert notifications[0]['title'] == \"Test Alert\"\n        assert notifications[0]['severity'] == \"warning\"\n    \n    def test_send_deployment_notification(self, test_config):\n        \"\"\"Test sending a deployment notification.\"\"\"\n        gateway = NotificationGateway(test_config)\n        \n        result = gateway.send_deployment_notification(\n            deployment_id=\"deploy-123\",\n            status=\"rolled_back\",\n            application_id=\"test-app\",\n            version=\"2.0.0\",\n            message=\"Deployment rolled back due to health check failure\"\n        )\n        \n        assert result is True\n        \n        notifications = gateway.get_sent_notifications()\n        assert len(notifications) == 1\n        assert 'rolled_back' in notifications[0]['title'].lower()\n        assert notifications[0]['severity'] == 'warning'\n\n\nclass TestRecoveryCoordinator:\n    \"\"\"Tests for RecoveryCoordinator.\"\"\"\n    \n    def test_recovery_coordinator_init(self, test_config):\n        \"\"\"Test RecoveryCoordinator initialization.\"\"\"\n        coordinator = RecoveryCoordinator(test_config)\n        assert coordinator is not None\n\n\nclass TestPerformanceCoordinator:\n    \"\"\"Tests for PerformanceCoordinator.\"\"\"\n    \n    def test_performance_coordinator_init(self, test_config):\n        \"\"\"Test PerformanceCoordinator initialization.\"\"\"\n        coordinator = PerformanceCoordinator(test_config)\n        assert coordinator is not None\n",
          "vitalops_orchestrator/vitalops/core/eventing.py": "\"\"\"Event bus and eventing system for VitalOps Orchestrator.\"\"\"\n\nimport logging\nimport threading\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Any, Callable, Dict, List, Optional\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Event:\n    \"\"\"Represents an event in the system.\"\"\"\n    event_type: str\n    data: Dict[str, Any] = field(default_factory=dict)\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    source: Optional[str] = None\n\n\nclass EventBus:\n    \"\"\"Simple event bus for publishing and subscribing to events.\"\"\"\n    \n    def __init__(self):\n        self._subscribers: Dict[str, List[Callable[[Event], None]]] = {}\n        self._lock = threading.Lock()\n        logger.info(\"EventBus initialized\")\n    \n    def subscribe(self, event_type: str, handler: Callable[[Event], None]) -> None:\n        \"\"\"Subscribe to events of a specific type.\n        \n        Args:\n            event_type: Type of event to subscribe to (supports wildcards with '*')\n            handler: Callback function to handle the event\n        \"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                self._subscribers[event_type] = []\n            self._subscribers[event_type].append(handler)\n            logger.debug(f\"Subscribed handler to event type: {event_type}\")\n    \n    def unsubscribe(self, event_type: str, handler: Callable[[Event], None]) -> None:\n        \"\"\"Unsubscribe from events of a specific type.\n        \n        Args:\n            event_type: Type of event to unsubscribe from\n            handler: Handler to remove\n        \"\"\"\n        with self._lock:\n            if event_type in self._subscribers:\n                try:\n                    self._subscribers[event_type].remove(handler)\n                    logger.debug(f\"Unsubscribed handler from event type: {event_type}\")\n                except ValueError:\n                    pass\n    \n    def publish(self, event: Event) -> None:\n        \"\"\"Publish an event to all subscribers.\n        \n        Args:\n            event: Event to publish\n        \"\"\"\n        handlers_to_call = []\n        \n        with self._lock:\n            # Get exact match subscribers\n            if event.event_type in self._subscribers:\n                handlers_to_call.extend(self._subscribers[event.event_type])\n            \n            # Get wildcard subscribers\n            for pattern, handlers in self._subscribers.items():\n                if '*' in pattern:\n                    if self._matches_pattern(event.event_type, pattern):\n                        handlers_to_call.extend(handlers)\n        \n        # Call handlers outside the lock\n        for handler in handlers_to_call:\n            try:\n                handler(event)\n            except Exception as e:\n                logger.error(f\"Error in event handler for {event.event_type}: {e}\")\n    \n    def _matches_pattern(self, event_type: str, pattern: str) -> bool:\n        \"\"\"Check if event type matches a wildcard pattern.\"\"\"\n        if pattern == '*':\n            return True\n        \n        pattern_parts = pattern.split('.')\n        type_parts = event_type.split('.')\n        \n        if len(pattern_parts) != len(type_parts):\n            return False\n        \n        for p, t in zip(pattern_parts, type_parts):\n            if p != '*' and p != t:\n                return False\n        \n        return True\n",
          "vitalops_orchestrator/vitalops/coordinators/recovery.py": "\"\"\"Recovery coordinator for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass RecoveryCoordinator:\n    \"\"\"Coordinates recovery operations for unhealthy nodes.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.recovery_config = config.get('recovery', {})\n        self.auto_recovery = self.recovery_config.get('auto_recovery', True)\n        self.max_attempts = self.recovery_config.get('max_recovery_attempts', 3)\n        self.cooldown = self.recovery_config.get('recovery_cooldown', 300)\n        \n        self._recovery_attempts: Dict[str, int] = {}\n        \n        logger.info(\"RecoveryCoordinator initialized\")\n    \n    def trigger_recovery(self, node_id: str) -> Dict[str, Any]:\n        \"\"\"Trigger recovery for a specific node.\n        \n        Args:\n            node_id: ID of the node to recover\n            \n        Returns:\n            Dictionary with recovery result\n        \"\"\"\n        attempts = self._recovery_attempts.get(node_id, 0)\n        \n        if attempts >= self.max_attempts:\n            logger.warning(f\"Max recovery attempts reached for node {node_id}\")\n            return {\n                'success': False,\n                'node_id': node_id,\n                'message': 'Max recovery attempts reached',\n                'attempts': attempts\n            }\n        \n        self._recovery_attempts[node_id] = attempts + 1\n        \n        # Perform recovery (placeholder for actual implementation)\n        logger.info(f\"Triggering recovery for node {node_id} (attempt {attempts + 1})\")\n        \n        return {\n            'success': True,\n            'node_id': node_id,\n            'message': 'Recovery triggered',\n            'attempts': attempts + 1\n        }\n    \n    def reset_attempts(self, node_id: str) -> None:\n        \"\"\"Reset recovery attempts for a node.\"\"\"\n        if node_id in self._recovery_attempts:\n            del self._recovery_attempts[node_id]\n",
          "vitalops_orchestrator/vitalops/coordinators/performance.py": "\"\"\"Performance coordinator for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, List, Optional\n\nfrom vitalops.services.metric_collector import MetricCollector\n\nlogger = logging.getLogger(__name__)\n\n\nclass PerformanceCoordinator:\n    \"\"\"Coordinates performance monitoring and analysis.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.metric_collector = MetricCollector(config)\n        \n        logger.info(\"PerformanceCoordinator initialized\")\n    \n    def get_node_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Get current metrics for a node.\n        \n        Args:\n            node_id: ID of the node\n            \n        Returns:\n            Dictionary of metric values\n        \"\"\"\n        return self.metric_collector.collect_metrics(node_id)\n    \n    def get_cluster_metrics(self, node_ids: List[str]) -> Dict[str, Any]:\n        \"\"\"Get aggregated metrics for a cluster of nodes.\n        \n        Args:\n            node_ids: List of node IDs\n            \n        Returns:\n            Dictionary with aggregated metrics\n        \"\"\"\n        all_metrics = self.metric_collector.collect_metrics_batch(node_ids)\n        \n        # Aggregate metrics\n        aggregated = {}\n        metric_names = set()\n        \n        for node_metrics in all_metrics.values():\n            metric_names.update(node_metrics.keys())\n        \n        for metric_name in metric_names:\n            values = [\n                m.get(metric_name, 0) \n                for m in all_metrics.values() \n                if metric_name in m\n            ]\n            if values:\n                aggregated[metric_name] = {\n                    'avg': sum(values) / len(values),\n                    'min': min(values),\n                    'max': max(values)\n                }\n        \n        return {\n            'node_count': len(node_ids),\n            'metrics': aggregated\n        }\n"
        },
        "generated_files": [
          "vitalops_orchestrator/config.yaml",
          "vitalops_orchestrator/vitalops/models/domain.py",
          "vitalops_orchestrator/vitalops/interfaces/api.py",
          "vitalops_orchestrator/vitalops/coordinators/deployment.py",
          "vitalops_orchestrator/vitalops/policy_engine/handlers.py",
          "vitalops_orchestrator/vitalops/services/metric_collector.py",
          "vitalops_orchestrator/vitalops/services/notification_gateway.py",
          "vitalops_orchestrator/tests/test_coordinators.py",
          "vitalops_orchestrator/vitalops/core/eventing.py",
          "vitalops_orchestrator/vitalops/coordinators/recovery.py",
          "vitalops_orchestrator/vitalops/coordinators/performance.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7705016775842787,
              "dependency_traversal_accuracy": 0.7445406288926719,
              "cross_file_reasoning_depth": 0.33257575757575764,
              "system_thinking_score": 0.645662270433035,
              "robustness_score": 0.17366482504604053,
              "comprehensiveness_score": 0.7212946780922314,
              "innovation_score": 0.4131560773480663,
              "solution_elegance_score": 0.4988073121981015
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09631270969803483,
              "dependency_traversal_weighted": 0.09306757861158399,
              "cross_file_reasoning_weighted": 0.041571969696969704,
              "system_thinking_weighted": 0.08070778380412938,
              "robustness_weighted": 0.021708103130755066,
              "comprehensiveness_weighted": 0.09016183476152892,
              "innovation_weighted": 0.05164450966850829,
              "solution_elegance_weighted": 0.062350914024762685
            },
            "total_software_engineering_score": 0.5375254033962729
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.6958315372467041,
              "errors": [
                "  File \"vitalops_orchestrator/config.py\", line 3",
                "    server:",
                "           ^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "vitalops_orchestrator/config.yaml",
                "vitalops_orchestrator/vitalops/models/domain.py",
                "vitalops_orchestrator/vitalops/interfaces/api.py",
                "vitalops_orchestrator/vitalops/coordinators/deployment.py",
                "vitalops_orchestrator/vitalops/policy_engine/handlers.py",
                "vitalops_orchestrator/vitalops/services/metric_collector.py",
                "vitalops_orchestrator/vitalops/services/notification_gateway.py",
                "vitalops_orchestrator/tests/test_coordinators.py",
                "vitalops_orchestrator/vitalops/core/eventing.py",
                "vitalops_orchestrator/vitalops/coordinators/recovery.py",
                "vitalops_orchestrator/vitalops/coordinators/performance.py"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 11,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 11 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.30366001050972147,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.30366001050972147,
              "idc_weight": 0.2,
              "total_functional_score": 0.40073200210194426
            }
          },
          "code_quality_details": {
            "files_analyzed": 11,
            "quality_checks": {
              "vitalops_orchestrator/config.yaml": {
                "line_count": 57,
                "non_empty_lines": 48,
                "comment_lines": 1,
                "comment_ratio": 0.020833333333333332,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.7
              },
              "vitalops_orchestrator/vitalops/models/domain.py": {
                "line_count": 152,
                "non_empty_lines": 125,
                "comment_lines": 1,
                "comment_ratio": 0.008,
                "function_count": 3,
                "class_count": 11,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/interfaces/api.py": {
                "line_count": 208,
                "non_empty_lines": 164,
                "comment_lines": 4,
                "comment_ratio": 0.024390243902439025,
                "function_count": 9,
                "class_count": 0,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/coordinators/deployment.py": {
                "line_count": 361,
                "non_empty_lines": 293,
                "comment_lines": 16,
                "comment_ratio": 0.05460750853242321,
                "function_count": 14,
                "class_count": 1,
                "import_count": 20,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/policy_engine/handlers.py": {
                "line_count": 241,
                "non_empty_lines": 184,
                "comment_lines": 4,
                "comment_ratio": 0.021739130434782608,
                "function_count": 17,
                "class_count": 7,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/services/metric_collector.py": {
                "line_count": 183,
                "non_empty_lines": 145,
                "comment_lines": 14,
                "comment_ratio": 0.09655172413793103,
                "function_count": 9,
                "class_count": 1,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/services/notification_gateway.py": {
                "line_count": 194,
                "non_empty_lines": 157,
                "comment_lines": 7,
                "comment_ratio": 0.044585987261146494,
                "function_count": 9,
                "class_count": 1,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/tests/test_coordinators.py": {
                "line_count": 550,
                "non_empty_lines": 444,
                "comment_lines": 21,
                "comment_ratio": 0.0472972972972973,
                "function_count": 26,
                "class_count": 7,
                "import_count": 21,
                "quality_score": 0.6
              },
              "vitalops_orchestrator/vitalops/core/eventing.py": {
                "line_count": 101,
                "non_empty_lines": 79,
                "comment_lines": 3,
                "comment_ratio": 0.0379746835443038,
                "function_count": 5,
                "class_count": 6,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/coordinators/recovery.py": {
                "line_count": 59,
                "non_empty_lines": 43,
                "comment_lines": 1,
                "comment_ratio": 0.023255813953488372,
                "function_count": 3,
                "class_count": 1,
                "import_count": 3,
                "quality_score": 0.7999999999999999
              },
              "vitalops_orchestrator/vitalops/coordinators/performance.py": {
                "line_count": 66,
                "non_empty_lines": 48,
                "comment_lines": 1,
                "comment_ratio": 0.020833333333333332,
                "function_count": 3,
                "class_count": 1,
                "import_count": 5,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7809090909090908,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8776785714285715,
              "multi_session_memory_retention": 0.8538610038610039
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.43883928571428577,
              "multi_session_memory_retention_weighted": 0.42693050193050197
            },
            "total_longcontext_utilization_score": 0.8657697876447877
          }
        },
        "timestamp": "2026-01-14T21:25:56.780151"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_fintech_payment_expert_029_feature_implementation_expert_01",
        "scenario_title": "Implement Dynamic, Risk-Based Transaction Fees",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5781345341314588,
        "functional_correctness_score": 0.6489113739232005,
        "code_quality_score": 0.7999999999999999,
        "longcontext_utilization_score": 0.8579365079365079,
        "total_score": 3.3586043831159724,
        "generation_time": 222.36056971549988,
        "code_files_generated": 9,
        "total_lines_generated": 1896,
        "parsing_success": true,
        "solution_code": {
          "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py": "\"\"\"Fee calculation API endpoint for risk-based transaction fees.\"\"\"\nfrom fastapi import APIRouter, HTTPException\nfrom pydantic import BaseModel, Field\nfrom decimal import Decimal, ROUND_HALF_UP\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(prefix=\"/v1/fees\", tags=[\"fees\"])\n\n# Constants for fee calculation\nBASE_RATE = Decimal(\"0.005\")  # 0.5%\nRISK_PREMIUM = Decimal(\"0.02\")  # 2%\n\n\nclass FeeCalculationRequest(BaseModel):\n    \"\"\"Request model for fee calculation.\"\"\"\n    amount: Decimal = Field(..., gt=0, description=\"Transaction amount\")\n    currency: str = Field(..., min_length=3, max_length=3, description=\"Currency code\")\n    source_user_id: str = Field(..., description=\"Source user ID\")\n    destination_pod_id: str = Field(..., description=\"Destination pod ID\")\n\n\nclass FeeCalculationResponse(BaseModel):\n    \"\"\"Response model for fee calculation.\"\"\"\n    fee: Decimal = Field(..., description=\"Calculated transaction fee\")\n    total_debit_amount: Decimal = Field(..., description=\"Total amount to debit (amount + fee)\")\n    base_rate: Decimal = Field(..., description=\"Base rate used\")\n    risk_premium: Decimal = Field(..., description=\"Risk premium used\")\n    user_reputation_score: Decimal = Field(..., description=\"User reputation score used\")\n    currency: str = Field(..., description=\"Currency code\")\n\n\ndef get_user_reputation_score(user_id: str) -> Decimal:\n    \"\"\"Fetch user reputation score.\n    \n    In a real implementation, this would call the user service or a cache.\n    For this implementation, we use a deterministic mock based on user_id.\n    \n    Args:\n        user_id: The user's unique identifier\n        \n    Returns:\n        A reputation score between 0.0 and 1.0\n    \"\"\"\n    # Mock implementation: hash the user_id to get a deterministic score\n    # In production, this would call the user_service reputation endpoint\n    hash_value = hash(user_id)\n    # Normalize to 0.0-1.0 range\n    score = abs(hash_value % 100) / 100.0\n    return Decimal(str(score)).quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\n\n\ndef calculate_transaction_fee(\n    amount: Decimal,\n    user_reputation_score: Decimal,\n    base_rate: Decimal = BASE_RATE,\n    risk_premium: Decimal = RISK_PREMIUM\n) -> Decimal:\n    \"\"\"Calculate the transaction fee based on amount and user reputation.\n    \n    Formula: fee = (base_rate * amount) + (risk_premium * amount * user_reputation_score)\n    \n    Higher reputation scores result in higher fees (risk-based pricing).\n    This incentivizes maintaining good standing while covering platform risk.\n    \n    Args:\n        amount: Transaction amount\n        user_reputation_score: User's reputation score (0.0 to 1.0)\n        base_rate: Base fee rate (default 0.5%)\n        risk_premium: Risk premium rate (default 2%)\n        \n    Returns:\n        Calculated fee amount\n    \"\"\"\n    base_fee = base_rate * amount\n    risk_fee = risk_premium * amount * user_reputation_score\n    total_fee = base_fee + risk_fee\n    # Round to 2 decimal places\n    return total_fee.quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\n\n\n@router.post(\"/calculate\", response_model=FeeCalculationResponse)\nasync def calculate_fees(request: FeeCalculationRequest) -> FeeCalculationResponse:\n    \"\"\"Calculate transaction fees based on risk assessment.\n    \n    This endpoint calculates dynamic fees based on:\n    - Transaction amount\n    - Source user's reputation score\n    - Base rate and risk premium\n    \n    Args:\n        request: Fee calculation request with transaction details\n        \n    Returns:\n        Calculated fee and total debit amount\n    \"\"\"\n    try:\n        logger.info(\n            f\"Calculating fees for user {request.source_user_id}, \"\n            f\"amount {request.amount} {request.currency}\"\n        )\n        \n        # Get user reputation score\n        user_reputation_score = get_user_reputation_score(request.source_user_id)\n        \n        # Calculate fee\n        fee = calculate_transaction_fee(\n            amount=request.amount,\n            user_reputation_score=user_reputation_score\n        )\n        \n        # Calculate total debit amount\n        total_debit_amount = request.amount + fee\n        \n        logger.info(\n            f\"Fee calculated: {fee} {request.currency}, \"\n            f\"total debit: {total_debit_amount} {request.currency}, \"\n            f\"reputation score: {user_reputation_score}\"\n        )\n        \n        return FeeCalculationResponse(\n            fee=fee,\n            total_debit_amount=total_debit_amount,\n            base_rate=BASE_RATE,\n            risk_premium=RISK_PREMIUM,\n            user_reputation_score=user_reputation_score,\n            currency=request.currency\n        )\n        \n    except Exception as e:\n        logger.error(f\"Error calculating fees: {str(e)}\")\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to calculate transaction fees: {str(e)}\"\n        )\n",
          "crowdpay_connect/services/risk_compliance_service/app/main.py": "\"\"\"Main application entry point for the Risk Compliance Service.\"\"\"\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nimport logging\n\nfrom app.api.v1 import assessment\nfrom app.api.v1 import fees\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(\n    title=\"Risk Compliance Service\",\n    description=\"Service for risk assessment, compliance checking, and fee calculation\",\n    version=\"1.0.0\"\n)\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(assessment.router)\napp.include_router(fees.router)\n\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"service\": \"risk_compliance_service\"}\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Handle application startup.\"\"\"\n    logger.info(\"Risk Compliance Service starting up...\")\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    \"\"\"Handle application shutdown.\"\"\"\n    logger.info(\"Risk Compliance Service shutting down...\")\n",
          "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py": "\"\"\"Unit tests for fee calculation logic.\"\"\"\nimport pytest\nfrom decimal import Decimal\nfrom unittest.mock import patch, AsyncMock\nfrom fastapi.testclient import TestClient\n\nfrom app.main import app\nfrom app.api.v1.fees import (\n    calculate_transaction_fee,\n    get_user_reputation_score,\n    BASE_RATE,\n    RISK_PREMIUM,\n    FeeCalculationRequest,\n    FeeCalculationResponse\n)\n\nclient = TestClient(app)\n\n\nclass TestFeeCalculationLogic:\n    \"\"\"Test cases for fee calculation logic.\"\"\"\n    \n    def test_calculate_fee_with_zero_reputation(self):\n        \"\"\"Test fee calculation with zero reputation score.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"0.0\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # With 0 reputation, only base fee applies: 0.005 * 100 = 0.50\n        expected_fee = Decimal(\"0.50\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_with_full_reputation(self):\n        \"\"\"Test fee calculation with maximum reputation score.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"1.0\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 100 = 0.50\n        # Risk fee: 0.02 * 100 * 1.0 = 2.00\n        # Total: 2.50\n        expected_fee = Decimal(\"2.50\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_with_partial_reputation(self):\n        \"\"\"Test fee calculation with 50% reputation score.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"0.5\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 100 = 0.50\n        # Risk fee: 0.02 * 100 * 0.5 = 1.00\n        # Total: 1.50\n        expected_fee = Decimal(\"1.50\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_large_amount(self):\n        \"\"\"Test fee calculation with large transaction amount.\"\"\"\n        amount = Decimal(\"10000.00\")\n        reputation_score = Decimal(\"0.75\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 10000 = 50.00\n        # Risk fee: 0.02 * 10000 * 0.75 = 150.00\n        # Total: 200.00\n        expected_fee = Decimal(\"200.00\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_small_amount(self):\n        \"\"\"Test fee calculation with small transaction amount.\"\"\"\n        amount = Decimal(\"1.00\")\n        reputation_score = Decimal(\"0.5\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 1 = 0.005 -> rounds to 0.01 or 0.02\n        # Risk fee: 0.02 * 1 * 0.5 = 0.01\n        # Total: ~0.02\n        assert fee >= Decimal(\"0.01\")\n        assert fee <= Decimal(\"0.03\")\n    \n    def test_calculate_fee_custom_rates(self):\n        \"\"\"Test fee calculation with custom base rate and risk premium.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"0.5\")\n        custom_base_rate = Decimal(\"0.01\")  # 1%\n        custom_risk_premium = Decimal(\"0.05\")  # 5%\n        \n        fee = calculate_transaction_fee(\n            amount,\n            reputation_score,\n            base_rate=custom_base_rate,\n            risk_premium=custom_risk_premium\n        )\n        \n        # Base fee: 0.01 * 100 = 1.00\n        # Risk fee: 0.05 * 100 * 0.5 = 2.50\n        # Total: 3.50\n        expected_fee = Decimal(\"3.50\")\n        assert fee == expected_fee\n    \n    def test_fee_rounding(self):\n        \"\"\"Test that fees are properly rounded to 2 decimal places.\"\"\"\n        amount = Decimal(\"33.33\")\n        reputation_score = Decimal(\"0.33\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Ensure fee has exactly 2 decimal places\n        assert fee == fee.quantize(Decimal(\"0.01\"))\n\n\nclass TestUserReputationScore:\n    \"\"\"Test cases for user reputation score retrieval.\"\"\"\n    \n    def test_reputation_score_range(self):\n        \"\"\"Test that reputation score is within valid range.\"\"\"\n        for user_id in [\"user1\", \"user2\", \"user123\", \"test-user\"]:\n            score = get_user_reputation_score(user_id)\n            assert Decimal(\"0.0\") <= score <= Decimal(\"1.0\")\n    \n    def test_reputation_score_deterministic(self):\n        \"\"\"Test that same user_id always returns same score.\"\"\"\n        user_id = \"consistent-user-123\"\n        score1 = get_user_reputation_score(user_id)\n        score2 = get_user_reputation_score(user_id)\n        assert score1 == score2\n    \n    def test_different_users_can_have_different_scores(self):\n        \"\"\"Test that different users can have different scores.\"\"\"\n        # With enough users, we should see variation\n        scores = set()\n        for i in range(100):\n            score = get_user_reputation_score(f\"user-{i}\")\n            scores.add(score)\n        \n        # Should have multiple unique scores\n        assert len(scores) > 1\n\n\nclass TestFeeCalculationEndpoint:\n    \"\"\"Test cases for the /v1/fees/calculate endpoint.\"\"\"\n    \n    def test_calculate_fees_success(self):\n        \"\"\"Test successful fee calculation via API.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 200\n        data = response.json()\n        \n        assert \"fee\" in data\n        assert \"total_debit_amount\" in data\n        assert \"base_rate\" in data\n        assert \"risk_premium\" in data\n        assert \"user_reputation_score\" in data\n        assert \"currency\" in data\n        \n        # Verify total = amount + fee\n        fee = Decimal(data[\"fee\"])\n        total = Decimal(data[\"total_debit_amount\"])\n        assert total == Decimal(\"100.00\") + fee\n    \n    def test_calculate_fees_invalid_amount(self):\n        \"\"\"Test fee calculation with invalid amount.\"\"\"\n        request_data = {\n            \"amount\": \"-100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 422  # Validation error\n    \n    def test_calculate_fees_invalid_currency(self):\n        \"\"\"Test fee calculation with invalid currency code.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\",\n            \"currency\": \"INVALID\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 422  # Validation error\n    \n    def test_calculate_fees_missing_fields(self):\n        \"\"\"Test fee calculation with missing required fields.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\"\n            # Missing other required fields\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 422  # Validation error\n    \n    def test_calculate_fees_returns_correct_rates(self):\n        \"\"\"Test that endpoint returns correct base rate and risk premium.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 200\n        data = response.json()\n        \n        assert Decimal(data[\"base_rate\"]) == BASE_RATE\n        assert Decimal(data[\"risk_premium\"]) == RISK_PREMIUM\n    \n    def test_calculate_fees_different_currencies(self):\n        \"\"\"Test fee calculation with different currencies.\"\"\"\n        currencies = [\"USD\", \"EUR\", \"GBP\"]\n        \n        for currency in currencies:\n            request_data = {\n                \"amount\": \"100.00\",\n                \"currency\": currency,\n                \"source_user_id\": \"user-123\",\n                \"destination_pod_id\": \"pod-456\"\n            }\n            \n            response = client.post(\"/v1/fees/calculate\", json=request_data)\n            \n            assert response.status_code == 200\n            assert response.json()[\"currency\"] == currency\n\n\nclass TestFeeCalculationIntegration:\n    \"\"\"Integration tests for fee calculation.\"\"\"\n    \n    def test_fee_calculation_consistency(self):\n        \"\"\"Test that fee calculation is consistent for same inputs.\"\"\"\n        request_data = {\n            \"amount\": \"500.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"consistent-user\",\n            \"destination_pod_id\": \"pod-789\"\n        }\n        \n        response1 = client.post(\"/v1/fees/calculate\", json=request_data)\n        response2 = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response1.json() == response2.json()\n    \n    def test_fee_scales_with_amount(self):\n        \"\"\"Test that fee scales proportionally with amount.\"\"\"\n        user_id = \"scaling-test-user\"\n        \n        response1 = client.post(\"/v1/fees/calculate\", json={\n            \"amount\": \"100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": user_id,\n            \"destination_pod_id\": \"pod-123\"\n        })\n        \n        response2 = client.post(\"/v1/fees/calculate\", json={\n            \"amount\": \"200.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": user_id,\n            \"destination_pod_id\": \"pod-123\"\n        })\n        \n        fee1 = Decimal(response1.json()[\"fee\"])\n        fee2 = Decimal(response2.json()[\"fee\"])\n        \n        # Fee should roughly double when amount doubles\n        assert Decimal(\"1.9\") <= fee2 / fee1 <= Decimal(\"2.1\")\n",
          "crowdpay_connect/services/transaction_service/app/models/saga_state.py": "\"\"\"Saga state model for tracking payment saga progress.\"\"\"\nfrom sqlalchemy import Column, String, Enum, DateTime, JSON, Numeric\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom datetime import datetime\nimport enum\nimport uuid\n\nfrom app.db.base import Base\n\n\nclass SagaStatus(enum.Enum):\n    \"\"\"Enumeration of possible saga statuses.\"\"\"\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    COMPENSATING = \"compensating\"\n    FAILED = \"failed\"\n    ROLLED_BACK = \"rolled_back\"\n\n\nclass SagaStepStatus(enum.Enum):\n    \"\"\"Enumeration of possible saga step statuses.\"\"\"\n    PENDING = \"pending\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    COMPENSATED = \"compensated\"\n\n\nclass SagaState(Base):\n    \"\"\"Model representing the state of a payment saga.\"\"\"\n    \n    __tablename__ = \"saga_states\"\n    \n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    transaction_id = Column(UUID(as_uuid=True), unique=True, nullable=False, index=True)\n    \n    # Saga status tracking\n    status = Column(Enum(SagaStatus), default=SagaStatus.PENDING, nullable=False)\n    current_step = Column(String(100), nullable=True)\n    current_step_status = Column(Enum(SagaStepStatus), default=SagaStepStatus.PENDING)\n    \n    # Transaction details\n    source_wallet_id = Column(UUID(as_uuid=True), nullable=False)\n    destination_pod_id = Column(UUID(as_uuid=True), nullable=False)\n    source_user_id = Column(String(100), nullable=False)\n    amount = Column(Numeric(precision=18, scale=2), nullable=False)\n    currency = Column(String(3), nullable=False)\n    \n    # Fee information (new fields for dynamic fees)\n    transaction_fee = Column(Numeric(precision=18, scale=2), nullable=True)\n    total_debit_amount = Column(Numeric(precision=18, scale=2), nullable=True)\n    fee_calculation_details = Column(JSON, nullable=True)  # Stores full fee response\n    \n    # Step completion tracking\n    completed_steps = Column(JSON, default=list)\n    step_results = Column(JSON, default=dict)\n    \n    # Error tracking\n    error_message = Column(String(500), nullable=True)\n    failed_step = Column(String(100), nullable=True)\n    \n    # Timestamps\n    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)\n    completed_at = Column(DateTime, nullable=True)\n    \n    def __repr__(self):\n        return f\"<SagaState(id={self.id}, transaction_id={self.transaction_id}, status={self.status})>\"\n    \n    def to_dict(self):\n        \"\"\"Convert saga state to dictionary.\"\"\"\n        return {\n            \"id\": str(self.id),\n            \"transaction_id\": str(self.transaction_id),\n            \"status\": self.status.value,\n            \"current_step\": self.current_step,\n            \"current_step_status\": self.current_step_status.value if self.current_step_status else None,\n            \"source_wallet_id\": str(self.source_wallet_id),\n            \"destination_pod_id\": str(self.destination_pod_id),\n            \"source_user_id\": self.source_user_id,\n            \"amount\": str(self.amount),\n            \"currency\": self.currency,\n            \"transaction_fee\": str(self.transaction_fee) if self.transaction_fee else None,\n            \"total_debit_amount\": str(self.total_debit_amount) if self.total_debit_amount else None,\n            \"fee_calculation_details\": self.fee_calculation_details,\n            \"completed_steps\": self.completed_steps,\n            \"step_results\": self.step_results,\n            \"error_message\": self.error_message,\n            \"failed_step\": self.failed_step,\n            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n            \"updated_at\": self.updated_at.isoformat() if self.updated_at else None,\n            \"completed_at\": self.completed_at.isoformat() if self.completed_at else None\n        }\n    \n    def mark_step_completed(self, step_name: str, result: dict = None):\n        \"\"\"Mark a step as completed and store its result.\"\"\"\n        if self.completed_steps is None:\n            self.completed_steps = []\n        if step_name not in self.completed_steps:\n            self.completed_steps = self.completed_steps + [step_name]\n        \n        if result:\n            if self.step_results is None:\n                self.step_results = {}\n            self.step_results = {**self.step_results, step_name: result}\n    \n    def set_fee_details(self, fee: float, total_debit: float, details: dict = None):\n        \"\"\"Set fee calculation details.\"\"\"\n        from decimal import Decimal\n        self.transaction_fee = Decimal(str(fee))\n        self.total_debit_amount = Decimal(str(total_debit))\n        self.fee_calculation_details = details\n",
          "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py": "\"\"\"Payment Saga implementation for orchestrating payment transactions.\"\"\"\nimport logging\nimport httpx\nfrom decimal import Decimal\nfrom typing import Optional, Dict, Any\nfrom datetime import datetime\nimport json\n\nfrom app.models.saga_state import SagaState, SagaStatus, SagaStepStatus\nfrom app.events.saga_coordinator import SagaCoordinator\nfrom libs.shared_events.schemas import DebitWallet, CreditPod, PaymentCompleted, PaymentFailed\n\nlogger = logging.getLogger(__name__)\n\n# Configuration for risk service\nRISK_SERVICE_URL = \"http://risk-compliance-service:8000\"\nFEE_CALCULATION_ENDPOINT = \"/v1/fees/calculate\"\nFEE_CALCULATION_TIMEOUT = 10.0  # seconds\n\n\nclass PaymentSagaError(Exception):\n    \"\"\"Custom exception for payment saga errors.\"\"\"\n    pass\n\n\nclass PaymentSaga:\n    \"\"\"Orchestrates the payment transaction saga.\n    \n    Steps:\n    1. Validate transaction\n    2. Calculate fees (NEW)\n    3. Debit source wallet\n    4. Credit destination pod\n    5. Complete transaction\n    \n    Each step has a corresponding compensation action for rollback.\n    \"\"\"\n    \n    STEPS = [\n        \"validate_transaction\",\n        \"calculate_fees\",\n        \"debit_source_wallet\",\n        \"credit_destination_pod\",\n        \"complete_transaction\"\n    ]\n    \n    def __init__(self, saga_state: SagaState, coordinator: SagaCoordinator):\n        \"\"\"Initialize the payment saga.\n        \n        Args:\n            saga_state: The saga state model instance\n            coordinator: The saga coordinator for event publishing\n        \"\"\"\n        self.saga_state = saga_state\n        self.coordinator = coordinator\n        self._http_client: Optional[httpx.AsyncClient] = None\n    \n    async def execute(self) -> bool:\n        \"\"\"Execute the payment saga.\n        \n        Returns:\n            True if saga completed successfully, False otherwise\n        \"\"\"\n        logger.info(f\"Starting payment saga for transaction {self.saga_state.transaction_id}\")\n        \n        self.saga_state.status = SagaStatus.IN_PROGRESS\n        await self.coordinator.update_saga_state(self.saga_state)\n        \n        try:\n            for step in self.STEPS:\n                if step in (self.saga_state.completed_steps or []):\n                    logger.info(f\"Skipping already completed step: {step}\")\n                    continue\n                \n                self.saga_state.current_step = step\n                self.saga_state.current_step_status = SagaStepStatus.EXECUTING\n                await self.coordinator.update_saga_state(self.saga_state)\n                \n                step_method = getattr(self, f\"_step_{step}\")\n                result = await step_method()\n                \n                self.saga_state.mark_step_completed(step, result)\n                self.saga_state.current_step_status = SagaStepStatus.COMPLETED\n                await self.coordinator.update_saga_state(self.saga_state)\n                \n                logger.info(f\"Completed step: {step}\")\n            \n            self.saga_state.status = SagaStatus.COMPLETED\n            self.saga_state.completed_at = datetime.utcnow()\n            await self.coordinator.update_saga_state(self.saga_state)\n            \n            logger.info(f\"Payment saga completed successfully for transaction {self.saga_state.transaction_id}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Payment saga failed at step {self.saga_state.current_step}: {str(e)}\")\n            self.saga_state.error_message = str(e)\n            self.saga_state.failed_step = self.saga_state.current_step\n            self.saga_state.current_step_status = SagaStepStatus.FAILED\n            await self.coordinator.update_saga_state(self.saga_state)\n            \n            await self.compensate()\n            return False\n        finally:\n            if self._http_client:\n                await self._http_client.aclose()\n    \n    async def compensate(self):\n        \"\"\"Execute compensation for all completed steps in reverse order.\"\"\"\n        logger.info(f\"Starting compensation for transaction {self.saga_state.transaction_id}\")\n        \n        self.saga_state.status = SagaStatus.COMPENSATING\n        await self.coordinator.update_saga_state(self.saga_state)\n        \n        completed_steps = list(reversed(self.saga_state.completed_steps or []))\n        \n        for step in completed_steps:\n            try:\n                compensate_method = getattr(self, f\"_compensate_{step}\", None)\n                if compensate_method:\n                    logger.info(f\"Compensating step: {step}\")\n                    await compensate_method()\n            except Exception as e:\n                logger.error(f\"Compensation failed for step {step}: {str(e)}\")\n        \n        self.saga_state.status = SagaStatus.ROLLED_BACK\n        await self.coordinator.update_saga_state(self.saga_state)\n        \n        # Publish payment failed event\n        await self.coordinator.publish_event(PaymentFailed(\n            transaction_id=str(self.saga_state.transaction_id),\n            source_wallet_id=str(self.saga_state.source_wallet_id),\n            destination_pod_id=str(self.saga_state.destination_pod_id),\n            amount=str(self.saga_state.amount),\n            currency=self.saga_state.currency,\n            error_message=self.saga_state.error_message,\n            failed_step=self.saga_state.failed_step\n        ))\n        \n        logger.info(f\"Compensation completed for transaction {self.saga_state.transaction_id}\")\n    \n    # Step implementations\n    \n    async def _step_validate_transaction(self) -> Dict[str, Any]:\n        \"\"\"Validate the transaction details.\"\"\"\n        logger.info(f\"Validating transaction {self.saga_state.transaction_id}\")\n        \n        # Validate amount is positive\n        if self.saga_state.amount <= 0:\n            raise PaymentSagaError(\"Transaction amount must be positive\")\n        \n        # Validate currency\n        valid_currencies = [\"USD\", \"EUR\", \"GBP\", \"CAD\", \"AUD\"]\n        if self.saga_state.currency not in valid_currencies:\n            raise PaymentSagaError(f\"Invalid currency: {self.saga_state.currency}\")\n        \n        return {\"validated\": True, \"timestamp\": datetime.utcnow().isoformat()}\n    \n    async def _compensate_validate_transaction(self):\n        \"\"\"Compensation for validate step - nothing to undo.\"\"\"\n        logger.info(f\"Compensating validate_transaction - no action needed\")\n    \n    async def _step_calculate_fees(self) -> Dict[str, Any]:\n        \"\"\"Calculate transaction fees via risk compliance service.\"\"\"\n        logger.info(f\"Calculating fees for transaction {self.saga_state.transaction_id}\")\n        \n        if not self._http_client:\n            self._http_client = httpx.AsyncClient(timeout=FEE_CALCULATION_TIMEOUT)\n        \n        request_payload = {\n            \"amount\": str(self.saga_state.amount),\n            \"currency\": self.saga_state.currency,\n            \"source_user_id\": self.saga_state.source_user_id,\n            \"destination_pod_id\": str(self.saga_state.destination_pod_id)\n        }\n        \n        try:\n            response = await self._http_client.post(\n                f\"{RISK_SERVICE_URL}{FEE_CALCULATION_ENDPOINT}\",\n                json=request_payload\n            )\n            response.raise_for_status()\n            \n            fee_data = response.json()\n            \n            # Update saga state with fee information\n            self.saga_state.set_fee_details(\n                fee=float(fee_data[\"fee\"]),\n                total_debit=float(fee_data[\"total_debit_amount\"]),\n                details=fee_data\n            )\n            \n            logger.info(\n                f\"Fee calculated: {fee_data['fee']} {self.saga_state.currency}, \"\n                f\"total debit: {fee_data['total_debit_amount']}\"\n            )\n            \n            return {\n                \"fee\": fee_data[\"fee\"],\n                \"total_debit_amount\": fee_data[\"total_debit_amount\"],\n                \"user_reputation_score\": fee_data[\"user_reputation_score\"],\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n            \n        except httpx.HTTPStatusError as e:\n            logger.error(f\"Fee calculation API error: {e.response.status_code} - {e.response.text}\")\n            raise PaymentSagaError(f\"Fee calculation failed: {e.response.text}\")\n        except httpx.RequestError as e:\n            logger.error(f\"Fee calculation request error: {str(e)}\")\n            raise PaymentSagaError(f\"Fee calculation service unavailable: {str(e)}\")\n    \n    async def _compensate_calculate_fees(self):\n        \"\"\"Compensation for calculate_fees step.\n        \n        While there's nothing to undo (fees are just calculated, not charged),\n        we log the compensation for audit purposes and pattern integrity.\n        \"\"\"\n        logger.info(\n            f\"Compensating calculate_fees for transaction {self.saga_state.transaction_id} - \"\n            f\"Fee calculation reversed (no action needed, fee was: {self.saga_state.transaction_fee})\"\n        )\n        # Clear fee data from saga state for clarity\n        self.saga_state.fee_calculation_details = {\n            **(self.saga_state.fee_calculation_details or {}),\n            \"compensated\": True,\n            \"compensation_timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _step_debit_source_wallet(self) -> Dict[str, Any]:\n        \"\"\"Debit the source wallet with total amount (including fee).\"\"\"\n        logger.info(f\"Debiting source wallet for transaction {self.saga_state.transaction_id}\")\n        \n        # Use total_debit_amount which includes the fee\n        debit_amount = self.saga_state.total_debit_amount or self.saga_state.amount\n        fee_amount = self.saga_state.transaction_fee or Decimal(\"0.00\")\n        \n        # Publish DebitWallet event with separate amount and fee fields\n        await self.coordinator.publish_event(DebitWallet(\n            transaction_id=str(self.saga_state.transaction_id),\n            wallet_id=str(self.saga_state.source_wallet_id),\n            amount=str(self.saga_state.amount),\n            fee=str(fee_amount),\n            total_debit_amount=str(debit_amount),\n            currency=self.saga_state.currency,\n            source_user_id=self.saga_state.source_user_id,\n            destination_pod_id=str(self.saga_state.destination_pod_id)\n        ))\n        \n        logger.info(\n            f\"DebitWallet event published: amount={self.saga_state.amount}, \"\n            f\"fee={fee_amount}, total={debit_amount}\"\n        )\n        \n        return {\n            \"debited\": True,\n            \"amount\": str(self.saga_state.amount),\n            \"fee\": str(fee_amount),\n            \"total_debit_amount\": str(debit_amount),\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _compensate_debit_source_wallet(self):\n        \"\"\"Compensation for debit step - credit back the debited amount.\"\"\"\n        logger.info(f\"Compensating debit_source_wallet for transaction {self.saga_state.transaction_id}\")\n        \n        # Credit back the full debited amount (including fee)\n        refund_amount = self.saga_state.total_debit_amount or self.saga_state.amount\n        \n        await self.coordinator.publish_event({\n            \"event_type\": \"CreditWallet\",\n            \"transaction_id\": str(self.saga_state.transaction_id),\n            \"wallet_id\": str(self.saga_state.source_wallet_id),\n            \"amount\": str(refund_amount),\n            \"currency\": self.saga_state.currency,\n            \"reason\": \"saga_compensation\"\n        })\n    \n    async def _step_credit_destination_pod(self) -> Dict[str, Any]:\n        \"\"\"Credit the destination pod with the principal amount.\"\"\"\n        logger.info(f\"Crediting destination pod for transaction {self.saga_state.transaction_id}\")\n        \n        # Credit only the principal amount (not the fee)\n        await self.coordinator.publish_event(CreditPod(\n            transaction_id=str(self.saga_state.transaction_id),\n            pod_id=str(self.saga_state.destination_pod_id),\n            amount=str(self.saga_state.amount),\n            currency=self.saga_state.currency,\n            source_wallet_id=str(self.saga_state.source_wallet_id)\n        ))\n        \n        return {\n            \"credited\": True,\n            \"amount\": str(self.saga_state.amount),\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _compensate_credit_destination_pod(self):\n        \"\"\"Compensation for credit step - debit back from pod.\"\"\"\n        logger.info(f\"Compensating credit_destination_pod for transaction {self.saga_state.transaction_id}\")\n        \n        await self.coordinator.publish_event({\n            \"event_type\": \"DebitPod\",\n            \"transaction_id\": str(self.saga_state.transaction_id),\n            \"pod_id\": str(self.saga_state.destination_pod_id),\n            \"amount\": str(self.saga_state.amount),\n            \"currency\": self.saga_state.currency,\n            \"reason\": \"saga_compensation\"\n        })\n    \n    async def _step_complete_transaction(self) -> Dict[str, Any]:\n        \"\"\"Complete the transaction and publish success event.\"\"\"\n        logger.info(f\"Completing transaction {self.saga_state.transaction_id}\")\n        \n        await self.coordinator.publish_event(PaymentCompleted(\n            transaction_id=str(self.saga_state.transaction_id),\n            source_wallet_id=str(self.saga_state.source_wallet_id),\n            destination_pod_id=str(self.saga_state.destination_pod_id),\n            amount=str(self.saga_state.amount),\n            fee=str(self.saga_state.transaction_fee or Decimal(\"0.00\")),\n            total_amount=str(self.saga_state.total_debit_amount or self.saga_state.amount),\n            currency=self.saga_state.currency\n        ))\n        \n        return {\n            \"completed\": True,\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _compensate_complete_transaction(self):\n        \"\"\"Compensation for complete step - nothing to undo.\"\"\"\n        logger.info(f\"Compensating complete_transaction - no action needed\")\n",
          "crowdpay_connect/libs/shared_events/schemas.py": "\"\"\"Shared event schemas for inter-service communication.\"\"\"\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\nfrom datetime import datetime\nfrom enum import Enum\n\n\nclass EventType(str, Enum):\n    \"\"\"Enumeration of event types.\"\"\"\n    DEBIT_WALLET = \"DebitWallet\"\n    CREDIT_WALLET = \"CreditWallet\"\n    CREDIT_POD = \"CreditPod\"\n    DEBIT_POD = \"DebitPod\"\n    PAYMENT_COMPLETED = \"PaymentCompleted\"\n    PAYMENT_FAILED = \"PaymentFailed\"\n    USER_CREATED = \"UserCreated\"\n    USER_UPDATED = \"UserUpdated\"\n    POD_CREATED = \"PodCreated\"\n    POD_UPDATED = \"PodUpdated\"\n    KYC_COMPLETED = \"KycCompleted\"\n    RISK_ASSESSMENT_COMPLETED = \"RiskAssessmentCompleted\"\n\n\nclass BaseEvent(BaseModel):\n    \"\"\"Base class for all events.\"\"\"\n    event_type: str\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n    correlation_id: Optional[str] = None\n    \n    class Config:\n        json_encoders = {\n            datetime: lambda v: v.isoformat()\n        }\n\n\nclass DebitWallet(BaseEvent):\n    \"\"\"Event for debiting a wallet.\n    \n    This event now includes separate amount and fee fields for better\n    transparency and audit capabilities.\n    \"\"\"\n    event_type: str = EventType.DEBIT_WALLET.value\n    transaction_id: str\n    wallet_id: str\n    amount: str  # Principal amount\n    fee: str = \"0.00\"  # Transaction fee (NEW)\n    total_debit_amount: str  # Total to debit (amount + fee) (NEW)\n    currency: str\n    source_user_id: Optional[str] = None\n    destination_pod_id: Optional[str] = None\n    reason: Optional[str] = None\n\n\nclass CreditWallet(BaseEvent):\n    \"\"\"Event for crediting a wallet.\"\"\"\n    event_type: str = EventType.CREDIT_WALLET.value\n    transaction_id: str\n    wallet_id: str\n    amount: str\n    currency: str\n    source_pod_id: Optional[str] = None\n    reason: Optional[str] = None\n\n\nclass CreditPod(BaseEvent):\n    \"\"\"Event for crediting a pod.\"\"\"\n    event_type: str = EventType.CREDIT_POD.value\n    transaction_id: str\n    pod_id: str\n    amount: str\n    currency: str\n    source_wallet_id: Optional[str] = None\n\n\nclass DebitPod(BaseEvent):\n    \"\"\"Event for debiting a pod.\"\"\"\n    event_type: str = EventType.DEBIT_POD.value\n    transaction_id: str\n    pod_id: str\n    amount: str\n    currency: str\n    destination_wallet_id: Optional[str] = None\n    reason: Optional[str] = None\n\n\nclass PaymentCompleted(BaseEvent):\n    \"\"\"Event indicating a payment has been completed successfully.\"\"\"\n    event_type: str = EventType.PAYMENT_COMPLETED.value\n    transaction_id: str\n    source_wallet_id: str\n    destination_pod_id: str\n    amount: str  # Principal amount\n    fee: str = \"0.00\"  # Transaction fee (NEW)\n    total_amount: str  # Total debited (amount + fee) (NEW)\n    currency: str\n\n\nclass PaymentFailed(BaseEvent):\n    \"\"\"Event indicating a payment has failed.\"\"\"\n    event_type: str = EventType.PAYMENT_FAILED.value\n    transaction_id: str\n    source_wallet_id: str\n    destination_pod_id: str\n    amount: str\n    currency: str\n    error_message: Optional[str] = None\n    failed_step: Optional[str] = None\n\n\nclass UserCreated(BaseEvent):\n    \"\"\"Event indicating a new user has been created.\"\"\"\n    event_type: str = EventType.USER_CREATED.value\n    user_id: str\n    email: str\n    username: str\n\n\nclass UserUpdated(BaseEvent):\n    \"\"\"Event indicating a user has been updated.\"\"\"\n    event_type: str = EventType.USER_UPDATED.value\n    user_id: str\n    updated_fields: dict\n\n\nclass PodCreated(BaseEvent):\n    \"\"\"Event indicating a new pod has been created.\"\"\"\n    event_type: str = EventType.POD_CREATED.value\n    pod_id: str\n    name: str\n    owner_id: str\n    target_amount: Optional[str] = None\n    currency: str\n\n\nclass PodUpdated(BaseEvent):\n    \"\"\"Event indicating a pod has been updated.\"\"\"\n    event_type: str = EventType.POD_UPDATED.value\n    pod_id: str\n    updated_fields: dict\n\n\nclass KycCompleted(BaseEvent):\n    \"\"\"Event indicating KYC verification has been completed.\"\"\"\n    event_type: str = EventType.KYC_COMPLETED.value\n    user_id: str\n    verification_id: str\n    status: str  # approved, rejected, pending_review\n    verification_level: Optional[str] = None\n\n\nclass RiskAssessmentCompleted(BaseEvent):\n    \"\"\"Event indicating a risk assessment has been completed.\"\"\"\n    event_type: str = EventType.RISK_ASSESSMENT_COMPLETED.value\n    assessment_id: str\n    entity_type: str  # user, transaction, pod\n    entity_id: str\n    risk_score: float\n    risk_level: str  # low, medium, high, critical\n    factors: Optional[dict] = None\n\n\n# Event factory for deserializing events\nEVENT_TYPE_MAP = {\n    EventType.DEBIT_WALLET.value: DebitWallet,\n    EventType.CREDIT_WALLET.value: CreditWallet,\n    EventType.CREDIT_POD.value: CreditPod,\n    EventType.DEBIT_POD.value: DebitPod,\n    EventType.PAYMENT_COMPLETED.value: PaymentCompleted,\n    EventType.PAYMENT_FAILED.value: PaymentFailed,\n    EventType.USER_CREATED.value: UserCreated,\n    EventType.USER_UPDATED.value: UserUpdated,\n    EventType.POD_CREATED.value: PodCreated,\n    EventType.POD_UPDATED.value: PodUpdated,\n    EventType.KYC_COMPLETED.value: KycCompleted,\n    EventType.RISK_ASSESSMENT_COMPLETED.value: RiskAssessmentCompleted,\n}\n\n\ndef deserialize_event(event_data: dict) -> BaseEvent:\n    \"\"\"Deserialize event data into the appropriate event class.\n    \n    Args:\n        event_data: Dictionary containing event data\n        \n    Returns:\n        Deserialized event instance\n        \n    Raises:\n        ValueError: If event type is unknown\n    \"\"\"\n    event_type = event_data.get(\"event_type\")\n    if event_type not in EVENT_TYPE_MAP:\n        raise ValueError(f\"Unknown event type: {event_type}\")\n    \n    event_class = EVENT_TYPE_MAP[event_type]\n    return event_class(**event_data)\n",
          "crowdpay_connect/services/wallet_service/app/models/transaction_log.py": "\"\"\"Transaction log model for recording all wallet transactions.\"\"\"\nfrom sqlalchemy import Column, String, Enum, DateTime, Numeric, Text, Index\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom datetime import datetime\nimport enum\nimport uuid\n\nfrom app.db.base import Base\n\n\nclass TransactionType(enum.Enum):\n    \"\"\"Enumeration of transaction types.\"\"\"\n    DEBIT = \"debit\"\n    CREDIT = \"credit\"\n    TRANSFER = \"transfer\"\n    FEE = \"fee\"\n    REFUND = \"refund\"\n    ADJUSTMENT = \"adjustment\"\n\n\nclass TransactionStatus(enum.Enum):\n    \"\"\"Enumeration of transaction statuses.\"\"\"\n    PENDING = \"pending\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    REVERSED = \"reversed\"\n\n\nclass TransactionLog(Base):\n    \"\"\"Model for logging all wallet transactions.\n    \n    This provides an immutable audit trail of all financial movements.\n    \"\"\"\n    \n    __tablename__ = \"transaction_logs\"\n    \n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    transaction_id = Column(UUID(as_uuid=True), nullable=False, index=True)\n    \n    # Wallet information\n    wallet_id = Column(UUID(as_uuid=True), nullable=False, index=True)\n    user_id = Column(String(100), nullable=True, index=True)\n    \n    # Transaction details\n    transaction_type = Column(Enum(TransactionType), nullable=False)\n    status = Column(Enum(TransactionStatus), default=TransactionStatus.PENDING, nullable=False)\n    \n    # Amount fields - now with separate fee tracking\n    amount = Column(Numeric(precision=18, scale=2), nullable=False)  # Principal amount\n    fee = Column(Numeric(precision=18, scale=2), nullable=True, default=0)  # Transaction fee (NEW)\n    total_amount = Column(Numeric(precision=18, scale=2), nullable=True)  # Total (amount + fee) (NEW)\n    currency = Column(String(3), nullable=False)\n    \n    # Balance tracking\n    balance_before = Column(Numeric(precision=18, scale=2), nullable=True)\n    balance_after = Column(Numeric(precision=18, scale=2), nullable=True)\n    \n    # Reference information\n    reference_type = Column(String(50), nullable=True)  # pod, wallet, external\n    reference_id = Column(UUID(as_uuid=True), nullable=True)  # pod_id, wallet_id, etc.\n    \n    # Additional metadata\n    description = Column(Text, nullable=True)\n    metadata = Column(Text, nullable=True)  # JSON string for additional data\n    \n    # Timestamps\n    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)\n    completed_at = Column(DateTime, nullable=True)\n    \n    # Indexes for common queries\n    __table_args__ = (\n        Index('idx_transaction_log_wallet_created', 'wallet_id', 'created_at'),\n        Index('idx_transaction_log_user_created', 'user_id', 'created_at'),\n        Index('idx_transaction_log_type_status', 'transaction_type', 'status'),\n    )\n    \n    def __repr__(self):\n        return (\n            f\"<TransactionLog(id={self.id}, transaction_id={self.transaction_id}, \"\n            f\"type={self.transaction_type}, amount={self.amount}, fee={self.fee})>\"\n        )\n    \n    def to_dict(self):\n        \"\"\"Convert transaction log to dictionary.\"\"\"\n        return {\n            \"id\": str(self.id),\n            \"transaction_id\": str(self.transaction_id),\n            \"wallet_id\": str(self.wallet_id),\n            \"user_id\": self.user_id,\n            \"transaction_type\": self.transaction_type.value,\n            \"status\": self.status.value,\n            \"amount\": str(self.amount),\n            \"fee\": str(self.fee) if self.fee else \"0.00\",\n            \"total_amount\": str(self.total_amount) if self.total_amount else str(self.amount),\n            \"currency\": self.currency,\n            \"balance_before\": str(self.balance_before) if self.balance_before else None,\n            \"balance_after\": str(self.balance_after) if self.balance_after else None,\n            \"reference_type\": self.reference_type,\n            \"reference_id\": str(self.reference_id) if self.reference_id else None,\n            \"description\": self.description,\n            \"metadata\": self.metadata,\n            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n            \"updated_at\": self.updated_at.isoformat() if self.updated_at else None,\n            \"completed_at\": self.completed_at.isoformat() if self.completed_at else None\n        }\n    \n    @classmethod\n    def create_debit_log(\n        cls,\n        transaction_id: uuid.UUID,\n        wallet_id: uuid.UUID,\n        amount: float,\n        currency: str,\n        fee: float = 0.0,\n        user_id: str = None,\n        reference_type: str = None,\n        reference_id: uuid.UUID = None,\n        description: str = None,\n        balance_before: float = None,\n        balance_after: float = None\n    ) -> \"TransactionLog\":\n        \"\"\"Factory method to create a debit transaction log.\"\"\"\n        from decimal import Decimal\n        \n        amount_decimal = Decimal(str(amount))\n        fee_decimal = Decimal(str(fee))\n        total = amount_decimal + fee_decimal\n        \n        return cls(\n            transaction_id=transaction_id,\n            wallet_id=wallet_id,\n            user_id=user_id,\n            transaction_type=TransactionType.DEBIT,\n            status=TransactionStatus.PENDING,\n            amount=amount_decimal,\n            fee=fee_decimal,\n            total_amount=total,\n            currency=currency,\n            reference_type=reference_type,\n            reference_id=reference_id,\n            description=description,\n            balance_before=Decimal(str(balance_before)) if balance_before is not None else None,\n            balance_after=Decimal(str(balance_after)) if balance_after is not None else None\n        )\n    \n    @classmethod\n    def create_credit_log(\n        cls,\n        transaction_id: uuid.UUID,\n        wallet_id: uuid.UUID,\n        amount: float,\n        currency: str,\n        user_id: str = None,\n        reference_type: str = None,\n        reference_id: uuid.UUID = None,\n        description: str = None,\n        balance_before: float = None,\n        balance_after: float = None\n    ) -> \"TransactionLog\":\n        \"\"\"Factory method to create a credit transaction log.\"\"\"\n        from decimal import Decimal\n        \n        amount_decimal = Decimal(str(amount))\n        \n        return cls(\n            transaction_id=transaction_id,\n            wallet_id=wallet_id,\n            user_id=user_id,\n            transaction_type=TransactionType.CREDIT,\n            status=TransactionStatus.PENDING,\n            amount=amount_decimal,\n            fee=Decimal(\"0.00\"),\n            total_amount=amount_decimal,\n            currency=currency,\n            reference_type=reference_type,\n            reference_id=reference_id,\n            description=description,\n            balance_before=Decimal(str(balance_before)) if balance_before is not None else None,\n            balance_after=Decimal(str(balance_after)) if balance_after is not None else None\n        )\n",
          "crowdpay_connect/services/wallet_service/app/events/consumer.py": "\"\"\"Event consumer for wallet service.\"\"\"\nimport json\nimport logging\nfrom decimal import Decimal\nfrom typing import Optional\nfrom datetime import datetime\nimport uuid\n\nfrom kafka import KafkaConsumer\nfrom sqlalchemy.orm import Session\n\nfrom app.db.session import get_db_session\nfrom app.models.wallet import Wallet\nfrom app.models.transaction_log import TransactionLog, TransactionType, TransactionStatus\nfrom app.core.ledger import Ledger\nfrom libs.shared_events.schemas import DebitWallet, CreditWallet, deserialize_event\n\nlogger = logging.getLogger(__name__)\n\n# Kafka configuration\nKAFKA_BOOTSTRAP_SERVERS = \"kafka:9092\"\nWALLET_EVENTS_TOPIC = \"wallet-events\"\nCONSUMER_GROUP = \"wallet-service-consumer\"\n\n\nclass WalletEventConsumer:\n    \"\"\"Consumer for wallet-related events.\"\"\"\n    \n    def __init__(self, bootstrap_servers: str = KAFKA_BOOTSTRAP_SERVERS):\n        \"\"\"Initialize the wallet event consumer.\n        \n        Args:\n            bootstrap_servers: Kafka bootstrap servers\n        \"\"\"\n        self.bootstrap_servers = bootstrap_servers\n        self.consumer: Optional[KafkaConsumer] = None\n        self.ledger = Ledger()\n    \n    def start(self):\n        \"\"\"Start consuming events.\"\"\"\n        logger.info(\"Starting wallet event consumer...\")\n        \n        self.consumer = KafkaConsumer(\n            WALLET_EVENTS_TOPIC,\n            bootstrap_servers=self.bootstrap_servers,\n            group_id=CONSUMER_GROUP,\n            auto_offset_reset='earliest',\n            enable_auto_commit=True,\n            value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n        )\n        \n        logger.info(f\"Subscribed to topic: {WALLET_EVENTS_TOPIC}\")\n        \n        for message in self.consumer:\n            try:\n                self._process_message(message.value)\n            except Exception as e:\n                logger.error(f\"Error processing message: {str(e)}\")\n    \n    def stop(self):\n        \"\"\"Stop consuming events.\"\"\"\n        if self.consumer:\n            self.consumer.close()\n            logger.info(\"Wallet event consumer stopped\")\n    \n    def _process_message(self, message: dict):\n        \"\"\"Process an incoming message.\n        \n        Args:\n            message: The message payload\n        \"\"\"\n        event_type = message.get(\"event_type\")\n        logger.info(f\"Processing event: {event_type}\")\n        \n        if event_type == \"DebitWallet\":\n            self._handle_debit_wallet(message)\n        elif event_type == \"CreditWallet\":\n            self._handle_credit_wallet(message)\n        else:\n            logger.warning(f\"Unknown event type: {event_type}\")\n    \n    def _handle_debit_wallet(self, event_data: dict):\n        \"\"\"Handle DebitWallet event.\n        \n        This now processes the updated event schema with separate amount and fee fields.\n        \n        Args:\n            event_data: The event payload\n        \"\"\"\n        logger.info(f\"Handling DebitWallet event: {event_data.get('transaction_id')}\")\n        \n        try:\n            # Parse event data\n            transaction_id = uuid.UUID(event_data[\"transaction_id\"])\n            wallet_id = uuid.UUID(event_data[\"wallet_id\"])\n            amount = Decimal(event_data[\"amount\"])  # Principal amount\n            fee = Decimal(event_data.get(\"fee\", \"0.00\"))  # Transaction fee\n            total_debit = Decimal(event_data.get(\"total_debit_amount\", str(amount + fee)))\n            currency = event_data[\"currency\"]\n            source_user_id = event_data.get(\"source_user_id\")\n            destination_pod_id = event_data.get(\"destination_pod_id\")\n            \n            with get_db_session() as db:\n                # Get wallet\n                wallet = db.query(Wallet).filter(Wallet.id == wallet_id).first()\n                if not wallet:\n                    logger.error(f\"Wallet not found: {wallet_id}\")\n                    return\n                \n                balance_before = wallet.balance\n                \n                # Validate sufficient balance\n                if wallet.balance < total_debit:\n                    logger.error(\n                        f\"Insufficient balance for wallet {wallet_id}: \"\n                        f\"balance={wallet.balance}, required={total_debit}\"\n                    )\n                    self._create_failed_transaction_log(\n                        db, transaction_id, wallet_id, amount, fee, currency,\n                        source_user_id, destination_pod_id, \"Insufficient balance\"\n                    )\n                    return\n                \n                # Perform debit using ledger\n                self.ledger.debit(\n                    wallet=wallet,\n                    amount=total_debit,\n                    currency=currency\n                )\n                \n                balance_after = wallet.balance\n                \n                # Create transaction log with fee information\n                transaction_log = TransactionLog.create_debit_log(\n                    transaction_id=transaction_id,\n                    wallet_id=wallet_id,\n                    amount=float(amount),\n                    currency=currency,\n                    fee=float(fee),\n                    user_id=source_user_id,\n                    reference_type=\"pod\" if destination_pod_id else None,\n                    reference_id=uuid.UUID(destination_pod_id) if destination_pod_id else None,\n                    description=f\"Payment to pod {destination_pod_id}\" if destination_pod_id else \"Debit\",\n                    balance_before=float(balance_before),\n                    balance_after=float(balance_after)\n                )\n                transaction_log.status = TransactionStatus.COMPLETED\n                transaction_log.completed_at = datetime.utcnow()\n                \n                db.add(transaction_log)\n                db.commit()\n                \n                logger.info(\n                    f\"DebitWallet completed: transaction={transaction_id}, \"\n                    f\"amount={amount}, fee={fee}, total={total_debit}, \"\n                    f\"balance: {balance_before} -> {balance_after}\"\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error handling DebitWallet event: {str(e)}\")\n            raise\n    \n    def _handle_credit_wallet(self, event_data: dict):\n        \"\"\"Handle CreditWallet event.\n        \n        Args:\n            event_data: The event payload\n        \"\"\"\n        logger.info(f\"Handling CreditWallet event: {event_data.get('transaction_id')}\")\n        \n        try:\n            transaction_id = uuid.UUID(event_data[\"transaction_id\"])\n            wallet_id = uuid.UUID(event_data[\"wallet_id\"])\n            amount = Decimal(event_data[\"amount\"])\n            currency = event_data[\"currency\"]\n            source_pod_id = event_data.get(\"source_pod_id\")\n            reason = event_data.get(\"reason\")\n            \n            with get_db_session() as db:\n                # Get wallet\n                wallet = db.query(Wallet).filter(Wallet.id == wallet_id).first()\n                if not wallet:\n                    logger.error(f\"Wallet not found: {wallet_id}\")\n                    return\n                \n                balance_before = wallet.balance\n                \n                # Perform credit using ledger\n                self.ledger.credit(\n                    wallet=wallet,\n                    amount=amount,\n                    currency=currency\n                )\n                \n                balance_after = wallet.balance\n                \n                # Create transaction log\n                transaction_log = TransactionLog.create_credit_log(\n                    transaction_id=transaction_id,\n                    wallet_id=wallet_id,\n                    amount=float(amount),\n                    currency=currency,\n                    user_id=str(wallet.user_id) if wallet.user_id else None,\n                    reference_type=\"pod\" if source_pod_id else None,\n                    reference_id=uuid.UUID(source_pod_id) if source_pod_id else None,\n                    description=reason or f\"Credit from pod {source_pod_id}\" if source_pod_id else \"Credit\",\n                    balance_before=float(balance_before),\n                    balance_after=float(balance_after)\n                )\n                transaction_log.status = TransactionStatus.COMPLETED\n                transaction_log.completed_at = datetime.utcnow()\n                \n                db.add(transaction_log)\n                db.commit()\n                \n                logger.info(\n                    f\"CreditWallet completed: transaction={transaction_id}, \"\n                    f\"amount={amount}, balance: {balance_before} -> {balance_after}\"\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error handling CreditWallet event: {str(e)}\")\n            raise\n    \n    def _create_failed_transaction_log(\n        self,\n        db: Session,\n        transaction_id: uuid.UUID,\n        wallet_id: uuid.UUID,\n        amount: Decimal,\n        fee: Decimal,\n        currency: str,\n        user_id: str,\n        destination_pod_id: str,\n        error_message: str\n    ):\n        \"\"\"Create a failed transaction log entry.\"\"\"\n        transaction_log = TransactionLog(\n            transaction_id=transaction_id,\n            wallet_id=wallet_id,\n            user_id=user_id,\n            transaction_type=TransactionType.DEBIT,\n            status=TransactionStatus.FAILED,\n            amount=amount,\n            fee=fee,\n            total_amount=amount + fee,\n            currency=currency,\n            reference_type=\"pod\" if destination_pod_id else None,\n            reference_id=uuid.UUID(destination_pod_id) if destination_pod_id else None,\n            description=f\"Failed: {error_message}\"\n        )\n        db.add(transaction_log)\n        db.commit()\n\n\ndef start_consumer():\n    \"\"\"Start the wallet event consumer.\"\"\"\n    consumer = WalletEventConsumer()\n    try:\n        consumer.start()\n    except KeyboardInterrupt:\n        consumer.stop()\n\n\nif __name__ == \"__main__\":\n    start_consumer()\n",
          "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py": "\"\"\"Integration tests for payment saga with fee calculation.\"\"\"\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\nfrom decimal import Decimal\nfrom datetime import datetime\nimport uuid\nimport httpx\n\nfrom app.sagas.payment_saga import PaymentSaga, PaymentSagaError, RISK_SERVICE_URL, FEE_CALCULATION_ENDPOINT\nfrom app.models.saga_state import SagaState, SagaStatus, SagaStepStatus\nfrom app.events.saga_coordinator import SagaCoordinator\n\n\nclass TestPaymentSagaFeeCalculation:\n    \"\"\"Test cases for fee calculation step in payment saga.\"\"\"\n    \n    @pytest.fixture\n    def mock_coordinator(self):\n        \"\"\"Create a mock saga coordinator.\"\"\"\n        coordinator = MagicMock(spec=SagaCoordinator)\n        coordinator.update_saga_state = AsyncMock()\n        coordinator.publish_event = AsyncMock()\n        return coordinator\n    \n    @pytest.fixture\n    def saga_state(self):\n        \"\"\"Create a test saga state.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"test-user-123\",\n            amount=Decimal(\"100.00\"),\n            currency=\"USD\",\n            status=SagaStatus.PENDING,\n            completed_steps=[]\n        )\n        return state\n    \n    @pytest.fixture\n    def fee_response(self):\n        \"\"\"Create a mock fee calculation response.\"\"\"\n        return {\n            \"fee\": \"1.50\",\n            \"total_debit_amount\": \"101.50\",\n            \"base_rate\": \"0.005\",\n            \"risk_premium\": \"0.02\",\n            \"user_reputation_score\": \"0.50\",\n            \"currency\": \"USD\"\n        }\n    \n    @pytest.mark.asyncio\n    async def test_fee_calculation_step_success(self, saga_state, mock_coordinator, fee_response):\n        \"\"\"Test successful fee calculation step.\"\"\"\n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        # Mock HTTP client response\n        mock_response = MagicMock()\n        mock_response.json.return_value = fee_response\n        mock_response.raise_for_status = MagicMock()\n        \n        with patch.object(httpx.AsyncClient, 'post', new_callable=AsyncMock) as mock_post:\n            mock_post.return_value = mock_response\n            \n            # Create HTTP client manually for the test\n            saga._http_client = httpx.AsyncClient()\n            saga._http_client.post = mock_post\n            \n            result = await saga._step_calculate_fees()\n            \n            # Verify API was called with correct payload\n            mock_post.assert_called_once()\n            call_args = mock_post.call_args\n            assert call_args[0][0] == f\"{RISK_SERVICE_URL}{FEE_CALCULATION_ENDPOINT}\"\n            \n            request_payload = call_args[1][\"json\"]\n            assert request_payload[\"amount\"] == \"100.00\"\n            assert request_payload[\"currency\"] == \"USD\"\n            assert request_payload[\"source_user_id\"] == \"test-user-123\"\n            \n            # Verify saga state was updated\n            assert saga_state.transaction_fee == Decimal(\"1.50\")\n            assert saga_state.total_debit_amount == Decimal(\"101.50\")\n            assert saga_state.fee_calculation_details == fee_response\n            \n            # Verify result\n            assert result[\"fee\"] == \"1.50\"\n            assert result[\"total_debit_amount\"] == \"101.50\"\n            assert result[\"user_reputation_score\"] == \"0.50\"\n    \n    @pytest.mark.asyncio\n    async def test_fee_calculation_step_api_error(self, saga_state, mock_coordinator):\n        \"\"\"Test fee calculation step with API error.\"\"\"\n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        # Mock HTTP client to raise error\n        mock_response = MagicMock()\n        mock_response.status_code = 500\n        mock_response.text = \"Internal Server Error\"\n        mock_response.raise_for_status.side_effect = httpx.HTTPStatusError(\n            \"Server Error\",\n            request=MagicMock(),\n            response=mock_response\n        )\n        \n        with patch.object(httpx.AsyncClient, 'post', new_callable=AsyncMock) as mock_post:\n            mock_post.return_value = mock_response\n            \n            saga._http_client = httpx.AsyncClient()\n            saga._http_client.post = mock_post\n            \n            with pytest.raises(PaymentSagaError) as exc_info:\n                await saga._step_calculate_fees()\n            \n            assert \"Fee calculation failed\" in str(exc_info.value)\n    \n    @pytest.mark.asyncio\n    async def test_fee_calculation_step_connection_error(self, saga_state, mock_coordinator):\n        \"\"\"Test fee calculation step with connection error.\"\"\"\n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        with patch.object(httpx.AsyncClient, 'post', new_callable=AsyncMock) as mock_post:\n            mock_post.side_effect = httpx.RequestError(\"Connection refused\")\n            \n            saga._http_client = httpx.AsyncClient()\n            saga._http_client.post = mock_post\n            \n            with pytest.raises(PaymentSagaError) as exc_info:\n                await saga._step_calculate_fees()\n            \n            assert \"Fee calculation service unavailable\" in str(exc_info.value)\n    \n    @pytest.mark.asyncio\n    async def test_compensate_fee_calculation(self, saga_state, mock_coordinator):\n        \"\"\"Test fee calculation compensation.\"\"\"\n        saga_state.transaction_fee = Decimal(\"1.50\")\n        saga_state.fee_calculation_details = {\"fee\": \"1.50\"}\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        await saga._compensate_calculate_fees()\n        \n        # Verify compensation was logged\n        assert saga_state.fee_calculation_details.get(\"compensated\") is True\n        assert \"compensation_timestamp\" in saga_state.fee_calculation_details\n    \n    @pytest.mark.asyncio\n    async def test_debit_wallet_uses_total_amount(self, saga_state, mock_coordinator, fee_response):\n        \"\"\"Test that debit wallet step uses total_debit_amount.\"\"\"\n        # Set up saga state with fee information\n        saga_state.transaction_fee = Decimal(\"1.50\")\n        saga_state.total_debit_amount = Decimal(\"101.50\")\n        saga_state.fee_calculation_details = fee_response\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        result = await saga._step_debit_source_wallet()\n        \n        # Verify event was published with correct amounts\n        mock_coordinator.publish_event.assert_called_once()\n        event = mock_coordinator.publish_event.call_args[0][0]\n        \n        assert event.amount == \"100.00\"  # Principal amount\n        assert event.fee == \"1.50\"  # Fee\n        assert event.total_debit_amount == \"101.50\"  # Total\n        \n        # Verify result\n        assert result[\"amount\"] == \"100.00\"\n        assert result[\"fee\"] == \"1.50\"\n        assert result[\"total_debit_amount\"] == \"101.50\"\n    \n    @pytest.mark.asyncio\n    async def test_debit_wallet_without_fee(self, saga_state, mock_coordinator):\n        \"\"\"Test debit wallet step when no fee is calculated (fallback).\"\"\"\n        # No fee information set\n        saga_state.transaction_fee = None\n        saga_state.total_debit_amount = None\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        result = await saga._step_debit_source_wallet()\n        \n        # Verify event was published with original amount\n        mock_coordinator.publish_event.assert_called_once()\n        event = mock_coordinator.publish_event.call_args[0][0]\n        \n        assert event.amount == \"100.00\"\n        assert event.fee == \"0.00\"  # Default fee\n        assert event.total_debit_amount == \"100.00\"  # Same as amount\n\n\nclass TestPaymentSagaFullFlow:\n    \"\"\"Integration tests for complete payment saga flow with fees.\"\"\"\n    \n    @pytest.fixture\n    def mock_coordinator(self):\n        \"\"\"Create a mock saga coordinator.\"\"\"\n        coordinator = MagicMock(spec=SagaCoordinator)\n        coordinator.update_saga_state = AsyncMock()\n        coordinator.publish_event = AsyncMock()\n        return coordinator\n    \n    @pytest.fixture\n    def saga_state(self):\n        \"\"\"Create a test saga state.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"test-user-456\",\n            amount=Decimal(\"500.00\"),\n            currency=\"USD\",\n            status=SagaStatus.PENDING,\n            completed_steps=[]\n        )\n        return state\n    \n    @pytest.mark.asyncio\n    async def test_saga_steps_order(self):\n        \"\"\"Test that saga steps are in correct order.\"\"\"\n        expected_steps = [\n            \"validate_transaction\",\n            \"calculate_fees\",\n            \"debit_source_wallet\",\n            \"credit_destination_pod\",\n            \"complete_transaction\"\n        ]\n        assert PaymentSaga.STEPS == expected_steps\n    \n    @pytest.mark.asyncio\n    async def test_saga_rollback_after_fee_calculation(self, saga_state, mock_coordinator):\n        \"\"\"Test saga rollback when failure occurs after fee calculation.\"\"\"\n        saga_state.completed_steps = [\"validate_transaction\", \"calculate_fees\"]\n        saga_state.transaction_fee = Decimal(\"5.00\")\n        saga_state.total_debit_amount = Decimal(\"505.00\")\n        saga_state.fee_calculation_details = {\"fee\": \"5.00\"}\n        saga_state.error_message = \"Debit failed\"\n        saga_state.failed_step = \"debit_source_wallet\"\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        await saga.compensate()\n        \n        # Verify compensation was called for completed steps in reverse order\n        assert saga_state.status == SagaStatus.ROLLED_BACK\n        assert saga_state.fee_calculation_details.get(\"compensated\") is True\n        \n        # Verify PaymentFailed event was published\n        payment_failed_call = None\n        for call in mock_coordinator.publish_event.call_args_list:\n            event = call[0][0]\n            if hasattr(event, 'event_type') and event.event_type == \"PaymentFailed\":\n                payment_failed_call = event\n                break\n        \n        assert payment_failed_call is not None\n        assert payment_failed_call.error_message == \"Debit failed\"\n    \n    @pytest.mark.asyncio\n    async def test_payment_completed_includes_fee(self, saga_state, mock_coordinator):\n        \"\"\"Test that PaymentCompleted event includes fee information.\"\"\"\n        saga_state.transaction_fee = Decimal(\"5.00\")\n        saga_state.total_debit_amount = Decimal(\"505.00\")\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        result = await saga._step_complete_transaction()\n        \n        # Verify PaymentCompleted event\n        mock_coordinator.publish_event.assert_called_once()\n        event = mock_coordinator.publish_event.call_args[0][0]\n        \n        assert event.event_type == \"PaymentCompleted\"\n        assert event.amount == \"500.00\"\n        assert event.fee == \"5.00\"\n        assert event.total_amount == \"505.00\"\n\n\nclass TestSagaStateModel:\n    \"\"\"Tests for SagaState model fee-related fields.\"\"\"\n    \n    def test_saga_state_set_fee_details(self):\n        \"\"\"Test setting fee details on saga state.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"user-123\",\n            amount=Decimal(\"100.00\"),\n            currency=\"USD\"\n        )\n        \n        details = {\n            \"base_rate\": \"0.005\",\n            \"risk_premium\": \"0.02\",\n            \"user_reputation_score\": \"0.75\"\n        }\n        \n        state.set_fee_details(fee=2.25, total_debit=102.25, details=details)\n        \n        assert state.transaction_fee == Decimal(\"2.25\")\n        assert state.total_debit_amount == Decimal(\"102.25\")\n        assert state.fee_calculation_details == details\n    \n    def test_saga_state_to_dict_includes_fees(self):\n        \"\"\"Test that to_dict includes fee fields.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"user-123\",\n            amount=Decimal(\"100.00\"),\n            currency=\"USD\",\n            transaction_fee=Decimal(\"1.50\"),\n            total_debit_amount=Decimal(\"101.50\"),\n            fee_calculation_details={\"test\": \"data\"}\n        )\n        \n        result = state.to_dict()\n        \n        assert result[\"transaction_fee\"] == \"1.50\"\n        assert result[\"total_debit_amount\"] == \"101.50\"\n        assert result[\"fee_calculation_details\"] == {\"test\": \"data\"}\n"
        },
        "generated_files": [
          "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py",
          "crowdpay_connect/services/risk_compliance_service/app/main.py",
          "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py",
          "crowdpay_connect/services/transaction_service/app/models/saga_state.py",
          "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py",
          "crowdpay_connect/libs/shared_events/schemas.py",
          "crowdpay_connect/services/wallet_service/app/models/transaction_log.py",
          "crowdpay_connect/services/wallet_service/app/events/consumer.py",
          "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8000565981531128,
              "dependency_traversal_accuracy": 0.7767769167267604,
              "cross_file_reasoning_depth": 0.34990740740740744,
              "system_thinking_score": 0.5215795896417639,
              "robustness_score": 0.3716772151898734,
              "comprehensiveness_score": 0.6759215893108299,
              "innovation_score": 0.39699367088607596,
              "solution_elegance_score": 0.7321632857358469
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.1000070747691391,
              "dependency_traversal_weighted": 0.09709711459084505,
              "cross_file_reasoning_weighted": 0.04373842592592593,
              "system_thinking_weighted": 0.06519744870522048,
              "robustness_weighted": 0.046459651898734175,
              "comprehensiveness_weighted": 0.08449019866385374,
              "innovation_weighted": 0.049624208860759494,
              "solution_elegance_weighted": 0.09152041071698086
            },
            "total_software_engineering_score": 0.5781345341314588
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.5676507949829102,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py",
                "crowdpay_connect/services/risk_compliance_service/app/main.py",
                "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py",
                "crowdpay_connect/services/transaction_service/app/models/saga_state.py",
                "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py",
                "crowdpay_connect/libs/shared_events/schemas.py",
                "crowdpay_connect/services/wallet_service/app/models/transaction_log.py",
                "crowdpay_connect/services/wallet_service/app/events/consumer.py",
                "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 9,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 9 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.34455686961600235,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.34455686961600235,
              "idc_weight": 0.2,
              "total_functional_score": 0.6489113739232005
            }
          },
          "code_quality_details": {
            "files_analyzed": 9,
            "quality_checks": {
              "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py": {
                "line_count": 138,
                "non_empty_lines": 108,
                "comment_lines": 8,
                "comment_ratio": 0.07407407407407407,
                "function_count": 3,
                "class_count": 2,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/risk_compliance_service/app/main.py": {
                "line_count": 52,
                "non_empty_lines": 40,
                "comment_lines": 3,
                "comment_ratio": 0.075,
                "function_count": 3,
                "class_count": 0,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py": {
                "line_count": 286,
                "non_empty_lines": 220,
                "comment_lines": 22,
                "comment_ratio": 0.1,
                "function_count": 18,
                "class_count": 4,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/transaction_service/app/models/saga_state.py": {
                "line_count": 114,
                "non_empty_lines": 93,
                "comment_lines": 6,
                "comment_ratio": 0.06451612903225806,
                "function_count": 4,
                "class_count": 3,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py": {
                "line_count": 332,
                "non_empty_lines": 266,
                "comment_lines": 11,
                "comment_ratio": 0.041353383458646614,
                "function_count": 13,
                "class_count": 2,
                "import_count": 17,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/libs/shared_events/schemas.py": {
                "line_count": 197,
                "non_empty_lines": 158,
                "comment_lines": 1,
                "comment_ratio": 0.006329113924050633,
                "function_count": 1,
                "class_count": 20,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/wallet_service/app/models/transaction_log.py": {
                "line_count": 182,
                "non_empty_lines": 155,
                "comment_lines": 8,
                "comment_ratio": 0.05161290322580645,
                "function_count": 4,
                "class_count": 5,
                "import_count": 14,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/wallet_service/app/events/consumer.py": {
                "line_count": 267,
                "non_empty_lines": 221,
                "comment_lines": 9,
                "comment_ratio": 0.04072398190045249,
                "function_count": 8,
                "class_count": 4,
                "import_count": 24,
                "quality_score": 0.7999999999999999
              },
              "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py": {
                "line_count": 328,
                "non_empty_lines": 261,
                "comment_lines": 15,
                "comment_ratio": 0.05747126436781609,
                "function_count": 16,
                "class_count": 5,
                "import_count": 15,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7999999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8339285714285714,
              "multi_session_memory_retention": 0.8819444444444444
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4169642857142857,
              "multi_session_memory_retention_weighted": 0.4409722222222222
            },
            "total_longcontext_utilization_score": 0.8579365079365079
          }
        },
        "timestamp": "2026-01-14T21:29:40.723889"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_web_cms_hard_074_feature_implementation_expert_01",
        "scenario_title": "Implement Content Approval Workflow for Medical Articles",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5496649634001931,
        "functional_correctness_score": 0.6248691860465116,
        "code_quality_score": 0.7999999999999999,
        "longcontext_utilization_score": 0.826121794871795,
        "total_score": 3.249694603306051,
        "generation_time": 172.8133988380432,
        "code_files_generated": 8,
        "total_lines_generated": 1601,
        "parsing_success": true,
        "solution_code": {
          "mediverse_cms/apps/cms/models.py": "from django.db import models\nfrom django.conf import settings\nfrom django.utils import timezone\n\n\nclass ArticleStatus(models.TextChoices):\n    DRAFT = 'Draft', 'Draft'\n    PENDING_REVIEW = 'Pending Review', 'Pending Review'\n    APPROVED = 'Approved', 'Approved'\n    REJECTED = 'Rejected', 'Rejected'\n\n\nclass Category(models.Model):\n    \"\"\"Category model for organizing articles.\"\"\"\n    name = models.CharField(max_length=100)\n    slug = models.SlugField(unique=True)\n    description = models.TextField(blank=True)\n    parent = models.ForeignKey(\n        'self',\n        on_delete=models.CASCADE,\n        null=True,\n        blank=True,\n        related_name='children'\n    )\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    class Meta:\n        verbose_name_plural = 'categories'\n\n    def __str__(self):\n        return self.name\n\n\nclass Tag(models.Model):\n    \"\"\"Tag model for labeling articles.\"\"\"\n    name = models.CharField(max_length=50, unique=True)\n    slug = models.SlugField(unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass Article(models.Model):\n    \"\"\"Article model for medical content.\"\"\"\n    title = models.CharField(max_length=255)\n    slug = models.SlugField(unique=True)\n    content = models.TextField()\n    excerpt = models.TextField(blank=True)\n    author = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='articles'\n    )\n    category = models.ForeignKey(\n        Category,\n        on_delete=models.SET_NULL,\n        null=True,\n        blank=True,\n        related_name='articles'\n    )\n    tags = models.ManyToManyField(Tag, blank=True, related_name='articles')\n    featured_image = models.URLField(blank=True)\n    is_featured = models.BooleanField(default=False)\n    view_count = models.PositiveIntegerField(default=0)\n    \n    # Approval workflow fields\n    status = models.CharField(\n        max_length=20,\n        choices=ArticleStatus.choices,\n        default=ArticleStatus.DRAFT\n    )\n    latest_version = models.ForeignKey(\n        'ArticleVersion',\n        on_delete=models.SET_NULL,\n        null=True,\n        blank=True,\n        related_name='article_as_latest'\n    )\n    published_version = models.ForeignKey(\n        'ArticleVersion',\n        on_delete=models.SET_NULL,\n        null=True,\n        blank=True,\n        related_name='article_as_published'\n    )\n    \n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n    published_at = models.DateTimeField(null=True, blank=True)\n\n    class Meta:\n        ordering = ['-created_at']\n\n    def __str__(self):\n        return self.title\n\n    def increment_view_count(self):\n        self.view_count += 1\n        self.save(update_fields=['view_count'])\n\n\nclass ArticleVersion(models.Model):\n    \"\"\"Model to track version history of articles.\"\"\"\n    article = models.ForeignKey(\n        Article,\n        on_delete=models.CASCADE,\n        related_name='versions'\n    )\n    title = models.CharField(max_length=255)\n    content = models.TextField()\n    excerpt = models.TextField(blank=True)\n    author = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='article_versions'\n    )\n    version_number = models.PositiveIntegerField(default=1)\n    created_at = models.DateTimeField(auto_now_add=True)\n    \n    class Meta:\n        ordering = ['-version_number']\n        unique_together = ['article', 'version_number']\n\n    def __str__(self):\n        return f\"{self.article.title} - Version {self.version_number}\"\n\n\nclass MediaAsset(models.Model):\n    \"\"\"Media asset model for storing images and files.\"\"\"\n    ASSET_TYPES = [\n        ('image', 'Image'),\n        ('video', 'Video'),\n        ('document', 'Document'),\n    ]\n\n    name = models.CharField(max_length=255)\n    asset_type = models.CharField(max_length=20, choices=ASSET_TYPES)\n    file_url = models.URLField()\n    file_size = models.PositiveIntegerField(help_text='File size in bytes')\n    mime_type = models.CharField(max_length=100)\n    uploaded_by = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='media_assets'\n    )\n    article = models.ForeignKey(\n        Article,\n        on_delete=models.CASCADE,\n        null=True,\n        blank=True,\n        related_name='media_assets'\n    )\n    created_at = models.DateTimeField(auto_now_add=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass Comment(models.Model):\n    \"\"\"Comment model for article discussions.\"\"\"\n    article = models.ForeignKey(\n        Article,\n        on_delete=models.CASCADE,\n        related_name='comments'\n    )\n    author = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='comments'\n    )\n    content = models.TextField()\n    parent = models.ForeignKey(\n        'self',\n        on_delete=models.CASCADE,\n        null=True,\n        blank=True,\n        related_name='replies'\n    )\n    is_approved = models.BooleanField(default=False)\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    class Meta:\n        ordering = ['created_at']\n\n    def __str__(self):\n        return f\"Comment by {self.author} on {self.article}\"\n",
          "mediverse_cms/apps/cms/services.py": "from typing import Optional, List, Dict, Any\nfrom django.db import transaction\nfrom django.utils import timezone\nfrom django.utils.text import slugify\n\nfrom .models import Article, ArticleVersion, Category, Tag, MediaAsset, Comment, ArticleStatus\nfrom apps.users.models import User\nfrom apps.integrations.notification_service import NotificationService\n\n\nclass ArticleService:\n    \"\"\"Service class for article-related operations.\"\"\"\n\n    def __init__(self):\n        self.notification_service = NotificationService()\n\n    @transaction.atomic\n    def create_article(self, data: Dict[str, Any], author: User) -> Article:\n        \"\"\"Create a new article with initial version.\"\"\"\n        # Generate slug if not provided\n        slug = data.get('slug') or slugify(data['title'])\n        \n        # Ensure unique slug\n        base_slug = slug\n        counter = 1\n        while Article.objects.filter(slug=slug).exists():\n            slug = f\"{base_slug}-{counter}\"\n            counter += 1\n\n        # Create article with Draft status\n        article = Article.objects.create(\n            title=data['title'],\n            slug=slug,\n            content=data['content'],\n            excerpt=data.get('excerpt', ''),\n            author=author,\n            category_id=data.get('category_id'),\n            featured_image=data.get('featured_image', ''),\n            is_featured=data.get('is_featured', False),\n            status=ArticleStatus.DRAFT\n        )\n\n        # Handle tags\n        if 'tags' in data:\n            article.tags.set(data['tags'])\n\n        # Create initial version\n        version = ArticleVersion.objects.create(\n            article=article,\n            title=article.title,\n            content=article.content,\n            excerpt=article.excerpt,\n            author=author,\n            version_number=1\n        )\n        \n        # Link the version to the article\n        article.latest_version = version\n        article.save(update_fields=['latest_version'])\n\n        return article\n\n    @transaction.atomic\n    def update_article(self, article: Article, data: Dict[str, Any], editor: User) -> Article:\n        \"\"\"Update an article, creating a new version if needed.\"\"\"\n        # Check if we need to create a new version\n        # Create new version if article is Approved or Rejected\n        create_new_version = article.status in [ArticleStatus.APPROVED, ArticleStatus.REJECTED]\n        \n        # Update article fields\n        if 'title' in data:\n            article.title = data['title']\n        if 'content' in data:\n            article.content = data['content']\n        if 'excerpt' in data:\n            article.excerpt = data['excerpt']\n        if 'category_id' in data:\n            article.category_id = data['category_id']\n        if 'featured_image' in data:\n            article.featured_image = data['featured_image']\n        if 'is_featured' in data:\n            article.is_featured = data['is_featured']\n        if 'slug' in data:\n            article.slug = data['slug']\n\n        # Handle tags\n        if 'tags' in data:\n            article.tags.set(data['tags'])\n\n        if create_new_version:\n            # Create a new version\n            latest_version_number = article.versions.aggregate(\n                max_version=models.Max('version_number')\n            )['max_version'] or 0\n            \n            version = ArticleVersion.objects.create(\n                article=article,\n                title=article.title,\n                content=article.content,\n                excerpt=article.excerpt,\n                author=editor,\n                version_number=latest_version_number + 1\n            )\n            \n            article.latest_version = version\n            article.status = ArticleStatus.DRAFT\n        else:\n            # Update existing latest version if in Draft or Pending Review\n            if article.latest_version:\n                article.latest_version.title = article.title\n                article.latest_version.content = article.content\n                article.latest_version.excerpt = article.excerpt\n                article.latest_version.save()\n\n        article.save()\n        return article\n\n    @transaction.atomic\n    def submit_for_review(self, article: Article, user: User) -> Article:\n        \"\"\"Submit an article for review.\"\"\"\n        if article.status != ArticleStatus.DRAFT:\n            raise ValueError(\"Only draft articles can be submitted for review.\")\n        \n        article.status = ArticleStatus.PENDING_REVIEW\n        article.save(update_fields=['status'])\n        \n        # Notify all editors\n        self._notify_editors_of_submission(article)\n        \n        return article\n\n    @transaction.atomic\n    def approve_article(self, article: Article, editor: User) -> Article:\n        \"\"\"Approve an article for publication.\"\"\"\n        if article.status != ArticleStatus.PENDING_REVIEW:\n            raise ValueError(\"Only articles pending review can be approved.\")\n        \n        article.status = ArticleStatus.APPROVED\n        article.published_version = article.latest_version\n        article.published_at = timezone.now()\n        article.save(update_fields=['status', 'published_version', 'published_at'])\n        \n        # Notify the author\n        self._notify_author_of_decision(article, approved=True, editor=editor)\n        \n        return article\n\n    @transaction.atomic\n    def reject_article(self, article: Article, editor: User, reason: str = None) -> Article:\n        \"\"\"Reject an article.\"\"\"\n        if article.status != ArticleStatus.PENDING_REVIEW:\n            raise ValueError(\"Only articles pending review can be rejected.\")\n        \n        article.status = ArticleStatus.REJECTED\n        article.save(update_fields=['status'])\n        \n        # Notify the author\n        self._notify_author_of_decision(article, approved=False, editor=editor, reason=reason)\n        \n        return article\n\n    def _notify_editors_of_submission(self, article: Article) -> None:\n        \"\"\"Send notification to all editors about new submission.\"\"\"\n        try:\n            editors = User.objects.filter(role='Editor', is_active=True)\n            for editor in editors:\n                self.notification_service.send_notification(\n                    user_id=str(editor.id),\n                    notification_type='article_submission',\n                    title='New Article Submitted for Review',\n                    message=f'Article \"{article.title}\" by {article.author.get_full_name() or article.author.email} has been submitted for review.',\n                    data={\n                        'article_id': article.id,\n                        'article_title': article.title,\n                        'author_id': article.author.id,\n                        'author_name': article.author.get_full_name() or article.author.email\n                    }\n                )\n        except Exception as e:\n            # Log error but don't fail the operation\n            print(f\"Failed to send editor notifications: {e}\")\n\n    def _notify_author_of_decision(self, article: Article, approved: bool, editor: User, reason: str = None) -> None:\n        \"\"\"Send notification to author about approval decision.\"\"\"\n        try:\n            status_text = 'approved' if approved else 'rejected'\n            message = f'Your article \"{article.title}\" has been {status_text} by {editor.get_full_name() or editor.email}.'\n            if reason and not approved:\n                message += f' Reason: {reason}'\n            \n            self.notification_service.send_notification(\n                user_id=str(article.author.id),\n                notification_type='article_decision',\n                title=f'Article {status_text.title()}',\n                message=message,\n                data={\n                    'article_id': article.id,\n                    'article_title': article.title,\n                    'decision': status_text,\n                    'editor_id': editor.id,\n                    'editor_name': editor.get_full_name() or editor.email,\n                    'reason': reason\n                }\n            )\n        except Exception as e:\n            # Log error but don't fail the operation\n            print(f\"Failed to send author notification: {e}\")\n\n    def get_article_by_slug(self, slug: str) -> Optional[Article]:\n        \"\"\"Get an article by its slug.\"\"\"\n        try:\n            return Article.objects.select_related('author', 'category', 'latest_version', 'published_version').get(slug=slug)\n        except Article.DoesNotExist:\n            return None\n\n    def get_published_articles(self, category_slug: str = None, tag_slug: str = None) -> List[Article]:\n        \"\"\"Get all published (approved) articles with optional filtering.\"\"\"\n        queryset = Article.objects.filter(\n            status=ArticleStatus.APPROVED,\n            published_version__isnull=False\n        ).select_related('author', 'category', 'published_version')\n\n        if category_slug:\n            queryset = queryset.filter(category__slug=category_slug)\n        if tag_slug:\n            queryset = queryset.filter(tags__slug=tag_slug)\n\n        return list(queryset)\n\n    def get_featured_articles(self, limit: int = 5) -> List[Article]:\n        \"\"\"Get featured published articles.\"\"\"\n        return list(\n            Article.objects.filter(\n                is_featured=True,\n                status=ArticleStatus.APPROVED,\n                published_version__isnull=False\n            ).select_related('author', 'category', 'published_version')[:limit]\n        )\n\n    def get_articles_pending_review(self) -> List[Article]:\n        \"\"\"Get all articles pending review.\"\"\"\n        return list(\n            Article.objects.filter(\n                status=ArticleStatus.PENDING_REVIEW\n            ).select_related('author', 'category', 'latest_version')\n        )\n\n    def delete_article(self, article: Article) -> bool:\n        \"\"\"Delete an article.\"\"\"\n        article.delete()\n        return True\n\n\nclass CategoryService:\n    \"\"\"Service class for category-related operations.\"\"\"\n\n    def get_all_categories(self) -> List[Category]:\n        \"\"\"Get all categories.\"\"\"\n        return list(Category.objects.all())\n\n    def get_category_by_slug(self, slug: str) -> Optional[Category]:\n        \"\"\"Get a category by its slug.\"\"\"\n        try:\n            return Category.objects.get(slug=slug)\n        except Category.DoesNotExist:\n            return None\n\n    def create_category(self, data: Dict[str, Any]) -> Category:\n        \"\"\"Create a new category.\"\"\"\n        return Category.objects.create(\n            name=data['name'],\n            slug=data.get('slug') or slugify(data['name']),\n            description=data.get('description', ''),\n            parent_id=data.get('parent_id')\n        )\n\n\nclass TagService:\n    \"\"\"Service class for tag-related operations.\"\"\"\n\n    def get_all_tags(self) -> List[Tag]:\n        \"\"\"Get all tags.\"\"\"\n        return list(Tag.objects.all())\n\n    def get_or_create_tag(self, name: str) -> Tag:\n        \"\"\"Get or create a tag by name.\"\"\"\n        tag, _ = Tag.objects.get_or_create(\n            name=name,\n            defaults={'slug': slugify(name)}\n        )\n        return tag\n\n\nclass MediaAssetService:\n    \"\"\"Service class for media asset operations.\"\"\"\n\n    def create_media_asset(self, data: Dict[str, Any], user: User) -> MediaAsset:\n        \"\"\"Create a new media asset.\"\"\"\n        return MediaAsset.objects.create(\n            name=data['name'],\n            asset_type=data['asset_type'],\n            file_url=data['file_url'],\n            file_size=data['file_size'],\n            mime_type=data['mime_type'],\n            uploaded_by=user,\n            article_id=data.get('article_id')\n        )\n\n    def get_assets_for_article(self, article_id: int) -> List[MediaAsset]:\n        \"\"\"Get all media assets for an article.\"\"\"\n        return list(MediaAsset.objects.filter(article_id=article_id))\n\n\nclass CommentService:\n    \"\"\"Service class for comment operations.\"\"\"\n\n    def create_comment(self, data: Dict[str, Any], user: User) -> Comment:\n        \"\"\"Create a new comment.\"\"\"\n        return Comment.objects.create(\n            article_id=data['article_id'],\n            author=user,\n            content=data['content'],\n            parent_id=data.get('parent_id')\n        )\n\n    def get_comments_for_article(self, article_id: int, approved_only: bool = True) -> List[Comment]:\n        \"\"\"Get comments for an article.\"\"\"\n        queryset = Comment.objects.filter(article_id=article_id)\n        if approved_only:\n            queryset = queryset.filter(is_approved=True)\n        return list(queryset.select_related('author'))\n\n    def approve_comment(self, comment: Comment) -> Comment:\n        \"\"\"Approve a comment.\"\"\"\n        comment.is_approved = True\n        comment.save(update_fields=['is_approved'])\n        return comment\n\n\n# Import models for aggregate function\nfrom django.db import models\n",
          "mediverse_cms/apps/cms/api.py": "from rest_framework import viewsets, status, serializers\nfrom rest_framework.decorators import action\nfrom rest_framework.response import Response\nfrom rest_framework.permissions import IsAuthenticated, IsAuthenticatedOrReadOnly\nfrom django.shortcuts import get_object_or_404\n\nfrom .models import Article, ArticleVersion, Category, Tag, MediaAsset, Comment, ArticleStatus\nfrom .services import (\n    ArticleService,\n    CategoryService,\n    TagService,\n    MediaAssetService,\n    CommentService\n)\nfrom apps.core.permissions import IsEditorUser, IsOwnerOrReadOnly\n\n\nclass ArticleVersionSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for ArticleVersion model.\"\"\"\n    author_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = ArticleVersion\n        fields = ['id', 'title', 'content', 'excerpt', 'author', 'author_name', 'version_number', 'created_at']\n        read_only_fields = ['id', 'author', 'version_number', 'created_at']\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n\nclass ArticleSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Article model.\"\"\"\n    author_name = serializers.SerializerMethodField()\n    category_name = serializers.SerializerMethodField()\n    tags_list = serializers.SerializerMethodField()\n    latest_version = ArticleVersionSerializer(read_only=True)\n    published_version = ArticleVersionSerializer(read_only=True)\n\n    class Meta:\n        model = Article\n        fields = [\n            'id', 'title', 'slug', 'content', 'excerpt', 'author', 'author_name',\n            'category', 'category_name', 'tags', 'tags_list', 'featured_image',\n            'is_featured', 'view_count', 'status', 'latest_version', 'published_version',\n            'created_at', 'updated_at', 'published_at'\n        ]\n        read_only_fields = ['id', 'author', 'view_count', 'status', 'created_at', 'updated_at', 'published_at']\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n    def get_category_name(self, obj):\n        return obj.category.name if obj.category else None\n\n    def get_tags_list(self, obj):\n        return [{'id': tag.id, 'name': tag.name, 'slug': tag.slug} for tag in obj.tags.all()]\n\n\nclass ArticleCreateSerializer(serializers.Serializer):\n    \"\"\"Serializer for creating articles.\"\"\"\n    title = serializers.CharField(max_length=255)\n    content = serializers.CharField()\n    excerpt = serializers.CharField(required=False, allow_blank=True)\n    slug = serializers.SlugField(required=False, allow_blank=True)\n    category_id = serializers.IntegerField(required=False, allow_null=True)\n    tags = serializers.ListField(\n        child=serializers.IntegerField(),\n        required=False\n    )\n    featured_image = serializers.URLField(required=False, allow_blank=True)\n    is_featured = serializers.BooleanField(required=False, default=False)\n\n\nclass ArticleUpdateSerializer(serializers.Serializer):\n    \"\"\"Serializer for updating articles.\"\"\"\n    title = serializers.CharField(max_length=255, required=False)\n    content = serializers.CharField(required=False)\n    excerpt = serializers.CharField(required=False, allow_blank=True)\n    slug = serializers.SlugField(required=False)\n    category_id = serializers.IntegerField(required=False, allow_null=True)\n    tags = serializers.ListField(\n        child=serializers.IntegerField(),\n        required=False\n    )\n    featured_image = serializers.URLField(required=False, allow_blank=True)\n    is_featured = serializers.BooleanField(required=False)\n\n\nclass RejectSerializer(serializers.Serializer):\n    \"\"\"Serializer for rejection reason.\"\"\"\n    reason = serializers.CharField(required=False, allow_blank=True)\n\n\nclass ArticleViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Article CRUD operations and workflow actions.\"\"\"\n    queryset = Article.objects.all()\n    serializer_class = ArticleSerializer\n    permission_classes = [IsAuthenticated]\n    lookup_field = 'pk'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.article_service = ArticleService()\n\n    def get_queryset(self):\n        \"\"\"Filter queryset based on user permissions.\"\"\"\n        user = self.request.user\n        if user.is_staff or getattr(user, 'role', None) == 'Editor':\n            return Article.objects.all().select_related('author', 'category', 'latest_version', 'published_version')\n        # Regular users can only see their own articles\n        return Article.objects.filter(author=user).select_related('author', 'category', 'latest_version', 'published_version')\n\n    def get_serializer_class(self):\n        if self.action == 'create':\n            return ArticleCreateSerializer\n        elif self.action in ['update', 'partial_update']:\n            return ArticleUpdateSerializer\n        elif self.action == 'reject':\n            return RejectSerializer\n        return ArticleSerializer\n\n    def create(self, request, *args, **kwargs):\n        \"\"\"Create a new article.\"\"\"\n        serializer = self.get_serializer(data=request.data)\n        serializer.is_valid(raise_exception=True)\n        \n        article = self.article_service.create_article(\n            data=serializer.validated_data,\n            author=request.user\n        )\n        \n        response_serializer = ArticleSerializer(article)\n        return Response(response_serializer.data, status=status.HTTP_201_CREATED)\n\n    def update(self, request, *args, **kwargs):\n        \"\"\"Update an article.\"\"\"\n        partial = kwargs.pop('partial', False)\n        instance = self.get_object()\n        \n        serializer = self.get_serializer(data=request.data, partial=partial)\n        serializer.is_valid(raise_exception=True)\n        \n        article = self.article_service.update_article(\n            article=instance,\n            data=serializer.validated_data,\n            editor=request.user\n        )\n        \n        response_serializer = ArticleSerializer(article)\n        return Response(response_serializer.data)\n\n    def destroy(self, request, *args, **kwargs):\n        \"\"\"Delete an article.\"\"\"\n        instance = self.get_object()\n        self.article_service.delete_article(instance)\n        return Response(status=status.HTTP_204_NO_CONTENT)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated])\n    def submit(self, request, pk=None):\n        \"\"\"Submit an article for review.\"\"\"\n        article = self.get_object()\n        \n        # Check if user is the author\n        if article.author != request.user and not request.user.is_staff:\n            return Response(\n                {'error': 'Only the author can submit this article for review.'},\n                status=status.HTTP_403_FORBIDDEN\n            )\n        \n        try:\n            article = self.article_service.submit_for_review(article, request.user)\n            serializer = ArticleSerializer(article)\n            return Response(serializer.data)\n        except ValueError as e:\n            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def approve(self, request, pk=None):\n        \"\"\"Approve an article for publication. Editor only.\"\"\"\n        article = self.get_object()\n        \n        try:\n            article = self.article_service.approve_article(article, request.user)\n            serializer = ArticleSerializer(article)\n            return Response(serializer.data)\n        except ValueError as e:\n            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def reject(self, request, pk=None):\n        \"\"\"Reject an article. Editor only.\"\"\"\n        article = self.get_object()\n        \n        reject_serializer = RejectSerializer(data=request.data)\n        reject_serializer.is_valid(raise_exception=True)\n        reason = reject_serializer.validated_data.get('reason', '')\n        \n        try:\n            article = self.article_service.reject_article(article, request.user, reason)\n            serializer = ArticleSerializer(article)\n            return Response(serializer.data)\n        except ValueError as e:\n            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\n    @action(detail=False, methods=['get'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def pending_review(self, request):\n        \"\"\"Get all articles pending review. Editor only.\"\"\"\n        articles = self.article_service.get_articles_pending_review()\n        serializer = ArticleSerializer(articles, many=True)\n        return Response(serializer.data)\n\n    @action(detail=True, methods=['get'])\n    def versions(self, request, pk=None):\n        \"\"\"Get all versions of an article.\"\"\"\n        article = self.get_object()\n        versions = article.versions.all()\n        serializer = ArticleVersionSerializer(versions, many=True)\n        return Response(serializer.data)\n\n\nclass CategorySerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Category model.\"\"\"\n    class Meta:\n        model = Category\n        fields = ['id', 'name', 'slug', 'description', 'parent', 'created_at', 'updated_at']\n        read_only_fields = ['id', 'created_at', 'updated_at']\n\n\nclass CategoryViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Category CRUD operations.\"\"\"\n    queryset = Category.objects.all()\n    serializer_class = CategorySerializer\n    permission_classes = [IsAuthenticatedOrReadOnly]\n    lookup_field = 'slug'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.category_service = CategoryService()\n\n\nclass TagSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Tag model.\"\"\"\n    class Meta:\n        model = Tag\n        fields = ['id', 'name', 'slug']\n        read_only_fields = ['id']\n\n\nclass TagViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Tag CRUD operations.\"\"\"\n    queryset = Tag.objects.all()\n    serializer_class = TagSerializer\n    permission_classes = [IsAuthenticatedOrReadOnly]\n    lookup_field = 'slug'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tag_service = TagService()\n\n\nclass MediaAssetSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for MediaAsset model.\"\"\"\n    class Meta:\n        model = MediaAsset\n        fields = ['id', 'name', 'asset_type', 'file_url', 'file_size', 'mime_type', 'uploaded_by', 'article', 'created_at']\n        read_only_fields = ['id', 'uploaded_by', 'created_at']\n\n\nclass MediaAssetViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for MediaAsset CRUD operations.\"\"\"\n    queryset = MediaAsset.objects.all()\n    serializer_class = MediaAssetSerializer\n    permission_classes = [IsAuthenticated]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.media_service = MediaAssetService()\n\n    def perform_create(self, serializer):\n        serializer.save(uploaded_by=self.request.user)\n\n\nclass CommentSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Comment model.\"\"\"\n    author_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = Comment\n        fields = ['id', 'article', 'author', 'author_name', 'content', 'parent', 'is_approved', 'created_at', 'updated_at']\n        read_only_fields = ['id', 'author', 'is_approved', 'created_at', 'updated_at']\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n\nclass CommentViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Comment CRUD operations.\"\"\"\n    queryset = Comment.objects.all()\n    serializer_class = CommentSerializer\n    permission_classes = [IsAuthenticated]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.comment_service = CommentService()\n\n    def perform_create(self, serializer):\n        serializer.save(author=self.request.user)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def approve(self, request, pk=None):\n        \"\"\"Approve a comment. Editor only.\"\"\"\n        comment = self.get_object()\n        comment = self.comment_service.approve_comment(comment)\n        serializer = self.get_serializer(comment)\n        return Response(serializer.data)\n",
          "mediverse_cms/apps/core/permissions.py": "from rest_framework import permissions\n\n\nclass IsOwnerOrReadOnly(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow owners of an object to edit it.\n    \"\"\"\n\n    def has_object_permission(self, request, view, obj):\n        # Read permissions are allowed to any request\n        if request.method in permissions.SAFE_METHODS:\n            return True\n\n        # Write permissions are only allowed to the owner\n        if hasattr(obj, 'author'):\n            return obj.author == request.user\n        if hasattr(obj, 'user'):\n            return obj.user == request.user\n        if hasattr(obj, 'owner'):\n            return obj.owner == request.user\n        \n        return False\n\n\nclass IsAdminUser(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow admin users.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        return request.user and request.user.is_staff\n\n\nclass IsEditorUser(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow users with 'Editor' role.\n    Editors can approve or reject articles for publication.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        # Check if user has Editor role\n        user_role = getattr(request.user, 'role', None)\n        \n        # Also allow staff/superusers to perform editor actions\n        if request.user.is_staff or request.user.is_superuser:\n            return True\n        \n        return user_role == 'Editor'\n\n    def has_object_permission(self, request, view, obj):\n        # Same check as has_permission for object-level\n        return self.has_permission(request, view)\n\n\nclass IsAuthorOrEditor(permissions.BasePermission):\n    \"\"\"\n    Custom permission that allows authors to edit their own content,\n    or editors to edit any content.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        return request.user and request.user.is_authenticated\n\n    def has_object_permission(self, request, view, obj):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        # Editors can edit any content\n        user_role = getattr(request.user, 'role', None)\n        if user_role == 'Editor' or request.user.is_staff:\n            return True\n        \n        # Authors can edit their own content\n        if hasattr(obj, 'author'):\n            return obj.author == request.user\n        \n        return False\n\n\nclass IsPatient(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow users with 'Patient' role.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        user_role = getattr(request.user, 'role', None)\n        return user_role == 'Patient'\n\n\nclass IsHealthcareProvider(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow healthcare providers.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        user_role = getattr(request.user, 'role', None)\n        return user_role in ['Doctor', 'Nurse', 'Healthcare Provider']\n",
          "mediverse_cms/apps/portal/api.py": "from rest_framework import viewsets, status, serializers\nfrom rest_framework.decorators import action\nfrom rest_framework.response import Response\nfrom rest_framework.permissions import IsAuthenticated, AllowAny\nfrom django.shortcuts import get_object_or_404\n\nfrom .models import PatientProfile, Appointment, MedicalRecord\nfrom .services import PatientPortalService\nfrom apps.cms.models import Article, ArticleStatus\nfrom apps.cms.services import ArticleService\n\n\nclass PatientProfileSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for PatientProfile model.\"\"\"\n    user_email = serializers.SerializerMethodField()\n\n    class Meta:\n        model = PatientProfile\n        fields = [\n            'id', 'user', 'user_email', 'date_of_birth', 'blood_type',\n            'allergies', 'emergency_contact_name', 'emergency_contact_phone',\n            'insurance_provider', 'insurance_policy_number', 'created_at', 'updated_at'\n        ]\n        read_only_fields = ['id', 'user', 'created_at', 'updated_at']\n\n    def get_user_email(self, obj):\n        return obj.user.email\n\n\nclass PatientProfileViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for PatientProfile CRUD operations.\"\"\"\n    queryset = PatientProfile.objects.all()\n    serializer_class = PatientProfileSerializer\n    permission_classes = [IsAuthenticated]\n\n    def get_queryset(self):\n        \"\"\"Filter to only show the current user's profile.\"\"\"\n        if self.request.user.is_staff:\n            return PatientProfile.objects.all()\n        return PatientProfile.objects.filter(user=self.request.user)\n\n\nclass AppointmentSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Appointment model.\"\"\"\n    patient_name = serializers.SerializerMethodField()\n    provider_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = Appointment\n        fields = [\n            'id', 'patient', 'patient_name', 'provider', 'provider_name',\n            'appointment_type', 'scheduled_at', 'duration_minutes', 'status',\n            'notes', 'created_at', 'updated_at'\n        ]\n        read_only_fields = ['id', 'created_at', 'updated_at']\n\n    def get_patient_name(self, obj):\n        return obj.patient.user.get_full_name() or obj.patient.user.email\n\n    def get_provider_name(self, obj):\n        return obj.provider.get_full_name() or obj.provider.email\n\n\nclass AppointmentViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Appointment CRUD operations.\"\"\"\n    queryset = Appointment.objects.all()\n    serializer_class = AppointmentSerializer\n    permission_classes = [IsAuthenticated]\n\n    def get_queryset(self):\n        \"\"\"Filter appointments based on user role.\"\"\"\n        user = self.request.user\n        if user.is_staff:\n            return Appointment.objects.all()\n        \n        # Check if user is a patient\n        try:\n            patient_profile = PatientProfile.objects.get(user=user)\n            return Appointment.objects.filter(patient=patient_profile)\n        except PatientProfile.DoesNotExist:\n            pass\n        \n        # Check if user is a provider\n        return Appointment.objects.filter(provider=user)\n\n\nclass MedicalRecordSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for MedicalRecord model.\"\"\"\n    patient_name = serializers.SerializerMethodField()\n    provider_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = MedicalRecord\n        fields = [\n            'id', 'patient', 'patient_name', 'provider', 'provider_name',\n            'record_type', 'title', 'content', 'attachments', 'is_confidential',\n            'created_at', 'updated_at'\n        ]\n        read_only_fields = ['id', 'created_at', 'updated_at']\n\n    def get_patient_name(self, obj):\n        return obj.patient.user.get_full_name() or obj.patient.user.email\n\n    def get_provider_name(self, obj):\n        return obj.provider.get_full_name() or obj.provider.email\n\n\nclass MedicalRecordViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for MedicalRecord CRUD operations.\"\"\"\n    queryset = MedicalRecord.objects.all()\n    serializer_class = MedicalRecordSerializer\n    permission_classes = [IsAuthenticated]\n\n    def get_queryset(self):\n        \"\"\"Filter medical records based on user role.\"\"\"\n        user = self.request.user\n        if user.is_staff:\n            return MedicalRecord.objects.all()\n        \n        # Check if user is a patient\n        try:\n            patient_profile = PatientProfile.objects.get(user=user)\n            return MedicalRecord.objects.filter(patient=patient_profile)\n        except PatientProfile.DoesNotExist:\n            pass\n        \n        # Check if user is a provider\n        return MedicalRecord.objects.filter(provider=user)\n\n\n# Public Article Serializer for Portal - serves published content only\nclass PublicArticleSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for public-facing articles in the patient portal.\n    \n    This serializer serves content from the published_version of an article,\n    ensuring only approved content is displayed to patients.\n    \"\"\"\n    author_name = serializers.SerializerMethodField()\n    category_name = serializers.SerializerMethodField()\n    tags_list = serializers.SerializerMethodField()\n    # Serve content from published version\n    title = serializers.SerializerMethodField()\n    content = serializers.SerializerMethodField()\n    excerpt = serializers.SerializerMethodField()\n\n    class Meta:\n        model = Article\n        fields = [\n            'id', 'title', 'slug', 'content', 'excerpt', 'author_name',\n            'category_name', 'tags_list', 'featured_image', 'is_featured',\n            'view_count', 'published_at'\n        ]\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n    def get_category_name(self, obj):\n        return obj.category.name if obj.category else None\n\n    def get_tags_list(self, obj):\n        return [{'id': tag.id, 'name': tag.name, 'slug': tag.slug} for tag in obj.tags.all()]\n\n    def get_title(self, obj):\n        \"\"\"Return title from published version.\"\"\"\n        if obj.published_version:\n            return obj.published_version.title\n        return obj.title\n\n    def get_content(self, obj):\n        \"\"\"Return content from published version.\"\"\"\n        if obj.published_version:\n            return obj.published_version.content\n        return obj.content\n\n    def get_excerpt(self, obj):\n        \"\"\"Return excerpt from published version.\"\"\"\n        if obj.published_version:\n            return obj.published_version.excerpt\n        return obj.excerpt\n\n\nclass PublicArticleViewSet(viewsets.ReadOnlyModelViewSet):\n    \"\"\"ViewSet for public article access in the patient portal.\n    \n    This viewset only returns articles that have been approved and have\n    a published version. Content is served from the published_version\n    to ensure only reviewed content is displayed.\n    \"\"\"\n    serializer_class = PublicArticleSerializer\n    permission_classes = [AllowAny]  # Public access for patients\n    lookup_field = 'slug'\n\n    def get_queryset(self):\n        \"\"\"Return only approved articles with published versions.\"\"\"\n        queryset = Article.objects.filter(\n            status=ArticleStatus.APPROVED,\n            published_version__isnull=False\n        ).select_related(\n            'author', 'category', 'published_version'\n        ).prefetch_related('tags')\n        \n        # Optional filtering by category\n        category_slug = self.request.query_params.get('category', None)\n        if category_slug:\n            queryset = queryset.filter(category__slug=category_slug)\n        \n        # Optional filtering by tag\n        tag_slug = self.request.query_params.get('tag', None)\n        if tag_slug:\n            queryset = queryset.filter(tags__slug=tag_slug)\n        \n        # Optional featured filter\n        featured = self.request.query_params.get('featured', None)\n        if featured and featured.lower() == 'true':\n            queryset = queryset.filter(is_featured=True)\n        \n        return queryset.order_by('-published_at')\n\n    def retrieve(self, request, *args, **kwargs):\n        \"\"\"Retrieve a single article and increment view count.\"\"\"\n        instance = self.get_object()\n        instance.increment_view_count()\n        serializer = self.get_serializer(instance)\n        return Response(serializer.data)\n\n    @action(detail=False, methods=['get'])\n    def featured(self, request):\n        \"\"\"Get featured articles.\"\"\"\n        queryset = self.get_queryset().filter(is_featured=True)[:5]\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)\n\n    @action(detail=False, methods=['get'])\n    def recent(self, request):\n        \"\"\"Get most recent articles.\"\"\"\n        limit = int(request.query_params.get('limit', 10))\n        queryset = self.get_queryset()[:limit]\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)\n",
          "mediverse_cms/apps/integrations/notification_service.py": "import logging\nfrom typing import Dict, Any, Optional, List\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\n\nclass NotificationType(Enum):\n    \"\"\"Types of notifications supported by the system.\"\"\"\n    EMAIL = 'email'\n    SMS = 'sms'\n    PUSH = 'push'\n    IN_APP = 'in_app'\n\n\n@dataclass\nclass NotificationResult:\n    \"\"\"Result of a notification operation.\"\"\"\n    success: bool\n    message_id: Optional[str] = None\n    error: Optional[str] = None\n\n\nclass NotificationService:\n    \"\"\"Service for sending notifications through various channels.\"\"\"\n\n    def __init__(self, config: Dict[str, Any] = None):\n        self.config = config or {}\n        self._email_provider = self.config.get('email_provider', 'smtp')\n        self._sms_provider = self.config.get('sms_provider', 'twilio')\n        self._push_provider = self.config.get('push_provider', 'firebase')\n\n    def send_notification(\n        self,\n        user_id: str,\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any] = None,\n        channels: List[str] = None\n    ) -> NotificationResult:\n        \"\"\"\n        Send a notification to a user through specified channels.\n        \n        Args:\n            user_id: The ID of the user to notify\n            notification_type: Type of notification (e.g., 'article_submission', 'article_decision')\n            title: Notification title\n            message: Notification message body\n            data: Additional data to include with the notification\n            channels: List of channels to use (defaults to ['in_app', 'email'])\n        \n        Returns:\n            NotificationResult indicating success or failure\n        \"\"\"\n        channels = channels or ['in_app', 'email']\n        data = data or {}\n        \n        logger.info(\n            f\"Sending notification to user {user_id}: \"\n            f\"type={notification_type}, title={title}, channels={channels}\"\n        )\n        \n        results = []\n        \n        for channel in channels:\n            try:\n                if channel == 'email':\n                    result = self._send_email(user_id, title, message, data)\n                elif channel == 'sms':\n                    result = self._send_sms(user_id, message, data)\n                elif channel == 'push':\n                    result = self._send_push(user_id, title, message, data)\n                elif channel == 'in_app':\n                    result = self._send_in_app(user_id, notification_type, title, message, data)\n                else:\n                    logger.warning(f\"Unknown notification channel: {channel}\")\n                    continue\n                \n                results.append(result)\n                \n            except Exception as e:\n                logger.error(f\"Failed to send {channel} notification to {user_id}: {e}\")\n                results.append(NotificationResult(success=False, error=str(e)))\n        \n        # Return success if at least one channel succeeded\n        any_success = any(r.success for r in results)\n        return NotificationResult(\n            success=any_success,\n            message_id=f\"notif_{user_id}_{notification_type}\",\n            error=None if any_success else \"All notification channels failed\"\n        )\n\n    def _send_email(self, user_id: str, subject: str, body: str, data: Dict[str, Any]) -> NotificationResult:\n        \"\"\"Send an email notification.\"\"\"\n        logger.info(f\"Sending email to user {user_id}: subject={subject}\")\n        # In production, this would integrate with an email service\n        # For now, we simulate success\n        return NotificationResult(success=True, message_id=f\"email_{user_id}\")\n\n    def _send_sms(self, user_id: str, message: str, data: Dict[str, Any]) -> NotificationResult:\n        \"\"\"Send an SMS notification.\"\"\"\n        logger.info(f\"Sending SMS to user {user_id}\")\n        # In production, this would integrate with Twilio or similar\n        return NotificationResult(success=True, message_id=f\"sms_{user_id}\")\n\n    def _send_push(self, user_id: str, title: str, body: str, data: Dict[str, Any]) -> NotificationResult:\n        \"\"\"Send a push notification.\"\"\"\n        logger.info(f\"Sending push notification to user {user_id}: title={title}\")\n        # In production, this would integrate with Firebase or similar\n        return NotificationResult(success=True, message_id=f\"push_{user_id}\")\n\n    def _send_in_app(\n        self,\n        user_id: str,\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any]\n    ) -> NotificationResult:\n        \"\"\"Send an in-app notification.\"\"\"\n        logger.info(f\"Creating in-app notification for user {user_id}: type={notification_type}\")\n        # In production, this would create a database record\n        # that the frontend can poll or receive via WebSocket\n        return NotificationResult(success=True, message_id=f\"inapp_{user_id}_{notification_type}\")\n\n    def send_bulk_notification(\n        self,\n        user_ids: List[str],\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any] = None,\n        channels: List[str] = None\n    ) -> Dict[str, NotificationResult]:\n        \"\"\"\n        Send notifications to multiple users.\n        \n        Args:\n            user_ids: List of user IDs to notify\n            notification_type: Type of notification\n            title: Notification title\n            message: Notification message body\n            data: Additional data to include\n            channels: List of channels to use\n        \n        Returns:\n            Dictionary mapping user_id to NotificationResult\n        \"\"\"\n        results = {}\n        for user_id in user_ids:\n            results[user_id] = self.send_notification(\n                user_id=user_id,\n                notification_type=notification_type,\n                title=title,\n                message=message,\n                data=data,\n                channels=channels\n            )\n        return results\n\n    def send_to_role(\n        self,\n        role: str,\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any] = None,\n        channels: List[str] = None\n    ) -> List[NotificationResult]:\n        \"\"\"\n        Send notifications to all users with a specific role.\n        \n        Args:\n            role: User role to target (e.g., 'Editor', 'Admin')\n            notification_type: Type of notification\n            title: Notification title\n            message: Notification message body\n            data: Additional data to include\n            channels: List of channels to use\n        \n        Returns:\n            List of NotificationResults\n        \"\"\"\n        # In production, this would query the database for users with the role\n        logger.info(f\"Sending notification to all users with role: {role}\")\n        \n        # Placeholder - in real implementation, fetch user IDs from database\n        # from apps.users.models import User\n        # user_ids = list(User.objects.filter(role=role, is_active=True).values_list('id', flat=True))\n        \n        # For now, return a placeholder result\n        return [NotificationResult(success=True, message_id=f\"role_{role}_notification\")]\n",
          "mediverse_cms/apps/users/models.py": "from django.contrib.auth.models import AbstractUser, BaseUserManager\nfrom django.db import models\n\n\nclass UserManager(BaseUserManager):\n    \"\"\"Custom user manager for email-based authentication.\"\"\"\n\n    def create_user(self, email, password=None, **extra_fields):\n        \"\"\"Create and save a regular user with the given email and password.\"\"\"\n        if not email:\n            raise ValueError('The Email field must be set')\n        email = self.normalize_email(email)\n        user = self.model(email=email, **extra_fields)\n        user.set_password(password)\n        user.save(using=self._db)\n        return user\n\n    def create_superuser(self, email, password=None, **extra_fields):\n        \"\"\"Create and save a superuser with the given email and password.\"\"\"\n        extra_fields.setdefault('is_staff', True)\n        extra_fields.setdefault('is_superuser', True)\n\n        if extra_fields.get('is_staff') is not True:\n            raise ValueError('Superuser must have is_staff=True.')\n        if extra_fields.get('is_superuser') is not True:\n            raise ValueError('Superuser must have is_superuser=True.')\n\n        return self.create_user(email, password, **extra_fields)\n\n\nclass User(AbstractUser):\n    \"\"\"Custom user model with email as the unique identifier.\"\"\"\n    \n    ROLE_CHOICES = [\n        ('Patient', 'Patient'),\n        ('Doctor', 'Doctor'),\n        ('Nurse', 'Nurse'),\n        ('Admin', 'Admin'),\n        ('Editor', 'Editor'),\n        ('Author', 'Author'),\n        ('Healthcare Provider', 'Healthcare Provider'),\n    ]\n\n    username = None\n    email = models.EmailField('email address', unique=True)\n    phone_number = models.CharField(max_length=20, blank=True)\n    role = models.CharField(max_length=30, choices=ROLE_CHOICES, default='Patient')\n    department = models.CharField(max_length=100, blank=True)\n    specialization = models.CharField(max_length=100, blank=True)\n    license_number = models.CharField(max_length=50, blank=True)\n    profile_picture = models.URLField(blank=True)\n    bio = models.TextField(blank=True)\n    is_verified = models.BooleanField(default=False)\n    \n    # Preferences\n    notification_preferences = models.JSONField(default=dict, blank=True)\n    \n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    USERNAME_FIELD = 'email'\n    REQUIRED_FIELDS = []\n\n    objects = UserManager()\n\n    def __str__(self):\n        return self.email\n\n    def get_full_name(self):\n        \"\"\"Return the first_name plus the last_name, with a space in between.\"\"\"\n        full_name = f\"{self.first_name} {self.last_name}\".strip()\n        return full_name or self.email\n\n    def get_short_name(self):\n        \"\"\"Return the short name for the user.\"\"\"\n        return self.first_name or self.email.split('@')[0]\n\n\nclass UserSession(models.Model):\n    \"\"\"Model to track user sessions.\"\"\"\n    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='sessions')\n    session_key = models.CharField(max_length=255, unique=True)\n    ip_address = models.GenericIPAddressField(null=True, blank=True)\n    user_agent = models.TextField(blank=True)\n    device_type = models.CharField(max_length=50, blank=True)\n    is_active = models.BooleanField(default=True)\n    created_at = models.DateTimeField(auto_now_add=True)\n    last_activity = models.DateTimeField(auto_now=True)\n    expires_at = models.DateTimeField(null=True, blank=True)\n\n    def __str__(self):\n        return f\"{self.user.email} - {self.session_key[:20]}...\"\n",
          "mediverse_cms/apps/cms/admin.py": "from django.contrib import admin\nfrom .models import Article, ArticleVersion, Category, Tag, MediaAsset, Comment\n\n\n@admin.register(Category)\nclass CategoryAdmin(admin.ModelAdmin):\n    list_display = ['name', 'slug', 'parent', 'created_at']\n    prepopulated_fields = {'slug': ('name',)}\n    search_fields = ['name']\n    list_filter = ['parent']\n\n\n@admin.register(Tag)\nclass TagAdmin(admin.ModelAdmin):\n    list_display = ['name', 'slug']\n    prepopulated_fields = {'slug': ('name',)}\n    search_fields = ['name']\n\n\nclass ArticleVersionInline(admin.TabularInline):\n    model = ArticleVersion\n    extra = 0\n    readonly_fields = ['version_number', 'author', 'created_at']\n    fields = ['version_number', 'title', 'author', 'created_at']\n    ordering = ['-version_number']\n\n\n@admin.register(Article)\nclass ArticleAdmin(admin.ModelAdmin):\n    list_display = ['title', 'author', 'category', 'status', 'is_featured', 'view_count', 'created_at', 'published_at']\n    list_filter = ['status', 'is_featured', 'category', 'created_at']\n    search_fields = ['title', 'content', 'author__email']\n    prepopulated_fields = {'slug': ('title',)}\n    raw_id_fields = ['author', 'latest_version', 'published_version']\n    filter_horizontal = ['tags']\n    date_hierarchy = 'created_at'\n    readonly_fields = ['view_count', 'created_at', 'updated_at', 'published_at']\n    inlines = [ArticleVersionInline]\n    \n    fieldsets = (\n        (None, {\n            'fields': ('title', 'slug', 'content', 'excerpt')\n        }),\n        ('Classification', {\n            'fields': ('category', 'tags', 'featured_image', 'is_featured')\n        }),\n        ('Authorship', {\n            'fields': ('author',)\n        }),\n        ('Workflow', {\n            'fields': ('status', 'latest_version', 'published_version')\n        }),\n        ('Statistics', {\n            'fields': ('view_count', 'created_at', 'updated_at', 'published_at'),\n            'classes': ('collapse',)\n        }),\n    )\n    \n    actions = ['approve_articles', 'reject_articles']\n    \n    def approve_articles(self, request, queryset):\n        \"\"\"Bulk approve articles.\"\"\"\n        from .models import ArticleStatus\n        from django.utils import timezone\n        \n        count = 0\n        for article in queryset.filter(status=ArticleStatus.PENDING_REVIEW):\n            article.status = ArticleStatus.APPROVED\n            article.published_version = article.latest_version\n            article.published_at = timezone.now()\n            article.save()\n            count += 1\n        \n        self.message_user(request, f\"{count} article(s) approved successfully.\")\n    approve_articles.short_description = \"Approve selected articles\"\n    \n    def reject_articles(self, request, queryset):\n        \"\"\"Bulk reject articles.\"\"\"\n        from .models import ArticleStatus\n        \n        count = queryset.filter(status=ArticleStatus.PENDING_REVIEW).update(\n            status=ArticleStatus.REJECTED\n        )\n        self.message_user(request, f\"{count} article(s) rejected.\")\n    reject_articles.short_description = \"Reject selected articles\"\n\n\n@admin.register(ArticleVersion)\nclass ArticleVersionAdmin(admin.ModelAdmin):\n    list_display = ['article', 'version_number', 'author', 'created_at']\n    list_filter = ['created_at', 'author']\n    search_fields = ['article__title', 'title', 'content']\n    raw_id_fields = ['article', 'author']\n    readonly_fields = ['version_number', 'created_at']\n    ordering = ['-created_at']\n\n\n@admin.register(MediaAsset)\nclass MediaAssetAdmin(admin.ModelAdmin):\n    list_display = ['name', 'asset_type', 'uploaded_by', 'article', 'file_size', 'created_at']\n    list_filter = ['asset_type', 'created_at']\n    search_fields = ['name', 'uploaded_by__email']\n    raw_id_fields = ['uploaded_by', 'article']\n\n\n@admin.register(Comment)\nclass CommentAdmin(admin.ModelAdmin):\n    list_display = ['article', 'author', 'is_approved', 'parent', 'created_at']\n    list_filter = ['is_approved', 'created_at']\n    search_fields = ['content', 'author__email', 'article__title']\n    raw_id_fields = ['article', 'author', 'parent']\n    actions = ['approve_comments']\n    \n    def approve_comments(self, request, queryset):\n        \"\"\"Bulk approve comments.\"\"\"\n        count = queryset.update(is_approved=True)\n        self.message_user(request, f\"{count} comment(s) approved.\")\n    approve_comments.short_description = \"Approve selected comments\"\n"
        },
        "generated_files": [
          "mediverse_cms/apps/cms/models.py",
          "mediverse_cms/apps/cms/services.py",
          "mediverse_cms/apps/cms/api.py",
          "mediverse_cms/apps/core/permissions.py",
          "mediverse_cms/apps/portal/api.py",
          "mediverse_cms/apps/integrations/notification_service.py",
          "mediverse_cms/apps/users/models.py",
          "mediverse_cms/apps/cms/admin.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8041151928912007,
              "dependency_traversal_accuracy": 0.8064327715682418,
              "cross_file_reasoning_depth": 0.4357291666666666,
              "system_thinking_score": 0.4628238073349786,
              "robustness_score": 0.4406240240474703,
              "comprehensiveness_score": 0.24853288309389965,
              "innovation_score": 0.3375,
              "solution_elegance_score": 0.8615618615990877
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.10051439911140009,
              "dependency_traversal_weighted": 0.10080409644603022,
              "cross_file_reasoning_weighted": 0.054466145833333326,
              "system_thinking_weighted": 0.05785297591687232,
              "robustness_weighted": 0.05507800300593379,
              "comprehensiveness_weighted": 0.031066610386737456,
              "innovation_weighted": 0.0421875,
              "solution_elegance_weighted": 0.10769523269988596
            },
            "total_software_engineering_score": 0.5496649634001931
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.5227899551391602,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "mediverse_cms/apps/cms/models.py",
                "mediverse_cms/apps/cms/services.py",
                "mediverse_cms/apps/cms/api.py",
                "mediverse_cms/apps/core/permissions.py",
                "mediverse_cms/apps/portal/api.py",
                "mediverse_cms/apps/integrations/notification_service.py",
                "mediverse_cms/apps/users/models.py",
                "mediverse_cms/apps/cms/admin.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 8,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 8 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.22434593023255814,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.22434593023255814,
              "idc_weight": 0.2,
              "total_functional_score": 0.6248691860465116
            }
          },
          "code_quality_details": {
            "files_analyzed": 8,
            "quality_checks": {
              "mediverse_cms/apps/cms/models.py": {
                "line_count": 189,
                "non_empty_lines": 160,
                "comment_lines": 1,
                "comment_ratio": 0.00625,
                "function_count": 7,
                "class_count": 13,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/cms/services.py": {
                "line_count": 342,
                "non_empty_lines": 281,
                "comment_lines": 18,
                "comment_ratio": 0.06405693950177936,
                "function_count": 23,
                "class_count": 10,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/cms/api.py": {
                "line_count": 316,
                "non_empty_lines": 250,
                "comment_lines": 2,
                "comment_ratio": 0.008,
                "function_count": 23,
                "class_count": 25,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/core/permissions.py": {
                "line_count": 107,
                "non_empty_lines": 76,
                "comment_lines": 7,
                "comment_ratio": 0.09210526315789473,
                "function_count": 8,
                "class_count": 6,
                "import_count": 2,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/portal/api.py": {
                "line_count": 240,
                "non_empty_lines": 190,
                "comment_lines": 9,
                "comment_ratio": 0.04736842105263158,
                "function_count": 18,
                "class_count": 16,
                "import_count": 24,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/integrations/notification_service.py": {
                "line_count": 195,
                "non_empty_lines": 165,
                "comment_lines": 12,
                "comment_ratio": 0.07272727272727272,
                "function_count": 8,
                "class_count": 3,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/users/models.py": {
                "line_count": 93,
                "non_empty_lines": 72,
                "comment_lines": 1,
                "comment_ratio": 0.013888888888888888,
                "function_count": 6,
                "class_count": 4,
                "import_count": 4,
                "quality_score": 0.7999999999999999
              },
              "mediverse_cms/apps/cms/admin.py": {
                "line_count": 119,
                "non_empty_lines": 96,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 3,
                "class_count": 7,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7999999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8365384615384617,
              "multi_session_memory_retention": 0.8157051282051284
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.41826923076923084,
              "multi_session_memory_retention_weighted": 0.4078525641025642
            },
            "total_longcontext_utilization_score": 0.826121794871795
          }
        },
        "timestamp": "2026-01-14T21:32:34.725676"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_api_gateway_hard_009_feature_implementation_expert_01",
        "scenario_title": "Implement Bulk Student Enrollment Endpoint with Partial Success Handling",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5592560158134906,
        "functional_correctness_score": 0.4100233506300964,
        "code_quality_score": 0.7562499999999999,
        "longcontext_utilization_score": 0.8775219298245611,
        "total_score": 2.9285580224844066,
        "generation_time": 158.92781400680542,
        "code_files_generated": 8,
        "total_lines_generated": 1689,
        "parsing_success": true,
        "solution_code": {
          "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py": "\"\"\"Enrollment schemas for bulk operations.\"\"\"\nfrom typing import List, Literal\nfrom pydantic import BaseModel, Field\nfrom uuid import UUID\n\n\nclass BulkEnrollmentRequest(BaseModel):\n    \"\"\"Request schema for bulk student enrollment.\"\"\"\n    student_ids: List[str] = Field(\n        ...,\n        description=\"List of student IDs to enroll in the course\",\n        min_length=0\n    )\n\n\nclass EnrollmentResult(BaseModel):\n    \"\"\"Result of a single enrollment operation.\"\"\"\n    student_id: str = Field(..., description=\"The student ID\")\n    status: Literal[\"success\", \"failed\"] = Field(..., description=\"Enrollment status\")\n\n\nclass SuccessfulEnrollment(EnrollmentResult):\n    \"\"\"Successful enrollment result.\"\"\"\n    status: Literal[\"success\"] = \"success\"\n\n\nclass FailedEnrollment(EnrollmentResult):\n    \"\"\"Failed enrollment result with reason.\"\"\"\n    status: Literal[\"failed\"] = \"failed\"\n    reason: str = Field(..., description=\"Reason for failure\")\n\n\nclass BulkEnrollmentResponse(BaseModel):\n    \"\"\"Response schema for bulk enrollment operation.\"\"\"\n    successful_enrollments: List[SuccessfulEnrollment] = Field(\n        default_factory=list,\n        description=\"List of successful enrollments\"\n    )\n    failed_enrollments: List[FailedEnrollment] = Field(\n        default_factory=list,\n        description=\"List of failed enrollments with reasons\"\n    )\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"successful_enrollments\": [\n                    {\"student_id\": \"550e8400-e29b-41d4-a716-446655440001\", \"status\": \"success\"}\n                ],\n                \"failed_enrollments\": [\n                    {\n                        \"student_id\": \"550e8400-e29b-41d4-a716-446655440002\",\n                        \"status\": \"failed\",\n                        \"reason\": \"Student not found\"\n                    }\n                ]\n            }\n        }\n",
          "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py": "\"\"\"API Schemas.\"\"\"\nfrom edubridge_gateway.api.schemas.base import BaseSchema, PaginatedResponse\nfrom edubridge_gateway.api.schemas.student import (\n    StudentCreate,\n    StudentUpdate,\n    StudentResponse,\n    StudentListResponse,\n)\nfrom edubridge_gateway.api.schemas.course import (\n    CourseCreate,\n    CourseUpdate,\n    CourseResponse,\n    CourseListResponse,\n    EnrollmentCreate,\n    EnrollmentResponse,\n)\nfrom edubridge_gateway.api.schemas.enrollment import (\n    BulkEnrollmentRequest,\n    BulkEnrollmentResponse,\n    SuccessfulEnrollment,\n    FailedEnrollment,\n    EnrollmentResult,\n)\n\n__all__ = [\n    \"BaseSchema\",\n    \"PaginatedResponse\",\n    \"StudentCreate\",\n    \"StudentUpdate\",\n    \"StudentResponse\",\n    \"StudentListResponse\",\n    \"CourseCreate\",\n    \"CourseUpdate\",\n    \"CourseResponse\",\n    \"CourseListResponse\",\n    \"EnrollmentCreate\",\n    \"EnrollmentResponse\",\n    \"BulkEnrollmentRequest\",\n    \"BulkEnrollmentResponse\",\n    \"SuccessfulEnrollment\",\n    \"FailedEnrollment\",\n    \"EnrollmentResult\",\n]\n",
          "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py": "\"\"\"Student Information System (SIS) Repository.\n\nThis module provides the repository for interacting with the\nexternal Student Information System.\n\"\"\"\nimport httpx\nfrom typing import Any, Dict, List, Optional\nfrom edubridge_gateway.repositories.base import BaseRepository\nfrom edubridge_gateway.core.exceptions import (\n    ExternalServiceException,\n    NotFoundException,\n)\n\n\nclass SISRepository(BaseRepository):\n    \"\"\"Repository for Student Information System operations.\"\"\"\n\n    def __init__(self, base_url: str, timeout: float = 30.0):\n        \"\"\"Initialize the SIS repository.\n\n        Args:\n            base_url: Base URL for the SIS API\n            timeout: Request timeout in seconds\n        \"\"\"\n        self.base_url = base_url.rstrip(\"/\")\n        self.timeout = timeout\n        self._client: Optional[httpx.AsyncClient] = None\n\n    async def _get_client(self) -> httpx.AsyncClient:\n        \"\"\"Get or create the HTTP client.\"\"\"\n        if self._client is None or self._client.is_closed:\n            self._client = httpx.AsyncClient(\n                base_url=self.base_url,\n                timeout=self.timeout,\n            )\n        return self._client\n\n    async def close(self) -> None:\n        \"\"\"Close the HTTP client.\"\"\"\n        if self._client and not self._client.is_closed:\n            await self._client.aclose()\n\n    async def get_student(self, student_id: str) -> Dict[str, Any]:\n        \"\"\"Fetch a student by ID from SIS.\n\n        Args:\n            student_id: The student's unique identifier\n\n        Returns:\n            Student data dictionary\n\n        Raises:\n            NotFoundException: If student not found\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.get(f\"/students/{student_id}\")\n            if response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n        except httpx.RequestError as e:\n            raise ExternalServiceException(f\"SIS connection error: {str(e)}\")\n\n    async def get_students_by_ids(self, student_ids: List[str]) -> Dict[str, Optional[Dict[str, Any]]]:\n        \"\"\"Fetch multiple students by IDs from SIS in batch.\n\n        This method validates multiple students efficiently by making\n        individual requests but returning a consolidated result.\n        In a real implementation, this could use a batch API endpoint.\n\n        Args:\n            student_ids: List of student unique identifiers\n\n        Returns:\n            Dictionary mapping student_id to student data (or None if not found)\n\n        Raises:\n            ExternalServiceException: If SIS request fails unexpectedly\n        \"\"\"\n        results: Dict[str, Optional[Dict[str, Any]]] = {}\n        \n        for student_id in student_ids:\n            try:\n                student_data = await self.get_student(student_id)\n                results[student_id] = student_data\n            except NotFoundException:\n                results[student_id] = None\n            except ExternalServiceException:\n                # For connection errors, mark as None but could also re-raise\n                results[student_id] = None\n        \n        return results\n\n    async def list_students(\n        self, skip: int = 0, limit: int = 100\n    ) -> Dict[str, Any]:\n        \"\"\"List students from SIS with pagination.\n\n        Args:\n            skip: Number of records to skip\n            limit: Maximum number of records to return\n\n        Returns:\n            Paginated student list\n\n        Raises:\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.get(\n                \"/students\",\n                params={\"skip\": skip, \"limit\": limit},\n            )\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPError as e:\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n\n    async def create_student(self, student_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a new student in SIS.\n\n        Args:\n            student_data: Student information\n\n        Returns:\n            Created student data\n\n        Raises:\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.post(\"/students\", json=student_data)\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPError as e:\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n\n    async def update_student(\n        self, student_id: str, student_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Update a student in SIS.\n\n        Args:\n            student_id: The student's unique identifier\n            student_data: Updated student information\n\n        Returns:\n            Updated student data\n\n        Raises:\n            NotFoundException: If student not found\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.put(\n                f\"/students/{student_id}\",\n                json=student_data,\n            )\n            if response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n        except httpx.RequestError as e:\n            raise ExternalServiceException(f\"SIS connection error: {str(e)}\")\n\n    async def delete_student(self, student_id: str) -> None:\n        \"\"\"Delete a student from SIS.\n\n        Args:\n            student_id: The student's unique identifier\n\n        Raises:\n            NotFoundException: If student not found\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.delete(f\"/students/{student_id}\")\n            if response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            response.raise_for_status()\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n        except httpx.RequestError as e:\n            raise ExternalServiceException(f\"SIS connection error: {str(e)}\")\n",
          "edubridge-gateway/edubridge_gateway/services/course_service.py": "\"\"\"Course Service.\n\nThis module provides the business logic layer for course operations,\norchestrating between the LMS repository and other services.\n\"\"\"\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom edubridge_gateway.repositories.lms_repository import LMSRepository\nfrom edubridge_gateway.repositories.sis_repository import SISRepository\nfrom edubridge_gateway.core.exceptions import (\n    NotFoundException,\n    ValidationException,\n    ExternalServiceException,\n)\n\n\nclass BulkEnrollmentResult:\n    \"\"\"Result container for bulk enrollment operations.\"\"\"\n    \n    def __init__(self):\n        self.successful: List[Dict[str, str]] = []\n        self.failed: List[Dict[str, str]] = []\n    \n    def add_success(self, student_id: str) -> None:\n        \"\"\"Record a successful enrollment.\"\"\"\n        self.successful.append({\n            \"student_id\": student_id,\n            \"status\": \"success\"\n        })\n    \n    def add_failure(self, student_id: str, reason: str) -> None:\n        \"\"\"Record a failed enrollment.\"\"\"\n        self.failed.append({\n            \"student_id\": student_id,\n            \"status\": \"failed\",\n            \"reason\": reason\n        })\n\n\nclass CourseService:\n    \"\"\"Service for course-related business operations.\"\"\"\n\n    def __init__(\n        self,\n        lms_repository: LMSRepository,\n        sis_repository: Optional[SISRepository] = None,\n    ):\n        \"\"\"Initialize the course service.\n\n        Args:\n            lms_repository: Repository for LMS operations\n            sis_repository: Repository for SIS operations (for student validation)\n        \"\"\"\n        self.lms_repository = lms_repository\n        self.sis_repository = sis_repository\n\n    async def get_course(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get a course by ID.\n\n        Args:\n            course_id: The course's unique identifier\n\n        Returns:\n            Course data dictionary\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        return await self.lms_repository.get_course(course_id)\n\n    async def list_courses(\n        self, skip: int = 0, limit: int = 100\n    ) -> Dict[str, Any]:\n        \"\"\"List courses with pagination.\n\n        Args:\n            skip: Number of records to skip\n            limit: Maximum number of records to return\n\n        Returns:\n            Paginated course list\n        \"\"\"\n        return await self.lms_repository.list_courses(skip=skip, limit=limit)\n\n    async def create_course(self, course_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a new course.\n\n        Args:\n            course_data: Course information\n\n        Returns:\n            Created course data\n        \"\"\"\n        return await self.lms_repository.create_course(course_data)\n\n    async def update_course(\n        self, course_id: str, course_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Update a course.\n\n        Args:\n            course_id: The course's unique identifier\n            course_data: Updated course information\n\n        Returns:\n            Updated course data\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        return await self.lms_repository.update_course(course_id, course_data)\n\n    async def delete_course(self, course_id: str) -> None:\n        \"\"\"Delete a course.\n\n        Args:\n            course_id: The course's unique identifier\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        await self.lms_repository.delete_course(course_id)\n\n    async def enroll_student(\n        self, course_id: str, student_id: str\n    ) -> Dict[str, Any]:\n        \"\"\"Enroll a student in a course.\n\n        Args:\n            course_id: The course's unique identifier\n            student_id: The student's unique identifier\n\n        Returns:\n            Enrollment data\n\n        Raises:\n            NotFoundException: If course or student not found\n            ValidationException: If enrollment fails validation\n        \"\"\"\n        return await self.lms_repository.enroll_student(course_id, student_id)\n\n    async def bulk_enroll_students(\n        self, course_id: str, student_ids: List[str]\n    ) -> BulkEnrollmentResult:\n        \"\"\"Enroll multiple students in a course with partial success handling.\n\n        This method validates all students first via the SIS repository,\n        then attempts to enroll each valid student in the LMS.\n        Individual failures do not affect other enrollments.\n\n        Args:\n            course_id: The course's unique identifier\n            student_ids: List of student unique identifiers\n\n        Returns:\n            BulkEnrollmentResult containing successful and failed enrollments\n\n        Raises:\n            NotFoundException: If the course itself is not found\n        \"\"\"\n        result = BulkEnrollmentResult()\n        \n        # Handle empty list case\n        if not student_ids:\n            return result\n        \n        # First, verify the course exists\n        try:\n            await self.lms_repository.get_course(course_id)\n        except NotFoundException:\n            raise NotFoundException(f\"Course {course_id} not found\")\n        \n        # Batch validate students via SIS if repository is available\n        valid_students: Dict[str, bool] = {}\n        \n        if self.sis_repository:\n            try:\n                students_data = await self.sis_repository.get_students_by_ids(student_ids)\n                for student_id in student_ids:\n                    valid_students[student_id] = students_data.get(student_id) is not None\n            except ExternalServiceException as e:\n                # If SIS is unavailable, mark all as validation failed\n                for student_id in student_ids:\n                    result.add_failure(student_id, f\"Student validation service unavailable: {str(e)}\")\n                return result\n        else:\n            # If no SIS repository, assume all students are valid\n            # (let LMS handle validation)\n            for student_id in student_ids:\n                valid_students[student_id] = True\n        \n        # Process each student\n        for student_id in student_ids:\n            # Check if student was validated\n            if not valid_students.get(student_id, False):\n                result.add_failure(student_id, \"Student not found\")\n                continue\n            \n            # Attempt enrollment in LMS\n            try:\n                await self.lms_repository.enroll_student(course_id, student_id)\n                result.add_success(student_id)\n            except NotFoundException as e:\n                result.add_failure(student_id, str(e))\n            except ValidationException as e:\n                result.add_failure(student_id, str(e))\n            except ExternalServiceException as e:\n                result.add_failure(student_id, f\"LMS error: {str(e)}\")\n            except Exception as e:\n                result.add_failure(student_id, f\"Unexpected error: {str(e)}\")\n        \n        return result\n\n    async def get_course_enrollments(self, course_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all enrollments for a course.\n\n        Args:\n            course_id: The course's unique identifier\n\n        Returns:\n            List of enrollment data\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        return await self.lms_repository.get_course_enrollments(course_id)\n\n    async def unenroll_student(self, course_id: str, student_id: str) -> None:\n        \"\"\"Remove a student from a course.\n\n        Args:\n            course_id: The course's unique identifier\n            student_id: The student's unique identifier\n\n        Raises:\n            NotFoundException: If enrollment not found\n        \"\"\"\n        await self.lms_repository.unenroll_student(course_id, student_id)\n",
          "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py": "\"\"\"Course API Endpoints.\n\nThis module provides REST API endpoints for course operations.\n\"\"\"\nfrom typing import List\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\n\nfrom edubridge_gateway.api.schemas.course import (\n    CourseCreate,\n    CourseUpdate,\n    CourseResponse,\n    CourseListResponse,\n    EnrollmentCreate,\n    EnrollmentResponse,\n)\nfrom edubridge_gateway.api.schemas.enrollment import (\n    BulkEnrollmentRequest,\n    BulkEnrollmentResponse,\n    SuccessfulEnrollment,\n    FailedEnrollment,\n)\nfrom edubridge_gateway.services.course_service import CourseService\nfrom edubridge_gateway.core.exceptions import NotFoundException, ValidationException\nfrom edubridge_gateway.core.kernel import get_kernel\n\nrouter = APIRouter(prefix=\"/courses\", tags=[\"courses\"])\n\n\nasync def get_course_service() -> CourseService:\n    \"\"\"Dependency to get the course service.\"\"\"\n    kernel = get_kernel()\n    return kernel.get_service(\"course_service\")\n\n\n@router.get(\"\", response_model=CourseListResponse)\nasync def list_courses(\n    skip: int = 0,\n    limit: int = 100,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"List all courses with pagination.\"\"\"\n    result = await service.list_courses(skip=skip, limit=limit)\n    return result\n\n\n@router.post(\"\", response_model=CourseResponse, status_code=status.HTTP_201_CREATED)\nasync def create_course(\n    course: CourseCreate,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Create a new course.\"\"\"\n    result = await service.create_course(course.model_dump())\n    return result\n\n\n@router.get(\"/{course_id}\", response_model=CourseResponse)\nasync def get_course(\n    course_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Get a course by ID.\"\"\"\n    try:\n        result = await service.get_course(course_id)\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.put(\"/{course_id}\", response_model=CourseResponse)\nasync def update_course(\n    course_id: str,\n    course: CourseUpdate,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Update a course.\"\"\"\n    try:\n        result = await service.update_course(\n            course_id, course.model_dump(exclude_unset=True)\n        )\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.delete(\"/{course_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_course(\n    course_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Delete a course.\"\"\"\n    try:\n        await service.delete_course(course_id)\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.post(\n    \"/{course_id}/enrollments\",\n    response_model=EnrollmentResponse,\n    status_code=status.HTTP_201_CREATED,\n)\nasync def enroll_student(\n    course_id: str,\n    enrollment: EnrollmentCreate,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Enroll a student in a course.\"\"\"\n    try:\n        result = await service.enroll_student(course_id, enrollment.student_id)\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n    except ValidationException as e:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))\n\n\n@router.post(\n    \"/{course_id}/enrollments/bulk\",\n    response_model=BulkEnrollmentResponse,\n    status_code=status.HTTP_207_MULTI_STATUS,\n    responses={\n        207: {\n            \"description\": \"Multi-Status response with individual enrollment results\",\n            \"model\": BulkEnrollmentResponse,\n        },\n        404: {\"description\": \"Course not found\"},\n    },\n)\nasync def bulk_enroll_students(\n    course_id: str,\n    request: BulkEnrollmentRequest,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Bulk enroll multiple students in a course.\n    \n    This endpoint processes all enrollment requests and returns a detailed\n    report of which enrollments succeeded and which failed. The operation\n    uses partial success handling - individual failures do not affect\n    other enrollments in the batch.\n    \n    Returns HTTP 207 Multi-Status with a breakdown of results.\n    \"\"\"\n    try:\n        result = await service.bulk_enroll_students(course_id, request.student_ids)\n        \n        response_data = BulkEnrollmentResponse(\n            successful_enrollments=[\n                SuccessfulEnrollment(student_id=s[\"student_id\"])\n                for s in result.successful\n            ],\n            failed_enrollments=[\n                FailedEnrollment(student_id=f[\"student_id\"], reason=f[\"reason\"])\n                for f in result.failed\n            ],\n        )\n        \n        return JSONResponse(\n            status_code=status.HTTP_207_MULTI_STATUS,\n            content=response_data.model_dump(),\n        )\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.get(\"/{course_id}/enrollments\", response_model=List[EnrollmentResponse])\nasync def get_course_enrollments(\n    course_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Get all enrollments for a course.\"\"\"\n    try:\n        result = await service.get_course_enrollments(course_id)\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.delete(\n    \"/{course_id}/enrollments/{student_id}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n)\nasync def unenroll_student(\n    course_id: str,\n    student_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Remove a student from a course.\"\"\"\n    try:\n        await service.unenroll_student(course_id, student_id)\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n",
          "edubridge-gateway/tests/integration/test_rest_api.py": "\"\"\"Integration tests for REST API endpoints.\"\"\"\nimport pytest\nfrom httpx import AsyncClient, ASGITransport\nfrom unittest.mock import AsyncMock, MagicMock, patch\nimport uuid\n\nfrom edubridge_gateway.main import app\nfrom edubridge_gateway.core.kernel import Kernel, get_kernel, set_kernel\nfrom edubridge_gateway.services.course_service import CourseService, BulkEnrollmentResult\nfrom edubridge_gateway.services.student_service import StudentService\nfrom edubridge_gateway.core.exceptions import NotFoundException, ValidationException\n\n\n@pytest.fixture\ndef mock_kernel():\n    \"\"\"Create a mock kernel with mock services.\"\"\"\n    kernel = MagicMock(spec=Kernel)\n    \n    # Mock course service\n    mock_course_service = AsyncMock(spec=CourseService)\n    mock_student_service = AsyncMock(spec=StudentService)\n    \n    def get_service(name):\n        if name == \"course_service\":\n            return mock_course_service\n        elif name == \"student_service\":\n            return mock_student_service\n        return None\n    \n    kernel.get_service = get_service\n    return kernel, mock_course_service, mock_student_service\n\n\n@pytest.fixture\nasync def client(mock_kernel):\n    \"\"\"Create test client with mocked kernel.\"\"\"\n    kernel, _, _ = mock_kernel\n    set_kernel(kernel)\n    \n    transport = ASGITransport(app=app)\n    async with AsyncClient(transport=transport, base_url=\"http://test\") as ac:\n        yield ac\n\n\nclass TestCourseEndpoints:\n    \"\"\"Tests for course-related endpoints.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_list_courses(self, client, mock_kernel):\n        \"\"\"Test listing courses.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        mock_course_service.list_courses.return_value = {\n            \"items\": [{\"id\": \"course-1\", \"name\": \"Test Course\"}],\n            \"total\": 1,\n            \"skip\": 0,\n            \"limit\": 100,\n        }\n        \n        response = await client.get(\"/api/v1/courses\")\n        assert response.status_code == 200\n        data = response.json()\n        assert \"items\" in data\n\n    @pytest.mark.asyncio\n    async def test_get_course(self, client, mock_kernel):\n        \"\"\"Test getting a single course.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        mock_course_service.get_course.return_value = {\n            \"id\": course_id,\n            \"name\": \"Test Course\",\n            \"description\": \"A test course\",\n        }\n        \n        response = await client.get(f\"/api/v1/courses/{course_id}\")\n        assert response.status_code == 200\n        data = response.json()\n        assert data[\"id\"] == course_id\n\n    @pytest.mark.asyncio\n    async def test_get_course_not_found(self, client, mock_kernel):\n        \"\"\"Test getting a non-existent course.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        mock_course_service.get_course.side_effect = NotFoundException(\"Course not found\")\n        \n        response = await client.get(f\"/api/v1/courses/{course_id}\")\n        assert response.status_code == 404\n\n\nclass TestBulkEnrollmentEndpoint:\n    \"\"\"Tests for the bulk enrollment endpoint.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_successful(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment where all enrollments succeed.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(3)]\n        \n        # Create a result with all successes\n        result = BulkEnrollmentResult()\n        for sid in student_ids:\n            result.add_success(sid)\n        \n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 3\n        assert len(data[\"failed_enrollments\"]) == 0\n        for enrollment in data[\"successful_enrollments\"]:\n            assert enrollment[\"status\"] == \"success\"\n            assert enrollment[\"student_id\"] in student_ids\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_mixed_results(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment with mix of successes and failures.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        valid_student = str(uuid.uuid4())\n        invalid_student = str(uuid.uuid4())\n        student_ids = [valid_student, invalid_student]\n        \n        # Create a result with mixed outcomes\n        result = BulkEnrollmentResult()\n        result.add_success(valid_student)\n        result.add_failure(invalid_student, \"Student not found\")\n        \n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 1\n        assert len(data[\"failed_enrollments\"]) == 1\n        assert data[\"successful_enrollments\"][0][\"student_id\"] == valid_student\n        assert data[\"failed_enrollments\"][0][\"student_id\"] == invalid_student\n        assert data[\"failed_enrollments\"][0][\"reason\"] == \"Student not found\"\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_failed(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment where all enrollments fail.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(2)]\n        \n        # Create a result with all failures\n        result = BulkEnrollmentResult()\n        result.add_failure(student_ids[0], \"Student not found\")\n        result.add_failure(student_ids[1], \"LMS error: Connection timeout\")\n        \n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 0\n        assert len(data[\"failed_enrollments\"]) == 2\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_empty_list(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment with empty student list.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        \n        # Create an empty result\n        result = BulkEnrollmentResult()\n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": []}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 0\n        assert len(data[\"failed_enrollments\"]) == 0\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_course_not_found(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment when course doesn't exist.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4())]\n        \n        mock_course_service.bulk_enroll_students.side_effect = NotFoundException(\n            f\"Course {course_id} not found\"\n        )\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 404\n\n\nclass TestStudentEndpoints:\n    \"\"\"Tests for student-related endpoints.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_list_students(self, client, mock_kernel):\n        \"\"\"Test listing students.\"\"\"\n        _, _, mock_student_service = mock_kernel\n        mock_student_service.list_students.return_value = {\n            \"items\": [{\"id\": \"student-1\", \"name\": \"Test Student\"}],\n            \"total\": 1,\n            \"skip\": 0,\n            \"limit\": 100,\n        }\n        \n        response = await client.get(\"/api/v1/students\")\n        assert response.status_code == 200\n        data = response.json()\n        assert \"items\" in data\n",
          "edubridge-gateway/tests/unit/test_services.py": "\"\"\"Unit tests for service layer.\"\"\"\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock\nimport uuid\n\nfrom edubridge_gateway.services.course_service import CourseService, BulkEnrollmentResult\nfrom edubridge_gateway.services.student_service import StudentService\nfrom edubridge_gateway.repositories.lms_repository import LMSRepository\nfrom edubridge_gateway.repositories.sis_repository import SISRepository\nfrom edubridge_gateway.core.exceptions import (\n    NotFoundException,\n    ValidationException,\n    ExternalServiceException,\n)\n\n\nclass TestCourseService:\n    \"\"\"Tests for CourseService.\"\"\"\n\n    @pytest.fixture\n    def mock_lms_repository(self):\n        \"\"\"Create a mock LMS repository.\"\"\"\n        return AsyncMock(spec=LMSRepository)\n\n    @pytest.fixture\n    def mock_sis_repository(self):\n        \"\"\"Create a mock SIS repository.\"\"\"\n        return AsyncMock(spec=SISRepository)\n\n    @pytest.fixture\n    def course_service(self, mock_lms_repository, mock_sis_repository):\n        \"\"\"Create a CourseService with mocked dependencies.\"\"\"\n        return CourseService(\n            lms_repository=mock_lms_repository,\n            sis_repository=mock_sis_repository,\n        )\n\n    @pytest.mark.asyncio\n    async def test_get_course(self, course_service, mock_lms_repository):\n        \"\"\"Test getting a course.\"\"\"\n        course_id = str(uuid.uuid4())\n        expected_course = {\"id\": course_id, \"name\": \"Test Course\"}\n        mock_lms_repository.get_course.return_value = expected_course\n        \n        result = await course_service.get_course(course_id)\n        \n        assert result == expected_course\n        mock_lms_repository.get_course.assert_called_once_with(course_id)\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_successful(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment with all successful enrollments.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(3)]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock all students exist in SIS\n        mock_sis_repository.get_students_by_ids.return_value = {\n            sid: {\"id\": sid, \"name\": f\"Student {i}\"}\n            for i, sid in enumerate(student_ids)\n        }\n        \n        # Mock successful enrollments\n        mock_lms_repository.enroll_student.return_value = {\"status\": \"enrolled\"}\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 3\n        assert len(result.failed) == 0\n        assert all(s[\"status\"] == \"success\" for s in result.successful)\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_mixed_results(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment with mixed success and failure.\"\"\"\n        course_id = str(uuid.uuid4())\n        valid_student = str(uuid.uuid4())\n        invalid_student = str(uuid.uuid4())\n        student_ids = [valid_student, invalid_student]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock one student exists, one doesn't\n        mock_sis_repository.get_students_by_ids.return_value = {\n            valid_student: {\"id\": valid_student, \"name\": \"Valid Student\"},\n            invalid_student: None,  # Student not found\n        }\n        \n        # Mock successful enrollment for valid student\n        mock_lms_repository.enroll_student.return_value = {\"status\": \"enrolled\"}\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 1\n        assert len(result.failed) == 1\n        assert result.successful[0][\"student_id\"] == valid_student\n        assert result.failed[0][\"student_id\"] == invalid_student\n        assert \"not found\" in result.failed[0][\"reason\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_failed(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment where all enrollments fail.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(2)]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock no students found in SIS\n        mock_sis_repository.get_students_by_ids.return_value = {\n            sid: None for sid in student_ids\n        }\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 0\n        assert len(result.failed) == 2\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_empty_list(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment with empty student list.\"\"\"\n        course_id = str(uuid.uuid4())\n        \n        result = await course_service.bulk_enroll_students(course_id, [])\n        \n        assert len(result.successful) == 0\n        assert len(result.failed) == 0\n        # Should not call repositories for empty list\n        mock_lms_repository.get_course.assert_not_called()\n        mock_sis_repository.get_students_by_ids.assert_not_called()\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_course_not_found(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment when course doesn't exist.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4())]\n        \n        # Mock course not found\n        mock_lms_repository.get_course.side_effect = NotFoundException(\n            f\"Course {course_id} not found\"\n        )\n        \n        with pytest.raises(NotFoundException) as exc_info:\n            await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert course_id in str(exc_info.value)\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_lms_failure(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment when LMS fails for some students.\"\"\"\n        course_id = str(uuid.uuid4())\n        student1 = str(uuid.uuid4())\n        student2 = str(uuid.uuid4())\n        student_ids = [student1, student2]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock all students exist in SIS\n        mock_sis_repository.get_students_by_ids.return_value = {\n            student1: {\"id\": student1},\n            student2: {\"id\": student2},\n        }\n        \n        # Mock first enrollment succeeds, second fails\n        mock_lms_repository.enroll_student.side_effect = [\n            {\"status\": \"enrolled\"},\n            ExternalServiceException(\"LMS timeout\"),\n        ]\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 1\n        assert len(result.failed) == 1\n        assert result.successful[0][\"student_id\"] == student1\n        assert result.failed[0][\"student_id\"] == student2\n        assert \"LMS\" in result.failed[0][\"reason\"]\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_sis_unavailable(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment when SIS is unavailable.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4())]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock SIS unavailable\n        mock_sis_repository.get_students_by_ids.side_effect = ExternalServiceException(\n            \"SIS connection failed\"\n        )\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 0\n        assert len(result.failed) == 1\n        assert \"unavailable\" in result.failed[0][\"reason\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_without_sis_repository(\n        self, mock_lms_repository\n    ):\n        \"\"\"Test bulk enrollment when SIS repository is not configured.\"\"\"\n        # Create service without SIS repository\n        service = CourseService(\n            lms_repository=mock_lms_repository,\n            sis_repository=None,\n        )\n        \n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(2)]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock successful enrollments\n        mock_lms_repository.enroll_student.return_value = {\"status\": \"enrolled\"}\n        \n        result = await service.bulk_enroll_students(course_id, student_ids)\n        \n        # Should attempt all enrollments without SIS validation\n        assert len(result.successful) == 2\n        assert len(result.failed) == 0\n\n\nclass TestStudentService:\n    \"\"\"Tests for StudentService.\"\"\"\n\n    @pytest.fixture\n    def mock_sis_repository(self):\n        \"\"\"Create a mock SIS repository.\"\"\"\n        return AsyncMock(spec=SISRepository)\n\n    @pytest.fixture\n    def student_service(self, mock_sis_repository):\n        \"\"\"Create a StudentService with mocked dependencies.\"\"\"\n        return StudentService(sis_repository=mock_sis_repository)\n\n    @pytest.mark.asyncio\n    async def test_get_student(self, student_service, mock_sis_repository):\n        \"\"\"Test getting a student.\"\"\"\n        student_id = str(uuid.uuid4())\n        expected_student = {\"id\": student_id, \"name\": \"Test Student\"}\n        mock_sis_repository.get_student.return_value = expected_student\n        \n        result = await student_service.get_student(student_id)\n        \n        assert result == expected_student\n        mock_sis_repository.get_student.assert_called_once_with(student_id)\n\n\nclass TestBulkEnrollmentResult:\n    \"\"\"Tests for BulkEnrollmentResult helper class.\"\"\"\n\n    def test_add_success(self):\n        \"\"\"Test adding a successful enrollment.\"\"\"\n        result = BulkEnrollmentResult()\n        student_id = str(uuid.uuid4())\n        \n        result.add_success(student_id)\n        \n        assert len(result.successful) == 1\n        assert result.successful[0][\"student_id\"] == student_id\n        assert result.successful[0][\"status\"] == \"success\"\n\n    def test_add_failure(self):\n        \"\"\"Test adding a failed enrollment.\"\"\"\n        result = BulkEnrollmentResult()\n        student_id = str(uuid.uuid4())\n        reason = \"Student not found\"\n        \n        result.add_failure(student_id, reason)\n        \n        assert len(result.failed) == 1\n        assert result.failed[0][\"student_id\"] == student_id\n        assert result.failed[0][\"status\"] == \"failed\"\n        assert result.failed[0][\"reason\"] == reason\n\n    def test_multiple_results(self):\n        \"\"\"Test adding multiple results.\"\"\"\n        result = BulkEnrollmentResult()\n        \n        result.add_success(\"student-1\")\n        result.add_success(\"student-2\")\n        result.add_failure(\"student-3\", \"Not found\")\n        \n        assert len(result.successful) == 2\n        assert len(result.failed) == 1\n",
          "edubridge-gateway/docs/API_REFERENCE.md": "# EduBridge Gateway API Reference\n\nThis document provides a comprehensive reference for all API endpoints available in the EduBridge Gateway.\n\n## Base URL\n\nAll REST API endpoints are prefixed with `/api/v1`.\n\n## Authentication\n\nAll endpoints require authentication via Bearer token in the Authorization header:\n\n```\nAuthorization: Bearer <token>\n```\n\n## Endpoints\n\n### Courses\n\n#### List Courses\n\n```\nGET /api/v1/courses\n```\n\nReturns a paginated list of courses.\n\n**Query Parameters:**\n- `skip` (integer, optional): Number of records to skip. Default: 0\n- `limit` (integer, optional): Maximum number of records to return. Default: 100\n\n**Response:** `200 OK`\n```json\n{\n  \"items\": [\n    {\n      \"id\": \"uuid\",\n      \"name\": \"string\",\n      \"description\": \"string\"\n    }\n  ],\n  \"total\": 0,\n  \"skip\": 0,\n  \"limit\": 100\n}\n```\n\n#### Get Course\n\n```\nGET /api/v1/courses/{course_id}\n```\n\nReturns a single course by ID.\n\n**Response:** `200 OK`\n```json\n{\n  \"id\": \"uuid\",\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n#### Create Course\n\n```\nPOST /api/v1/courses\n```\n\nCreates a new course.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n**Response:** `201 Created`\n```json\n{\n  \"id\": \"uuid\",\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n#### Update Course\n\n```\nPUT /api/v1/courses/{course_id}\n```\n\nUpdates an existing course.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n**Response:** `200 OK`\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n#### Delete Course\n\n```\nDELETE /api/v1/courses/{course_id}\n```\n\nDeletes a course.\n\n**Response:** `204 No Content`\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n### Enrollments\n\n#### Enroll Student\n\n```\nPOST /api/v1/courses/{course_id}/enrollments\n```\n\nEnrolls a single student in a course.\n\n**Request Body:**\n```json\n{\n  \"student_id\": \"uuid\"\n}\n```\n\n**Response:** `201 Created`\n```json\n{\n  \"id\": \"uuid\",\n  \"course_id\": \"uuid\",\n  \"student_id\": \"uuid\",\n  \"enrolled_at\": \"datetime\"\n}\n```\n\n**Error Responses:**\n- `404 Not Found`: Course or student not found\n- `400 Bad Request`: Validation error\n\n#### Bulk Enroll Students\n\n```\nPOST /api/v1/courses/{course_id}/enrollments/bulk\n```\n\nEnrolls multiple students in a course with partial success handling. This endpoint processes all enrollment requests and returns a detailed report of which enrollments succeeded and which failed. Individual failures do not affect other enrollments in the batch.\n\n**Request Body:**\n```json\n{\n  \"student_ids\": [\"uuid-1\", \"uuid-2\", \"uuid-3\"]\n}\n```\n\n**Response:** `207 Multi-Status`\n\nThe response contains two arrays: one for successful enrollments and one for failed enrollments.\n\n```json\n{\n  \"successful_enrollments\": [\n    {\n      \"student_id\": \"uuid-1\",\n      \"status\": \"success\"\n    },\n    {\n      \"student_id\": \"uuid-2\",\n      \"status\": \"success\"\n    }\n  ],\n  \"failed_enrollments\": [\n    {\n      \"student_id\": \"uuid-3\",\n      \"status\": \"failed\",\n      \"reason\": \"Student not found\"\n    }\n  ]\n}\n```\n\n**Response Fields:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `successful_enrollments` | array | List of successfully enrolled students |\n| `successful_enrollments[].student_id` | string | The student's unique identifier |\n| `successful_enrollments[].status` | string | Always \"success\" for successful enrollments |\n| `failed_enrollments` | array | List of failed enrollment attempts |\n| `failed_enrollments[].student_id` | string | The student's unique identifier |\n| `failed_enrollments[].status` | string | Always \"failed\" for failed enrollments |\n| `failed_enrollments[].reason` | string | Human-readable explanation of why the enrollment failed |\n\n**Possible Failure Reasons:**\n- `Student not found`: The student ID does not exist in the Student Information System\n- `LMS error: <details>`: An error occurred when communicating with the Learning Management System\n- `Student validation service unavailable: <details>`: The SIS could not be reached to validate students\n\n**Error Responses:**\n- `404 Not Found`: The specified course does not exist\n\n**Example Request:**\n```bash\ncurl -X POST \"https://api.example.com/api/v1/courses/550e8400-e29b-41d4-a716-446655440000/enrollments/bulk\" \n  -H \"Authorization: Bearer <token>\" \n  -H \"Content-Type: application/json\" \n  -d '{\n    \"student_ids\": [\n      \"550e8400-e29b-41d4-a716-446655440001\",\n      \"550e8400-e29b-41d4-a716-446655440002\",\n      \"invalid-student-id\"\n    ]\n  }'\n```\n\n**Example Response:**\n```json\n{\n  \"successful_enrollments\": [\n    {\n      \"student_id\": \"550e8400-e29b-41d4-a716-446655440001\",\n      \"status\": \"success\"\n    },\n    {\n      \"student_id\": \"550e8400-e29b-41d4-a716-446655440002\",\n      \"status\": \"success\"\n    }\n  ],\n  \"failed_enrollments\": [\n    {\n      \"student_id\": \"invalid-student-id\",\n      \"status\": \"failed\",\n      \"reason\": \"Student not found\"\n    }\n  ]\n}\n```\n\n#### Get Course Enrollments\n\n```\nGET /api/v1/courses/{course_id}/enrollments\n```\n\nReturns all enrollments for a course.\n\n**Response:** `200 OK`\n```json\n[\n  {\n    \"id\": \"uuid\",\n    \"course_id\": \"uuid\",\n    \"student_id\": \"uuid\",\n    \"enrolled_at\": \"datetime\"\n  }\n]\n```\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n#### Unenroll Student\n\n```\nDELETE /api/v1/courses/{course_id}/enrollments/{student_id}\n```\n\nRemoves a student from a course.\n\n**Response:** `204 No Content`\n\n**Error Responses:**\n- `404 Not Found`: Enrollment not found\n\n### Students\n\n#### List Students\n\n```\nGET /api/v1/students\n```\n\nReturns a paginated list of students.\n\n**Query Parameters:**\n- `skip` (integer, optional): Number of records to skip. Default: 0\n- `limit` (integer, optional): Maximum number of records to return. Default: 100\n\n**Response:** `200 OK`\n```json\n{\n  \"items\": [\n    {\n      \"id\": \"uuid\",\n      \"name\": \"string\",\n      \"email\": \"string\"\n    }\n  ],\n  \"total\": 0,\n  \"skip\": 0,\n  \"limit\": 100\n}\n```\n\n#### Get Student\n\n```\nGET /api/v1/students/{student_id}\n```\n\nReturns a single student by ID.\n\n**Response:** `200 OK`\n```json\n{\n  \"id\": \"uuid\",\n  \"name\": \"string\",\n  \"email\": \"string\"\n}\n```\n\n**Error Responses:**\n- `404 Not Found`: Student not found\n\n#### Create Student\n\n```\nPOST /api/v1/students\n```\n\nCreates a new student.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"email\": \"string\"\n}\n```\n\n**Response:** `201 Created`\n\n#### Update Student\n\n```\nPUT /api/v1/students/{student_id}\n```\n\nUpdates an existing student.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"email\": \"string\"\n}\n```\n\n**Response:** `200 OK`\n\n**Error Responses:**\n- `404 Not Found`: Student not found\n\n#### Delete Student\n\n```\nDELETE /api/v1/students/{student_id}\n```\n\nDeletes a student.\n\n**Response:** `204 No Content`\n\n**Error Responses:**\n- `404 Not Found`: Student not found\n\n## HTTP Status Codes\n\n| Code | Description |\n|------|-------------|\n| 200 | OK - Request succeeded |\n| 201 | Created - Resource created successfully |\n| 204 | No Content - Request succeeded with no response body |\n| 207 | Multi-Status - Partial success (used for bulk operations) |\n| 400 | Bad Request - Invalid request data |\n| 401 | Unauthorized - Authentication required |\n| 403 | Forbidden - Insufficient permissions |\n| 404 | Not Found - Resource not found |\n| 500 | Internal Server Error - Server error |\n\n## Error Response Format\n\nAll error responses follow this format:\n\n```json\n{\n  \"detail\": \"Error message describing what went wrong\"\n}\n```\n"
        },
        "generated_files": [
          "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py",
          "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py",
          "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py",
          "edubridge-gateway/edubridge_gateway/services/course_service.py",
          "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py",
          "edubridge-gateway/tests/integration/test_rest_api.py",
          "edubridge-gateway/tests/unit/test_services.py",
          "edubridge-gateway/docs/API_REFERENCE.md"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8502729885057472,
              "dependency_traversal_accuracy": 0.700855319217653,
              "cross_file_reasoning_depth": 0.38145833333333334,
              "system_thinking_score": 0.4934944682431883,
              "robustness_score": 0.43732978093546476,
              "comprehensiveness_score": 0.5827252812314979,
              "innovation_score": 0.54375,
              "solution_elegance_score": 0.4841619550410401
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.1062841235632184,
              "dependency_traversal_weighted": 0.08760691490220662,
              "cross_file_reasoning_weighted": 0.04768229166666667,
              "system_thinking_weighted": 0.06168680853039854,
              "robustness_weighted": 0.054666222616933095,
              "comprehensiveness_weighted": 0.07284066015393724,
              "innovation_weighted": 0.06796875,
              "solution_elegance_weighted": 0.06052024438013001
            },
            "total_software_engineering_score": 0.5592560158134906
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.5650472640991211,
              "errors": [
                "  File \"edubridge-gateway/docs/API_REFERENCE.py\", line 205",
                "    | `successful_enrollments[].student_id` | string | The student's unique identifier |",
                "                                                                  ^",
                "SyntaxError: unterminated string literal (detected at line 205)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py",
                "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py",
                "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py",
                "edubridge-gateway/edubridge_gateway/services/course_service.py",
                "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py",
                "edubridge-gateway/tests/integration/test_rest_api.py",
                "edubridge-gateway/tests/unit/test_services.py",
                "edubridge-gateway/docs/API_REFERENCE.md"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 8,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 8 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.3501167531504818,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.3501167531504818,
              "idc_weight": 0.2,
              "total_functional_score": 0.4100233506300964
            }
          },
          "code_quality_details": {
            "files_analyzed": 8,
            "quality_checks": {
              "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py": {
                "line_count": 59,
                "non_empty_lines": 47,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 6,
                "import_count": 6,
                "quality_score": 0.7
              },
              "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py": {
                "line_count": 44,
                "non_empty_lines": 42,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 8,
                "quality_score": 0.5
              },
              "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py": {
                "line_count": 201,
                "non_empty_lines": 167,
                "comment_lines": 1,
                "comment_ratio": 0.005988023952095809,
                "function_count": 9,
                "class_count": 1,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "edubridge-gateway/edubridge_gateway/services/course_service.py": {
                "line_count": 238,
                "non_empty_lines": 187,
                "comment_lines": 9,
                "comment_ratio": 0.0481283422459893,
                "function_count": 13,
                "class_count": 2,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py": {
                "line_count": 193,
                "non_empty_lines": 165,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 10,
                "class_count": 0,
                "import_count": 17,
                "quality_score": 0.7999999999999999
              },
              "edubridge-gateway/tests/integration/test_rest_api.py": {
                "line_count": 231,
                "non_empty_lines": 184,
                "comment_lines": 5,
                "comment_ratio": 0.02717391304347826,
                "function_count": 12,
                "class_count": 3,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "edubridge-gateway/tests/unit/test_services.py": {
                "line_count": 305,
                "non_empty_lines": 236,
                "comment_lines": 19,
                "comment_ratio": 0.08050847457627118,
                "function_count": 18,
                "class_count": 3,
                "import_count": 14,
                "quality_score": 0.7999999999999999
              },
              "edubridge-gateway/docs/API_REFERENCE.md": {
                "line_count": 418,
                "non_empty_lines": 321,
                "comment_lines": 23,
                "comment_ratio": 0.07165109034267912,
                "function_count": 0,
                "class_count": 0,
                "import_count": 1,
                "quality_score": 0.7
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7562499999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.9046052631578945,
              "multi_session_memory_retention": 0.8504385964912279
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.45230263157894723,
              "multi_session_memory_retention_weighted": 0.42521929824561394
            },
            "total_longcontext_utilization_score": 0.8775219298245611
          }
        },
        "timestamp": "2026-01-14T21:35:15.191886"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_ml_nlp_easy_089_feature_implementation_expert_01",
        "scenario_title": "Implement Topic Modeling Strategy with Coherence-Based Evaluation and Visualization",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.48468632919184707,
        "functional_correctness_score": 0.37104195804195805,
        "code_quality_score": 0.7407692307692306,
        "longcontext_utilization_score": 0.8070471256684492,
        "total_score": 2.6702283890500866,
        "generation_time": 107.1990556716919,
        "code_files_generated": 13,
        "total_lines_generated": 1062,
        "parsing_success": true,
        "solution_code": {
          "lexilearn_lab/strategies/topic_modeling_strategy.py": "\"\"\"Topic Modeling Strategy using NMF.\"\"\"\n\nfrom typing import Any, Dict, Optional\nimport numpy as np\nfrom sklearn.decomposition import NMF\n\nfrom .base_strategy import BaseStrategy\nfrom ..components.feature_engineering import create_count_vectorizer_pipeline\nfrom ..visualization import plot_top_words_per_topic\n\n\nclass TopicModelingStrategy(BaseStrategy):\n    \"\"\"Strategy for topic modeling using Non-negative Matrix Factorization (NMF).\"\"\"\n    \n    def __init__(self, n_topics: int = 5, max_features: int = 1000, \n                 n_top_words: int = 10, random_state: int = 42):\n        \"\"\"Initialize the Topic Modeling Strategy.\n        \n        Args:\n            n_topics: Number of topics to extract.\n            max_features: Maximum number of features for vectorizer.\n            n_top_words: Number of top words to display per topic.\n            random_state: Random state for reproducibility.\n        \"\"\"\n        super().__init__()\n        self.n_topics = n_topics\n        self.max_features = max_features\n        self.n_top_words = n_top_words\n        self.random_state = random_state\n        self.vectorizer = None\n        self.feature_names = None\n        self.document_topic_matrix = None\n        \n    def _create_model(self) -> NMF:\n        \"\"\"Create and return an NMF model.\n        \n        Returns:\n            NMF model instance.\n        \"\"\"\n        return NMF(\n            n_components=self.n_topics,\n            random_state=self.random_state,\n            max_iter=200,\n            init='nndsvd'\n        )\n    \n    def _get_evaluation_metrics(self) -> Dict[str, float]:\n        \"\"\"Get evaluation metrics for the topic model.\n        \n        Returns:\n            Dictionary containing reconstruction error as coherence proxy.\n        \"\"\"\n        if self.model is None:\n            return {'reconstruction_error': float('inf')}\n        \n        return {\n            'reconstruction_error': self.model.reconstruction_err_\n        }\n    \n    def preprocess(self, documents: list) -> np.ndarray:\n        \"\"\"Preprocess documents using count vectorization.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Document-term matrix.\n        \"\"\"\n        self.vectorizer = create_count_vectorizer_pipeline(\n            max_features=self.max_features\n        )\n        document_term_matrix = self.vectorizer.fit_transform(documents)\n        self.feature_names = self.vectorizer.get_feature_names_out()\n        return document_term_matrix\n    \n    def train(self, documents: list) -> 'TopicModelingStrategy':\n        \"\"\"Train the topic model on the given documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        # Preprocess documents\n        document_term_matrix = self.preprocess(documents)\n        \n        # Create and fit the model\n        self.model = self._create_model()\n        self.document_topic_matrix = self.model.fit_transform(document_term_matrix)\n        \n        return self\n    \n    def predict(self, documents: list) -> np.ndarray:\n        \"\"\"Predict topic distributions for new documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Document-topic matrix.\n        \"\"\"\n        if self.model is None or self.vectorizer is None:\n            raise ValueError(\"Model must be trained before prediction.\")\n        \n        document_term_matrix = self.vectorizer.transform(documents)\n        return self.model.transform(document_term_matrix)\n    \n    def evaluate(self, documents: Optional[list] = None, \n                 output_path: str = 'topic_visualization.png') -> Dict[str, Any]:\n        \"\"\"Evaluate the topic model and generate visualization.\n        \n        Args:\n            documents: Optional list of documents (not used for NMF evaluation).\n            output_path: Path to save the visualization.\n            \n        Returns:\n            Dictionary containing evaluation metrics and topic information.\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"Model must be trained before evaluation.\")\n        \n        # Get evaluation metrics\n        metrics = self._get_evaluation_metrics()\n        \n        # Generate visualization\n        plot_top_words_per_topic(\n            model=self.model,\n            feature_names=self.feature_names,\n            n_top_words=self.n_top_words,\n            output_path=output_path\n        )\n        \n        # Get top words for each topic\n        topics = self.get_topics()\n        \n        return {\n            'metrics': metrics,\n            'topics': topics,\n            'visualization_path': output_path\n        }\n    \n    def get_topics(self) -> Dict[int, list]:\n        \"\"\"Get the top words for each topic.\n        \n        Returns:\n            Dictionary mapping topic index to list of top words.\n        \"\"\"\n        if self.model is None or self.feature_names is None:\n            raise ValueError(\"Model must be trained first.\")\n        \n        topics = {}\n        for topic_idx, topic in enumerate(self.model.components_):\n            top_word_indices = topic.argsort()[:-self.n_top_words - 1:-1]\n            top_words = [self.feature_names[i] for i in top_word_indices]\n            topics[topic_idx] = top_words\n        \n        return topics\n    \n    def get_document_topics(self) -> np.ndarray:\n        \"\"\"Get the topic distribution for each document.\n        \n        Returns:\n            Document-topic matrix.\n        \"\"\"\n        if self.document_topic_matrix is None:\n            raise ValueError(\"Model must be trained first.\")\n        \n        return self.document_topic_matrix\n    \n    def get_dominant_topic(self, documents: Optional[list] = None) -> np.ndarray:\n        \"\"\"Get the dominant topic for each document.\n        \n        Args:\n            documents: Optional list of new documents. If None, uses training documents.\n            \n        Returns:\n            Array of dominant topic indices.\n        \"\"\"\n        if documents is not None:\n            topic_matrix = self.predict(documents)\n        else:\n            if self.document_topic_matrix is None:\n                raise ValueError(\"Model must be trained first.\")\n            topic_matrix = self.document_topic_matrix\n        \n        return np.argmax(topic_matrix, axis=1)\n",
          "lexilearn_lab/components/feature_engineering.py": "\"\"\"Feature engineering components for text processing.\"\"\"\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom typing import Optional\n\n\ndef create_tfidf_pipeline(max_features: int = 5000, \n                          ngram_range: tuple = (1, 2),\n                          min_df: int = 2,\n                          max_df: float = 0.95) -> TfidfVectorizer:\n    \"\"\"Create a TF-IDF vectorizer pipeline.\n    \n    Args:\n        max_features: Maximum number of features.\n        ngram_range: Range of n-grams to extract.\n        min_df: Minimum document frequency.\n        max_df: Maximum document frequency.\n        \n    Returns:\n        Configured TfidfVectorizer.\n    \"\"\"\n    return TfidfVectorizer(\n        max_features=max_features,\n        ngram_range=ngram_range,\n        min_df=min_df,\n        max_df=max_df,\n        stop_words='english',\n        lowercase=True,\n        strip_accents='unicode'\n    )\n\n\ndef create_count_vectorizer_pipeline(max_features: int = 1000,\n                                     ngram_range: tuple = (1, 1),\n                                     min_df: int = 2,\n                                     max_df: float = 0.95,\n                                     stop_words: Optional[str] = 'english') -> CountVectorizer:\n    \"\"\"Create a Count vectorizer pipeline suitable for topic modeling.\n    \n    Count vectorization is preferred for topic modeling algorithms like NMF\n    as they work better with raw term frequencies rather than TF-IDF weights.\n    \n    Args:\n        max_features: Maximum number of features to extract.\n        ngram_range: Range of n-grams to extract (default unigrams only).\n        min_df: Minimum document frequency for a term to be included.\n        max_df: Maximum document frequency for a term to be included.\n        stop_words: Stop words to remove (default 'english').\n        \n    Returns:\n        Configured CountVectorizer.\n    \"\"\"\n    return CountVectorizer(\n        max_features=max_features,\n        ngram_range=ngram_range,\n        min_df=min_df,\n        max_df=max_df,\n        stop_words=stop_words,\n        lowercase=True,\n        strip_accents='unicode'\n    )\n\n\ndef create_normalized_tfidf_pipeline(max_features: int = 5000,\n                                     ngram_range: tuple = (1, 2)) -> Pipeline:\n    \"\"\"Create a TF-IDF pipeline with L2 normalization.\n    \n    Args:\n        max_features: Maximum number of features.\n        ngram_range: Range of n-grams to extract.\n        \n    Returns:\n        Pipeline with TF-IDF and normalization.\n    \"\"\"\n    return Pipeline([\n        ('tfidf', TfidfVectorizer(\n            max_features=max_features,\n            ngram_range=ngram_range,\n            stop_words='english'\n        )),\n        ('normalizer', Normalizer(norm='l2'))\n    ])\n",
          "lexilearn_lab/visualization.py": "\"\"\"Visualization components for LexiLearn Lab.\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom typing import List, Optional, Any\nimport os\n\n\ndef plot_sentiment_distribution(sentiments: List[str], \n                                output_path: str = 'sentiment_distribution.png') -> None:\n    \"\"\"Plot the distribution of sentiments.\n    \n    Args:\n        sentiments: List of sentiment labels.\n        output_path: Path to save the plot.\n    \"\"\"\n    unique, counts = np.unique(sentiments, return_counts=True)\n    \n    plt.figure(figsize=(10, 6))\n    plt.bar(unique, counts, color=['red', 'gray', 'green'])\n    plt.xlabel('Sentiment')\n    plt.ylabel('Count')\n    plt.title('Sentiment Distribution')\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n\n\ndef plot_confusion_matrix(cm: np.ndarray, \n                          labels: List[str],\n                          output_path: str = 'confusion_matrix.png') -> None:\n    \"\"\"Plot a confusion matrix.\n    \n    Args:\n        cm: Confusion matrix array.\n        labels: Class labels.\n        output_path: Path to save the plot.\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    \n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=45)\n    plt.yticks(tick_marks, labels)\n    \n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n\n\ndef plot_top_words_per_topic(model: Any,\n                             feature_names: np.ndarray,\n                             n_top_words: int = 10,\n                             output_path: str = 'topic_visualization.png') -> None:\n    \"\"\"Plot the top words for each topic as horizontal bar charts.\n    \n    This function generates a visualization showing the most important words\n    for each topic identified by a topic model (e.g., NMF or LDA).\n    \n    Args:\n        model: Fitted topic model with components_ attribute (e.g., NMF, LDA).\n        feature_names: Array of feature names from the vectorizer.\n        n_top_words: Number of top words to display per topic.\n        output_path: Path to save the visualization.\n    \"\"\"\n    if not hasattr(model, 'components_'):\n        raise ValueError(\"Model must have 'components_' attribute (fitted NMF or LDA).\")\n    \n    n_topics = model.components_.shape[0]\n    \n    # Calculate grid dimensions\n    n_cols = min(3, n_topics)\n    n_rows = (n_topics + n_cols - 1) // n_cols\n    \n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n    \n    # Ensure axes is always a 2D array for consistent indexing\n    if n_topics == 1:\n        axes = np.array([[axes]])\n    elif n_rows == 1:\n        axes = axes.reshape(1, -1)\n    elif n_cols == 1:\n        axes = axes.reshape(-1, 1)\n    \n    # Color palette for topics\n    colors = plt.cm.viridis(np.linspace(0.2, 0.8, n_topics))\n    \n    for topic_idx, topic in enumerate(model.components_):\n        row = topic_idx // n_cols\n        col = topic_idx % n_cols\n        ax = axes[row, col]\n        \n        # Get top word indices and their weights\n        top_word_indices = topic.argsort()[:-n_top_words - 1:-1]\n        top_words = [feature_names[i] for i in top_word_indices]\n        top_weights = topic[top_word_indices]\n        \n        # Normalize weights for better visualization\n        if top_weights.max() > 0:\n            top_weights_normalized = top_weights / top_weights.max()\n        else:\n            top_weights_normalized = top_weights\n        \n        # Create horizontal bar chart\n        y_pos = np.arange(n_top_words)\n        ax.barh(y_pos, top_weights_normalized, color=colors[topic_idx], alpha=0.8)\n        ax.set_yticks(y_pos)\n        ax.set_yticklabels(top_words)\n        ax.invert_yaxis()  # Top word at the top\n        ax.set_xlabel('Relative Weight')\n        ax.set_title(f'Topic {topic_idx + 1}', fontsize=12, fontweight='bold')\n        ax.set_xlim(0, 1.1)\n        \n        # Add weight values on bars\n        for i, (weight, word) in enumerate(zip(top_weights_normalized, top_words)):\n            ax.text(weight + 0.02, i, f'{weight:.2f}', va='center', fontsize=8)\n    \n    # Hide empty subplots\n    for idx in range(n_topics, n_rows * n_cols):\n        row = idx // n_cols\n        col = idx % n_cols\n        axes[row, col].set_visible(False)\n    \n    plt.suptitle('Top Words per Topic', fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    \n    # Ensure directory exists\n    output_dir = os.path.dirname(output_path)\n    if output_dir and not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    print(f\"Topic visualization saved to: {output_path}\")\n\n\ndef plot_topic_distribution(document_topic_matrix: np.ndarray,\n                            output_path: str = 'topic_distribution.png') -> None:\n    \"\"\"Plot the distribution of topics across documents.\n    \n    Args:\n        document_topic_matrix: Matrix of document-topic weights.\n        output_path: Path to save the plot.\n    \"\"\"\n    n_topics = document_topic_matrix.shape[1]\n    topic_sums = document_topic_matrix.sum(axis=0)\n    topic_proportions = topic_sums / topic_sums.sum()\n    \n    plt.figure(figsize=(10, 6))\n    colors = plt.cm.viridis(np.linspace(0.2, 0.8, n_topics))\n    \n    bars = plt.bar(range(n_topics), topic_proportions, color=colors)\n    plt.xlabel('Topic')\n    plt.ylabel('Proportion')\n    plt.title('Topic Distribution Across Documents')\n    plt.xticks(range(n_topics), [f'Topic {i+1}' for i in range(n_topics)])\n    \n    # Add value labels on bars\n    for bar, prop in zip(bars, topic_proportions):\n        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                f'{prop:.2%}', ha='center', va='bottom', fontsize=9)\n    \n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n",
          "lexilearn_lab/main.py": "\"\"\"Main entry point for LexiLearn Lab.\"\"\"\n\nimport argparse\nfrom typing import Dict, Type\n\nfrom .strategies.base_strategy import BaseStrategy\nfrom .strategies.sentiment_strategy import SentimentStrategy\nfrom .strategies.topic_modeling_strategy import TopicModelingStrategy\nfrom .components.data_ingestion import load_documents\n\n\n# Strategy mapping for different NLP tasks\nSTRATEGY_MAP: Dict[str, Type[BaseStrategy]] = {\n    'sentiment': SentimentStrategy,\n    'topic_modeling': TopicModelingStrategy,\n}\n\n\ndef get_strategy(task: str, **kwargs) -> BaseStrategy:\n    \"\"\"Get the appropriate strategy for the given task.\n    \n    Args:\n        task: The NLP task to perform.\n        **kwargs: Additional arguments for the strategy.\n        \n    Returns:\n        An instance of the appropriate strategy.\n        \n    Raises:\n        ValueError: If the task is not supported.\n    \"\"\"\n    if task not in STRATEGY_MAP:\n        available = ', '.join(STRATEGY_MAP.keys())\n        raise ValueError(f\"Unknown task: {task}. Available tasks: {available}\")\n    \n    strategy_class = STRATEGY_MAP[task]\n    return strategy_class(**kwargs)\n\n\ndef main():\n    \"\"\"Main function to run LexiLearn Lab.\"\"\"\n    parser = argparse.ArgumentParser(\n        description='LexiLearn Lab - NLP-driven insights for educators'\n    )\n    parser.add_argument(\n        '--task', \n        type=str, \n        choices=list(STRATEGY_MAP.keys()),\n        required=True,\n        help='The NLP task to perform'\n    )\n    parser.add_argument(\n        '--input', \n        type=str, \n        required=True,\n        help='Path to input documents'\n    )\n    parser.add_argument(\n        '--output', \n        type=str, \n        default='output',\n        help='Output directory for results'\n    )\n    parser.add_argument(\n        '--n-topics',\n        type=int,\n        default=5,\n        help='Number of topics for topic modeling (default: 5)'\n    )\n    parser.add_argument(\n        '--n-top-words',\n        type=int,\n        default=10,\n        help='Number of top words per topic (default: 10)'\n    )\n    \n    args = parser.parse_args()\n    \n    # Load documents\n    print(f\"Loading documents from {args.input}...\")\n    documents = load_documents(args.input)\n    print(f\"Loaded {len(documents)} documents.\")\n    \n    # Get the appropriate strategy\n    strategy_kwargs = {}\n    if args.task == 'topic_modeling':\n        strategy_kwargs['n_topics'] = args.n_topics\n        strategy_kwargs['n_top_words'] = args.n_top_words\n    \n    strategy = get_strategy(args.task, **strategy_kwargs)\n    \n    # Run the analysis\n    print(f\"Running {args.task} analysis...\")\n    strategy.train(documents)\n    \n    # Evaluate and visualize\n    output_path = f\"{args.output}/{args.task}_visualization.png\"\n    results = strategy.evaluate(output_path=output_path)\n    \n    print(\"\nResults:\")\n    print(f\"  Metrics: {results.get('metrics', {})}\")\n    \n    if args.task == 'topic_modeling' and 'topics' in results:\n        print(\"\nDiscovered Topics:\")\n        for topic_idx, words in results['topics'].items():\n            print(f\"  Topic {topic_idx + 1}: {', '.join(words[:5])}...\")\n    \n    print(f\"\nVisualization saved to: {results.get('visualization_path', output_path)}\")\n\n\nif __name__ == '__main__':\n    main()\n",
          "lexilearn_lab/strategies/__init__.py": "\"\"\"Strategies module for LexiLearn Lab.\"\"\"\n\nfrom .base_strategy import BaseStrategy\nfrom .sentiment_strategy import SentimentStrategy\nfrom .topic_modeling_strategy import TopicModelingStrategy\n\n__all__ = [\n    'BaseStrategy',\n    'SentimentStrategy',\n    'TopicModelingStrategy',\n]\n",
          "lexilearn_lab/strategies/base_strategy.py": "\"\"\"Base strategy class for NLP tasks.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\n\n\nclass BaseStrategy(ABC):\n    \"\"\"Abstract base class for NLP strategies.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the base strategy.\"\"\"\n        self.model = None\n        self.is_trained = False\n    \n    @abstractmethod\n    def _create_model(self) -> Any:\n        \"\"\"Create and return the model for this strategy.\n        \n        Returns:\n            The model instance.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def _get_evaluation_metrics(self) -> Dict[str, float]:\n        \"\"\"Get evaluation metrics for the trained model.\n        \n        Returns:\n            Dictionary of metric names to values.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def train(self, documents: List[str]) -> 'BaseStrategy':\n        \"\"\"Train the model on the given documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def predict(self, documents: List[str]) -> Any:\n        \"\"\"Make predictions on the given documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Predictions for the documents.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def evaluate(self, documents: Optional[List[str]] = None, \n                 output_path: str = 'visualization.png') -> Dict[str, Any]:\n        \"\"\"Evaluate the model and generate visualizations.\n        \n        Args:\n            documents: Optional list of documents for evaluation.\n            output_path: Path to save visualizations.\n            \n        Returns:\n            Dictionary containing evaluation results.\n        \"\"\"\n        pass\n",
          "lexilearn_lab/strategies/sentiment_strategy.py": "\"\"\"Sentiment analysis strategy.\"\"\"\n\nfrom typing import Any, Dict, List, Optional\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\nfrom .base_strategy import BaseStrategy\nfrom ..components.feature_engineering import create_tfidf_pipeline\nfrom ..visualization import plot_sentiment_distribution\n\n\nclass SentimentStrategy(BaseStrategy):\n    \"\"\"Strategy for sentiment analysis.\"\"\"\n    \n    def __init__(self, n_classes: int = 3):\n        \"\"\"Initialize the sentiment strategy.\n        \n        Args:\n            n_classes: Number of sentiment classes.\n        \"\"\"\n        super().__init__()\n        self.n_classes = n_classes\n        self.vectorizer = None\n        self.labels = None\n        self.cv_scores = None\n    \n    def _create_model(self) -> LogisticRegression:\n        \"\"\"Create a logistic regression model for sentiment.\n        \n        Returns:\n            LogisticRegression model.\n        \"\"\"\n        return LogisticRegression(\n            max_iter=1000,\n            multi_class='multinomial',\n            random_state=42\n        )\n    \n    def _get_evaluation_metrics(self) -> Dict[str, float]:\n        \"\"\"Get evaluation metrics.\n        \n        Returns:\n            Dictionary with accuracy metrics.\n        \"\"\"\n        if self.cv_scores is None:\n            return {'accuracy': 0.0}\n        \n        return {\n            'accuracy': float(np.mean(self.cv_scores)),\n            'std': float(np.std(self.cv_scores))\n        }\n    \n    def train(self, documents: List[str], labels: Optional[List[int]] = None) -> 'SentimentStrategy':\n        \"\"\"Train the sentiment model.\n        \n        Args:\n            documents: List of text documents.\n            labels: Optional sentiment labels.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.vectorizer = create_tfidf_pipeline()\n        X = self.vectorizer.fit_transform(documents)\n        \n        self.model = self._create_model()\n        \n        if labels is not None:\n            self.labels = labels\n            self.model.fit(X, labels)\n            self.cv_scores = cross_val_score(self.model, X, labels, cv=5)\n            self.is_trained = True\n        \n        return self\n    \n    def predict(self, documents: List[str]) -> np.ndarray:\n        \"\"\"Predict sentiments for documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Predicted sentiment labels.\n        \"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before prediction.\")\n        \n        X = self.vectorizer.transform(documents)\n        return self.model.predict(X)\n    \n    def evaluate(self, documents: Optional[List[str]] = None,\n                 output_path: str = 'sentiment_visualization.png') -> Dict[str, Any]:\n        \"\"\"Evaluate the sentiment model.\n        \n        Args:\n            documents: Optional documents for evaluation.\n            output_path: Path to save visualization.\n            \n        Returns:\n            Evaluation results.\n        \"\"\"\n        metrics = self._get_evaluation_metrics()\n        \n        if documents is not None and self.is_trained:\n            predictions = self.predict(documents)\n            sentiment_labels = ['Negative', 'Neutral', 'Positive']\n            pred_labels = [sentiment_labels[p] for p in predictions]\n            plot_sentiment_distribution(pred_labels, output_path)\n        \n        return {\n            'metrics': metrics,\n            'visualization_path': output_path\n        }\n",
          "lexilearn_lab/components/__init__.py": "\"\"\"Components module for LexiLearn Lab.\"\"\"\n\nfrom .data_ingestion import load_documents, load_from_csv, load_from_directory\nfrom .feature_engineering import (\n    create_tfidf_pipeline, \n    create_count_vectorizer_pipeline,\n    create_normalized_tfidf_pipeline\n)\nfrom .evaluation import calculate_metrics, classification_report\nfrom .modeling import train_model, save_model, load_model\n\n__all__ = [\n    'load_documents',\n    'load_from_csv',\n    'load_from_directory',\n    'create_tfidf_pipeline',\n    'create_count_vectorizer_pipeline',\n    'create_normalized_tfidf_pipeline',\n    'calculate_metrics',\n    'classification_report',\n    'train_model',\n    'save_model',\n    'load_model',\n]\n",
          "lexilearn_lab/components/data_ingestion.py": "\"\"\"Data ingestion components for LexiLearn Lab.\"\"\"\n\nimport os\nimport csv\nfrom typing import List, Optional, Tuple\nimport glob\n\n\ndef load_documents(path: str) -> List[str]:\n    \"\"\"Load documents from a file or directory.\n    \n    Args:\n        path: Path to a file or directory.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    if os.path.isfile(path):\n        if path.endswith('.csv'):\n            return load_from_csv(path)\n        else:\n            return load_from_text_file(path)\n    elif os.path.isdir(path):\n        return load_from_directory(path)\n    else:\n        raise ValueError(f\"Path does not exist: {path}\")\n\n\ndef load_from_csv(filepath: str, text_column: str = 'text') -> List[str]:\n    \"\"\"Load documents from a CSV file.\n    \n    Args:\n        filepath: Path to the CSV file.\n        text_column: Name of the column containing text.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    documents = []\n    with open(filepath, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if text_column in row:\n                documents.append(row[text_column])\n    return documents\n\n\ndef load_from_directory(directory: str, extensions: List[str] = None) -> List[str]:\n    \"\"\"Load documents from all text files in a directory.\n    \n    Args:\n        directory: Path to the directory.\n        extensions: List of file extensions to include.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    if extensions is None:\n        extensions = ['.txt', '.md']\n    \n    documents = []\n    for ext in extensions:\n        pattern = os.path.join(directory, f'*{ext}')\n        for filepath in glob.glob(pattern):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                documents.append(f.read())\n    \n    return documents\n\n\ndef load_from_text_file(filepath: str) -> List[str]:\n    \"\"\"Load documents from a text file (one document per line).\n    \n    Args:\n        filepath: Path to the text file.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    documents = []\n    with open(filepath, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if line:\n                documents.append(line)\n    return documents\n\n\ndef load_labeled_data(filepath: str, text_column: str = 'text',\n                      label_column: str = 'label') -> Tuple[List[str], List[int]]:\n    \"\"\"Load labeled documents from a CSV file.\n    \n    Args:\n        filepath: Path to the CSV file.\n        text_column: Name of the text column.\n        label_column: Name of the label column.\n        \n    Returns:\n        Tuple of (documents, labels).\n    \"\"\"\n    documents = []\n    labels = []\n    \n    with open(filepath, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if text_column in row and label_column in row:\n                documents.append(row[text_column])\n                labels.append(int(row[label_column]))\n    \n    return documents, labels\n",
          "lexilearn_lab/components/evaluation.py": "\"\"\"Evaluation components for LexiLearn Lab.\"\"\"\n\nfrom typing import Dict, List, Any\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report as sklearn_classification_report\n\n\ndef calculate_metrics(y_true: List[int], y_pred: List[int], \n                      average: str = 'weighted') -> Dict[str, float]:\n    \"\"\"Calculate classification metrics.\n    \n    Args:\n        y_true: True labels.\n        y_pred: Predicted labels.\n        average: Averaging method for multi-class.\n        \n    Returns:\n        Dictionary of metrics.\n    \"\"\"\n    return {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average=average, zero_division=0),\n        'recall': recall_score(y_true, y_pred, average=average, zero_division=0),\n        'f1_score': f1_score(y_true, y_pred, average=average, zero_division=0)\n    }\n\n\ndef classification_report(y_true: List[int], y_pred: List[int],\n                          target_names: List[str] = None) -> str:\n    \"\"\"Generate a classification report.\n    \n    Args:\n        y_true: True labels.\n        y_pred: Predicted labels.\n        target_names: Names for each class.\n        \n    Returns:\n        Classification report string.\n    \"\"\"\n    return sklearn_classification_report(\n        y_true, y_pred, \n        target_names=target_names,\n        zero_division=0\n    )\n",
          "lexilearn_lab/components/modeling.py": "\"\"\"Modeling utilities for LexiLearn Lab.\"\"\"\n\nimport pickle\nfrom typing import Any, Optional\nimport os\n\n\ndef train_model(model: Any, X: Any, y: Optional[Any] = None) -> Any:\n    \"\"\"Train a model.\n    \n    Args:\n        model: The model to train.\n        X: Training features.\n        y: Training labels (optional for unsupervised).\n        \n    Returns:\n        Trained model.\n    \"\"\"\n    if y is not None:\n        model.fit(X, y)\n    else:\n        model.fit(X)\n    return model\n\n\ndef save_model(model: Any, filepath: str) -> None:\n    \"\"\"Save a model to disk.\n    \n    Args:\n        model: The model to save.\n        filepath: Path to save the model.\n    \"\"\"\n    directory = os.path.dirname(filepath)\n    if directory and not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    with open(filepath, 'wb') as f:\n        pickle.dump(model, f)\n\n\ndef load_model(filepath: str) -> Any:\n    \"\"\"Load a model from disk.\n    \n    Args:\n        filepath: Path to the saved model.\n        \n    Returns:\n        Loaded model.\n    \"\"\"\n    with open(filepath, 'rb') as f:\n        return pickle.load(f)\n",
          "lexilearn_lab/pipeline.py": "\"\"\"Pipeline utilities for LexiLearn Lab.\"\"\"\n\nfrom typing import Any, Dict, List, Optional\nfrom .strategies.base_strategy import BaseStrategy\n\n\nclass NLPPipeline:\n    \"\"\"Pipeline for running NLP tasks.\"\"\"\n    \n    def __init__(self, strategy: BaseStrategy):\n        \"\"\"Initialize the pipeline with a strategy.\n        \n        Args:\n            strategy: The NLP strategy to use.\n        \"\"\"\n        self.strategy = strategy\n        self.results = None\n    \n    def run(self, documents: List[str], \n            output_path: str = 'output.png',\n            **kwargs) -> Dict[str, Any]:\n        \"\"\"Run the pipeline on documents.\n        \n        Args:\n            documents: List of text documents.\n            output_path: Path for visualization output.\n            **kwargs: Additional arguments for training.\n            \n        Returns:\n            Pipeline results.\n        \"\"\"\n        # Train the model\n        self.strategy.train(documents, **kwargs)\n        \n        # Evaluate and visualize\n        self.results = self.strategy.evaluate(\n            documents=documents,\n            output_path=output_path\n        )\n        \n        return self.results\n    \n    def predict(self, documents: List[str]) -> Any:\n        \"\"\"Make predictions using the trained strategy.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Predictions.\n        \"\"\"\n        return self.strategy.predict(documents)\n",
          "lexilearn_lab/__init__.py": "\"\"\"LexiLearn Lab - NLP-driven insights for educators.\"\"\"\n\nfrom .strategies import BaseStrategy, SentimentStrategy, TopicModelingStrategy\nfrom .pipeline import NLPPipeline\nfrom .main import get_strategy, STRATEGY_MAP\n\n__version__ = '1.0.0'\n\n__all__ = [\n    'BaseStrategy',\n    'SentimentStrategy',\n    'TopicModelingStrategy',\n    'NLPPipeline',\n    'get_strategy',\n    'STRATEGY_MAP',\n]\n"
        },
        "generated_files": [
          "lexilearn_lab/strategies/topic_modeling_strategy.py",
          "lexilearn_lab/components/feature_engineering.py",
          "lexilearn_lab/visualization.py",
          "lexilearn_lab/main.py",
          "lexilearn_lab/strategies/__init__.py",
          "lexilearn_lab/strategies/base_strategy.py",
          "lexilearn_lab/strategies/sentiment_strategy.py",
          "lexilearn_lab/components/__init__.py",
          "lexilearn_lab/components/data_ingestion.py",
          "lexilearn_lab/components/evaluation.py",
          "lexilearn_lab/components/modeling.py",
          "lexilearn_lab/pipeline.py",
          "lexilearn_lab/__init__.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8253197871311079,
              "dependency_traversal_accuracy": 0.7856228743536435,
              "cross_file_reasoning_depth": 0.288525641025641,
              "system_thinking_score": 0.27753208628084003,
              "robustness_score": 0.2523540489642185,
              "comprehensiveness_score": 0.514227199354318,
              "innovation_score": 0.30625,
              "solution_elegance_score": 0.6276589964250078
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.10316497339138848,
              "dependency_traversal_weighted": 0.09820285929420544,
              "cross_file_reasoning_weighted": 0.036065705128205124,
              "system_thinking_weighted": 0.034691510785105004,
              "robustness_weighted": 0.03154425612052731,
              "comprehensiveness_weighted": 0.06427839991928976,
              "innovation_weighted": 0.03828125,
              "solution_elegance_weighted": 0.07845737455312597
            },
            "total_software_engineering_score": 0.48468632919184707
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.1,
              "execution_time": 0.8626515865325928,
              "errors": [
                "  File \"lexilearn_lab/main.py\", line 100",
                "    print(\"",
                "          ^",
                "SyntaxError: unterminated string literal (detected at line 100)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "lexilearn_lab/strategies/topic_modeling_strategy.py",
                "lexilearn_lab/components/feature_engineering.py",
                "lexilearn_lab/visualization.py",
                "lexilearn_lab/main.py",
                "lexilearn_lab/strategies/__init__.py",
                "lexilearn_lab/strategies/base_strategy.py",
                "lexilearn_lab/strategies/sentiment_strategy.py",
                "lexilearn_lab/components/__init__.py",
                "lexilearn_lab/components/data_ingestion.py",
                "lexilearn_lab/components/evaluation.py",
                "lexilearn_lab/components/modeling.py",
                "lexilearn_lab/pipeline.py",
                "lexilearn_lab/__init__.py"
              ],
              "scoring_breakdown": {
                "minimal_credit": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 13,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 13 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.1552097902097902,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.1,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.1552097902097902,
              "idc_weight": 0.2,
              "total_functional_score": 0.37104195804195805
            }
          },
          "code_quality_details": {
            "files_analyzed": 13,
            "quality_checks": {
              "lexilearn_lab/strategies/topic_modeling_strategy.py": {
                "line_count": 188,
                "non_empty_lines": 146,
                "comment_lines": 5,
                "comment_ratio": 0.03424657534246575,
                "function_count": 10,
                "class_count": 1,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/components/feature_engineering.py": {
                "line_count": 85,
                "non_empty_lines": 70,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 3,
                "class_count": 0,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/visualization.py": {
                "line_count": 171,
                "non_empty_lines": 134,
                "comment_lines": 10,
                "comment_ratio": 0.07462686567164178,
                "function_count": 4,
                "class_count": 0,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/main.py": {
                "line_count": 116,
                "non_empty_lines": 92,
                "comment_lines": 5,
                "comment_ratio": 0.05434782608695652,
                "function_count": 2,
                "class_count": 1,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/strategies/__init__.py": {
                "line_count": 12,
                "non_empty_lines": 9,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 6,
                "quality_score": 0.5
              },
              "lexilearn_lab/strategies/base_strategy.py": {
                "line_count": 70,
                "non_empty_lines": 52,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 6,
                "class_count": 3,
                "import_count": 4,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/strategies/sentiment_strategy.py": {
                "line_count": 115,
                "non_empty_lines": 88,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 6,
                "class_count": 1,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/components/__init__.py": {
                "line_count": 25,
                "non_empty_lines": 22,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 8,
                "quality_score": 0.5
              },
              "lexilearn_lab/components/data_ingestion.py": {
                "line_count": 112,
                "non_empty_lines": 86,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 5,
                "class_count": 0,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/components/evaluation.py": {
                "line_count": 46,
                "non_empty_lines": 36,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 2,
                "class_count": 0,
                "import_count": 7,
                "quality_score": 0.6
              },
              "lexilearn_lab/components/modeling.py": {
                "line_count": 52,
                "non_empty_lines": 38,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 3,
                "class_count": 0,
                "import_count": 5,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/pipeline.py": {
                "line_count": 53,
                "non_empty_lines": 39,
                "comment_lines": 2,
                "comment_ratio": 0.05128205128205128,
                "function_count": 3,
                "class_count": 1,
                "import_count": 4,
                "quality_score": 0.7999999999999999
              },
              "lexilearn_lab/__init__.py": {
                "line_count": 17,
                "non_empty_lines": 13,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 6,
                "quality_score": 0.5
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7407692307692306,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8296022727272727,
              "multi_session_memory_retention": 0.7844919786096256
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.41480113636363636,
              "multi_session_memory_retention_weighted": 0.3922459893048128
            },
            "total_longcontext_utilization_score": 0.8070471256684492
          }
        },
        "timestamp": "2026-01-14T21:37:03.809216"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_data_lake_hard_014_feature_implementation_expert_01",
        "scenario_title": "Implement a Data Quarantine and Replay Mechanism for Failed Stream Processing Events",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5161790783918421,
        "functional_correctness_score": 0.3729959032383925,
        "code_quality_score": 0.7490909090909089,
        "longcontext_utilization_score": 0.9282521645021645,
        "total_score": 2.8050690029832643,
        "generation_time": 320.3164758682251,
        "code_files_generated": 11,
        "total_lines_generated": 3308,
        "parsing_success": true,
        "solution_code": {
          "UtilityLake_Sentinel/configs/default.yml": "# Default configuration for UtilityLake Sentinel Platform\n\napplication:\n  name: UtilityLake Sentinel\n  version: 1.0.0\n  environment: default\n\nlogging:\n  level: INFO\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  handlers:\n    - console\n    - file\n  file_path: /var/log/utilitylake/app.log\n\nstorage:\n  default_path: s3a://utilitylake-data/\n  raw_zone: s3a://utilitylake-data/raw/\n  processed_zone: s3a://utilitylake-data/processed/\n  curated_zone: s3a://utilitylake-data/curated/\n  quarantine_storage_path: s3a://utilitylake-quarantine/\n\nkafka:\n  bootstrap_servers:\n    - localhost:9092\n  consumer_group: utilitylake-consumers\n  auto_offset_reset: earliest\n  enable_auto_commit: true\n\ndatabase:\n  host: localhost\n  port: 5432\n  name: utilitylake_catalog\n  pool_size: 10\n  max_overflow: 20\n\napi:\n  host: 0.0.0.0\n  port: 8000\n  debug: false\n  cors_origins:\n    - \"*\"\n\nmonitoring:\n  prometheus_port: 9090\n  metrics_prefix: utilitylake\n  health_check_interval: 30\n\ndata_quality:\n  enable_validation: true\n  fail_on_error: false\n  quarantine_failed_records: true\n",
          "UtilityLake_Sentinel/configs/development.yml": "# Development configuration for UtilityLake Sentinel Platform\n\napplication:\n  name: UtilityLake Sentinel\n  version: 1.0.0-dev\n  environment: development\n\nlogging:\n  level: DEBUG\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  handlers:\n    - console\n  file_path: /tmp/utilitylake/app.log\n\nstorage:\n  default_path: file:///tmp/utilitylake-data/\n  raw_zone: file:///tmp/utilitylake-data/raw/\n  processed_zone: file:///tmp/utilitylake-data/processed/\n  curated_zone: file:///tmp/utilitylake-data/curated/\n  quarantine_storage_path: file:///tmp/utilitylake-quarantine/\n\nkafka:\n  bootstrap_servers:\n    - localhost:9092\n  consumer_group: utilitylake-dev-consumers\n  auto_offset_reset: earliest\n  enable_auto_commit: true\n\ndatabase:\n  host: localhost\n  port: 5432\n  name: utilitylake_catalog_dev\n  pool_size: 5\n  max_overflow: 10\n\napi:\n  host: 0.0.0.0\n  port: 8000\n  debug: true\n  cors_origins:\n    - \"*\"\n    - \"http://localhost:3000\"\n\nmonitoring:\n  prometheus_port: 9090\n  metrics_prefix: utilitylake_dev\n  health_check_interval: 10\n\ndata_quality:\n  enable_validation: true\n  fail_on_error: false\n  quarantine_failed_records: true\n\ndata_catalog_api:\n  base_url: http://localhost:8001\n  timeout: 30\n",
          "UtilityLake_Sentinel/services/data_catalog_api/models.py": "\"\"\"SQLAlchemy models and Pydantic schemas for the Data Catalog API.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Optional, List\nfrom enum import Enum\n\nfrom sqlalchemy import Column, Integer, String, DateTime, Text, JSON, ForeignKey, Enum as SQLEnum\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\nfrom pydantic import BaseModel, Field\n\nBase = declarative_base()\n\n\nclass DatasetStatus(str, Enum):\n    \"\"\"Status of a dataset in the catalog.\"\"\"\n    ACTIVE = \"active\"\n    DEPRECATED = \"deprecated\"\n    ARCHIVED = \"archived\"\n\n\nclass QuarantineStatus(str, Enum):\n    \"\"\"Status of a quarantined record.\"\"\"\n    QUARANTINED = \"quarantined\"\n    PENDING_REPLAY = \"pending_replay\"\n    REPLAYED = \"replayed\"\n    ARCHIVED = \"archived\"\n\n\n# SQLAlchemy Models\n\nclass Dataset(Base):\n    \"\"\"SQLAlchemy model for datasets in the catalog.\"\"\"\n    __tablename__ = \"datasets\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String(255), unique=True, nullable=False, index=True)\n    description = Column(Text, nullable=True)\n    schema_definition = Column(JSON, nullable=True)\n    storage_location = Column(String(512), nullable=False)\n    format = Column(String(50), nullable=False, default=\"parquet\")\n    owner = Column(String(255), nullable=True)\n    status = Column(SQLEnum(DatasetStatus), default=DatasetStatus.ACTIVE)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    tags = Column(JSON, nullable=True)\n    metadata = Column(JSON, nullable=True)\n\n\nclass DataLineage(Base):\n    \"\"\"SQLAlchemy model for tracking data lineage.\"\"\"\n    __tablename__ = \"data_lineage\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    source_dataset_id = Column(Integer, ForeignKey(\"datasets.id\"), nullable=False)\n    target_dataset_id = Column(Integer, ForeignKey(\"datasets.id\"), nullable=False)\n    transformation_type = Column(String(100), nullable=False)\n    transformation_details = Column(JSON, nullable=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n\nclass QuarantinedRecord(Base):\n    \"\"\"SQLAlchemy model for quarantined records that failed data quality checks.\"\"\"\n    __tablename__ = \"quarantined_records\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    source_topic = Column(String(255), nullable=False, index=True)\n    payload = Column(JSON, nullable=False)\n    failure_reason = Column(Text, nullable=False)\n    quarantined_at = Column(DateTime, default=datetime.utcnow, index=True)\n    status = Column(SQLEnum(QuarantineStatus), default=QuarantineStatus.QUARANTINED, index=True)\n    storage_path = Column(String(512), nullable=True)\n    original_timestamp = Column(DateTime, nullable=True)\n    replay_attempts = Column(Integer, default=0)\n    last_replay_at = Column(DateTime, nullable=True)\n    metadata = Column(JSON, nullable=True)\n\n\n# Pydantic Schemas\n\nclass DatasetBase(BaseModel):\n    \"\"\"Base Pydantic schema for Dataset.\"\"\"\n    name: str\n    description: Optional[str] = None\n    schema_definition: Optional[dict] = None\n    storage_location: str\n    format: str = \"parquet\"\n    owner: Optional[str] = None\n    tags: Optional[List[str]] = None\n    metadata: Optional[dict] = None\n\n\nclass DatasetCreate(DatasetBase):\n    \"\"\"Pydantic schema for creating a Dataset.\"\"\"\n    pass\n\n\nclass DatasetUpdate(BaseModel):\n    \"\"\"Pydantic schema for updating a Dataset.\"\"\"\n    name: Optional[str] = None\n    description: Optional[str] = None\n    schema_definition: Optional[dict] = None\n    storage_location: Optional[str] = None\n    format: Optional[str] = None\n    owner: Optional[str] = None\n    status: Optional[DatasetStatus] = None\n    tags: Optional[List[str]] = None\n    metadata: Optional[dict] = None\n\n\nclass DatasetResponse(DatasetBase):\n    \"\"\"Pydantic schema for Dataset response.\"\"\"\n    id: int\n    status: DatasetStatus\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\nclass DataLineageBase(BaseModel):\n    \"\"\"Base Pydantic schema for DataLineage.\"\"\"\n    source_dataset_id: int\n    target_dataset_id: int\n    transformation_type: str\n    transformation_details: Optional[dict] = None\n\n\nclass DataLineageCreate(DataLineageBase):\n    \"\"\"Pydantic schema for creating DataLineage.\"\"\"\n    pass\n\n\nclass DataLineageResponse(DataLineageBase):\n    \"\"\"Pydantic schema for DataLineage response.\"\"\"\n    id: int\n    created_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\n# Quarantined Record Schemas\n\nclass QuarantinedRecordBase(BaseModel):\n    \"\"\"Base Pydantic schema for QuarantinedRecord.\"\"\"\n    source_topic: str\n    payload: dict\n    failure_reason: str\n    storage_path: Optional[str] = None\n    original_timestamp: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass QuarantinedRecordCreate(QuarantinedRecordBase):\n    \"\"\"Pydantic schema for creating a QuarantinedRecord.\"\"\"\n    pass\n\n\nclass QuarantinedRecordUpdate(BaseModel):\n    \"\"\"Pydantic schema for updating a QuarantinedRecord.\"\"\"\n    status: Optional[QuarantineStatus] = None\n    replay_attempts: Optional[int] = None\n    last_replay_at: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass QuarantinedRecordResponse(QuarantinedRecordBase):\n    \"\"\"Pydantic schema for QuarantinedRecord response.\"\"\"\n    id: int\n    status: QuarantineStatus\n    quarantined_at: datetime\n    replay_attempts: int\n    last_replay_at: Optional[datetime] = None\n\n    class Config:\n        from_attributes = True\n\n\nclass QuarantinedRecordListResponse(BaseModel):\n    \"\"\"Pydantic schema for listing quarantined records.\"\"\"\n    records: List[QuarantinedRecordResponse]\n    total: int\n    page: int\n    page_size: int\n",
          "UtilityLake_Sentinel/services/data_catalog_api/crud.py": "\"\"\"CRUD operations for the Data Catalog API.\"\"\"\n\nfrom datetime import datetime\nfrom typing import List, Optional, Tuple\n\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import and_, or_\n\nfrom .models import (\n    Dataset, DatasetCreate, DatasetUpdate, DatasetStatus,\n    DataLineage, DataLineageCreate,\n    QuarantinedRecord, QuarantinedRecordCreate, QuarantinedRecordUpdate, QuarantineStatus\n)\n\n\n# Dataset CRUD operations\n\ndef create_dataset(db: Session, dataset: DatasetCreate) -> Dataset:\n    \"\"\"Create a new dataset in the catalog.\"\"\"\n    db_dataset = Dataset(\n        name=dataset.name,\n        description=dataset.description,\n        schema_definition=dataset.schema_definition,\n        storage_location=dataset.storage_location,\n        format=dataset.format,\n        owner=dataset.owner,\n        tags=dataset.tags,\n        metadata=dataset.metadata\n    )\n    db.add(db_dataset)\n    db.commit()\n    db.refresh(db_dataset)\n    return db_dataset\n\n\ndef get_dataset(db: Session, dataset_id: int) -> Optional[Dataset]:\n    \"\"\"Get a dataset by ID.\"\"\"\n    return db.query(Dataset).filter(Dataset.id == dataset_id).first()\n\n\ndef get_dataset_by_name(db: Session, name: str) -> Optional[Dataset]:\n    \"\"\"Get a dataset by name.\"\"\"\n    return db.query(Dataset).filter(Dataset.name == name).first()\n\n\ndef get_datasets(\n    db: Session,\n    skip: int = 0,\n    limit: int = 100,\n    status: Optional[DatasetStatus] = None\n) -> List[Dataset]:\n    \"\"\"Get all datasets with optional filtering.\"\"\"\n    query = db.query(Dataset)\n    if status:\n        query = query.filter(Dataset.status == status)\n    return query.offset(skip).limit(limit).all()\n\n\ndef update_dataset(\n    db: Session,\n    dataset_id: int,\n    dataset_update: DatasetUpdate\n) -> Optional[Dataset]:\n    \"\"\"Update a dataset.\"\"\"\n    db_dataset = get_dataset(db, dataset_id)\n    if not db_dataset:\n        return None\n    \n    update_data = dataset_update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(db_dataset, field, value)\n    \n    db.commit()\n    db.refresh(db_dataset)\n    return db_dataset\n\n\ndef delete_dataset(db: Session, dataset_id: int) -> bool:\n    \"\"\"Delete a dataset.\"\"\"\n    db_dataset = get_dataset(db, dataset_id)\n    if not db_dataset:\n        return False\n    db.delete(db_dataset)\n    db.commit()\n    return True\n\n\n# DataLineage CRUD operations\n\ndef create_lineage(db: Session, lineage: DataLineageCreate) -> DataLineage:\n    \"\"\"Create a new lineage record.\"\"\"\n    db_lineage = DataLineage(\n        source_dataset_id=lineage.source_dataset_id,\n        target_dataset_id=lineage.target_dataset_id,\n        transformation_type=lineage.transformation_type,\n        transformation_details=lineage.transformation_details\n    )\n    db.add(db_lineage)\n    db.commit()\n    db.refresh(db_lineage)\n    return db_lineage\n\n\ndef get_lineage_for_dataset(\n    db: Session,\n    dataset_id: int,\n    direction: str = \"both\"\n) -> List[DataLineage]:\n    \"\"\"Get lineage records for a dataset.\"\"\"\n    if direction == \"upstream\":\n        return db.query(DataLineage).filter(\n            DataLineage.target_dataset_id == dataset_id\n        ).all()\n    elif direction == \"downstream\":\n        return db.query(DataLineage).filter(\n            DataLineage.source_dataset_id == dataset_id\n        ).all()\n    else:\n        return db.query(DataLineage).filter(\n            or_(\n                DataLineage.source_dataset_id == dataset_id,\n                DataLineage.target_dataset_id == dataset_id\n            )\n        ).all()\n\n\n# QuarantinedRecord CRUD operations\n\ndef create_quarantined_record(\n    db: Session,\n    record: QuarantinedRecordCreate\n) -> QuarantinedRecord:\n    \"\"\"Create a new quarantined record entry.\"\"\"\n    db_record = QuarantinedRecord(\n        source_topic=record.source_topic,\n        payload=record.payload,\n        failure_reason=record.failure_reason,\n        storage_path=record.storage_path,\n        original_timestamp=record.original_timestamp,\n        metadata=record.metadata,\n        status=QuarantineStatus.QUARANTINED,\n        quarantined_at=datetime.utcnow()\n    )\n    db.add(db_record)\n    db.commit()\n    db.refresh(db_record)\n    return db_record\n\n\ndef get_quarantined_record(\n    db: Session,\n    record_id: int\n) -> Optional[QuarantinedRecord]:\n    \"\"\"Get a quarantined record by ID.\"\"\"\n    return db.query(QuarantinedRecord).filter(\n        QuarantinedRecord.id == record_id\n    ).first()\n\n\ndef get_quarantined_records(\n    db: Session,\n    skip: int = 0,\n    limit: int = 100,\n    status: Optional[QuarantineStatus] = None,\n    source_topic: Optional[str] = None,\n    start_date: Optional[datetime] = None,\n    end_date: Optional[datetime] = None\n) -> Tuple[List[QuarantinedRecord], int]:\n    \"\"\"Get quarantined records with optional filtering.\n    \n    Returns a tuple of (records, total_count).\n    \"\"\"\n    query = db.query(QuarantinedRecord)\n    \n    # Apply filters\n    filters = []\n    if status:\n        filters.append(QuarantinedRecord.status == status)\n    if source_topic:\n        filters.append(QuarantinedRecord.source_topic == source_topic)\n    if start_date:\n        filters.append(QuarantinedRecord.quarantined_at >= start_date)\n    if end_date:\n        filters.append(QuarantinedRecord.quarantined_at <= end_date)\n    \n    if filters:\n        query = query.filter(and_(*filters))\n    \n    # Get total count before pagination\n    total = query.count()\n    \n    # Apply pagination and ordering\n    records = query.order_by(\n        QuarantinedRecord.quarantined_at.desc()\n    ).offset(skip).limit(limit).all()\n    \n    return records, total\n\n\ndef update_quarantined_record(\n    db: Session,\n    record_id: int,\n    record_update: QuarantinedRecordUpdate\n) -> Optional[QuarantinedRecord]:\n    \"\"\"Update a quarantined record.\"\"\"\n    db_record = get_quarantined_record(db, record_id)\n    if not db_record:\n        return None\n    \n    update_data = record_update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(db_record, field, value)\n    \n    db.commit()\n    db.refresh(db_record)\n    return db_record\n\n\ndef update_quarantined_record_status(\n    db: Session,\n    record_id: int,\n    new_status: QuarantineStatus\n) -> Optional[QuarantinedRecord]:\n    \"\"\"Update the status of a quarantined record.\"\"\"\n    db_record = get_quarantined_record(db, record_id)\n    if not db_record:\n        return None\n    \n    db_record.status = new_status\n    if new_status == QuarantineStatus.PENDING_REPLAY:\n        db_record.replay_attempts = (db_record.replay_attempts or 0) + 1\n        db_record.last_replay_at = datetime.utcnow()\n    \n    db.commit()\n    db.refresh(db_record)\n    return db_record\n\n\ndef delete_quarantined_record(db: Session, record_id: int) -> bool:\n    \"\"\"Delete a quarantined record.\"\"\"\n    db_record = get_quarantined_record(db, record_id)\n    if not db_record:\n        return False\n    db.delete(db_record)\n    db.commit()\n    return True\n\n\ndef get_quarantine_statistics(db: Session) -> dict:\n    \"\"\"Get statistics about quarantined records.\"\"\"\n    total = db.query(QuarantinedRecord).count()\n    by_status = {}\n    for status in QuarantineStatus:\n        count = db.query(QuarantinedRecord).filter(\n            QuarantinedRecord.status == status\n        ).count()\n        by_status[status.value] = count\n    \n    return {\n        \"total\": total,\n        \"by_status\": by_status\n    }\n",
          "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py": "\"\"\"Data quality checks for stream processing with quarantine support.\"\"\"\n\nimport json\nimport uuid\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional, Callable, Tuple\nfrom dataclasses import dataclass\nimport logging\nimport httpx\n\nfrom utilitylake_core.storage import StorageClient\nfrom utilitylake_core.config import get_config\nfrom utilitylake_core.errors import DataQualityError, ValidationError\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass QualityCheckResult:\n    \"\"\"Result of a quality check.\"\"\"\n    passed: bool\n    check_name: str\n    message: str\n    details: Optional[Dict[str, Any]] = None\n\n\n@dataclass\nclass QuarantineResult:\n    \"\"\"Result of quarantining a record.\"\"\"\n    success: bool\n    storage_path: Optional[str] = None\n    catalog_id: Optional[int] = None\n    error: Optional[str] = None\n\n\nclass DataCatalogClient:\n    \"\"\"Client for interacting with the Data Catalog API.\"\"\"\n    \n    def __init__(self, base_url: Optional[str] = None, timeout: int = 30):\n        config = get_config()\n        self.base_url = base_url or config.get(\n            'data_catalog_api', {}\n        ).get('base_url', 'http://localhost:8001')\n        self.timeout = timeout\n    \n    def create_quarantined_record(\n        self,\n        source_topic: str,\n        payload: Dict[str, Any],\n        failure_reason: str,\n        storage_path: Optional[str] = None,\n        original_timestamp: Optional[datetime] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> Optional[int]:\n        \"\"\"Create a quarantined record entry in the data catalog.\"\"\"\n        try:\n            data = {\n                \"source_topic\": source_topic,\n                \"payload\": payload,\n                \"failure_reason\": failure_reason,\n                \"storage_path\": storage_path,\n                \"metadata\": metadata\n            }\n            if original_timestamp:\n                data[\"original_timestamp\"] = original_timestamp.isoformat()\n            \n            with httpx.Client(timeout=self.timeout) as client:\n                response = client.post(\n                    f\"{self.base_url}/api/v1/quarantine/records\",\n                    json=data\n                )\n                response.raise_for_status()\n                result = response.json()\n                return result.get(\"id\")\n        except Exception as e:\n            logger.error(f\"Failed to create quarantine record in catalog: {e}\")\n            return None\n\n\nclass QuarantineManager:\n    \"\"\"Manages quarantining of failed records.\"\"\"\n    \n    def __init__(\n        self,\n        storage_client: Optional[StorageClient] = None,\n        catalog_client: Optional[DataCatalogClient] = None,\n        quarantine_path: Optional[str] = None\n    ):\n        config = get_config()\n        self.storage_client = storage_client or StorageClient()\n        self.catalog_client = catalog_client or DataCatalogClient()\n        self.quarantine_path = quarantine_path or config.get(\n            'storage', {}\n        ).get('quarantine_storage_path', 's3a://utilitylake-quarantine/')\n    \n    def quarantine_record(\n        self,\n        record: Dict[str, Any],\n        source_topic: str,\n        failure_reason: str,\n        original_timestamp: Optional[datetime] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> QuarantineResult:\n        \"\"\"Quarantine a failed record.\n        \n        1. Write the record to quarantine storage\n        2. Log the record in the data catalog\n        \"\"\"\n        # Generate unique path for the quarantined record\n        timestamp = datetime.utcnow()\n        record_id = str(uuid.uuid4())\n        date_partition = timestamp.strftime(\"%Y/%m/%d\")\n        storage_path = f\"{self.quarantine_path}{source_topic}/{date_partition}/{record_id}.json\"\n        \n        # Prepare quarantine data with metadata\n        quarantine_data = {\n            \"record\": record,\n            \"quarantine_metadata\": {\n                \"source_topic\": source_topic,\n                \"failure_reason\": failure_reason,\n                \"quarantined_at\": timestamp.isoformat(),\n                \"original_timestamp\": original_timestamp.isoformat() if original_timestamp else None,\n                \"additional_metadata\": metadata\n            }\n        }\n        \n        try:\n            # Write to quarantine storage\n            self.storage_client.write(\n                path=storage_path,\n                data=json.dumps(quarantine_data, default=str)\n            )\n            logger.info(f\"Record quarantined to storage: {storage_path}\")\n        except Exception as e:\n            error_msg = f\"Failed to write record to quarantine storage: {e}\"\n            logger.error(error_msg)\n            return QuarantineResult(success=False, error=error_msg)\n        \n        # Log to data catalog\n        try:\n            catalog_id = self.catalog_client.create_quarantined_record(\n                source_topic=source_topic,\n                payload=record,\n                failure_reason=failure_reason,\n                storage_path=storage_path,\n                original_timestamp=original_timestamp,\n                metadata=metadata\n            )\n            logger.info(f\"Quarantine record logged in catalog with ID: {catalog_id}\")\n        except Exception as e:\n            logger.warning(f\"Failed to log quarantine record in catalog: {e}\")\n            catalog_id = None\n        \n        return QuarantineResult(\n            success=True,\n            storage_path=storage_path,\n            catalog_id=catalog_id\n        )\n\n\nclass QualityChecker:\n    \"\"\"Performs data quality checks on streaming records.\"\"\"\n    \n    def __init__(\n        self,\n        quarantine_manager: Optional[QuarantineManager] = None,\n        enable_quarantine: bool = True\n    ):\n        self.quarantine_manager = quarantine_manager or QuarantineManager()\n        self.enable_quarantine = enable_quarantine\n        self.checks: List[Callable[[Dict[str, Any]], QualityCheckResult]] = []\n    \n    def add_check(self, check_func: Callable[[Dict[str, Any]], QualityCheckResult]):\n        \"\"\"Add a quality check function.\"\"\"\n        self.checks.append(check_func)\n    \n    def run_checks(\n        self,\n        record: Dict[str, Any],\n        source_topic: str = \"unknown\",\n        original_timestamp: Optional[datetime] = None\n    ) -> Tuple[bool, List[QualityCheckResult]]:\n        \"\"\"Run all quality checks on a record.\n        \n        Returns tuple of (all_passed, results).\n        \"\"\"\n        results = []\n        all_passed = True\n        \n        for check_func in self.checks:\n            try:\n                result = check_func(record)\n                results.append(result)\n                if not result.passed:\n                    all_passed = False\n            except Exception as e:\n                result = QualityCheckResult(\n                    passed=False,\n                    check_name=check_func.__name__,\n                    message=f\"Check failed with exception: {str(e)}\"\n                )\n                results.append(result)\n                all_passed = False\n        \n        return all_passed, results\n    \n    def process_record(\n        self,\n        record: Dict[str, Any],\n        source_topic: str = \"unknown\",\n        original_timestamp: Optional[datetime] = None\n    ) -> Tuple[bool, Optional[QuarantineResult]]:\n        \"\"\"Process a record through quality checks.\n        \n        If checks fail and quarantine is enabled, the record is quarantined.\n        Returns tuple of (passed, quarantine_result).\n        \"\"\"\n        all_passed, results = self.run_checks(\n            record, source_topic, original_timestamp\n        )\n        \n        if all_passed:\n            return True, None\n        \n        # Collect failure reasons\n        failure_reasons = [\n            f\"{r.check_name}: {r.message}\"\n            for r in results\n            if not r.passed\n        ]\n        failure_reason = \"; \".join(failure_reasons)\n        \n        # Quarantine the failed record\n        if self.enable_quarantine:\n            quarantine_result = self.quarantine_manager.quarantine_record(\n                record=record,\n                source_topic=source_topic,\n                failure_reason=failure_reason,\n                original_timestamp=original_timestamp,\n                metadata={\n                    \"check_results\": [\n                        {\n                            \"check_name\": r.check_name,\n                            \"passed\": r.passed,\n                            \"message\": r.message,\n                            \"details\": r.details\n                        }\n                        for r in results\n                    ]\n                }\n            )\n            return False, quarantine_result\n        \n        return False, None\n\n\n# Built-in quality check functions\n\ndef check_not_null(fields: List[str]) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that ensures specified fields are not null.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        missing_fields = [\n            field for field in fields\n            if field not in record or record[field] is None\n        ]\n        if missing_fields:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"not_null_check\",\n                message=f\"Missing or null fields: {missing_fields}\",\n                details={\"missing_fields\": missing_fields}\n            )\n        return QualityCheckResult(\n            passed=True,\n            check_name=\"not_null_check\",\n            message=\"All required fields present\"\n        )\n    return _check\n\n\ndef check_field_type(\n    field_types: Dict[str, type]\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates field types.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        type_errors = []\n        for field, expected_type in field_types.items():\n            if field in record and record[field] is not None:\n                if not isinstance(record[field], expected_type):\n                    type_errors.append({\n                        \"field\": field,\n                        \"expected\": expected_type.__name__,\n                        \"actual\": type(record[field]).__name__\n                    })\n        if type_errors:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"field_type_check\",\n                message=f\"Type validation failed for {len(type_errors)} field(s)\",\n                details={\"type_errors\": type_errors}\n            )\n        return QualityCheckResult(\n            passed=True,\n            check_name=\"field_type_check\",\n            message=\"All field types valid\"\n        )\n    return _check\n\n\ndef check_value_range(\n    field: str,\n    min_value: Optional[float] = None,\n    max_value: Optional[float] = None\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates a numeric field is within range.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        if field not in record or record[field] is None:\n            return QualityCheckResult(\n                passed=True,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} not present, skipping range check\"\n            )\n        \n        value = record[field]\n        try:\n            value = float(value)\n        except (ValueError, TypeError):\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} is not numeric\",\n                details={\"field\": field, \"value\": str(value)}\n            )\n        \n        if min_value is not None and value < min_value:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} value {value} is below minimum {min_value}\",\n                details={\"field\": field, \"value\": value, \"min\": min_value}\n            )\n        \n        if max_value is not None and value > max_value:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} value {value} is above maximum {max_value}\",\n                details={\"field\": field, \"value\": value, \"max\": max_value}\n            )\n        \n        return QualityCheckResult(\n            passed=True,\n            check_name=\"value_range_check\",\n            message=f\"Field {field} value {value} is within range\"\n        )\n    return _check\n\n\ndef check_schema_conformance(\n    required_fields: List[str],\n    optional_fields: Optional[List[str]] = None\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates record schema conformance.\"\"\"\n    optional_fields = optional_fields or []\n    all_known_fields = set(required_fields + optional_fields)\n    \n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        missing_required = [\n            field for field in required_fields\n            if field not in record\n        ]\n        unknown_fields = [\n            field for field in record.keys()\n            if field not in all_known_fields\n        ]\n        \n        issues = []\n        if missing_required:\n            issues.append(f\"Missing required fields: {missing_required}\")\n        if unknown_fields:\n            issues.append(f\"Unknown fields: {unknown_fields}\")\n        \n        if issues:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"schema_conformance_check\",\n                message=\"; \".join(issues),\n                details={\n                    \"missing_required\": missing_required,\n                    \"unknown_fields\": unknown_fields\n                }\n            )\n        \n        return QualityCheckResult(\n            passed=True,\n            check_name=\"schema_conformance_check\",\n            message=\"Record conforms to expected schema\"\n        )\n    return _check\n\n\ndef check_timestamp_valid(\n    field: str,\n    max_age_seconds: Optional[int] = None,\n    max_future_seconds: int = 300\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates timestamp fields.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        if field not in record or record[field] is None:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"timestamp_valid_check\",\n                message=f\"Timestamp field {field} is missing or null\"\n            )\n        \n        try:\n            if isinstance(record[field], str):\n                ts = datetime.fromisoformat(record[field].replace('Z', '+00:00'))\n            elif isinstance(record[field], (int, float)):\n                ts = datetime.fromtimestamp(record[field])\n            elif isinstance(record[field], datetime):\n                ts = record[field]\n            else:\n                raise ValueError(f\"Unknown timestamp format: {type(record[field])}\")\n        except Exception as e:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"timestamp_valid_check\",\n                message=f\"Invalid timestamp format: {e}\",\n                details={\"field\": field, \"value\": str(record[field])}\n            )\n        \n        now = datetime.utcnow()\n        \n        # Check if timestamp is too far in the future\n        future_delta = (ts.replace(tzinfo=None) - now).total_seconds()\n        if future_delta > max_future_seconds:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"timestamp_valid_check\",\n                message=f\"Timestamp is {future_delta:.0f}s in the future\",\n                details={\"field\": field, \"future_seconds\": future_delta}\n            )\n        \n        # Check if timestamp is too old\n        if max_age_seconds is not None:\n            age = (now - ts.replace(tzinfo=None)).total_seconds()\n            if age > max_age_seconds:\n                return QualityCheckResult(\n                    passed=False,\n                    check_name=\"timestamp_valid_check\",\n                    message=f\"Timestamp is {age:.0f}s old, max allowed is {max_age_seconds}s\",\n                    details={\"field\": field, \"age_seconds\": age}\n                )\n        \n        return QualityCheckResult(\n            passed=True,\n            check_name=\"timestamp_valid_check\",\n            message=f\"Timestamp {field} is valid\"\n        )\n    return _check\n\n\n# Factory function to create a configured quality checker\n\ndef create_quality_checker(\n    required_fields: Optional[List[str]] = None,\n    field_types: Optional[Dict[str, type]] = None,\n    enable_quarantine: bool = True,\n    quarantine_manager: Optional[QuarantineManager] = None\n) -> QualityChecker:\n    \"\"\"Create a QualityChecker with common checks configured.\"\"\"\n    checker = QualityChecker(\n        quarantine_manager=quarantine_manager,\n        enable_quarantine=enable_quarantine\n    )\n    \n    if required_fields:\n        checker.add_check(check_not_null(required_fields))\n    \n    if field_types:\n        checker.add_check(check_field_type(field_types))\n    \n    return checker\n",
          "UtilityLake_Sentinel/services/observability_api/endpoints.py": "\"\"\"API endpoints for the Observability API service.\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Optional, List\nimport logging\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, status\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\n\n# Health check router\nhealth_router = APIRouter(tags=[\"Health\"])\n\n\nclass HealthStatus(BaseModel):\n    \"\"\"Health status response model.\"\"\"\n    status: str\n    timestamp: datetime\n    version: str = \"1.0.0\"\n    services: dict = {}\n\n\n@health_router.get(\"/health\", response_model=HealthStatus)\nasync def health_check():\n    \"\"\"Check the health of the observability API.\"\"\"\n    return HealthStatus(\n        status=\"healthy\",\n        timestamp=datetime.utcnow(),\n        services={\n            \"api\": \"up\",\n            \"database\": \"up\"\n        }\n    )\n\n\n@health_router.get(\"/health/live\")\nasync def liveness_check():\n    \"\"\"Kubernetes liveness probe endpoint.\"\"\"\n    return {\"status\": \"alive\"}\n\n\n@health_router.get(\"/health/ready\")\nasync def readiness_check():\n    \"\"\"Kubernetes readiness probe endpoint.\"\"\"\n    return {\"status\": \"ready\"}\n\n\n# Metrics router\nmetrics_router = APIRouter(prefix=\"/metrics\", tags=[\"Metrics\"])\n\n\nclass MetricPoint(BaseModel):\n    \"\"\"A single metric data point.\"\"\"\n    timestamp: datetime\n    value: float\n    labels: dict = {}\n\n\nclass MetricSeries(BaseModel):\n    \"\"\"A time series of metric data points.\"\"\"\n    name: str\n    points: List[MetricPoint]\n    unit: Optional[str] = None\n\n\n@metrics_router.get(\"/summary\")\nasync def get_metrics_summary():\n    \"\"\"Get a summary of platform metrics.\"\"\"\n    return {\n        \"ingestion_rate\": 1500.0,\n        \"processing_latency_ms\": 45.2,\n        \"error_rate\": 0.02,\n        \"active_streams\": 12,\n        \"timestamp\": datetime.utcnow().isoformat()\n    }\n\n\n@metrics_router.get(\"/series/{metric_name}\", response_model=MetricSeries)\nasync def get_metric_series(\n    metric_name: str,\n    start_time: Optional[datetime] = None,\n    end_time: Optional[datetime] = None,\n    resolution: str = Query(default=\"1m\", regex=\"^[0-9]+[smhd]$\")\n):\n    \"\"\"Get time series data for a specific metric.\"\"\"\n    if start_time is None:\n        start_time = datetime.utcnow() - timedelta(hours=1)\n    if end_time is None:\n        end_time = datetime.utcnow()\n    \n    # Placeholder - would query actual metrics store\n    return MetricSeries(\n        name=metric_name,\n        points=[\n            MetricPoint(\n                timestamp=start_time + timedelta(minutes=i),\n                value=100.0 + i * 0.5\n            )\n            for i in range(10)\n        ],\n        unit=\"count\"\n    )\n\n\n# Alerts router\nalerts_router = APIRouter(prefix=\"/alerts\", tags=[\"Alerts\"])\n\n\nclass Alert(BaseModel):\n    \"\"\"Alert model.\"\"\"\n    id: str\n    name: str\n    severity: str\n    status: str\n    message: str\n    triggered_at: datetime\n    resolved_at: Optional[datetime] = None\n    labels: dict = {}\n\n\n@alerts_router.get(\"/\", response_model=List[Alert])\nasync def get_alerts(\n    status: Optional[str] = Query(default=None, description=\"Filter by status\"),\n    severity: Optional[str] = Query(default=None, description=\"Filter by severity\")\n):\n    \"\"\"Get active alerts.\"\"\"\n    # Placeholder - would query actual alerting system\n    return [\n        Alert(\n            id=\"alert-001\",\n            name=\"High Error Rate\",\n            severity=\"warning\",\n            status=\"active\",\n            message=\"Error rate exceeded threshold\",\n            triggered_at=datetime.utcnow() - timedelta(minutes=30),\n            labels={\"service\": \"stream_processor\"}\n        )\n    ]\n\n\n@alerts_router.post(\"/{alert_id}/acknowledge\")\nasync def acknowledge_alert(alert_id: str):\n    \"\"\"Acknowledge an alert.\"\"\"\n    return {\"status\": \"acknowledged\", \"alert_id\": alert_id}\n\n\n# Quarantine router\nquarantine_router = APIRouter(prefix=\"/quarantine\", tags=[\"Quarantine\"])\n\n\nclass QuarantineStatus(str):\n    \"\"\"Quarantine status enum values.\"\"\"\n    QUARANTINED = \"quarantined\"\n    PENDING_REPLAY = \"pending_replay\"\n    REPLAYED = \"replayed\"\n    ARCHIVED = \"archived\"\n\n\nclass QuarantinedRecordResponse(BaseModel):\n    \"\"\"Response model for a quarantined record.\"\"\"\n    id: int\n    source_topic: str\n    payload: dict\n    failure_reason: str\n    quarantined_at: datetime\n    status: str\n    storage_path: Optional[str] = None\n    original_timestamp: Optional[datetime] = None\n    replay_attempts: int = 0\n    last_replay_at: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass QuarantinedRecordListResponse(BaseModel):\n    \"\"\"Response model for listing quarantined records.\"\"\"\n    records: List[QuarantinedRecordResponse]\n    total: int\n    page: int\n    page_size: int\n\n\nclass QuarantinedRecordCreate(BaseModel):\n    \"\"\"Request model for creating a quarantined record.\"\"\"\n    source_topic: str\n    payload: dict\n    failure_reason: str\n    storage_path: Optional[str] = None\n    original_timestamp: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass ReplayResponse(BaseModel):\n    \"\"\"Response model for replay action.\"\"\"\n    id: int\n    status: str\n    message: str\n    replay_attempts: int\n\n\nclass QuarantineStatistics(BaseModel):\n    \"\"\"Statistics about quarantined records.\"\"\"\n    total: int\n    by_status: dict\n    by_topic: Optional[dict] = None\n\n\n# In-memory storage for demo purposes\n# In production, this would use the Data Catalog database\n_quarantine_store: List[dict] = []\n_quarantine_id_counter = 0\n\n\ndef _get_db_session():\n    \"\"\"Dependency to get database session.\n    \n    In production, this would return an actual SQLAlchemy session.\n    For now, we use in-memory storage.\n    \"\"\"\n    return None\n\n\n@quarantine_router.get(\"/records\", response_model=QuarantinedRecordListResponse)\nasync def get_quarantined_records(\n    status: Optional[str] = Query(\n        default=None,\n        description=\"Filter by status (quarantined, pending_replay, replayed, archived)\"\n    ),\n    source_topic: Optional[str] = Query(\n        default=None,\n        description=\"Filter by source topic\"\n    ),\n    start_date: Optional[datetime] = Query(\n        default=None,\n        description=\"Filter records quarantined after this date\"\n    ),\n    end_date: Optional[datetime] = Query(\n        default=None,\n        description=\"Filter records quarantined before this date\"\n    ),\n    page: int = Query(default=1, ge=1, description=\"Page number\"),\n    page_size: int = Query(default=50, ge=1, le=500, description=\"Records per page\")\n):\n    \"\"\"Get quarantined records with optional filtering.\n    \n    Supports filtering by:\n    - status: quarantined, pending_replay, replayed, archived\n    - source_topic: the Kafka topic the record originated from\n    - date_range: start_date and end_date for quarantined_at timestamp\n    \"\"\"\n    # Filter records\n    filtered_records = _quarantine_store.copy()\n    \n    if status:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"status\") == status\n        ]\n    \n    if source_topic:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"source_topic\") == source_topic\n        ]\n    \n    if start_date:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"quarantined_at\") and r[\"quarantined_at\"] >= start_date\n        ]\n    \n    if end_date:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"quarantined_at\") and r[\"quarantined_at\"] <= end_date\n        ]\n    \n    # Sort by quarantined_at descending\n    filtered_records.sort(\n        key=lambda x: x.get(\"quarantined_at\", datetime.min),\n        reverse=True\n    )\n    \n    # Paginate\n    total = len(filtered_records)\n    start_idx = (page - 1) * page_size\n    end_idx = start_idx + page_size\n    paginated_records = filtered_records[start_idx:end_idx]\n    \n    return QuarantinedRecordListResponse(\n        records=[QuarantinedRecordResponse(**r) for r in paginated_records],\n        total=total,\n        page=page,\n        page_size=page_size\n    )\n\n\n@quarantine_router.get(\"/records/{record_id}\", response_model=QuarantinedRecordResponse)\nasync def get_quarantined_record(record_id: int):\n    \"\"\"Get a specific quarantined record by ID.\"\"\"\n    for record in _quarantine_store:\n        if record.get(\"id\") == record_id:\n            return QuarantinedRecordResponse(**record)\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n\n\n@quarantine_router.post(\"/records\", response_model=QuarantinedRecordResponse, status_code=status.HTTP_201_CREATED)\nasync def create_quarantined_record(record: QuarantinedRecordCreate):\n    \"\"\"Create a new quarantined record entry.\n    \n    This endpoint is typically called by the stream processor when a record\n    fails data quality validation.\n    \"\"\"\n    global _quarantine_id_counter\n    _quarantine_id_counter += 1\n    \n    new_record = {\n        \"id\": _quarantine_id_counter,\n        \"source_topic\": record.source_topic,\n        \"payload\": record.payload,\n        \"failure_reason\": record.failure_reason,\n        \"quarantined_at\": datetime.utcnow(),\n        \"status\": \"quarantined\",\n        \"storage_path\": record.storage_path,\n        \"original_timestamp\": record.original_timestamp,\n        \"replay_attempts\": 0,\n        \"last_replay_at\": None,\n        \"metadata\": record.metadata\n    }\n    \n    _quarantine_store.append(new_record)\n    logger.info(f\"Created quarantine record {new_record['id']} for topic {record.source_topic}\")\n    \n    return QuarantinedRecordResponse(**new_record)\n\n\n@quarantine_router.post(\"/records/{record_id}/replay\", response_model=ReplayResponse)\nasync def replay_quarantined_record(record_id: int):\n    \"\"\"Initiate replay of a quarantined record.\n    \n    This endpoint updates the record's status to 'pending_replay'.\n    The actual replay logic (re-submitting to the stream processor)\n    is handled by a separate background process.\n    \"\"\"\n    for record in _quarantine_store:\n        if record.get(\"id\") == record_id:\n            # Check if record can be replayed\n            current_status = record.get(\"status\")\n            if current_status == \"replayed\":\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=\"Record has already been successfully replayed\"\n                )\n            \n            # Update status to pending_replay\n            record[\"status\"] = \"pending_replay\"\n            record[\"replay_attempts\"] = record.get(\"replay_attempts\", 0) + 1\n            record[\"last_replay_at\"] = datetime.utcnow()\n            \n            logger.info(\n                f\"Initiated replay for quarantine record {record_id}, \"\n                f\"attempt #{record['replay_attempts']}\"\n            )\n            \n            return ReplayResponse(\n                id=record_id,\n                status=\"pending_replay\",\n                message=\"Record queued for replay. Status will be updated upon completion.\",\n                replay_attempts=record[\"replay_attempts\"]\n            )\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n\n\n@quarantine_router.post(\"/records/{record_id}/archive\", response_model=QuarantinedRecordResponse)\nasync def archive_quarantined_record(record_id: int):\n    \"\"\"Archive a quarantined record.\n    \n    Archived records are kept for audit purposes but are no longer\n    considered for replay.\n    \"\"\"\n    for record in _quarantine_store:\n        if record.get(\"id\") == record_id:\n            record[\"status\"] = \"archived\"\n            logger.info(f\"Archived quarantine record {record_id}\")\n            return QuarantinedRecordResponse(**record)\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n\n\n@quarantine_router.get(\"/statistics\", response_model=QuarantineStatistics)\nasync def get_quarantine_statistics():\n    \"\"\"Get statistics about quarantined records.\"\"\"\n    total = len(_quarantine_store)\n    \n    by_status = {}\n    by_topic = {}\n    \n    for record in _quarantine_store:\n        # Count by status\n        status = record.get(\"status\", \"unknown\")\n        by_status[status] = by_status.get(status, 0) + 1\n        \n        # Count by topic\n        topic = record.get(\"source_topic\", \"unknown\")\n        by_topic[topic] = by_topic.get(topic, 0) + 1\n    \n    return QuarantineStatistics(\n        total=total,\n        by_status=by_status,\n        by_topic=by_topic\n    )\n\n\n@quarantine_router.delete(\"/records/{record_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_quarantined_record(record_id: int):\n    \"\"\"Delete a quarantined record.\n    \n    This permanently removes the record from the quarantine.\n    Use with caution - consider archiving instead.\n    \"\"\"\n    global _quarantine_store\n    \n    for i, record in enumerate(_quarantine_store):\n        if record.get(\"id\") == record_id:\n            del _quarantine_store[i]\n            logger.info(f\"Deleted quarantine record {record_id}\")\n            return\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n",
          "UtilityLake_Sentinel/services/observability_api/main.py": "\"\"\"Main entry point for the Observability API service.\"\"\"\n\nimport logging\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom .endpoints import (\n    health_router,\n    metrics_router,\n    alerts_router,\n    quarantine_router\n)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan handler.\"\"\"\n    logger.info(\"Starting Observability API service...\")\n    yield\n    logger.info(\"Shutting down Observability API service...\")\n\n\napp = FastAPI(\n    title=\"UtilityLake Sentinel Observability API\",\n    description=\"API for monitoring and observability of the UtilityLake Sentinel platform\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(health_router)\napp.include_router(metrics_router, prefix=\"/api/v1\")\napp.include_router(alerts_router, prefix=\"/api/v1\")\napp.include_router(quarantine_router, prefix=\"/api/v1\")\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint.\"\"\"\n    return {\n        \"service\": \"UtilityLake Sentinel Observability API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\"\n    }\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8002)\n",
          "UtilityLake_Sentinel/services/data_catalog_api/main.py": "\"\"\"Main entry point for the Data Catalog API service.\"\"\"\n\nimport logging\nfrom contextlib import asynccontextmanager\nfrom typing import List, Optional\nfrom datetime import datetime\n\nfrom fastapi import FastAPI, HTTPException, Depends, Query, status\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, Session\n\nfrom .models import (\n    Base,\n    DatasetCreate, DatasetUpdate, DatasetResponse, DatasetStatus,\n    DataLineageCreate, DataLineageResponse,\n    QuarantinedRecordCreate, QuarantinedRecordUpdate, QuarantinedRecordResponse,\n    QuarantinedRecordListResponse, QuarantineStatus\n)\nfrom . import crud\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n# Database configuration\nDATABASE_URL = \"sqlite:///./data_catalog.db\"\nengine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False})\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n\ndef get_db():\n    \"\"\"Dependency to get database session.\"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan handler.\"\"\"\n    logger.info(\"Starting Data Catalog API service...\")\n    # Create tables\n    Base.metadata.create_all(bind=engine)\n    logger.info(\"Database tables created/verified\")\n    yield\n    logger.info(\"Shutting down Data Catalog API service...\")\n\n\napp = FastAPI(\n    title=\"UtilityLake Sentinel Data Catalog API\",\n    description=\"API for managing the data catalog of the UtilityLake Sentinel platform\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint.\"\"\"\n    return {\n        \"service\": \"UtilityLake Sentinel Data Catalog API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\"\n    }\n\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"timestamp\": datetime.utcnow().isoformat()}\n\n\n# Dataset endpoints\n\n@app.post(\"/api/v1/datasets\", response_model=DatasetResponse, status_code=status.HTTP_201_CREATED)\nasync def create_dataset(dataset: DatasetCreate, db: Session = Depends(get_db)):\n    \"\"\"Create a new dataset in the catalog.\"\"\"\n    existing = crud.get_dataset_by_name(db, dataset.name)\n    if existing:\n        raise HTTPException(\n            status_code=status.HTTP_409_CONFLICT,\n            detail=f\"Dataset with name '{dataset.name}' already exists\"\n        )\n    return crud.create_dataset(db, dataset)\n\n\n@app.get(\"/api/v1/datasets\", response_model=List[DatasetResponse])\nasync def list_datasets(\n    skip: int = Query(default=0, ge=0),\n    limit: int = Query(default=100, ge=1, le=500),\n    status: Optional[DatasetStatus] = None,\n    db: Session = Depends(get_db)\n):\n    \"\"\"List all datasets with optional filtering.\"\"\"\n    return crud.get_datasets(db, skip=skip, limit=limit, status=status)\n\n\n@app.get(\"/api/v1/datasets/{dataset_id}\", response_model=DatasetResponse)\nasync def get_dataset(dataset_id: int, db: Session = Depends(get_db)):\n    \"\"\"Get a specific dataset by ID.\"\"\"\n    dataset = crud.get_dataset(db, dataset_id)\n    if not dataset:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Dataset with ID {dataset_id} not found\"\n        )\n    return dataset\n\n\n@app.put(\"/api/v1/datasets/{dataset_id}\", response_model=DatasetResponse)\nasync def update_dataset(\n    dataset_id: int,\n    dataset_update: DatasetUpdate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update a dataset.\"\"\"\n    dataset = crud.update_dataset(db, dataset_id, dataset_update)\n    if not dataset:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Dataset with ID {dataset_id} not found\"\n        )\n    return dataset\n\n\n@app.delete(\"/api/v1/datasets/{dataset_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_dataset(dataset_id: int, db: Session = Depends(get_db)):\n    \"\"\"Delete a dataset.\"\"\"\n    if not crud.delete_dataset(db, dataset_id):\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Dataset with ID {dataset_id} not found\"\n        )\n\n\n# Lineage endpoints\n\n@app.post(\"/api/v1/lineage\", response_model=DataLineageResponse, status_code=status.HTTP_201_CREATED)\nasync def create_lineage(lineage: DataLineageCreate, db: Session = Depends(get_db)):\n    \"\"\"Create a new lineage record.\"\"\"\n    return crud.create_lineage(db, lineage)\n\n\n@app.get(\"/api/v1/lineage/{dataset_id}\", response_model=List[DataLineageResponse])\nasync def get_lineage(\n    dataset_id: int,\n    direction: str = Query(default=\"both\", regex=\"^(upstream|downstream|both)$\"),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get lineage for a dataset.\"\"\"\n    return crud.get_lineage_for_dataset(db, dataset_id, direction)\n\n\n# Quarantine endpoints\n\n@app.post(\"/api/v1/quarantine/records\", response_model=QuarantinedRecordResponse, status_code=status.HTTP_201_CREATED)\nasync def create_quarantined_record(\n    record: QuarantinedRecordCreate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Create a new quarantined record entry.\"\"\"\n    return crud.create_quarantined_record(db, record)\n\n\n@app.get(\"/api/v1/quarantine/records\", response_model=QuarantinedRecordListResponse)\nasync def list_quarantined_records(\n    status: Optional[QuarantineStatus] = None,\n    source_topic: Optional[str] = None,\n    start_date: Optional[datetime] = None,\n    end_date: Optional[datetime] = None,\n    page: int = Query(default=1, ge=1),\n    page_size: int = Query(default=50, ge=1, le=500),\n    db: Session = Depends(get_db)\n):\n    \"\"\"List quarantined records with optional filtering.\"\"\"\n    skip = (page - 1) * page_size\n    records, total = crud.get_quarantined_records(\n        db,\n        skip=skip,\n        limit=page_size,\n        status=status,\n        source_topic=source_topic,\n        start_date=start_date,\n        end_date=end_date\n    )\n    return QuarantinedRecordListResponse(\n        records=records,\n        total=total,\n        page=page,\n        page_size=page_size\n    )\n\n\n@app.get(\"/api/v1/quarantine/records/{record_id}\", response_model=QuarantinedRecordResponse)\nasync def get_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Get a specific quarantined record by ID.\"\"\"\n    record = crud.get_quarantined_record(db, record_id)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    return record\n\n\n@app.put(\"/api/v1/quarantine/records/{record_id}\", response_model=QuarantinedRecordResponse)\nasync def update_quarantined_record(\n    record_id: int,\n    record_update: QuarantinedRecordUpdate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update a quarantined record.\"\"\"\n    record = crud.update_quarantined_record(db, record_id, record_update)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    return record\n\n\n@app.post(\"/api/v1/quarantine/records/{record_id}/replay\", response_model=QuarantinedRecordResponse)\nasync def replay_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Initiate replay of a quarantined record.\"\"\"\n    record = crud.get_quarantined_record(db, record_id)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    \n    if record.status == QuarantineStatus.REPLAYED:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Record has already been successfully replayed\"\n        )\n    \n    updated_record = crud.update_quarantined_record_status(\n        db, record_id, QuarantineStatus.PENDING_REPLAY\n    )\n    return updated_record\n\n\n@app.post(\"/api/v1/quarantine/records/{record_id}/archive\", response_model=QuarantinedRecordResponse)\nasync def archive_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Archive a quarantined record.\"\"\"\n    record = crud.get_quarantined_record(db, record_id)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    \n    updated_record = crud.update_quarantined_record_status(\n        db, record_id, QuarantineStatus.ARCHIVED\n    )\n    return updated_record\n\n\n@app.get(\"/api/v1/quarantine/statistics\")\nasync def get_quarantine_statistics(db: Session = Depends(get_db)):\n    \"\"\"Get statistics about quarantined records.\"\"\"\n    return crud.get_quarantine_statistics(db)\n\n\n@app.delete(\"/api/v1/quarantine/records/{record_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Delete a quarantined record.\"\"\"\n    if not crud.delete_quarantined_record(db, record_id):\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\n",
          "UtilityLake_Sentinel/docs/api/openapi.yaml": "openapi: 3.0.3\ninfo:\n  title: UtilityLake Sentinel Platform API\n  description: |\n    Comprehensive API for the UtilityLake Sentinel data platform.\n    This specification covers all platform services including ingestion,\n    data catalog, and observability APIs.\n  version: 1.0.0\n  contact:\n    name: UtilityLake Platform Team\n    email: platform@utilitylake.io\n  license:\n    name: MIT\n    url: https://opensource.org/licenses/MIT\n\nservers:\n  - url: http://localhost:8000\n    description: Ingestion Gateway\n  - url: http://localhost:8001\n    description: Data Catalog API\n  - url: http://localhost:8002\n    description: Observability API\n\ntags:\n  - name: Health\n    description: Health check endpoints\n  - name: Ingestion\n    description: Data ingestion endpoints\n  - name: Datasets\n    description: Dataset catalog management\n  - name: Lineage\n    description: Data lineage tracking\n  - name: Quarantine\n    description: Quarantined records management\n  - name: Metrics\n    description: Platform metrics\n  - name: Alerts\n    description: Alert management\n\npaths:\n  /health:\n    get:\n      tags:\n        - Health\n      summary: Health check\n      description: Check the health status of the service\n      operationId: healthCheck\n      responses:\n        '200':\n          description: Service is healthy\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/HealthStatus'\n\n  /api/v1/ingest:\n    post:\n      tags:\n        - Ingestion\n      summary: Ingest data\n      description: Submit data for ingestion into the platform\n      operationId: ingestData\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/IngestRequest'\n      responses:\n        '202':\n          description: Data accepted for processing\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/IngestResponse'\n        '400':\n          description: Invalid request\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/datasets:\n    get:\n      tags:\n        - Datasets\n      summary: List datasets\n      description: Retrieve a list of all datasets in the catalog\n      operationId: listDatasets\n      parameters:\n        - name: skip\n          in: query\n          schema:\n            type: integer\n            default: 0\n        - name: limit\n          in: query\n          schema:\n            type: integer\n            default: 100\n        - name: status\n          in: query\n          schema:\n            type: string\n            enum: [active, deprecated, archived]\n      responses:\n        '200':\n          description: List of datasets\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  $ref: '#/components/schemas/Dataset'\n    post:\n      tags:\n        - Datasets\n      summary: Create dataset\n      description: Create a new dataset in the catalog\n      operationId: createDataset\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/DatasetCreate'\n      responses:\n        '201':\n          description: Dataset created\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Dataset'\n        '409':\n          description: Dataset already exists\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/datasets/{dataset_id}:\n    get:\n      tags:\n        - Datasets\n      summary: Get dataset\n      description: Retrieve a specific dataset by ID\n      operationId: getDataset\n      parameters:\n        - name: dataset_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Dataset details\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Dataset'\n        '404':\n          description: Dataset not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/records:\n    get:\n      tags:\n        - Quarantine\n      summary: List quarantined records\n      description: |\n        Retrieve quarantined records with optional filtering.\n        Supports filtering by status, source topic, and date range.\n      operationId: listQuarantinedRecords\n      parameters:\n        - name: status\n          in: query\n          description: Filter by quarantine status\n          schema:\n            type: string\n            enum: [quarantined, pending_replay, replayed, archived]\n        - name: source_topic\n          in: query\n          description: Filter by source Kafka topic\n          schema:\n            type: string\n        - name: start_date\n          in: query\n          description: Filter records quarantined after this date\n          schema:\n            type: string\n            format: date-time\n        - name: end_date\n          in: query\n          description: Filter records quarantined before this date\n          schema:\n            type: string\n            format: date-time\n        - name: page\n          in: query\n          description: Page number (1-indexed)\n          schema:\n            type: integer\n            default: 1\n            minimum: 1\n        - name: page_size\n          in: query\n          description: Number of records per page\n          schema:\n            type: integer\n            default: 50\n            minimum: 1\n            maximum: 500\n      responses:\n        '200':\n          description: List of quarantined records\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecordList'\n    post:\n      tags:\n        - Quarantine\n      summary: Create quarantined record\n      description: |\n        Create a new quarantined record entry.\n        Typically called by the stream processor when a record fails validation.\n      operationId: createQuarantinedRecord\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/QuarantinedRecordCreate'\n      responses:\n        '201':\n          description: Quarantined record created\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n\n  /api/v1/quarantine/records/{record_id}:\n    get:\n      tags:\n        - Quarantine\n      summary: Get quarantined record\n      description: Retrieve a specific quarantined record by ID\n      operationId: getQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Quarantined record details\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n    put:\n      tags:\n        - Quarantine\n      summary: Update quarantined record\n      description: Update a quarantined record's metadata\n      operationId: updateQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/QuarantinedRecordUpdate'\n      responses:\n        '200':\n          description: Record updated\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n    delete:\n      tags:\n        - Quarantine\n      summary: Delete quarantined record\n      description: Permanently delete a quarantined record\n      operationId: deleteQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '204':\n          description: Record deleted\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/records/{record_id}/replay:\n    post:\n      tags:\n        - Quarantine\n      summary: Replay quarantined record\n      description: |\n        Initiate replay of a quarantined record.\n        Updates the record's status to 'pending_replay'.\n        The actual replay is handled by a background process.\n      operationId: replayQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Replay initiated\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ReplayResponse'\n        '400':\n          description: Record cannot be replayed\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/records/{record_id}/archive:\n    post:\n      tags:\n        - Quarantine\n      summary: Archive quarantined record\n      description: Archive a quarantined record (no longer eligible for replay)\n      operationId: archiveQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Record archived\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/statistics:\n    get:\n      tags:\n        - Quarantine\n      summary: Get quarantine statistics\n      description: Get aggregated statistics about quarantined records\n      operationId: getQuarantineStatistics\n      responses:\n        '200':\n          description: Quarantine statistics\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantineStatistics'\n\n  /api/v1/metrics/summary:\n    get:\n      tags:\n        - Metrics\n      summary: Get metrics summary\n      description: Get a summary of platform metrics\n      operationId: getMetricsSummary\n      responses:\n        '200':\n          description: Metrics summary\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/MetricsSummary'\n\n  /api/v1/alerts:\n    get:\n      tags:\n        - Alerts\n      summary: List alerts\n      description: Get active alerts\n      operationId: listAlerts\n      parameters:\n        - name: status\n          in: query\n          schema:\n            type: string\n        - name: severity\n          in: query\n          schema:\n            type: string\n      responses:\n        '200':\n          description: List of alerts\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  $ref: '#/components/schemas/Alert'\n\ncomponents:\n  schemas:\n    HealthStatus:\n      type: object\n      properties:\n        status:\n          type: string\n          example: healthy\n        timestamp:\n          type: string\n          format: date-time\n        version:\n          type: string\n          example: \"1.0.0\"\n        services:\n          type: object\n          additionalProperties:\n            type: string\n\n    ErrorResponse:\n      type: object\n      properties:\n        detail:\n          type: string\n          example: Resource not found\n\n    IngestRequest:\n      type: object\n      required:\n        - source\n        - data\n      properties:\n        source:\n          type: string\n          example: sensor-network-1\n        data:\n          type: object\n        metadata:\n          type: object\n\n    IngestResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          example: accepted\n        request_id:\n          type: string\n          format: uuid\n        timestamp:\n          type: string\n          format: date-time\n\n    DatasetCreate:\n      type: object\n      required:\n        - name\n        - storage_location\n      properties:\n        name:\n          type: string\n        description:\n          type: string\n        schema_definition:\n          type: object\n        storage_location:\n          type: string\n        format:\n          type: string\n          default: parquet\n        owner:\n          type: string\n        tags:\n          type: array\n          items:\n            type: string\n        metadata:\n          type: object\n\n    Dataset:\n      allOf:\n        - $ref: '#/components/schemas/DatasetCreate'\n        - type: object\n          properties:\n            id:\n              type: integer\n            status:\n              type: string\n              enum: [active, deprecated, archived]\n            created_at:\n              type: string\n              format: date-time\n            updated_at:\n              type: string\n              format: date-time\n\n    QuarantinedRecordCreate:\n      type: object\n      required:\n        - source_topic\n        - payload\n        - failure_reason\n      properties:\n        source_topic:\n          type: string\n          description: The Kafka topic the record originated from\n          example: utility-meter-readings\n        payload:\n          type: object\n          description: The full data of the failed record\n        failure_reason:\n          type: string\n          description: Description of why the record failed validation\n          example: \"Missing required field: meter_id\"\n        storage_path:\n          type: string\n          description: Path where the record is stored in quarantine\n          example: s3a://utilitylake-quarantine/utility-meter-readings/2024/01/15/abc123.json\n        original_timestamp:\n          type: string\n          format: date-time\n          description: Original timestamp from the source record\n        metadata:\n          type: object\n          description: Additional metadata about the failure\n\n    QuarantinedRecordUpdate:\n      type: object\n      properties:\n        status:\n          type: string\n          enum: [quarantined, pending_replay, replayed, archived]\n        metadata:\n          type: object\n\n    QuarantinedRecord:\n      allOf:\n        - $ref: '#/components/schemas/QuarantinedRecordCreate'\n        - type: object\n          properties:\n            id:\n              type: integer\n            status:\n              type: string\n              enum: [quarantined, pending_replay, replayed, archived]\n            quarantined_at:\n              type: string\n              format: date-time\n            replay_attempts:\n              type: integer\n              default: 0\n            last_replay_at:\n              type: string\n              format: date-time\n              nullable: true\n\n    QuarantinedRecordList:\n      type: object\n      properties:\n        records:\n          type: array\n          items:\n            $ref: '#/components/schemas/QuarantinedRecord'\n        total:\n          type: integer\n          description: Total number of records matching the filter\n        page:\n          type: integer\n          description: Current page number\n        page_size:\n          type: integer\n          description: Number of records per page\n\n    ReplayResponse:\n      type: object\n      properties:\n        id:\n          type: integer\n        status:\n          type: string\n          example: pending_replay\n        message:\n          type: string\n          example: Record queued for replay\n        replay_attempts:\n          type: integer\n\n    QuarantineStatistics:\n      type: object\n      properties:\n        total:\n          type: integer\n          description: Total number of quarantined records\n        by_status:\n          type: object\n          additionalProperties:\n            type: integer\n          description: Count of records by status\n        by_topic:\n          type: object\n          additionalProperties:\n            type: integer\n          description: Count of records by source topic\n\n    MetricsSummary:\n      type: object\n      properties:\n        ingestion_rate:\n          type: number\n        processing_latency_ms:\n          type: number\n        error_rate:\n          type: number\n        active_streams:\n          type: integer\n        timestamp:\n          type: string\n          format: date-time\n\n    Alert:\n      type: object\n      properties:\n        id:\n          type: string\n        name:\n          type: string\n        severity:\n          type: string\n          enum: [info, warning, critical]\n        status:\n          type: string\n          enum: [active, acknowledged, resolved]\n        message:\n          type: string\n        triggered_at:\n          type: string\n          format: date-time\n        resolved_at:\n          type: string\n          format: date-time\n          nullable: true\n        labels:\n          type: object\n          additionalProperties:\n            type: string\n",
          "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py": "\"\"\"Tests for the data quarantine flow in stream processing.\"\"\"\n\nimport json\nimport pytest\nfrom datetime import datetime\nfrom unittest.mock import Mock, MagicMock, patch, call\nfrom typing import Dict, Any\n\nimport sys\nimport os\n\n# Add parent paths to allow imports\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'core_lib'))\n\nfrom services.stream_processor.transforms.quality_checks import (\n    QualityChecker,\n    QualityCheckResult,\n    QuarantineManager,\n    QuarantineResult,\n    DataCatalogClient,\n    check_not_null,\n    check_field_type,\n    check_value_range,\n    check_schema_conformance,\n    create_quality_checker\n)\n\n\nclass TestQualityCheckResult:\n    \"\"\"Tests for QualityCheckResult dataclass.\"\"\"\n    \n    def test_passed_result(self):\n        \"\"\"Test creating a passed result.\"\"\"\n        result = QualityCheckResult(\n            passed=True,\n            check_name=\"test_check\",\n            message=\"All good\"\n        )\n        assert result.passed is True\n        assert result.check_name == \"test_check\"\n        assert result.message == \"All good\"\n        assert result.details is None\n    \n    def test_failed_result_with_details(self):\n        \"\"\"Test creating a failed result with details.\"\"\"\n        result = QualityCheckResult(\n            passed=False,\n            check_name=\"validation_check\",\n            message=\"Validation failed\",\n            details={\"field\": \"meter_id\", \"error\": \"missing\"}\n        )\n        assert result.passed is False\n        assert result.details == {\"field\": \"meter_id\", \"error\": \"missing\"}\n\n\nclass TestBuiltInChecks:\n    \"\"\"Tests for built-in quality check functions.\"\"\"\n    \n    def test_check_not_null_passes(self):\n        \"\"\"Test not_null check passes when fields are present.\"\"\"\n        check = check_not_null([\"id\", \"name\"])\n        record = {\"id\": 1, \"name\": \"test\", \"value\": 100}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_not_null_fails_missing_field(self):\n        \"\"\"Test not_null check fails when field is missing.\"\"\"\n        check = check_not_null([\"id\", \"name\", \"required_field\"])\n        record = {\"id\": 1, \"name\": \"test\"}\n        result = check(record)\n        assert result.passed is False\n        assert \"required_field\" in result.message\n    \n    def test_check_not_null_fails_null_value(self):\n        \"\"\"Test not_null check fails when field is null.\"\"\"\n        check = check_not_null([\"id\", \"name\"])\n        record = {\"id\": 1, \"name\": None}\n        result = check(record)\n        assert result.passed is False\n    \n    def test_check_field_type_passes(self):\n        \"\"\"Test field_type check passes with correct types.\"\"\"\n        check = check_field_type({\"id\": int, \"name\": str, \"value\": float})\n        record = {\"id\": 1, \"name\": \"test\", \"value\": 3.14}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_field_type_fails(self):\n        \"\"\"Test field_type check fails with incorrect types.\"\"\"\n        check = check_field_type({\"id\": int, \"name\": str})\n        record = {\"id\": \"not_an_int\", \"name\": \"test\"}\n        result = check(record)\n        assert result.passed is False\n        assert \"type_errors\" in result.details\n    \n    def test_check_value_range_passes(self):\n        \"\"\"Test value_range check passes within range.\"\"\"\n        check = check_value_range(\"temperature\", min_value=0, max_value=100)\n        record = {\"temperature\": 50}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_value_range_fails_below_min(self):\n        \"\"\"Test value_range check fails below minimum.\"\"\"\n        check = check_value_range(\"temperature\", min_value=0, max_value=100)\n        record = {\"temperature\": -10}\n        result = check(record)\n        assert result.passed is False\n        assert \"below minimum\" in result.message\n    \n    def test_check_value_range_fails_above_max(self):\n        \"\"\"Test value_range check fails above maximum.\"\"\"\n        check = check_value_range(\"temperature\", min_value=0, max_value=100)\n        record = {\"temperature\": 150}\n        result = check(record)\n        assert result.passed is False\n        assert \"above maximum\" in result.message\n    \n    def test_check_schema_conformance_passes(self):\n        \"\"\"Test schema_conformance check passes with valid schema.\"\"\"\n        check = check_schema_conformance(\n            required_fields=[\"id\", \"name\"],\n            optional_fields=[\"description\"]\n        )\n        record = {\"id\": 1, \"name\": \"test\", \"description\": \"optional\"}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_schema_conformance_fails_missing_required(self):\n        \"\"\"Test schema_conformance check fails with missing required field.\"\"\"\n        check = check_schema_conformance(\n            required_fields=[\"id\", \"name\"],\n            optional_fields=[\"description\"]\n        )\n        record = {\"id\": 1}\n        result = check(record)\n        assert result.passed is False\n        assert \"name\" in result.details[\"missing_required\"]\n\n\nclass TestQuarantineManager:\n    \"\"\"Tests for QuarantineManager class.\"\"\"\n    \n    @pytest.fixture\n    def mock_storage_client(self):\n        \"\"\"Create a mock storage client.\"\"\"\n        client = Mock()\n        client.write = Mock(return_value=None)\n        return client\n    \n    @pytest.fixture\n    def mock_catalog_client(self):\n        \"\"\"Create a mock data catalog client.\"\"\"\n        client = Mock(spec=DataCatalogClient)\n        client.create_quarantined_record = Mock(return_value=123)\n        return client\n    \n    @pytest.fixture\n    def quarantine_manager(self, mock_storage_client, mock_catalog_client):\n        \"\"\"Create a QuarantineManager with mocked dependencies.\"\"\"\n        return QuarantineManager(\n            storage_client=mock_storage_client,\n            catalog_client=mock_catalog_client,\n            quarantine_path=\"s3a://test-quarantine/\"\n        )\n    \n    def test_quarantine_record_success(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test successful quarantining of a record.\"\"\"\n        record = {\"meter_id\": \"M001\", \"reading\": \"invalid\"}\n        source_topic = \"utility-meter-readings\"\n        failure_reason = \"Invalid reading format\"\n        \n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=source_topic,\n            failure_reason=failure_reason\n        )\n        \n        # Verify result\n        assert result.success is True\n        assert result.storage_path is not None\n        assert \"test-quarantine\" in result.storage_path\n        assert source_topic in result.storage_path\n        assert result.catalog_id == 123\n        \n        # Verify storage client was called\n        mock_storage_client.write.assert_called_once()\n        call_args = mock_storage_client.write.call_args\n        assert \"path\" in call_args.kwargs or len(call_args.args) > 0\n        \n        # Verify the data written contains the record\n        written_data = call_args.kwargs.get(\"data\") or call_args.args[1]\n        parsed_data = json.loads(written_data)\n        assert parsed_data[\"record\"] == record\n        assert parsed_data[\"quarantine_metadata\"][\"failure_reason\"] == failure_reason\n        \n        # Verify catalog client was called\n        mock_catalog_client.create_quarantined_record.assert_called_once_with(\n            source_topic=source_topic,\n            payload=record,\n            failure_reason=failure_reason,\n            storage_path=result.storage_path,\n            original_timestamp=None,\n            metadata=None\n        )\n    \n    def test_quarantine_record_with_metadata(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test quarantining a record with additional metadata.\"\"\"\n        record = {\"sensor_id\": \"S001\", \"value\": -999}\n        source_topic = \"sensor-data\"\n        failure_reason = \"Value out of range\"\n        original_timestamp = datetime(2024, 1, 15, 10, 30, 0)\n        metadata = {\"pipeline_stage\": \"validation\", \"attempt\": 1}\n        \n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=source_topic,\n            failure_reason=failure_reason,\n            original_timestamp=original_timestamp,\n            metadata=metadata\n        )\n        \n        assert result.success is True\n        \n        # Verify catalog client received metadata\n        mock_catalog_client.create_quarantined_record.assert_called_once()\n        call_kwargs = mock_catalog_client.create_quarantined_record.call_args.kwargs\n        assert call_kwargs[\"original_timestamp\"] == original_timestamp\n        assert call_kwargs[\"metadata\"] == metadata\n    \n    def test_quarantine_record_storage_failure(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test quarantine fails gracefully when storage write fails.\"\"\"\n        mock_storage_client.write.side_effect = Exception(\"Storage unavailable\")\n        \n        record = {\"id\": 1}\n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=\"test-topic\",\n            failure_reason=\"Test failure\"\n        )\n        \n        assert result.success is False\n        assert \"Storage unavailable\" in result.error\n        \n        # Catalog should not be called if storage fails\n        mock_catalog_client.create_quarantined_record.assert_not_called()\n    \n    def test_quarantine_record_catalog_failure_still_succeeds(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test quarantine succeeds even if catalog logging fails.\"\"\"\n        mock_catalog_client.create_quarantined_record.side_effect = Exception(\"Catalog unavailable\")\n        \n        record = {\"id\": 1}\n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=\"test-topic\",\n            failure_reason=\"Test failure\"\n        )\n        \n        # Should still succeed - storage write worked\n        assert result.success is True\n        assert result.storage_path is not None\n        assert result.catalog_id is None  # Catalog failed\n\n\nclass TestQualityChecker:\n    \"\"\"Tests for QualityChecker class.\"\"\"\n    \n    @pytest.fixture\n    def mock_quarantine_manager(self):\n        \"\"\"Create a mock quarantine manager.\"\"\"\n        manager = Mock(spec=QuarantineManager)\n        manager.quarantine_record = Mock(return_value=QuarantineResult(\n            success=True,\n            storage_path=\"s3a://quarantine/test/record.json\",\n            catalog_id=456\n        ))\n        return manager\n    \n    @pytest.fixture\n    def quality_checker(self, mock_quarantine_manager):\n        \"\"\"Create a QualityChecker with mocked quarantine manager.\"\"\"\n        checker = QualityChecker(\n            quarantine_manager=mock_quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"id\", \"value\"]))\n        checker.add_check(check_field_type({\"id\": int, \"value\": (int, float)}))\n        return checker\n    \n    def test_process_valid_record(self, quality_checker, mock_quarantine_manager):\n        \"\"\"Test processing a valid record passes all checks.\"\"\"\n        record = {\"id\": 1, \"value\": 100.5}\n        passed, quarantine_result = quality_checker.process_record(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert passed is True\n        assert quarantine_result is None\n        mock_quarantine_manager.quarantine_record.assert_not_called()\n    \n    def test_process_invalid_record_quarantined(self, quality_checker, mock_quarantine_manager):\n        \"\"\"Test processing an invalid record triggers quarantine.\"\"\"\n        # Missing 'value' field\n        record = {\"id\": 1}\n        passed, quarantine_result = quality_checker.process_record(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert passed is False\n        assert quarantine_result is not None\n        assert quarantine_result.success is True\n        \n        # Verify quarantine was called\n        mock_quarantine_manager.quarantine_record.assert_called_once()\n        call_kwargs = mock_quarantine_manager.quarantine_record.call_args.kwargs\n        assert call_kwargs[\"record\"] == record\n        assert call_kwargs[\"source_topic\"] == \"test-topic\"\n        assert \"value\" in call_kwargs[\"failure_reason\"]  # Should mention missing field\n    \n    def test_process_record_with_type_error_quarantined(self, quality_checker, mock_quarantine_manager):\n        \"\"\"Test record with wrong type is quarantined.\"\"\"\n        record = {\"id\": \"not_an_int\", \"value\": 100}\n        passed, quarantine_result = quality_checker.process_record(\n            record=record,\n            source_topic=\"sensor-data\"\n        )\n        \n        assert passed is False\n        mock_quarantine_manager.quarantine_record.assert_called_once()\n    \n    def test_process_record_quarantine_disabled(self, mock_quarantine_manager):\n        \"\"\"Test quarantine is not triggered when disabled.\"\"\"\n        checker = QualityChecker(\n            quarantine_manager=mock_quarantine_manager,\n            enable_quarantine=False\n        )\n        checker.add_check(check_not_null([\"id\"]))\n        \n        record = {}  # Missing required field\n        passed, quarantine_result = checker.process_record(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert passed is False\n        assert quarantine_result is None\n        mock_quarantine_manager.quarantine_record.assert_not_called()\n    \n    def test_run_checks_returns_all_results(self, quality_checker):\n        \"\"\"Test run_checks returns results for all checks.\"\"\"\n        record = {\"id\": 1, \"value\": 100}\n        all_passed, results = quality_checker.run_checks(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert all_passed is True\n        assert len(results) == 2  # Two checks added\n        assert all(r.passed for r in results)\n\n\nclass TestIntegrationQuarantineFlow:\n    \"\"\"Integration tests for the complete quarantine flow.\"\"\"\n    \n    def test_malformed_record_through_pipeline(self):\n        \"\"\"Test that a malformed record is properly quarantined.\n        \n        This test verifies:\n        1. StorageClient.write is called with correct quarantine path and data\n        2. DataCatalogClient.create_quarantined_record is called with correct metadata\n        \"\"\"\n        # Create mocks\n        mock_storage = Mock()\n        mock_storage.write = Mock(return_value=None)\n        \n        mock_catalog = Mock(spec=DataCatalogClient)\n        mock_catalog.create_quarantined_record = Mock(return_value=789)\n        \n        # Create quarantine manager with mocks\n        quarantine_manager = QuarantineManager(\n            storage_client=mock_storage,\n            catalog_client=mock_catalog,\n            quarantine_path=\"s3a://utilitylake-quarantine/\"\n        )\n        \n        # Create quality checker\n        checker = QualityChecker(\n            quarantine_manager=quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"meter_id\", \"reading\", \"timestamp\"]))\n        checker.add_check(check_field_type({\"reading\": (int, float)}))\n        checker.add_check(check_value_range(\"reading\", min_value=0, max_value=10000))\n        \n        # Create a malformed record (missing meter_id, invalid reading type)\n        malformed_record = {\n            \"reading\": \"not_a_number\",\n            \"timestamp\": \"2024-01-15T10:30:00Z\"\n        }\n        source_topic = \"utility-meter-readings\"\n        \n        # Process the malformed record\n        passed, quarantine_result = checker.process_record(\n            record=malformed_record,\n            source_topic=source_topic,\n            original_timestamp=datetime(2024, 1, 15, 10, 30, 0)\n        )\n        \n        # Assertions\n        assert passed is False, \"Malformed record should fail quality checks\"\n        assert quarantine_result is not None, \"Quarantine result should be returned\"\n        assert quarantine_result.success is True, \"Quarantine should succeed\"\n        \n        # Verify StorageClient.write was called correctly\n        mock_storage.write.assert_called_once()\n        storage_call = mock_storage.write.call_args\n        \n        # Check path contains quarantine base path and topic\n        storage_path = storage_call.kwargs.get(\"path\") or storage_call.args[0]\n        assert \"utilitylake-quarantine\" in storage_path, \n            f\"Storage path should contain quarantine path: {storage_path}\"\n        assert source_topic in storage_path, \n            f\"Storage path should contain source topic: {storage_path}\"\n        \n        # Check data contains the original record\n        storage_data = storage_call.kwargs.get(\"data\") or storage_call.args[1]\n        parsed_data = json.loads(storage_data)\n        assert parsed_data[\"record\"] == malformed_record, \n            \"Stored data should contain original record\"\n        assert parsed_data[\"quarantine_metadata\"][\"source_topic\"] == source_topic, \n            \"Stored metadata should contain source topic\"\n        assert \"meter_id\" in parsed_data[\"quarantine_metadata\"][\"failure_reason\"], \n            \"Failure reason should mention missing meter_id\"\n        \n        # Verify DataCatalogClient.create_quarantined_record was called correctly\n        mock_catalog.create_quarantined_record.assert_called_once()\n        catalog_call = mock_catalog.create_quarantined_record.call_args\n        catalog_kwargs = catalog_call.kwargs\n        \n        assert catalog_kwargs[\"source_topic\"] == source_topic, \n            \"Catalog should receive correct source topic\"\n        assert catalog_kwargs[\"payload\"] == malformed_record, \n            \"Catalog should receive original payload\"\n        assert \"meter_id\" in catalog_kwargs[\"failure_reason\"], \n            \"Catalog failure reason should mention missing field\"\n        assert catalog_kwargs[\"storage_path\"] == quarantine_result.storage_path, \n            \"Catalog should receive storage path\"\n    \n    def test_valid_record_not_quarantined(self):\n        \"\"\"Test that a valid record is not quarantined.\"\"\"\n        mock_storage = Mock()\n        mock_catalog = Mock(spec=DataCatalogClient)\n        \n        quarantine_manager = QuarantineManager(\n            storage_client=mock_storage,\n            catalog_client=mock_catalog,\n            quarantine_path=\"s3a://utilitylake-quarantine/\"\n        )\n        \n        checker = QualityChecker(\n            quarantine_manager=quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"meter_id\", \"reading\"]))\n        checker.add_check(check_field_type({\"reading\": (int, float)}))\n        \n        # Valid record\n        valid_record = {\n            \"meter_id\": \"M001\",\n            \"reading\": 1234.5,\n            \"timestamp\": \"2024-01-15T10:30:00Z\"\n        }\n        \n        passed, quarantine_result = checker.process_record(\n            record=valid_record,\n            source_topic=\"utility-meter-readings\"\n        )\n        \n        assert passed is True\n        assert quarantine_result is None\n        mock_storage.write.assert_not_called()\n        mock_catalog.create_quarantined_record.assert_not_called()\n    \n    def test_multiple_validation_failures_captured(self):\n        \"\"\"Test that multiple validation failures are all captured in failure reason.\"\"\"\n        mock_storage = Mock()\n        mock_storage.write = Mock(return_value=None)\n        \n        mock_catalog = Mock(spec=DataCatalogClient)\n        mock_catalog.create_quarantined_record = Mock(return_value=100)\n        \n        quarantine_manager = QuarantineManager(\n            storage_client=mock_storage,\n            catalog_client=mock_catalog,\n            quarantine_path=\"s3a://quarantine/\"\n        )\n        \n        checker = QualityChecker(\n            quarantine_manager=quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"field_a\", \"field_b\"]))\n        checker.add_check(check_field_type({\"field_c\": int}))\n        \n        # Record with multiple issues\n        bad_record = {\n            \"field_c\": \"not_an_int\"  # Missing field_a, field_b, and wrong type for field_c\n        }\n        \n        passed, result = checker.process_record(\n            record=bad_record,\n            source_topic=\"test\"\n        )\n        \n        assert passed is False\n        \n        # Check that failure reason contains all issues\n        catalog_call = mock_catalog.create_quarantined_record.call_args\n        failure_reason = catalog_call.kwargs[\"failure_reason\"]\n        \n        assert \"field_a\" in failure_reason or \"field_b\" in failure_reason, \n            \"Failure reason should mention missing fields\"\n\n\nclass TestCreateQualityChecker:\n    \"\"\"Tests for the create_quality_checker factory function.\"\"\"\n    \n    def test_create_with_required_fields(self):\n        \"\"\"Test creating checker with required fields.\"\"\"\n        checker = create_quality_checker(\n            required_fields=[\"id\", \"name\"],\n            enable_quarantine=False\n        )\n        \n        # Valid record\n        passed, _ = checker.run_checks({\"id\": 1, \"name\": \"test\"})\n        assert passed is True\n        \n        # Invalid record\n        passed, _ = checker.run_checks({\"id\": 1})\n        assert passed is False\n    \n    def test_create_with_field_types(self):\n        \"\"\"Test creating checker with field types.\"\"\"\n        checker = create_quality_checker(\n            field_types={\"count\": int, \"name\": str},\n            enable_quarantine=False\n        )\n        \n        # Valid record\n        passed, _ = checker.run_checks({\"count\": 10, \"name\": \"test\"})\n        assert passed is True\n        \n        # Invalid record\n        passed, _ = checker.run_checks({\"count\": \"ten\", \"name\": \"test\"})\n        assert passed is False\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])\n",
          "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py": "\"\"\"Storage client for UtilityLake Sentinel platform.\"\"\"\n\nimport os\nimport json\nimport logging\nfrom typing import Any, Optional, Union\nfrom pathlib import Path\nfrom abc import ABC, abstractmethod\n\nlogger = logging.getLogger(__name__)\n\n\nclass StorageBackend(ABC):\n    \"\"\"Abstract base class for storage backends.\"\"\"\n    \n    @abstractmethod\n    def read(self, path: str) -> str:\n        \"\"\"Read data from the given path.\"\"\"\n        pass\n    \n    @abstractmethod\n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to the given path.\"\"\"\n        pass\n    \n    @abstractmethod\n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists.\"\"\"\n        pass\n    \n    @abstractmethod\n    def delete(self, path: str) -> bool:\n        \"\"\"Delete data at the given path.\"\"\"\n        pass\n    \n    @abstractmethod\n    def list_files(self, path: str) -> list:\n        \"\"\"List files at the given path.\"\"\"\n        pass\n\n\nclass LocalStorageBackend(StorageBackend):\n    \"\"\"Local filesystem storage backend.\"\"\"\n    \n    def __init__(self, base_path: str = \"/tmp/utilitylake\"):\n        self.base_path = base_path\n        os.makedirs(base_path, exist_ok=True)\n    \n    def _resolve_path(self, path: str) -> str:\n        \"\"\"Resolve a path, handling file:// prefix.\"\"\"\n        if path.startswith(\"file://\"):\n            return path[7:]\n        return path\n    \n    def read(self, path: str) -> str:\n        \"\"\"Read data from a local file.\"\"\"\n        resolved_path = self._resolve_path(path)\n        with open(resolved_path, 'r') as f:\n            return f.read()\n    \n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to a local file.\"\"\"\n        resolved_path = self._resolve_path(path)\n        # Create parent directories if needed\n        parent_dir = os.path.dirname(resolved_path)\n        if parent_dir:\n            os.makedirs(parent_dir, exist_ok=True)\n        with open(resolved_path, 'w') as f:\n            f.write(data)\n        logger.debug(f\"Wrote {len(data)} bytes to {resolved_path}\")\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a local file exists.\"\"\"\n        resolved_path = self._resolve_path(path)\n        return os.path.exists(resolved_path)\n    \n    def delete(self, path: str) -> bool:\n        \"\"\"Delete a local file.\"\"\"\n        resolved_path = self._resolve_path(path)\n        if os.path.exists(resolved_path):\n            os.remove(resolved_path)\n            return True\n        return False\n    \n    def list_files(self, path: str) -> list:\n        \"\"\"List files in a local directory.\"\"\"\n        resolved_path = self._resolve_path(path)\n        if os.path.isdir(resolved_path):\n            return os.listdir(resolved_path)\n        return []\n\n\nclass S3StorageBackend(StorageBackend):\n    \"\"\"S3-compatible storage backend.\n    \n    Note: This is a placeholder implementation.\n    In production, this would use boto3 or similar.\n    \"\"\"\n    \n    def __init__(self, endpoint_url: Optional[str] = None):\n        self.endpoint_url = endpoint_url\n        self._storage: dict = {}  # In-memory mock for testing\n        logger.info(f\"S3 storage backend initialized (mock mode)\")\n    \n    def _normalize_path(self, path: str) -> str:\n        \"\"\"Normalize S3 path, removing s3:// or s3a:// prefix.\"\"\"\n        if path.startswith(\"s3a://\"):\n            return path[6:]\n        if path.startswith(\"s3://\"):\n            return path[5:]\n        return path\n    \n    def read(self, path: str) -> str:\n        \"\"\"Read data from S3.\"\"\"\n        normalized = self._normalize_path(path)\n        if normalized not in self._storage:\n            raise FileNotFoundError(f\"Object not found: {path}\")\n        return self._storage[normalized]\n    \n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to S3.\"\"\"\n        normalized = self._normalize_path(path)\n        self._storage[normalized] = data\n        logger.debug(f\"Wrote {len(data)} bytes to s3://{normalized}\")\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if an S3 object exists.\"\"\"\n        normalized = self._normalize_path(path)\n        return normalized in self._storage\n    \n    def delete(self, path: str) -> bool:\n        \"\"\"Delete an S3 object.\"\"\"\n        normalized = self._normalize_path(path)\n        if normalized in self._storage:\n            del self._storage[normalized]\n            return True\n        return False\n    \n    def list_files(self, path: str) -> list:\n        \"\"\"List objects with a given prefix.\"\"\"\n        normalized = self._normalize_path(path)\n        return [\n            key for key in self._storage.keys()\n            if key.startswith(normalized)\n        ]\n\n\nclass StorageClient:\n    \"\"\"Unified storage client for UtilityLake Sentinel.\n    \n    Automatically selects the appropriate backend based on the path prefix.\n    \"\"\"\n    \n    def __init__(\n        self,\n        default_backend: Optional[StorageBackend] = None,\n        s3_endpoint_url: Optional[str] = None\n    ):\n        self._local_backend = LocalStorageBackend()\n        self._s3_backend = S3StorageBackend(endpoint_url=s3_endpoint_url)\n        self._default_backend = default_backend or self._local_backend\n    \n    def _get_backend(self, path: str) -> StorageBackend:\n        \"\"\"Get the appropriate backend for a path.\"\"\"\n        if path.startswith(\"s3://\") or path.startswith(\"s3a://\"):\n            return self._s3_backend\n        if path.startswith(\"file://\"):\n            return self._local_backend\n        return self._default_backend\n    \n    def read(self, path: str) -> str:\n        \"\"\"Read data from storage.\"\"\"\n        backend = self._get_backend(path)\n        return backend.read(path)\n    \n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to storage.\"\"\"\n        backend = self._get_backend(path)\n        backend.write(path, data)\n    \n    def read_json(self, path: str) -> Any:\n        \"\"\"Read and parse JSON data from storage.\"\"\"\n        data = self.read(path)\n        return json.loads(data)\n    \n    def write_json(self, path: str, data: Any, indent: int = 2) -> None:\n        \"\"\"Write data as JSON to storage.\"\"\"\n        json_str = json.dumps(data, indent=indent, default=str)\n        self.write(path, json_str)\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists in storage.\"\"\"\n        backend = self._get_backend(path)\n        return backend.exists(path)\n    \n    def delete(self, path: str) -> bool:\n        \"\"\"Delete data from storage.\"\"\"\n        backend = self._get_backend(path)\n        return backend.delete(path)\n    \n    def list_files(self, path: str) -> list:\n        \"\"\"List files at a path.\"\"\"\n        backend = self._get_backend(path)\n        return backend.list_files(path)\n"
        },
        "generated_files": [
          "UtilityLake_Sentinel/configs/default.yml",
          "UtilityLake_Sentinel/configs/development.yml",
          "UtilityLake_Sentinel/services/data_catalog_api/models.py",
          "UtilityLake_Sentinel/services/data_catalog_api/crud.py",
          "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py",
          "UtilityLake_Sentinel/services/observability_api/endpoints.py",
          "UtilityLake_Sentinel/services/observability_api/main.py",
          "UtilityLake_Sentinel/services/data_catalog_api/main.py",
          "UtilityLake_Sentinel/docs/api/openapi.yaml",
          "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py",
          "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.6957515751575158,
              "dependency_traversal_accuracy": 0.634509242742249,
              "cross_file_reasoning_depth": 0.3238636363636364,
              "system_thinking_score": 0.5381461160580213,
              "robustness_score": 0.40668077388149937,
              "comprehensiveness_score": 0.7046371485792019,
              "innovation_score": 0.37014056831922615,
              "solution_elegance_score": 0.45570356603338663
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.08696894689468948,
              "dependency_traversal_weighted": 0.07931365534278112,
              "cross_file_reasoning_weighted": 0.04048295454545455,
              "system_thinking_weighted": 0.06726826450725266,
              "robustness_weighted": 0.05083509673518742,
              "comprehensiveness_weighted": 0.08807964357240024,
              "innovation_weighted": 0.04626757103990327,
              "solution_elegance_weighted": 0.05696294575417333
            },
            "total_software_engineering_score": 0.5161790783918421
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.0,
              "execution_time": 0.7128126621246338,
              "errors": [
                "  File \"UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py\", line 423",
                "    assert \"utilitylake-quarantine\" in storage_path, ",
                "                                                     ^",
                "SyntaxError: invalid syntax",
                "  File \"UtilityLake_Sentinel/docs/api/openapi.py\", line 275",
                "    description: Update a quarantined record's metadata",
                "                                            ^",
                "SyntaxError: unterminated string literal (detected at line 275)",
                "  File \"UtilityLake_Sentinel/configs/development.py\", line 3",
                "    application:",
                "                ^",
                "SyntaxError: invalid syntax",
                "  File \"UtilityLake_Sentinel/configs/default.py\", line 3",
                "    application:",
                "                ^",
                "SyntaxError: invalid syntax"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "UtilityLake_Sentinel/configs/default.yml",
                "UtilityLake_Sentinel/configs/development.yml",
                "UtilityLake_Sentinel/services/data_catalog_api/models.py",
                "UtilityLake_Sentinel/services/data_catalog_api/crud.py",
                "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py",
                "UtilityLake_Sentinel/services/observability_api/endpoints.py",
                "UtilityLake_Sentinel/services/observability_api/main.py",
                "UtilityLake_Sentinel/services/data_catalog_api/main.py",
                "UtilityLake_Sentinel/docs/api/openapi.yaml",
                "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py",
                "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py"
              ],
              "scoring_breakdown": {
                "no_credit": 0.0
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 11,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 9 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.31497951619196257,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.0,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.31497951619196257,
              "idc_weight": 0.2,
              "total_functional_score": 0.3729959032383925
            }
          },
          "code_quality_details": {
            "files_analyzed": 11,
            "quality_checks": {
              "UtilityLake_Sentinel/configs/default.yml": {
                "line_count": 53,
                "non_empty_lines": 44,
                "comment_lines": 1,
                "comment_ratio": 0.022727272727272728,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.7
              },
              "UtilityLake_Sentinel/configs/development.yml": {
                "line_count": 57,
                "non_empty_lines": 47,
                "comment_lines": 1,
                "comment_ratio": 0.02127659574468085,
                "function_count": 0,
                "class_count": 0,
                "import_count": 0,
                "quality_score": 0.7
              },
              "UtilityLake_Sentinel/services/data_catalog_api/models.py": {
                "line_count": 187,
                "non_empty_lines": 140,
                "comment_lines": 3,
                "comment_ratio": 0.02142857142857143,
                "function_count": 0,
                "class_count": 21,
                "import_count": 14,
                "quality_score": 0.7
              },
              "UtilityLake_Sentinel/services/data_catalog_api/crud.py": {
                "line_count": 263,
                "non_empty_lines": 213,
                "comment_lines": 6,
                "comment_ratio": 0.028169014084507043,
                "function_count": 15,
                "class_count": 0,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py": {
                "line_count": 485,
                "non_empty_lines": 419,
                "comment_lines": 10,
                "comment_ratio": 0.02386634844868735,
                "function_count": 20,
                "class_count": 6,
                "import_count": 16,
                "quality_score": 0.7999999999999999
              },
              "UtilityLake_Sentinel/services/observability_api/endpoints.py": {
                "line_count": 444,
                "non_empty_lines": 352,
                "comment_lines": 15,
                "comment_ratio": 0.04261363636363636,
                "function_count": 15,
                "class_count": 10,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "UtilityLake_Sentinel/services/observability_api/main.py": {
                "line_count": 68,
                "non_empty_lines": 53,
                "comment_lines": 3,
                "comment_ratio": 0.05660377358490566,
                "function_count": 2,
                "class_count": 0,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "UtilityLake_Sentinel/services/data_catalog_api/main.py": {
                "line_count": 294,
                "non_empty_lines": 239,
                "comment_lines": 7,
                "comment_ratio": 0.029288702928870293,
                "function_count": 19,
                "class_count": 0,
                "import_count": 20,
                "quality_score": 0.7999999999999999
              },
              "UtilityLake_Sentinel/docs/api/openapi.yaml": {
                "line_count": 688,
                "non_empty_lines": 660,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 0,
                "import_count": 1,
                "quality_score": 0.5
              },
              "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py": {
                "line_count": 564,
                "non_empty_lines": 465,
                "comment_lines": 27,
                "comment_ratio": 0.05806451612903226,
                "function_count": 31,
                "class_count": 10,
                "import_count": 12,
                "quality_score": 0.6
              },
              "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py": {
                "line_count": 205,
                "non_empty_lines": 164,
                "comment_lines": 1,
                "comment_ratio": 0.006097560975609756,
                "function_count": 28,
                "class_count": 5,
                "import_count": 15,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7490909090909089,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.9372619047619049,
              "multi_session_memory_retention": 0.9192424242424242
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.4686309523809524,
              "multi_session_memory_retention_weighted": 0.4596212121212121
            },
            "total_longcontext_utilization_score": 0.9282521645021645
          }
        },
        "timestamp": "2026-01-14T21:42:25.736667"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_system_automation_hard_062_feature_implementation_expert_01",
        "scenario_title": "Implement Proactive Remediation Engine for S3 Security Findings",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5360174270613095,
        "functional_correctness_score": 0.4866102635228849,
        "code_quality_score": 0.8199999999999998,
        "longcontext_utilization_score": 0.5122646280734516,
        "total_score": 2.878082563443672,
        "generation_time": 136.45841193199158,
        "code_files_generated": 7,
        "total_lines_generated": 1338,
        "parsing_success": true,
        "solution_code": {
          "src/remediation_engine.py": "\"\"\"Proactive Remediation Engine for NimbusCustodian.\n\nThis module provides automated remediation capabilities for security findings,\nstarting with S3 bucket public read ACL remediation.\n\"\"\"\n\nimport logging\nfrom typing import Optional, Any, Dict\n\nlogger = logging.getLogger(__name__)\n\n\nclass RemediationError(Exception):\n    \"\"\"Exception raised when remediation fails.\"\"\"\n    pass\n\n\nclass RemediationEngine:\n    \"\"\"Engine for automated remediation of security findings.\"\"\"\n    \n    def __init__(self, aws_client_factory=None):\n        \"\"\"Initialize the remediation engine.\n        \n        Args:\n            aws_client_factory: Optional callable that returns AWS clients.\n                               If None, will use utils.get_aws_client.\n        \"\"\"\n        self._aws_client_factory = aws_client_factory\n    \n    def _get_s3_client(self):\n        \"\"\"Get an S3 client using the configured factory.\"\"\"\n        if self._aws_client_factory:\n            return self._aws_client_factory('s3')\n        else:\n            from src.utils import get_aws_client\n            return get_aws_client('s3')\n    \n    def remediate_s3_public_read_acl(self, bucket_name: str) -> bool:\n        \"\"\"Remediate an S3 bucket with public read ACL by setting it to private.\n        \n        Args:\n            bucket_name: The name of the S3 bucket to remediate.\n            \n        Returns:\n            bool: True if remediation was successful, False otherwise.\n            \n        Raises:\n            RemediationError: If remediation fails due to an error.\n        \"\"\"\n        if not bucket_name:\n            raise RemediationError(\"Bucket name cannot be empty\")\n        \n        try:\n            s3_client = self._get_s3_client()\n            s3_client.put_bucket_acl(\n                Bucket=bucket_name,\n                ACL='private'\n            )\n            logger.info(f\"Successfully remediated S3 bucket {bucket_name} by setting ACL to private.\")\n            return True\n        except Exception as e:\n            error_msg = f\"Failed to remediate S3 bucket {bucket_name}: {str(e)}\"\n            logger.error(error_msg)\n            raise RemediationError(error_msg) from e\n    \n    def remediate_finding(self, finding: Any) -> bool:\n        \"\"\"Remediate a security finding based on its type.\n        \n        Args:\n            finding: The finding object to remediate.\n            \n        Returns:\n            bool: True if remediation was successful, False otherwise.\n        \"\"\"\n        finding_type = getattr(finding, 'type', None) or finding.get('type') if isinstance(finding, dict) else None\n        \n        if finding_type == 'S3_PUBLIC_READ_ACL':\n            # Extract bucket name from finding\n            if isinstance(finding, dict):\n                bucket_name = finding.get('resource', {}).get('bucket_name') or finding.get('bucket_name')\n            else:\n                resource = getattr(finding, 'resource', {})\n                bucket_name = resource.get('bucket_name') if isinstance(resource, dict) else getattr(finding, 'bucket_name', None)\n            \n            if not bucket_name:\n                logger.error(\"Cannot remediate: bucket_name not found in finding\")\n                return False\n            \n            try:\n                success = self.remediate_s3_public_read_acl(bucket_name)\n                if success and hasattr(finding, 'update_status'):\n                    finding.update_status('REMEDIATED')\n                return success\n            except RemediationError:\n                return False\n        else:\n            logger.warning(f\"No remediation handler for finding type: {finding_type}\")\n            return False\n\n\n# Module-level convenience functions\n_default_engine = None\n\n\ndef get_remediation_engine(aws_client_factory=None) -> RemediationEngine:\n    \"\"\"Get or create a remediation engine instance.\n    \n    Args:\n        aws_client_factory: Optional callable for creating AWS clients.\n        \n    Returns:\n        RemediationEngine: The remediation engine instance.\n    \"\"\"\n    global _default_engine\n    if aws_client_factory:\n        return RemediationEngine(aws_client_factory)\n    if _default_engine is None:\n        _default_engine = RemediationEngine()\n    return _default_engine\n\n\ndef remediate_s3_public_read_acl(bucket_name: str) -> bool:\n    \"\"\"Convenience function to remediate S3 public read ACL.\n    \n    Args:\n        bucket_name: The name of the S3 bucket to remediate.\n        \n    Returns:\n        bool: True if remediation was successful.\n    \"\"\"\n    engine = get_remediation_engine()\n    return engine.remediate_s3_public_read_acl(bucket_name)\n\n\ndef remediate_finding(finding: Any) -> bool:\n    \"\"\"Convenience function to remediate a security finding.\n    \n    Args:\n        finding: The finding object to remediate.\n        \n    Returns:\n        bool: True if remediation was successful.\n    \"\"\"\n    engine = get_remediation_engine()\n    return engine.remediate_finding(finding)\n",
          "src/module_7.py": "\"\"\"Central Event Handler Module for NimbusCustodian.\n\nThis module handles events from various sources including security findings\nand triggers appropriate actions including remediation when enabled.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional, Callable, List\n\nlogger = logging.getLogger(__name__)\n\n# Global configuration object - assumed to be loaded elsewhere\nconfig = {\n    'remediation': {\n        'enabled': False\n    }\n}\n\n\nclass EventHandler:\n    \"\"\"Central event handler for processing system events.\"\"\"\n    \n    def __init__(self, config_provider: Optional[Callable] = None):\n        \"\"\"Initialize the event handler.\n        \n        Args:\n            config_provider: Optional callable that returns configuration.\n        \"\"\"\n        self._config_provider = config_provider\n        self._handlers: Dict[str, List[Callable]] = {}\n        self._remediation_engine = None\n    \n    def _get_config(self) -> Dict:\n        \"\"\"Get the current configuration.\"\"\"\n        if self._config_provider:\n            return self._config_provider()\n        return config\n    \n    def _is_remediation_enabled(self) -> bool:\n        \"\"\"Check if remediation is enabled in configuration.\"\"\"\n        cfg = self._get_config()\n        remediation_config = cfg.get('remediation', {})\n        return remediation_config.get('enabled', False)\n    \n    def _get_remediation_engine(self):\n        \"\"\"Lazily load and return the remediation engine.\"\"\"\n        if self._remediation_engine is None:\n            from src.remediation_engine import get_remediation_engine\n            self._remediation_engine = get_remediation_engine()\n        return self._remediation_engine\n    \n    def register_handler(self, event_type: str, handler: Callable) -> None:\n        \"\"\"Register a handler for a specific event type.\n        \n        Args:\n            event_type: The type of event to handle.\n            handler: The handler function to call.\n        \"\"\"\n        if event_type not in self._handlers:\n            self._handlers[event_type] = []\n        self._handlers[event_type].append(handler)\n        logger.debug(f\"Registered handler for event type: {event_type}\")\n    \n    def process_event(self, event: Dict[str, Any]) -> bool:\n        \"\"\"Process an incoming event.\n        \n        Args:\n            event: The event data to process.\n            \n        Returns:\n            bool: True if event was processed successfully.\n        \"\"\"\n        event_type = event.get('type', 'UNKNOWN')\n        logger.info(f\"Processing event of type: {event_type}\")\n        \n        # Call registered handlers\n        handlers = self._handlers.get(event_type, [])\n        for handler in handlers:\n            try:\n                handler(event)\n            except Exception as e:\n                logger.error(f\"Handler error for {event_type}: {e}\")\n        \n        return True\n    \n    def process_security_finding(self, finding: Any) -> bool:\n        \"\"\"Process a security finding and trigger remediation if appropriate.\n        \n        Args:\n            finding: The security finding to process.\n            \n        Returns:\n            bool: True if finding was processed successfully.\n        \"\"\"\n        # Extract finding attributes\n        if isinstance(finding, dict):\n            finding_type = finding.get('type')\n            severity = finding.get('severity')\n        else:\n            finding_type = getattr(finding, 'type', None)\n            severity = getattr(finding, 'severity', None)\n        \n        logger.info(f\"Processing security finding: type={finding_type}, severity={severity}\")\n        \n        # Check if this is a critical S3 public read ACL finding\n        if finding_type == 'S3_PUBLIC_READ_ACL' and severity == 'CRITICAL':\n            logger.warning(f\"Critical S3 public read ACL finding detected\")\n            \n            # Check if remediation is enabled\n            if self._is_remediation_enabled():\n                logger.info(\"Remediation is enabled, attempting automatic remediation\")\n                try:\n                    engine = self._get_remediation_engine()\n                    success = engine.remediate_finding(finding)\n                    if success:\n                        logger.info(\"Remediation completed successfully\")\n                        return True\n                    else:\n                        logger.warning(\"Remediation was not successful\")\n                except Exception as e:\n                    logger.error(f\"Remediation failed with error: {e}\")\n            else:\n                logger.info(\"Remediation is disabled, skipping automatic remediation\")\n        \n        return True\n\n\n# Module-level event handler instance\n_event_handler = None\n\n\ndef get_event_handler(config_provider: Optional[Callable] = None) -> EventHandler:\n    \"\"\"Get or create the event handler instance.\n    \n    Args:\n        config_provider: Optional configuration provider callable.\n        \n    Returns:\n        EventHandler: The event handler instance.\n    \"\"\"\n    global _event_handler\n    if config_provider:\n        return EventHandler(config_provider)\n    if _event_handler is None:\n        _event_handler = EventHandler()\n    return _event_handler\n\n\ndef process_security_finding(finding: Any) -> bool:\n    \"\"\"Convenience function to process a security finding.\n    \n    Args:\n        finding: The security finding to process.\n        \n    Returns:\n        bool: True if finding was processed successfully.\n    \"\"\"\n    handler = get_event_handler()\n    return handler.process_security_finding(finding)\n\n\ndef handle_event(event: Dict[str, Any]) -> bool:\n    \"\"\"Convenience function to handle an event.\n    \n    Args:\n        event: The event to handle.\n        \n    Returns:\n        bool: True if event was handled successfully.\n    \"\"\"\n    handler = get_event_handler()\n    return handler.process_event(event)\n",
          "src/module_20.py": "\"\"\"Security Scanning Module for NimbusCustodian.\n\nThis module provides security scanning capabilities including\nS3 bucket ACL analysis and finding generation.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, List, Optional, Callable\nfrom dataclasses import dataclass, field\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\n\nclass FindingSeverity(Enum):\n    \"\"\"Severity levels for security findings.\"\"\"\n    LOW = 'LOW'\n    MEDIUM = 'MEDIUM'\n    HIGH = 'HIGH'\n    CRITICAL = 'CRITICAL'\n\n\nclass FindingStatus(Enum):\n    \"\"\"Status values for security findings.\"\"\"\n    OPEN = 'OPEN'\n    ACKNOWLEDGED = 'ACKNOWLEDGED'\n    REMEDIATED = 'REMEDIATED'\n    SUPPRESSED = 'SUPPRESSED'\n\n\n@dataclass\nclass Finding:\n    \"\"\"Represents a security finding.\"\"\"\n    type: str\n    severity: str\n    resource: Dict[str, Any]\n    description: str\n    status: str = 'OPEN'\n    id: Optional[str] = None\n    \n    def update_status(self, new_status: str) -> None:\n        \"\"\"Update the status of this finding.\n        \n        Args:\n            new_status: The new status value.\n        \"\"\"\n        old_status = self.status\n        self.status = new_status\n        logger.info(f\"Finding {self.id or self.type} status updated from {old_status} to {new_status}\")\n    \n    @property\n    def bucket_name(self) -> Optional[str]:\n        \"\"\"Get the bucket name from the resource if available.\"\"\"\n        return self.resource.get('bucket_name')\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert finding to dictionary.\"\"\"\n        return {\n            'id': self.id,\n            'type': self.type,\n            'severity': self.severity,\n            'resource': self.resource,\n            'description': self.description,\n            'status': self.status\n        }\n\n\nclass SecurityScanner:\n    \"\"\"Scanner for security issues in cloud resources.\"\"\"\n    \n    def __init__(self, aws_client_factory: Optional[Callable] = None):\n        \"\"\"Initialize the security scanner.\n        \n        Args:\n            aws_client_factory: Optional callable for creating AWS clients.\n        \"\"\"\n        self._aws_client_factory = aws_client_factory\n        self._findings: List[Finding] = []\n        self._finding_handlers: List[Callable] = []\n    \n    def _get_s3_client(self):\n        \"\"\"Get an S3 client.\"\"\"\n        if self._aws_client_factory:\n            return self._aws_client_factory('s3')\n        else:\n            from src.utils import get_aws_client\n            return get_aws_client('s3')\n    \n    def register_finding_handler(self, handler: Callable) -> None:\n        \"\"\"Register a handler to be called when findings are generated.\n        \n        Args:\n            handler: Callable that takes a Finding object.\n        \"\"\"\n        self._finding_handlers.append(handler)\n    \n    def _emit_finding(self, finding: Finding) -> None:\n        \"\"\"Emit a finding to all registered handlers.\n        \n        Args:\n            finding: The finding to emit.\n        \"\"\"\n        self._findings.append(finding)\n        for handler in self._finding_handlers:\n            try:\n                handler(finding)\n            except Exception as e:\n                logger.error(f\"Finding handler error: {e}\")\n    \n    def scan_s3_bucket_acls(self) -> List[Finding]:\n        \"\"\"Scan S3 buckets for public ACL configurations.\n        \n        Returns:\n            List of findings for buckets with public ACLs.\n        \"\"\"\n        findings = []\n        try:\n            s3_client = self._get_s3_client()\n            response = s3_client.list_buckets()\n            buckets = response.get('Buckets', [])\n            \n            for bucket in buckets:\n                bucket_name = bucket.get('Name')\n                if not bucket_name:\n                    continue\n                \n                try:\n                    acl_response = s3_client.get_bucket_acl(Bucket=bucket_name)\n                    grants = acl_response.get('Grants', [])\n                    \n                    for grant in grants:\n                        grantee = grant.get('Grantee', {})\n                        permission = grant.get('Permission', '')\n                        uri = grantee.get('URI', '')\n                        \n                        # Check for public read access\n                        if 'AllUsers' in uri and permission in ['READ', 'FULL_CONTROL']:\n                            finding = Finding(\n                                type='S3_PUBLIC_READ_ACL',\n                                severity='CRITICAL',\n                                resource={'bucket_name': bucket_name},\n                                description=f\"S3 bucket {bucket_name} has public read access via ACL\",\n                                id=f\"s3-public-acl-{bucket_name}\"\n                            )\n                            findings.append(finding)\n                            self._emit_finding(finding)\n                            logger.warning(f\"Found public read ACL on bucket: {bucket_name}\")\n                            break\n                \n                except Exception as e:\n                    logger.error(f\"Error checking ACL for bucket {bucket_name}: {e}\")\n        \n        except Exception as e:\n            logger.error(f\"Error scanning S3 buckets: {e}\")\n        \n        return findings\n    \n    def get_findings(self) -> List[Finding]:\n        \"\"\"Get all findings from the scanner.\n        \n        Returns:\n            List of all findings.\n        \"\"\"\n        return self._findings.copy()\n    \n    def clear_findings(self) -> None:\n        \"\"\"Clear all stored findings.\"\"\"\n        self._findings.clear()\n\n\n# Module-level scanner instance\n_scanner = None\n\n\ndef get_security_scanner(aws_client_factory: Optional[Callable] = None) -> SecurityScanner:\n    \"\"\"Get or create the security scanner instance.\n    \n    Args:\n        aws_client_factory: Optional callable for creating AWS clients.\n        \n    Returns:\n        SecurityScanner: The scanner instance.\n    \"\"\"\n    global _scanner\n    if aws_client_factory:\n        return SecurityScanner(aws_client_factory)\n    if _scanner is None:\n        _scanner = SecurityScanner()\n    return _scanner\n\n\ndef scan_s3_buckets() -> List[Finding]:\n    \"\"\"Convenience function to scan S3 buckets.\n    \n    Returns:\n        List of findings.\n    \"\"\"\n    scanner = get_security_scanner()\n    return scanner.scan_s3_bucket_acls()\n\n\ndef create_finding(finding_type: str, severity: str, resource: Dict[str, Any], \n                   description: str) -> Finding:\n    \"\"\"Create a new finding.\n    \n    Args:\n        finding_type: Type of the finding.\n        severity: Severity level.\n        resource: Resource information.\n        description: Finding description.\n        \n    Returns:\n        Finding: The created finding.\n    \"\"\"\n    return Finding(\n        type=finding_type,\n        severity=severity,\n        resource=resource,\n        description=description\n    )\n",
          "src/utils.py": "\"\"\"Utility functions for NimbusCustodian.\n\nProvides common utilities including AWS client management.\n\"\"\"\n\nimport logging\nfrom typing import Any, Optional, Dict\n\nlogger = logging.getLogger(__name__)\n\n# Cache for AWS clients\n_aws_clients: Dict[str, Any] = {}\n\n\ndef get_aws_client(service_name: str, region: Optional[str] = None) -> Any:\n    \"\"\"Get an AWS client for the specified service.\n    \n    Args:\n        service_name: The AWS service name (e.g., 's3', 'ec2').\n        region: Optional AWS region name.\n        \n    Returns:\n        A boto3 client for the specified service.\n    \"\"\"\n    cache_key = f\"{service_name}:{region or 'default'}\"\n    \n    if cache_key not in _aws_clients:\n        try:\n            import boto3\n            if region:\n                client = boto3.client(service_name, region_name=region)\n            else:\n                client = boto3.client(service_name)\n            _aws_clients[cache_key] = client\n            logger.debug(f\"Created AWS client for {service_name}\")\n        except Exception as e:\n            logger.error(f\"Failed to create AWS client for {service_name}: {e}\")\n            raise\n    \n    return _aws_clients[cache_key]\n\n\ndef clear_aws_client_cache() -> None:\n    \"\"\"Clear the AWS client cache.\"\"\"\n    global _aws_clients\n    _aws_clients.clear()\n    logger.debug(\"Cleared AWS client cache\")\n\n\ndef format_resource_arn(service: str, resource_type: str, resource_id: str,\n                        region: str = '', account_id: str = '') -> str:\n    \"\"\"Format an AWS resource ARN.\n    \n    Args:\n        service: AWS service name.\n        resource_type: Type of resource.\n        resource_id: Resource identifier.\n        region: AWS region (optional for global resources).\n        account_id: AWS account ID (optional for some resources).\n        \n    Returns:\n        Formatted ARN string.\n    \"\"\"\n    return f\"arn:aws:{service}:{region}:{account_id}:{resource_type}/{resource_id}\"\n\n\ndef parse_s3_uri(uri: str) -> Dict[str, str]:\n    \"\"\"Parse an S3 URI into bucket and key components.\n    \n    Args:\n        uri: S3 URI in format s3://bucket/key.\n        \n    Returns:\n        Dictionary with 'bucket' and 'key' keys.\n    \"\"\"\n    if not uri.startswith('s3://'):\n        raise ValueError(f\"Invalid S3 URI: {uri}\")\n    \n    path = uri[5:]  # Remove 's3://'\n    parts = path.split('/', 1)\n    \n    return {\n        'bucket': parts[0],\n        'key': parts[1] if len(parts) > 1 else ''\n    }\n\n\ndef safe_get(obj: Any, *keys: str, default: Any = None) -> Any:\n    \"\"\"Safely get a nested value from a dictionary or object.\n    \n    Args:\n        obj: The object to get values from.\n        *keys: Keys to traverse.\n        default: Default value if key not found.\n        \n    Returns:\n        The value at the specified path or default.\n    \"\"\"\n    current = obj\n    for key in keys:\n        if isinstance(current, dict):\n            current = current.get(key)\n        elif hasattr(current, key):\n            current = getattr(current, key)\n        else:\n            return default\n        if current is None:\n            return default\n    return current\n",
          "tests/test_remediation_engine.py": "\"\"\"Unit tests for the Remediation Engine module.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch\nimport logging\n\nfrom src.remediation_engine import (\n    RemediationEngine,\n    RemediationError,\n    get_remediation_engine,\n    remediate_s3_public_read_acl,\n    remediate_finding\n)\nfrom src.module_20 import Finding\n\n\nclass TestRemediationEngine:\n    \"\"\"Tests for the RemediationEngine class.\"\"\"\n    \n    def test_init_with_custom_client_factory(self):\n        \"\"\"Test initialization with custom AWS client factory.\"\"\"\n        mock_factory = Mock()\n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        assert engine._aws_client_factory == mock_factory\n    \n    def test_init_without_client_factory(self):\n        \"\"\"Test initialization without AWS client factory.\"\"\"\n        engine = RemediationEngine()\n        assert engine._aws_client_factory is None\n    \n    def test_remediate_s3_public_read_acl_success(self):\n        \"\"\"Test successful S3 bucket ACL remediation.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_s3_public_read_acl('test-bucket')\n        \n        assert result is True\n        mock_factory.assert_called_once_with('s3')\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='test-bucket',\n            ACL='private'\n        )\n    \n    def test_remediate_s3_public_read_acl_empty_bucket_name(self):\n        \"\"\"Test remediation with empty bucket name raises error.\"\"\"\n        engine = RemediationEngine()\n        \n        with pytest.raises(RemediationError) as exc_info:\n            engine.remediate_s3_public_read_acl('')\n        \n        assert \"Bucket name cannot be empty\" in str(exc_info.value)\n    \n    def test_remediate_s3_public_read_acl_aws_error(self):\n        \"\"\"Test remediation handles AWS errors properly.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"Access Denied\")\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        \n        with pytest.raises(RemediationError) as exc_info:\n            engine.remediate_s3_public_read_acl('test-bucket')\n        \n        assert \"Failed to remediate S3 bucket test-bucket\" in str(exc_info.value)\n    \n    def test_remediate_finding_s3_public_read_acl_with_finding_object(self):\n        \"\"\"Test remediation with Finding object.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'my-bucket'},\n            description='Test finding'\n        )\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_finding(finding)\n        \n        assert result is True\n        assert finding.status == 'REMEDIATED'\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='my-bucket',\n            ACL='private'\n        )\n    \n    def test_remediate_finding_s3_public_read_acl_with_dict(self):\n        \"\"\"Test remediation with dictionary finding.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        finding = {\n            'type': 'S3_PUBLIC_READ_ACL',\n            'severity': 'CRITICAL',\n            'resource': {'bucket_name': 'dict-bucket'},\n            'description': 'Test finding'\n        }\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_finding(finding)\n        \n        assert result is True\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='dict-bucket',\n            ACL='private'\n        )\n    \n    def test_remediate_finding_unknown_type(self):\n        \"\"\"Test remediation with unknown finding type.\"\"\"\n        engine = RemediationEngine()\n        \n        finding = {\n            'type': 'UNKNOWN_FINDING_TYPE',\n            'severity': 'HIGH',\n            'resource': {},\n            'description': 'Unknown finding'\n        }\n        \n        result = engine.remediate_finding(finding)\n        assert result is False\n    \n    def test_remediate_finding_missing_bucket_name(self):\n        \"\"\"Test remediation when bucket name is missing.\"\"\"\n        engine = RemediationEngine()\n        \n        finding = {\n            'type': 'S3_PUBLIC_READ_ACL',\n            'severity': 'CRITICAL',\n            'resource': {},\n            'description': 'Missing bucket'\n        }\n        \n        result = engine.remediate_finding(finding)\n        assert result is False\n    \n    def test_remediate_finding_handles_remediation_error(self):\n        \"\"\"Test that remediation errors are handled gracefully.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"AWS Error\")\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'error-bucket'},\n            description='Test finding'\n        )\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_finding(finding)\n        \n        assert result is False\n        # Status should not be updated on failure\n        assert finding.status == 'OPEN'\n\n\nclass TestModuleFunctions:\n    \"\"\"Tests for module-level convenience functions.\"\"\"\n    \n    def test_get_remediation_engine_returns_instance(self):\n        \"\"\"Test that get_remediation_engine returns an engine instance.\"\"\"\n        mock_factory = Mock()\n        engine = get_remediation_engine(aws_client_factory=mock_factory)\n        assert isinstance(engine, RemediationEngine)\n    \n    def test_remediate_s3_public_read_acl_function(self):\n        \"\"\"Test the module-level remediate function.\"\"\"\n        mock_s3_client = Mock()\n        \n        with patch('src.remediation_engine._default_engine') as mock_engine:\n            mock_engine.remediate_s3_public_read_acl.return_value = True\n            # Need to reset the default engine for this test\n            import src.remediation_engine as rem_module\n            rem_module._default_engine = None\n            \n            mock_factory = Mock(return_value=mock_s3_client)\n            engine = RemediationEngine(aws_client_factory=mock_factory)\n            result = engine.remediate_s3_public_read_acl('test-bucket')\n            \n            assert result is True\n\n\nclass TestLogging:\n    \"\"\"Tests for logging behavior.\"\"\"\n    \n    def test_successful_remediation_logs_message(self, caplog):\n        \"\"\"Test that successful remediation logs the correct message.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        \n        with caplog.at_level(logging.INFO):\n            engine.remediate_s3_public_read_acl('logged-bucket')\n        \n        assert \"Successfully remediated S3 bucket logged-bucket by setting ACL to private.\" in caplog.text\n    \n    def test_failed_remediation_logs_error(self, caplog):\n        \"\"\"Test that failed remediation logs an error.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"Test error\")\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        \n        with caplog.at_level(logging.ERROR):\n            with pytest.raises(RemediationError):\n                engine.remediate_s3_public_read_acl('error-bucket')\n        \n        assert \"Failed to remediate S3 bucket error-bucket\" in caplog.text\n",
          "tests/test_main.py": "\"\"\"Main test file for NimbusCustodian including integration tests.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch\nimport logging\n\nfrom src.module_7 import EventHandler, get_event_handler, process_security_finding\nfrom src.module_20 import Finding, SecurityScanner\nfrom src.remediation_engine import RemediationEngine\n\n\nclass TestEventHandler:\n    \"\"\"Tests for the EventHandler class.\"\"\"\n    \n    def test_process_event_basic(self):\n        \"\"\"Test basic event processing.\"\"\"\n        handler = EventHandler()\n        event = {'type': 'TEST_EVENT', 'data': 'test'}\n        result = handler.process_event(event)\n        assert result is True\n    \n    def test_register_and_call_handler(self):\n        \"\"\"Test registering and calling event handlers.\"\"\"\n        handler = EventHandler()\n        mock_callback = Mock()\n        \n        handler.register_handler('TEST_EVENT', mock_callback)\n        handler.process_event({'type': 'TEST_EVENT'})\n        \n        mock_callback.assert_called_once()\n\n\nclass TestSecurityFindingIntegration:\n    \"\"\"Integration tests for security finding processing and remediation.\"\"\"\n    \n    def test_critical_s3_finding_triggers_remediation_when_enabled(self):\n        \"\"\"Test that critical S3 findings trigger remediation when enabled.\"\"\"\n        # Setup mock S3 client\n        mock_s3_client = Mock()\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create event handler with config\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine\n        mock_remediation_engine = Mock()\n        mock_remediation_engine.remediate_finding.return_value = True\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'vulnerable-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_called_once_with(finding)\n    \n    def test_critical_s3_finding_does_not_trigger_remediation_when_disabled(self):\n        \"\"\"Test that critical S3 findings do not trigger remediation when disabled.\"\"\"\n        # Setup config with remediation disabled\n        config = {'remediation': {'enabled': False}}\n        config_provider = lambda: config\n        \n        # Create event handler with config\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine (should not be called)\n        mock_remediation_engine = Mock()\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'vulnerable-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was NOT triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_not_called()\n    \n    def test_non_critical_s3_finding_does_not_trigger_remediation(self):\n        \"\"\"Test that non-critical S3 findings do not trigger remediation.\"\"\"\n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine\n        mock_remediation_engine = Mock()\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create HIGH severity (not CRITICAL) S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='HIGH',  # Not CRITICAL\n            resource={'bucket_name': 'some-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was NOT triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_not_called()\n    \n    def test_different_finding_type_does_not_trigger_s3_remediation(self):\n        \"\"\"Test that different finding types do not trigger S3 remediation.\"\"\"\n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine\n        mock_remediation_engine = Mock()\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create different type of finding\n        finding = Finding(\n            type='EC2_SECURITY_GROUP_OPEN',\n            severity='CRITICAL',\n            resource={'instance_id': 'i-12345'},\n            description='Security group is open'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was NOT triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_not_called()\n    \n    def test_end_to_end_remediation_flow(self):\n        \"\"\"Test the complete flow from finding to remediation.\"\"\"\n        # Setup mock S3 client\n        mock_s3_client = Mock()\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create real remediation engine with mock AWS client\n        remediation_engine = RemediationEngine(aws_client_factory=mock_aws_factory)\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        event_handler._remediation_engine = remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'public-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify the complete flow\n        assert result is True\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='public-bucket',\n            ACL='private'\n        )\n        assert finding.status == 'REMEDIATED'\n    \n    def test_remediation_failure_handling(self):\n        \"\"\"Test handling of remediation failures.\"\"\"\n        # Setup mock S3 client that fails\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"Access Denied\")\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create real remediation engine with mock AWS client\n        remediation_engine = RemediationEngine(aws_client_factory=mock_aws_factory)\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        event_handler._remediation_engine = remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'protected-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding - should not raise exception\n        result = event_handler.process_security_finding(finding)\n        \n        # Finding status should remain OPEN since remediation failed\n        assert finding.status == 'OPEN'\n\n\nclass TestSecurityScanner:\n    \"\"\"Tests for the SecurityScanner class.\"\"\"\n    \n    def test_scan_s3_bucket_acls_finds_public_buckets(self):\n        \"\"\"Test that scanner correctly identifies public buckets.\"\"\"\n        # Setup mock S3 client\n        mock_s3_client = Mock()\n        mock_s3_client.list_buckets.return_value = {\n            'Buckets': [{'Name': 'public-bucket'}, {'Name': 'private-bucket'}]\n        }\n        mock_s3_client.get_bucket_acl.side_effect = [\n            # Public bucket\n            {\n                'Grants': [{\n                    'Grantee': {'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n                    'Permission': 'READ'\n                }]\n            },\n            # Private bucket\n            {\n                'Grants': [{\n                    'Grantee': {'Type': 'CanonicalUser'},\n                    'Permission': 'FULL_CONTROL'\n                }]\n            }\n        ]\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        scanner = SecurityScanner(aws_client_factory=mock_aws_factory)\n        findings = scanner.scan_s3_bucket_acls()\n        \n        assert len(findings) == 1\n        assert findings[0].type == 'S3_PUBLIC_READ_ACL'\n        assert findings[0].severity == 'CRITICAL'\n        assert findings[0].resource['bucket_name'] == 'public-bucket'\n    \n    def test_scanner_emits_findings_to_handlers(self):\n        \"\"\"Test that scanner emits findings to registered handlers.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.list_buckets.return_value = {\n            'Buckets': [{'Name': 'public-bucket'}]\n        }\n        mock_s3_client.get_bucket_acl.return_value = {\n            'Grants': [{\n                'Grantee': {'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n                'Permission': 'READ'\n            }]\n        }\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        scanner = SecurityScanner(aws_client_factory=mock_aws_factory)\n        \n        # Register a mock handler\n        mock_handler = Mock()\n        scanner.register_finding_handler(mock_handler)\n        \n        # Run scan\n        scanner.scan_s3_bucket_acls()\n        \n        # Verify handler was called\n        mock_handler.assert_called_once()\n        called_finding = mock_handler.call_args[0][0]\n        assert called_finding.type == 'S3_PUBLIC_READ_ACL'\n\n\nclass TestFinding:\n    \"\"\"Tests for the Finding class.\"\"\"\n    \n    def test_finding_update_status(self):\n        \"\"\"Test updating finding status.\"\"\"\n        finding = Finding(\n            type='TEST',\n            severity='HIGH',\n            resource={},\n            description='Test'\n        )\n        \n        assert finding.status == 'OPEN'\n        finding.update_status('REMEDIATED')\n        assert finding.status == 'REMEDIATED'\n    \n    def test_finding_bucket_name_property(self):\n        \"\"\"Test bucket_name property.\"\"\"\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'my-bucket'},\n            description='Test'\n        )\n        \n        assert finding.bucket_name == 'my-bucket'\n    \n    def test_finding_to_dict(self):\n        \"\"\"Test converting finding to dictionary.\"\"\"\n        finding = Finding(\n            type='TEST',\n            severity='HIGH',\n            resource={'key': 'value'},\n            description='Test finding',\n            id='test-123'\n        )\n        \n        result = finding.to_dict()\n        \n        assert result['type'] == 'TEST'\n        assert result['severity'] == 'HIGH'\n        assert result['resource'] == {'key': 'value'}\n        assert result['description'] == 'Test finding'\n        assert result['id'] == 'test-123'\n        assert result['status'] == 'OPEN'\n",
          "tests/test_utils.py": "\"\"\"Tests for utility functions.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, patch\n\nfrom src.utils import (\n    get_aws_client,\n    clear_aws_client_cache,\n    format_resource_arn,\n    parse_s3_uri,\n    safe_get\n)\n\n\nclass TestGetAwsClient:\n    \"\"\"Tests for get_aws_client function.\"\"\"\n    \n    @patch('src.utils.boto3')\n    def test_get_aws_client_creates_client(self, mock_boto3):\n        \"\"\"Test that get_aws_client creates a boto3 client.\"\"\"\n        clear_aws_client_cache()\n        mock_client = Mock()\n        mock_boto3.client.return_value = mock_client\n        \n        result = get_aws_client('s3')\n        \n        mock_boto3.client.assert_called_once_with('s3')\n        assert result == mock_client\n    \n    @patch('src.utils.boto3')\n    def test_get_aws_client_with_region(self, mock_boto3):\n        \"\"\"Test that get_aws_client passes region parameter.\"\"\"\n        clear_aws_client_cache()\n        mock_client = Mock()\n        mock_boto3.client.return_value = mock_client\n        \n        result = get_aws_client('s3', region='us-west-2')\n        \n        mock_boto3.client.assert_called_once_with('s3', region_name='us-west-2')\n    \n    @patch('src.utils.boto3')\n    def test_get_aws_client_caches_client(self, mock_boto3):\n        \"\"\"Test that get_aws_client caches clients.\"\"\"\n        clear_aws_client_cache()\n        mock_client = Mock()\n        mock_boto3.client.return_value = mock_client\n        \n        result1 = get_aws_client('s3')\n        result2 = get_aws_client('s3')\n        \n        # Should only create client once\n        assert mock_boto3.client.call_count == 1\n        assert result1 == result2\n\n\nclass TestFormatResourceArn:\n    \"\"\"Tests for format_resource_arn function.\"\"\"\n    \n    def test_format_full_arn(self):\n        \"\"\"Test formatting a complete ARN.\"\"\"\n        arn = format_resource_arn(\n            service='s3',\n            resource_type='bucket',\n            resource_id='my-bucket',\n            region='us-east-1',\n            account_id='123456789012'\n        )\n        \n        assert arn == 'arn:aws:s3:us-east-1:123456789012:bucket/my-bucket'\n    \n    def test_format_global_resource_arn(self):\n        \"\"\"Test formatting ARN for global resource.\"\"\"\n        arn = format_resource_arn(\n            service='s3',\n            resource_type='bucket',\n            resource_id='my-bucket'\n        )\n        \n        assert arn == 'arn:aws:s3:::bucket/my-bucket'\n\n\nclass TestParseS3Uri:\n    \"\"\"Tests for parse_s3_uri function.\"\"\"\n    \n    def test_parse_full_uri(self):\n        \"\"\"Test parsing S3 URI with key.\"\"\"\n        result = parse_s3_uri('s3://my-bucket/path/to/object.txt')\n        \n        assert result['bucket'] == 'my-bucket'\n        assert result['key'] == 'path/to/object.txt'\n    \n    def test_parse_bucket_only_uri(self):\n        \"\"\"Test parsing S3 URI with only bucket.\"\"\"\n        result = parse_s3_uri('s3://my-bucket')\n        \n        assert result['bucket'] == 'my-bucket'\n        assert result['key'] == ''\n    \n    def test_parse_invalid_uri_raises_error(self):\n        \"\"\"Test that invalid URI raises ValueError.\"\"\"\n        with pytest.raises(ValueError) as exc_info:\n            parse_s3_uri('http://example.com')\n        \n        assert 'Invalid S3 URI' in str(exc_info.value)\n\n\nclass TestSafeGet:\n    \"\"\"Tests for safe_get function.\"\"\"\n    \n    def test_safe_get_dict_single_key(self):\n        \"\"\"Test getting value from dict with single key.\"\"\"\n        obj = {'key': 'value'}\n        result = safe_get(obj, 'key')\n        assert result == 'value'\n    \n    def test_safe_get_dict_nested_keys(self):\n        \"\"\"Test getting nested value from dict.\"\"\"\n        obj = {'level1': {'level2': {'level3': 'deep_value'}}}\n        result = safe_get(obj, 'level1', 'level2', 'level3')\n        assert result == 'deep_value'\n    \n    def test_safe_get_missing_key_returns_default(self):\n        \"\"\"Test that missing key returns default value.\"\"\"\n        obj = {'key': 'value'}\n        result = safe_get(obj, 'missing', default='default_value')\n        assert result == 'default_value'\n    \n    def test_safe_get_none_value_returns_default(self):\n        \"\"\"Test that None value returns default.\"\"\"\n        obj = {'key': None}\n        result = safe_get(obj, 'key', default='default_value')\n        assert result == 'default_value'\n    \n    def test_safe_get_object_attribute(self):\n        \"\"\"Test getting attribute from object.\"\"\"\n        class TestObj:\n            attr = 'attr_value'\n        \n        obj = TestObj()\n        result = safe_get(obj, 'attr')\n        assert result == 'attr_value'\n"
        },
        "generated_files": [
          "src/remediation_engine.py",
          "src/module_7.py",
          "src/module_20.py",
          "src/utils.py",
          "tests/test_remediation_engine.py",
          "tests/test_main.py",
          "tests/test_utils.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7962346702021875,
              "dependency_traversal_accuracy": 0.8116628899323408,
              "cross_file_reasoning_depth": 0.20952380952380953,
              "system_thinking_score": 0.5658790849673203,
              "robustness_score": 0.1587742899850523,
              "comprehensiveness_score": 0.706509715994021,
              "innovation_score": 0.18125000000000002,
              "solution_elegance_score": 0.8583049558857447
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09952933377527344,
              "dependency_traversal_weighted": 0.1014578612415426,
              "cross_file_reasoning_weighted": 0.02619047619047619,
              "system_thinking_weighted": 0.07073488562091504,
              "robustness_weighted": 0.019846786248131538,
              "comprehensiveness_weighted": 0.08831371449925263,
              "innovation_weighted": 0.022656250000000003,
              "solution_elegance_weighted": 0.10728811948571809
            },
            "total_software_engineering_score": 0.5360174270613095
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.4560565948486328,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "src/remediation_engine.py",
                "src/module_7.py",
                "src/module_20.py",
                "src/utils.py",
                "tests/test_remediation_engine.py",
                "tests/test_main.py",
                "tests/test_utils.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.0,
              "tests_run": 4,
              "tests_passed": 0,
              "tests_failed": 4,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": false,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": false,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 7,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 7 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.2830513176144244,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.0,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.2830513176144244,
              "idc_weight": 0.2,
              "total_functional_score": 0.4866102635228849
            }
          },
          "code_quality_details": {
            "files_analyzed": 7,
            "quality_checks": {
              "src/remediation_engine.py": {
                "line_count": 146,
                "non_empty_lines": 110,
                "comment_lines": 2,
                "comment_ratio": 0.01818181818181818,
                "function_count": 7,
                "class_count": 4,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              },
              "src/module_7.py": {
                "line_count": 173,
                "non_empty_lines": 133,
                "comment_lines": 6,
                "comment_ratio": 0.045112781954887216,
                "function_count": 10,
                "class_count": 7,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "src/module_20.py": {
                "line_count": 221,
                "non_empty_lines": 173,
                "comment_lines": 2,
                "comment_ratio": 0.011560693641618497,
                "function_count": 13,
                "class_count": 4,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "src/utils.py": {
                "line_count": 110,
                "non_empty_lines": 83,
                "comment_lines": 1,
                "comment_ratio": 0.012048192771084338,
                "function_count": 5,
                "class_count": 0,
                "import_count": 5,
                "quality_score": 0.7999999999999999
              },
              "tests/test_remediation_engine.py": {
                "line_count": 214,
                "non_empty_lines": 162,
                "comment_lines": 2,
                "comment_ratio": 0.012345679012345678,
                "function_count": 14,
                "class_count": 3,
                "import_count": 9,
                "quality_score": 0.7999999999999999
              },
              "tests/test_main.py": {
                "line_count": 332,
                "non_empty_lines": 263,
                "comment_lines": 45,
                "comment_ratio": 0.17110266159695817,
                "function_count": 13,
                "class_count": 7,
                "import_count": 11,
                "quality_score": 0.9999999999999999
              },
              "tests/test_utils.py": {
                "line_count": 142,
                "non_empty_lines": 106,
                "comment_lines": 1,
                "comment_ratio": 0.009433962264150943,
                "function_count": 13,
                "class_count": 5,
                "import_count": 8,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.8199999999999998,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.48981092436974794,
              "multi_session_memory_retention": 0.5347183317771553
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.24490546218487397,
              "multi_session_memory_retention_weighted": 0.26735916588857767
            },
            "total_longcontext_utilization_score": 0.5122646280734516
          }
        },
        "timestamp": "2026-01-14T21:44:43.650491"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_desktop_productivity_easy_091_feature_implementation_expert_01",
        "scenario_title": "Implement User Profiles for Context Switching",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5230273001373705,
        "functional_correctness_score": 0.37047674418604654,
        "code_quality_score": 0.7999999999999999,
        "longcontext_utilization_score": 0.8007954545454545,
        "total_score": 2.802167443826538,
        "generation_time": 229.6129539012909,
        "code_files_generated": 6,
        "total_lines_generated": 2126,
        "parsing_success": true,
        "solution_code": {
          "QuestBoard_Maestro/services/settings_service.py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, asdict, field\n\n\n@dataclass\nclass ProfileSettings:\n    \"\"\"Settings for a single profile.\"\"\"\n    name: str\n    theme: str = \"default\"\n    notifications_enabled: bool = True\n    auto_save: bool = True\n    quest_sort_order: str = \"priority\"\n    show_completed: bool = True\n    custom_settings: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -> Dict[str, Any]:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'ProfileSettings':\n        return cls(\n            name=data.get('name', 'Unnamed'),\n            theme=data.get('theme', 'default'),\n            notifications_enabled=data.get('notifications_enabled', True),\n            auto_save=data.get('auto_save', True),\n            quest_sort_order=data.get('quest_sort_order', 'priority'),\n            show_completed=data.get('show_completed', True),\n            custom_settings=data.get('custom_settings', {})\n        )\n\n\n@dataclass\nclass GlobalConfig:\n    \"\"\"Global application configuration (not profile-specific).\"\"\"\n    last_active_profile: str = \"Primary\"\n    available_profiles: List[str] = field(default_factory=list)\n    window_geometry: Dict[str, int] = field(default_factory=lambda: {'x': 100, 'y': 100, 'width': 800, 'height': 600})\n\n    def to_dict(self) -> Dict[str, Any]:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'GlobalConfig':\n        return cls(\n            last_active_profile=data.get('last_active_profile', 'Primary'),\n            available_profiles=data.get('available_profiles', []),\n            window_geometry=data.get('window_geometry', {'x': 100, 'y': 100, 'width': 800, 'height': 600})\n        )\n\n\nclass SettingsService:\n    \"\"\"Service for managing application settings and user profiles.\"\"\"\n\n    def __init__(self, config_dir: Optional[str] = None):\n        if config_dir:\n            self._config_dir = Path(config_dir)\n        else:\n            self._config_dir = Path.home() / '.questboard_maestro'\n        self._config_dir.mkdir(parents=True, exist_ok=True)\n\n        self._global_config_file = self._config_dir / 'global_config.json'\n        self._global_config: GlobalConfig = GlobalConfig()\n        self._active_profile: Optional[ProfileSettings] = None\n        self._active_profile_name: str = \"\"\n\n        self._load_global_config()\n\n    @property\n    def config_dir(self) -> Path:\n        return self._config_dir\n\n    @property\n    def active_profile(self) -> Optional[ProfileSettings]:\n        return self._active_profile\n\n    @property\n    def active_profile_name(self) -> str:\n        return self._active_profile_name\n\n    @property\n    def global_config(self) -> GlobalConfig:\n        return self._global_config\n\n    def _get_profile_settings_path(self, profile_name: str) -> Path:\n        \"\"\"Get the path to a profile's settings file.\"\"\"\n        safe_name = self._sanitize_profile_name(profile_name)\n        return self._config_dir / f'settings_{safe_name}.json'\n\n    def _sanitize_profile_name(self, name: str) -> str:\n        \"\"\"Sanitize profile name for use in filenames.\"\"\"\n        return ''.join(c if c.isalnum() or c in ('_', '-') else '_' for c in name.lower())\n\n    def _load_global_config(self) -> None:\n        \"\"\"Load the global configuration file.\"\"\"\n        if self._global_config_file.exists():\n            try:\n                with open(self._global_config_file, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self._global_config = GlobalConfig.from_dict(data)\n            except (json.JSONDecodeError, IOError) as e:\n                print(f\"Error loading global config: {e}\")\n                self._global_config = GlobalConfig()\n        else:\n            self._global_config = GlobalConfig()\n\n    def _save_global_config(self) -> None:\n        \"\"\"Save the global configuration file.\"\"\"\n        try:\n            with open(self._global_config_file, 'w', encoding='utf-8') as f:\n                json.dump(self._global_config.to_dict(), f, indent=2)\n        except IOError as e:\n            print(f\"Error saving global config: {e}\")\n\n    def get_available_profiles(self) -> List[str]:\n        \"\"\"Get list of all available profile names.\"\"\"\n        return list(self._global_config.available_profiles)\n\n    def profile_exists(self, profile_name: str) -> bool:\n        \"\"\"Check if a profile exists.\"\"\"\n        return profile_name in self._global_config.available_profiles\n\n    def create_profile(self, profile_name: str, base_settings: Optional[Dict[str, Any]] = None) -> bool:\n        \"\"\"Create a new profile with the given name.\"\"\"\n        if self.profile_exists(profile_name):\n            return False\n\n        if base_settings:\n            base_settings['name'] = profile_name\n            settings = ProfileSettings.from_dict(base_settings)\n        else:\n            settings = ProfileSettings(name=profile_name)\n\n        settings_path = self._get_profile_settings_path(profile_name)\n        try:\n            with open(settings_path, 'w', encoding='utf-8') as f:\n                json.dump(settings.to_dict(), f, indent=2)\n\n            self._global_config.available_profiles.append(profile_name)\n            self._save_global_config()\n            return True\n        except IOError as e:\n            print(f\"Error creating profile {profile_name}: {e}\")\n            return False\n\n    def delete_profile(self, profile_name: str) -> bool:\n        \"\"\"Delete a profile and its associated files.\"\"\"\n        if not self.profile_exists(profile_name):\n            return False\n\n        if profile_name == self._active_profile_name:\n            return False\n\n        settings_path = self._get_profile_settings_path(profile_name)\n        quest_path = self.get_quest_file_path(profile_name)\n\n        try:\n            if settings_path.exists():\n                settings_path.unlink()\n            if quest_path.exists():\n                quest_path.unlink()\n\n            self._global_config.available_profiles.remove(profile_name)\n            self._save_global_config()\n            return True\n        except IOError as e:\n            print(f\"Error deleting profile {profile_name}: {e}\")\n            return False\n\n    def load_profile(self, profile_name: str) -> bool:\n        \"\"\"Load a profile as the active profile.\"\"\"\n        if not self.profile_exists(profile_name):\n            return False\n\n        settings_path = self._get_profile_settings_path(profile_name)\n        try:\n            with open(settings_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                self._active_profile = ProfileSettings.from_dict(data)\n                self._active_profile_name = profile_name\n                self._global_config.last_active_profile = profile_name\n                self._save_global_config()\n                return True\n        except (json.JSONDecodeError, IOError) as e:\n            print(f\"Error loading profile {profile_name}: {e}\")\n            return False\n\n    def save_active_profile(self) -> bool:\n        \"\"\"Save the current active profile settings.\"\"\"\n        if not self._active_profile:\n            return False\n\n        settings_path = self._get_profile_settings_path(self._active_profile_name)\n        try:\n            with open(settings_path, 'w', encoding='utf-8') as f:\n                json.dump(self._active_profile.to_dict(), f, indent=2)\n            return True\n        except IOError as e:\n            print(f\"Error saving active profile: {e}\")\n            return False\n\n    def switch_profile(self, profile_name: str) -> bool:\n        \"\"\"Switch to a different profile (saves current first).\"\"\"\n        if not self.profile_exists(profile_name):\n            return False\n\n        self.save_active_profile()\n        return self.load_profile(profile_name)\n\n    def get_quest_file_path(self, profile_name: Optional[str] = None) -> Path:\n        \"\"\"Get the path to the quest data file for a profile.\"\"\"\n        name = profile_name or self._active_profile_name\n        safe_name = self._sanitize_profile_name(name)\n        return self._config_dir / f'quests_{safe_name}.json'\n\n    def get_active_quest_file_path(self) -> Path:\n        \"\"\"Get the path to the active profile's quest file.\"\"\"\n        return self.get_quest_file_path(self._active_profile_name)\n\n    def get_last_active_profile(self) -> str:\n        \"\"\"Get the name of the last active profile.\"\"\"\n        return self._global_config.last_active_profile\n\n    def update_setting(self, key: str, value: Any) -> None:\n        \"\"\"Update a setting in the active profile.\"\"\"\n        if self._active_profile:\n            if hasattr(self._active_profile, key):\n                setattr(self._active_profile, key, value)\n            else:\n                self._active_profile.custom_settings[key] = value\n            self.save_active_profile()\n\n    def get_setting(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get a setting from the active profile.\"\"\"\n        if self._active_profile:\n            if hasattr(self._active_profile, key):\n                return getattr(self._active_profile, key)\n            return self._active_profile.custom_settings.get(key, default)\n        return default\n\n    def get_theme(self) -> str:\n        \"\"\"Get the theme setting from the active profile.\"\"\"\n        if self._active_profile:\n            return self._active_profile.theme\n        return \"default\"\n\n    def set_theme(self, theme_name: str) -> None:\n        \"\"\"Set the theme for the active profile.\"\"\"\n        if self._active_profile:\n            self._active_profile.theme = theme_name\n            self.save_active_profile()\n\n    def save_window_geometry(self, x: int, y: int, width: int, height: int) -> None:\n        \"\"\"Save window geometry to global config.\"\"\"\n        self._global_config.window_geometry = {'x': x, 'y': y, 'width': width, 'height': height}\n        self._save_global_config()\n\n    def get_window_geometry(self) -> Dict[str, int]:\n        \"\"\"Get saved window geometry.\"\"\"\n        return self._global_config.window_geometry\n\n\n# Singleton instance\n_settings_service_instance: Optional[SettingsService] = None\n\n\ndef get_settings_service(config_dir: Optional[str] = None) -> SettingsService:\n    \"\"\"Get or create the singleton settings service instance.\"\"\"\n    global _settings_service_instance\n    if _settings_service_instance is None:\n        _settings_service_instance = SettingsService(config_dir)\n    return _settings_service_instance\n\n\ndef reset_settings_service() -> None:\n    \"\"\"Reset the singleton instance (mainly for testing).\"\"\"\n    global _settings_service_instance\n    _settings_service_instance = None\n",
          "QuestBoard_Maestro/services/theme_service.py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Callable, List\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass ThemeColors:\n    \"\"\"Theme color definitions.\"\"\"\n    primary: str = \"#3498db\"\n    secondary: str = \"#2ecc71\"\n    background: str = \"#2c3e50\"\n    surface: str = \"#34495e\"\n    text: str = \"#ecf0f1\"\n    text_secondary: str = \"#bdc3c7\"\n    accent: str = \"#e74c3c\"\n    success: str = \"#27ae60\"\n    warning: str = \"#f39c12\"\n    error: str = \"#c0392b\"\n    border: str = \"#7f8c8d\"\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, str]) -> 'ThemeColors':\n        return cls(\n            primary=data.get('primary', '#3498db'),\n            secondary=data.get('secondary', '#2ecc71'),\n            background=data.get('background', '#2c3e50'),\n            surface=data.get('surface', '#34495e'),\n            text=data.get('text', '#ecf0f1'),\n            text_secondary=data.get('text_secondary', '#bdc3c7'),\n            accent=data.get('accent', '#e74c3c'),\n            success=data.get('success', '#27ae60'),\n            warning=data.get('warning', '#f39c12'),\n            error=data.get('error', '#c0392b'),\n            border=data.get('border', '#7f8c8d')\n        )\n\n\n@dataclass\nclass Theme:\n    \"\"\"Complete theme definition.\"\"\"\n    name: str\n    display_name: str\n    colors: ThemeColors\n    font_family: str = \"Segoe UI\"\n    font_size: int = 10\n    border_radius: int = 4\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Theme':\n        colors = ThemeColors.from_dict(data.get('colors', {}))\n        return cls(\n            name=data.get('name', 'default'),\n            display_name=data.get('display_name', 'Default'),\n            colors=colors,\n            font_family=data.get('font_family', 'Segoe UI'),\n            font_size=data.get('font_size', 10),\n            border_radius=data.get('border_radius', 4)\n        )\n\n    def generate_stylesheet(self) -> str:\n        \"\"\"Generate Qt stylesheet from theme.\"\"\"\n        return f\"\"\"\n        QMainWindow, QWidget {{\n            background-color: {self.colors.background};\n            color: {self.colors.text};\n            font-family: {self.font_family};\n            font-size: {self.font_size}pt;\n        }}\n\n        QMenuBar {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border-bottom: 1px solid {self.colors.border};\n        }}\n\n        QMenuBar::item:selected {{\n            background-color: {self.colors.primary};\n        }}\n\n        QMenu {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n        }}\n\n        QMenu::item:selected {{\n            background-color: {self.colors.primary};\n        }}\n\n        QPushButton {{\n            background-color: {self.colors.primary};\n            color: {self.colors.text};\n            border: none;\n            padding: 8px 16px;\n            border-radius: {self.border_radius}px;\n        }}\n\n        QPushButton:hover {{\n            background-color: {self.colors.secondary};\n        }}\n\n        QPushButton:pressed {{\n            background-color: {self.colors.accent};\n        }}\n\n        QLineEdit, QTextEdit, QPlainTextEdit {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            padding: 4px;\n        }}\n\n        QLineEdit:focus, QTextEdit:focus, QPlainTextEdit:focus {{\n            border: 1px solid {self.colors.primary};\n        }}\n\n        QListWidget, QTreeWidget, QTableWidget {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n        }}\n\n        QListWidget::item:selected, QTreeWidget::item:selected {{\n            background-color: {self.colors.primary};\n        }}\n\n        QListWidget::item:hover, QTreeWidget::item:hover {{\n            background-color: {self.colors.surface};\n        }}\n\n        QComboBox {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            padding: 4px 8px;\n        }}\n\n        QComboBox:hover {{\n            border: 1px solid {self.colors.primary};\n        }}\n\n        QComboBox::drop-down {{\n            border: none;\n        }}\n\n        QComboBox QAbstractItemView {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            selection-background-color: {self.colors.primary};\n        }}\n\n        QScrollBar:vertical {{\n            background-color: {self.colors.background};\n            width: 12px;\n            border-radius: 6px;\n        }}\n\n        QScrollBar::handle:vertical {{\n            background-color: {self.colors.border};\n            border-radius: 6px;\n            min-height: 20px;\n        }}\n\n        QScrollBar::handle:vertical:hover {{\n            background-color: {self.colors.primary};\n        }}\n\n        QLabel {{\n            color: {self.colors.text};\n        }}\n\n        QGroupBox {{\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            margin-top: 8px;\n            padding-top: 8px;\n        }}\n\n        QGroupBox::title {{\n            color: {self.colors.text};\n            subcontrol-origin: margin;\n            left: 10px;\n        }}\n\n        QCheckBox {{\n            color: {self.colors.text};\n        }}\n\n        QCheckBox::indicator {{\n            width: 16px;\n            height: 16px;\n            border: 1px solid {self.colors.border};\n            border-radius: 3px;\n            background-color: {self.colors.surface};\n        }}\n\n        QCheckBox::indicator:checked {{\n            background-color: {self.colors.primary};\n        }}\n\n        QStatusBar {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text_secondary};\n        }}\n\n        QToolBar {{\n            background-color: {self.colors.surface};\n            border: none;\n            spacing: 4px;\n        }}\n\n        QProgressBar {{\n            background-color: {self.colors.surface};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            text-align: center;\n            color: {self.colors.text};\n        }}\n\n        QProgressBar::chunk {{\n            background-color: {self.colors.primary};\n            border-radius: {self.border_radius}px;\n        }}\n        \"\"\"\n\n\nclass ThemeService:\n    \"\"\"Service for managing application themes.\"\"\"\n\n    def __init__(self, themes_dir: Optional[str] = None):\n        if themes_dir:\n            self._themes_dir = Path(themes_dir)\n        else:\n            self._themes_dir = Path(__file__).parent.parent / 'assets' / 'themes'\n\n        self._themes: Dict[str, Theme] = {}\n        self._current_theme: Optional[Theme] = None\n        self._settings_service = None\n        self._theme_change_callbacks: List[Callable[[Theme], None]] = []\n\n        self._load_themes()\n        self._ensure_default_theme()\n\n    def set_settings_service(self, settings_service) -> None:\n        \"\"\"Set the settings service for profile-aware theme loading.\"\"\"\n        self._settings_service = settings_service\n\n    def _load_themes(self) -> None:\n        \"\"\"Load all available themes from the themes directory.\"\"\"\n        if not self._themes_dir.exists():\n            self._themes_dir.mkdir(parents=True, exist_ok=True)\n            return\n\n        for theme_file in self._themes_dir.glob('*.json'):\n            try:\n                with open(theme_file, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    theme = Theme.from_dict(data)\n                    self._themes[theme.name] = theme\n            except (json.JSONDecodeError, IOError) as e:\n                print(f\"Error loading theme {theme_file}: {e}\")\n\n    def _ensure_default_theme(self) -> None:\n        \"\"\"Ensure a default theme exists.\"\"\"\n        if 'default' not in self._themes:\n            default_theme = Theme(\n                name='default',\n                display_name='Default Dark',\n                colors=ThemeColors()\n            )\n            self._themes['default'] = default_theme\n            self._save_theme(default_theme)\n\n        if 'light' not in self._themes:\n            light_theme = Theme(\n                name='light',\n                display_name='Light',\n                colors=ThemeColors(\n                    primary='#3498db',\n                    secondary='#2ecc71',\n                    background='#f5f6fa',\n                    surface='#ffffff',\n                    text='#2c3e50',\n                    text_secondary='#7f8c8d',\n                    accent='#e74c3c',\n                    success='#27ae60',\n                    warning='#f39c12',\n                    error='#c0392b',\n                    border='#dcdde1'\n                )\n            )\n            self._themes['light'] = light_theme\n            self._save_theme(light_theme)\n\n    def _save_theme(self, theme: Theme) -> None:\n        \"\"\"Save a theme to file.\"\"\"\n        theme_file = self._themes_dir / f'{theme.name}.json'\n        try:\n            self._themes_dir.mkdir(parents=True, exist_ok=True)\n            with open(theme_file, 'w', encoding='utf-8') as f:\n                json.dump({\n                    'name': theme.name,\n                    'display_name': theme.display_name,\n                    'colors': {\n                        'primary': theme.colors.primary,\n                        'secondary': theme.colors.secondary,\n                        'background': theme.colors.background,\n                        'surface': theme.colors.surface,\n                        'text': theme.colors.text,\n                        'text_secondary': theme.colors.text_secondary,\n                        'accent': theme.colors.accent,\n                        'success': theme.colors.success,\n                        'warning': theme.colors.warning,\n                        'error': theme.colors.error,\n                        'border': theme.colors.border\n                    },\n                    'font_family': theme.font_family,\n                    'font_size': theme.font_size,\n                    'border_radius': theme.border_radius\n                }, f, indent=2)\n        except IOError as e:\n            print(f\"Error saving theme {theme.name}: {e}\")\n\n    def get_available_themes(self) -> List[str]:\n        \"\"\"Get list of available theme names.\"\"\"\n        return list(self._themes.keys())\n\n    def get_theme(self, name: str) -> Optional[Theme]:\n        \"\"\"Get a theme by name.\"\"\"\n        return self._themes.get(name)\n\n    def get_current_theme(self) -> Optional[Theme]:\n        \"\"\"Get the currently active theme.\"\"\"\n        return self._current_theme\n\n    def load_theme_from_profile(self) -> Theme:\n        \"\"\"Load theme based on the active profile's settings.\"\"\"\n        theme_name = 'default'\n        if self._settings_service:\n            theme_name = self._settings_service.get_theme()\n\n        return self.set_theme(theme_name)\n\n    def set_theme(self, name: str) -> Theme:\n        \"\"\"Set the active theme by name.\"\"\"\n        theme = self._themes.get(name)\n        if not theme:\n            theme = self._themes.get('default', Theme(\n                name='default',\n                display_name='Default',\n                colors=ThemeColors()\n            ))\n\n        self._current_theme = theme\n\n        # Notify all registered callbacks\n        for callback in self._theme_change_callbacks:\n            try:\n                callback(theme)\n            except Exception as e:\n                print(f\"Error in theme change callback: {e}\")\n\n        return theme\n\n    def register_theme_change_callback(self, callback: Callable[[Theme], None]) -> None:\n        \"\"\"Register a callback to be called when theme changes.\"\"\"\n        if callback not in self._theme_change_callbacks:\n            self._theme_change_callbacks.append(callback)\n\n    def unregister_theme_change_callback(self, callback: Callable[[Theme], None]) -> None:\n        \"\"\"Unregister a theme change callback.\"\"\"\n        if callback in self._theme_change_callbacks:\n            self._theme_change_callbacks.remove(callback)\n\n    def get_stylesheet(self) -> str:\n        \"\"\"Get the stylesheet for the current theme.\"\"\"\n        if self._current_theme:\n            return self._current_theme.generate_stylesheet()\n        return \"\"\n\n    def get_color(self, color_name: str) -> str:\n        \"\"\"Get a specific color from the current theme.\"\"\"\n        if self._current_theme and hasattr(self._current_theme.colors, color_name):\n            return getattr(self._current_theme.colors, color_name)\n        return \"#000000\"\n\n\n# Singleton instance\n_theme_service_instance: Optional[ThemeService] = None\n\n\ndef get_theme_service(themes_dir: Optional[str] = None) -> ThemeService:\n    \"\"\"Get or create the singleton theme service instance.\"\"\"\n    global _theme_service_instance\n    if _theme_service_instance is None:\n        _theme_service_instance = ThemeService(themes_dir)\n    return _theme_service_instance\n\n\ndef reset_theme_service() -> None:\n    \"\"\"Reset the singleton instance (mainly for testing).\"\"\"\n    global _theme_service_instance\n    _theme_service_instance = None\n",
          "QuestBoard_Maestro/src/ui/quest_viewmodel.py": "import json\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Callable\nfrom dataclasses import dataclass, asdict, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\n\nclass QuestPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n\nclass QuestStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    ARCHIVED = \"archived\"\n\n\n@dataclass\nclass Quest:\n    \"\"\"Represents a single quest/task.\"\"\"\n    id: str\n    title: str\n    description: str = \"\"\n    priority: QuestPriority = QuestPriority.MEDIUM\n    status: QuestStatus = QuestStatus.PENDING\n    created_at: str = \"\"\n    updated_at: str = \"\"\n    due_date: Optional[str] = None\n    tags: List[str] = field(default_factory=list)\n    subtasks: List[Dict[str, Any]] = field(default_factory=list)\n    progress: int = 0\n    notes: str = \"\"\n\n    def __post_init__(self):\n        if not self.created_at:\n            self.created_at = datetime.now().isoformat()\n        if not self.updated_at:\n            self.updated_at = datetime.now().isoformat()\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            'id': self.id,\n            'title': self.title,\n            'description': self.description,\n            'priority': self.priority.value,\n            'status': self.status.value,\n            'created_at': self.created_at,\n            'updated_at': self.updated_at,\n            'due_date': self.due_date,\n            'tags': self.tags,\n            'subtasks': self.subtasks,\n            'progress': self.progress,\n            'notes': self.notes\n        }\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Quest':\n        return cls(\n            id=data.get('id', str(uuid.uuid4())),\n            title=data.get('title', 'Untitled Quest'),\n            description=data.get('description', ''),\n            priority=QuestPriority(data.get('priority', 2)),\n            status=QuestStatus(data.get('status', 'pending')),\n            created_at=data.get('created_at', ''),\n            updated_at=data.get('updated_at', ''),\n            due_date=data.get('due_date'),\n            tags=data.get('tags', []),\n            subtasks=data.get('subtasks', []),\n            progress=data.get('progress', 0),\n            notes=data.get('notes', '')\n        )\n\n\nclass QuestViewModel:\n    \"\"\"ViewModel for managing quests with profile-aware persistence.\"\"\"\n\n    def __init__(self, settings_service=None):\n        self._settings_service = settings_service\n        self._quests: List[Quest] = []\n        self._change_callbacks: List[Callable[[], None]] = []\n        self._filter_status: Optional[QuestStatus] = None\n        self._filter_priority: Optional[QuestPriority] = None\n        self._search_term: str = \"\"\n\n    def set_settings_service(self, settings_service) -> None:\n        \"\"\"Set the settings service for profile-aware file management.\"\"\"\n        self._settings_service = settings_service\n\n    def _get_quest_file_path(self) -> Path:\n        \"\"\"Get the path to the quest file for the active profile.\"\"\"\n        if self._settings_service:\n            return self._settings_service.get_active_quest_file_path()\n        # Fallback for when no settings service is available\n        return Path.home() / '.questboard_maestro' / 'quests_default.json'\n\n    def load_quests(self) -> bool:\n        \"\"\"Load quests from the profile-specific file.\"\"\"\n        quest_file = self._get_quest_file_path()\n        self._quests = []\n\n        if not quest_file.exists():\n            self._notify_change()\n            return True\n\n        try:\n            with open(quest_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                quests_data = data.get('quests', [])\n                self._quests = [Quest.from_dict(q) for q in quests_data]\n            self._notify_change()\n            return True\n        except (json.JSONDecodeError, IOError) as e:\n            print(f\"Error loading quests: {e}\")\n            self._notify_change()\n            return False\n\n    def save_quests(self) -> bool:\n        \"\"\"Save quests to the profile-specific file.\"\"\"\n        quest_file = self._get_quest_file_path()\n\n        try:\n            quest_file.parent.mkdir(parents=True, exist_ok=True)\n            data = {\n                'version': '1.0',\n                'saved_at': datetime.now().isoformat(),\n                'quests': [q.to_dict() for q in self._quests]\n            }\n            with open(quest_file, 'w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2)\n            return True\n        except IOError as e:\n            print(f\"Error saving quests: {e}\")\n            return False\n\n    def add_quest(self, title: str, description: str = \"\",\n                  priority: QuestPriority = QuestPriority.MEDIUM,\n                  due_date: Optional[str] = None,\n                  tags: Optional[List[str]] = None) -> Quest:\n        \"\"\"Add a new quest.\"\"\"\n        quest = Quest(\n            id=str(uuid.uuid4()),\n            title=title,\n            description=description,\n            priority=priority,\n            due_date=due_date,\n            tags=tags or []\n        )\n        self._quests.append(quest)\n        self._auto_save()\n        self._notify_change()\n        return quest\n\n    def update_quest(self, quest_id: str, **kwargs) -> Optional[Quest]:\n        \"\"\"Update an existing quest.\"\"\"\n        quest = self.get_quest_by_id(quest_id)\n        if not quest:\n            return None\n\n        for key, value in kwargs.items():\n            if hasattr(quest, key):\n                if key == 'priority' and isinstance(value, int):\n                    value = QuestPriority(value)\n                elif key == 'status' and isinstance(value, str):\n                    value = QuestStatus(value)\n                setattr(quest, key, value)\n\n        quest.updated_at = datetime.now().isoformat()\n        self._auto_save()\n        self._notify_change()\n        return quest\n\n    def delete_quest(self, quest_id: str) -> bool:\n        \"\"\"Delete a quest by ID.\"\"\"\n        quest = self.get_quest_by_id(quest_id)\n        if quest:\n            self._quests.remove(quest)\n            self._auto_save()\n            self._notify_change()\n            return True\n        return False\n\n    def get_quest_by_id(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Get a quest by its ID.\"\"\"\n        for quest in self._quests:\n            if quest.id == quest_id:\n                return quest\n        return None\n\n    def get_all_quests(self) -> List[Quest]:\n        \"\"\"Get all quests.\"\"\"\n        return list(self._quests)\n\n    def get_filtered_quests(self) -> List[Quest]:\n        \"\"\"Get quests filtered by current filter settings.\"\"\"\n        filtered = self._quests\n\n        if self._filter_status:\n            filtered = [q for q in filtered if q.status == self._filter_status]\n\n        if self._filter_priority:\n            filtered = [q for q in filtered if q.priority == self._filter_priority]\n\n        if self._search_term:\n            term = self._search_term.lower()\n            filtered = [q for q in filtered if\n                       term in q.title.lower() or\n                       term in q.description.lower() or\n                       any(term in tag.lower() for tag in q.tags)]\n\n        return filtered\n\n    def set_filter_status(self, status: Optional[QuestStatus]) -> None:\n        \"\"\"Set the status filter.\"\"\"\n        self._filter_status = status\n        self._notify_change()\n\n    def set_filter_priority(self, priority: Optional[QuestPriority]) -> None:\n        \"\"\"Set the priority filter.\"\"\"\n        self._filter_priority = priority\n        self._notify_change()\n\n    def set_search_term(self, term: str) -> None:\n        \"\"\"Set the search term filter.\"\"\"\n        self._search_term = term\n        self._notify_change()\n\n    def clear_filters(self) -> None:\n        \"\"\"Clear all filters.\"\"\"\n        self._filter_status = None\n        self._filter_priority = None\n        self._search_term = \"\"\n        self._notify_change()\n\n    def complete_quest(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Mark a quest as completed.\"\"\"\n        return self.update_quest(quest_id, status=QuestStatus.COMPLETED, progress=100)\n\n    def archive_quest(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Archive a quest.\"\"\"\n        return self.update_quest(quest_id, status=QuestStatus.ARCHIVED)\n\n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get quest statistics.\"\"\"\n        total = len(self._quests)\n        completed = len([q for q in self._quests if q.status == QuestStatus.COMPLETED])\n        in_progress = len([q for q in self._quests if q.status == QuestStatus.IN_PROGRESS])\n        pending = len([q for q in self._quests if q.status == QuestStatus.PENDING])\n\n        return {\n            'total': total,\n            'completed': completed,\n            'in_progress': in_progress,\n            'pending': pending,\n            'completion_rate': (completed / total * 100) if total > 0 else 0\n        }\n\n    def register_change_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Register a callback for when quests change.\"\"\"\n        if callback not in self._change_callbacks:\n            self._change_callbacks.append(callback)\n\n    def unregister_change_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Unregister a change callback.\"\"\"\n        if callback in self._change_callbacks:\n            self._change_callbacks.remove(callback)\n\n    def _notify_change(self) -> None:\n        \"\"\"Notify all registered callbacks of a change.\"\"\"\n        for callback in self._change_callbacks:\n            try:\n                callback()\n            except Exception as e:\n                print(f\"Error in change callback: {e}\")\n\n    def _auto_save(self) -> None:\n        \"\"\"Auto-save if enabled in settings.\"\"\"\n        if self._settings_service:\n            if self._settings_service.get_setting('auto_save', True):\n                self.save_quests()\n        else:\n            self.save_quests()\n\n    def reload_for_profile(self) -> None:\n        \"\"\"Reload quests for the current profile (called on profile switch).\"\"\"\n        self.load_quests()\n\n    def sort_quests(self, key: str = 'priority', reverse: bool = True) -> None:\n        \"\"\"Sort quests by the specified key.\"\"\"\n        if key == 'priority':\n            self._quests.sort(key=lambda q: q.priority.value, reverse=reverse)\n        elif key == 'created_at':\n            self._quests.sort(key=lambda q: q.created_at, reverse=reverse)\n        elif key == 'due_date':\n            self._quests.sort(key=lambda q: q.due_date or '', reverse=reverse)\n        elif key == 'title':\n            self._quests.sort(key=lambda q: q.title.lower(), reverse=reverse)\n        elif key == 'status':\n            self._quests.sort(key=lambda q: q.status.value, reverse=reverse)\n\n        self._notify_change()\n",
          "QuestBoard_Maestro/src/ui/main_window.py": "from typing import Optional\nimport sys\n\ntry:\n    from PyQt6.QtWidgets import (\n        QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,\n        QListWidget, QListWidgetItem, QPushButton, QLabel,\n        QLineEdit, QTextEdit, QComboBox, QMenuBar, QMenu,\n        QStatusBar, QMessageBox, QInputDialog, QSplitter,\n        QFrame, QProgressBar, QToolBar, QDialog, QFormLayout,\n        QDialogButtonBox, QGroupBox, QCheckBox\n    )\n    from PyQt6.QtCore import Qt, QSize\n    from PyQt6.QtGui import QAction, QIcon\n    HAS_PYQT6 = True\nexcept ImportError:\n    HAS_PYQT6 = False\n    # Provide mock classes for environments without PyQt6\n    class QMainWindow:\n        def __init__(self, *args, **kwargs):\n            pass\n\n\nif HAS_PYQT6:\n    from .quest_viewmodel import QuestViewModel, Quest, QuestPriority, QuestStatus\n\n\nclass ProfileManager:\n    \"\"\"Helper class to manage profile operations.\"\"\"\n\n    def __init__(self, settings_service, theme_service, quest_viewmodel):\n        self.settings_service = settings_service\n        self.theme_service = theme_service\n        self.quest_viewmodel = quest_viewmodel\n\n    def initialize_profiles(self) -> str:\n        \"\"\"Initialize profiles on startup, returns active profile name.\"\"\"\n        profiles = self.settings_service.get_available_profiles()\n\n        if not profiles:\n            # First run - create default profile\n            self.settings_service.create_profile('Primary')\n            self.settings_service.load_profile('Primary')\n            return 'Primary'\n\n        # Load last active profile\n        last_profile = self.settings_service.get_last_active_profile()\n        if last_profile and self.settings_service.profile_exists(last_profile):\n            self.settings_service.load_profile(last_profile)\n            return last_profile\n\n        # Fallback to first available profile\n        self.settings_service.load_profile(profiles[0])\n        return profiles[0]\n\n    def switch_profile(self, profile_name: str) -> bool:\n        \"\"\"Switch to a different profile.\"\"\"\n        if not self.settings_service.profile_exists(profile_name):\n            return False\n\n        # Save current quest state\n        self.quest_viewmodel.save_quests()\n\n        # Save current profile settings\n        self.settings_service.save_active_profile()\n\n        # Switch to new profile\n        if self.settings_service.switch_profile(profile_name):\n            # Reload quests for new profile\n            self.quest_viewmodel.reload_for_profile()\n\n            # Update theme\n            self.theme_service.load_theme_from_profile()\n\n            return True\n        return False\n\n    def create_profile(self, name: str) -> bool:\n        \"\"\"Create a new profile.\"\"\"\n        return self.settings_service.create_profile(name)\n\n    def get_profiles(self):\n        \"\"\"Get list of available profiles.\"\"\"\n        return self.settings_service.get_available_profiles()\n\n    def get_active_profile(self) -> str:\n        \"\"\"Get the active profile name.\"\"\"\n        return self.settings_service.active_profile_name\n\n\nif HAS_PYQT6:\n    class QuestDialog(QDialog):\n        \"\"\"Dialog for creating/editing quests.\"\"\"\n\n        def __init__(self, parent=None, quest: Optional[Quest] = None):\n            super().__init__(parent)\n            self.quest = quest\n            self.setup_ui()\n\n        def setup_ui(self):\n            self.setWindowTitle(\"Edit Quest\" if self.quest else \"New Quest\")\n            self.setMinimumWidth(400)\n\n            layout = QVBoxLayout(self)\n\n            form_layout = QFormLayout()\n\n            self.title_edit = QLineEdit()\n            if self.quest:\n                self.title_edit.setText(self.quest.title)\n            form_layout.addRow(\"Title:\", self.title_edit)\n\n            self.description_edit = QTextEdit()\n            self.description_edit.setMaximumHeight(100)\n            if self.quest:\n                self.description_edit.setText(self.quest.description)\n            form_layout.addRow(\"Description:\", self.description_edit)\n\n            self.priority_combo = QComboBox()\n            self.priority_combo.addItems([\"Low\", \"Medium\", \"High\", \"Critical\"])\n            if self.quest:\n                self.priority_combo.setCurrentIndex(self.quest.priority.value - 1)\n            else:\n                self.priority_combo.setCurrentIndex(1)  # Default to Medium\n            form_layout.addRow(\"Priority:\", self.priority_combo)\n\n            self.tags_edit = QLineEdit()\n            self.tags_edit.setPlaceholderText(\"Comma-separated tags\")\n            if self.quest and self.quest.tags:\n                self.tags_edit.setText(\", \".join(self.quest.tags))\n            form_layout.addRow(\"Tags:\", self.tags_edit)\n\n            layout.addLayout(form_layout)\n\n            button_box = QDialogButtonBox(\n                QDialogButtonBox.StandardButton.Ok |\n                QDialogButtonBox.StandardButton.Cancel\n            )\n            button_box.accepted.connect(self.accept)\n            button_box.rejected.connect(self.reject)\n            layout.addWidget(button_box)\n\n        def get_quest_data(self):\n            \"\"\"Get the quest data from the dialog.\"\"\"\n            tags = [t.strip() for t in self.tags_edit.text().split(',') if t.strip()]\n            return {\n                'title': self.title_edit.text(),\n                'description': self.description_edit.toPlainText(),\n                'priority': QuestPriority(self.priority_combo.currentIndex() + 1),\n                'tags': tags\n            }\n\n\n    class MainWindow(QMainWindow):\n        \"\"\"Main application window for QuestBoard Maestro.\"\"\"\n\n        def __init__(self, settings_service=None, theme_service=None):\n            super().__init__()\n\n            self.settings_service = settings_service\n            self.theme_service = theme_service\n            self.quest_viewmodel = QuestViewModel(settings_service)\n\n            # Create profile manager\n            self.profile_manager = ProfileManager(\n                settings_service, theme_service, self.quest_viewmodel\n            )\n\n            # Initialize profiles\n            active_profile = self.profile_manager.initialize_profiles()\n\n            # Load quests for active profile\n            self.quest_viewmodel.load_quests()\n\n            # Setup UI\n            self.setup_ui()\n            self.setup_menu_bar()\n            self.setup_status_bar()\n\n            # Apply theme\n            if self.theme_service:\n                self.theme_service.set_settings_service(settings_service)\n                self.theme_service.register_theme_change_callback(self.on_theme_changed)\n                self.theme_service.load_theme_from_profile()\n\n            # Register for quest changes\n            self.quest_viewmodel.register_change_callback(self.refresh_quest_list)\n\n            # Initial refresh\n            self.refresh_quest_list()\n            self.update_profile_indicator()\n\n        def setup_ui(self):\n            \"\"\"Setup the main UI components.\"\"\"\n            self.setWindowTitle(\"QuestBoard Maestro\")\n            self.setMinimumSize(900, 600)\n\n            # Restore window geometry\n            if self.settings_service:\n                geom = self.settings_service.get_window_geometry()\n                self.setGeometry(geom['x'], geom['y'], geom['width'], geom['height'])\n\n            central_widget = QWidget()\n            self.setCentralWidget(central_widget)\n\n            main_layout = QHBoxLayout(central_widget)\n\n            # Create splitter for resizable panels\n            splitter = QSplitter(Qt.Orientation.Horizontal)\n\n            # Left panel - Quest list\n            left_panel = QFrame()\n            left_layout = QVBoxLayout(left_panel)\n\n            # Search and filter bar\n            filter_layout = QHBoxLayout()\n\n            self.search_edit = QLineEdit()\n            self.search_edit.setPlaceholderText(\"Search quests...\")\n            self.search_edit.textChanged.connect(self.on_search_changed)\n            filter_layout.addWidget(self.search_edit)\n\n            self.status_filter = QComboBox()\n            self.status_filter.addItems([\"All Status\", \"Pending\", \"In Progress\", \"Completed\", \"Archived\"])\n            self.status_filter.currentIndexChanged.connect(self.on_status_filter_changed)\n            filter_layout.addWidget(self.status_filter)\n\n            left_layout.addLayout(filter_layout)\n\n            # Quest list\n            self.quest_list = QListWidget()\n            self.quest_list.itemClicked.connect(self.on_quest_selected)\n            self.quest_list.itemDoubleClicked.connect(self.on_quest_double_clicked)\n            left_layout.addWidget(self.quest_list)\n\n            # Quest action buttons\n            button_layout = QHBoxLayout()\n\n            self.add_button = QPushButton(\"Add Quest\")\n            self.add_button.clicked.connect(self.on_add_quest)\n            button_layout.addWidget(self.add_button)\n\n            self.complete_button = QPushButton(\"Complete\")\n            self.complete_button.clicked.connect(self.on_complete_quest)\n            self.complete_button.setEnabled(False)\n            button_layout.addWidget(self.complete_button)\n\n            self.delete_button = QPushButton(\"Delete\")\n            self.delete_button.clicked.connect(self.on_delete_quest)\n            self.delete_button.setEnabled(False)\n            button_layout.addWidget(self.delete_button)\n\n            left_layout.addLayout(button_layout)\n\n            splitter.addWidget(left_panel)\n\n            # Right panel - Quest details\n            right_panel = QFrame()\n            right_layout = QVBoxLayout(right_panel)\n\n            # Quest details header\n            self.detail_title = QLabel(\"Select a quest\")\n            self.detail_title.setStyleSheet(\"font-size: 16pt; font-weight: bold;\")\n            right_layout.addWidget(self.detail_title)\n\n            # Quest info group\n            info_group = QGroupBox(\"Quest Details\")\n            info_layout = QFormLayout(info_group)\n\n            self.detail_priority = QLabel(\"-\")\n            info_layout.addRow(\"Priority:\", self.detail_priority)\n\n            self.detail_status = QLabel(\"-\")\n            info_layout.addRow(\"Status:\", self.detail_status)\n\n            self.detail_created = QLabel(\"-\")\n            info_layout.addRow(\"Created:\", self.detail_created)\n\n            self.detail_tags = QLabel(\"-\")\n            info_layout.addRow(\"Tags:\", self.detail_tags)\n\n            right_layout.addWidget(info_group)\n\n            # Description\n            desc_group = QGroupBox(\"Description\")\n            desc_layout = QVBoxLayout(desc_group)\n            self.detail_description = QLabel(\"\")\n            self.detail_description.setWordWrap(True)\n            desc_layout.addWidget(self.detail_description)\n            right_layout.addWidget(desc_group)\n\n            # Progress\n            progress_group = QGroupBox(\"Progress\")\n            progress_layout = QVBoxLayout(progress_group)\n            self.detail_progress = QProgressBar()\n            self.detail_progress.setRange(0, 100)\n            progress_layout.addWidget(self.detail_progress)\n            right_layout.addWidget(progress_group)\n\n            right_layout.addStretch()\n\n            splitter.addWidget(right_panel)\n            splitter.setSizes([400, 500])\n\n            main_layout.addWidget(splitter)\n\n        def setup_menu_bar(self):\n            \"\"\"Setup the menu bar with profile management.\"\"\"\n            menubar = self.menuBar()\n\n            # File menu\n            file_menu = menubar.addMenu(\"&File\")\n\n            new_quest_action = QAction(\"&New Quest\", self)\n            new_quest_action.setShortcut(\"Ctrl+N\")\n            new_quest_action.triggered.connect(self.on_add_quest)\n            file_menu.addAction(new_quest_action)\n\n            save_action = QAction(\"&Save\", self)\n            save_action.setShortcut(\"Ctrl+S\")\n            save_action.triggered.connect(self.on_save)\n            file_menu.addAction(save_action)\n\n            file_menu.addSeparator()\n\n            exit_action = QAction(\"E&xit\", self)\n            exit_action.setShortcut(\"Ctrl+Q\")\n            exit_action.triggered.connect(self.close)\n            file_menu.addAction(exit_action)\n\n            # Profile menu\n            self.profile_menu = menubar.addMenu(\"&Profile\")\n            self.update_profile_menu()\n\n            # View menu\n            view_menu = menubar.addMenu(\"&View\")\n\n            # Theme submenu\n            theme_menu = view_menu.addMenu(\"&Theme\")\n            if self.theme_service:\n                for theme_name in self.theme_service.get_available_themes():\n                    theme_action = QAction(theme_name.title(), self)\n                    theme_action.triggered.connect(\n                        lambda checked, name=theme_name: self.on_change_theme(name)\n                    )\n                    theme_menu.addAction(theme_action)\n\n            refresh_action = QAction(\"&Refresh\", self)\n            refresh_action.setShortcut(\"F5\")\n            refresh_action.triggered.connect(self.refresh_quest_list)\n            view_menu.addAction(refresh_action)\n\n            # Help menu\n            help_menu = menubar.addMenu(\"&Help\")\n\n            about_action = QAction(\"&About\", self)\n            about_action.triggered.connect(self.on_about)\n            help_menu.addAction(about_action)\n\n        def update_profile_menu(self):\n            \"\"\"Update the profile menu with current profiles.\"\"\"\n            self.profile_menu.clear()\n\n            # Profile selector section\n            profiles = self.profile_manager.get_profiles()\n            active_profile = self.profile_manager.get_active_profile()\n\n            for profile_name in profiles:\n                action = QAction(profile_name, self)\n                action.setCheckable(True)\n                action.setChecked(profile_name == active_profile)\n                action.triggered.connect(\n                    lambda checked, name=profile_name: self.on_switch_profile(name)\n                )\n                self.profile_menu.addAction(action)\n\n            self.profile_menu.addSeparator()\n\n            # Create new profile action\n            new_profile_action = QAction(\"&Create New Profile...\", self)\n            new_profile_action.triggered.connect(self.on_create_profile)\n            self.profile_menu.addAction(new_profile_action)\n\n            # Delete profile action\n            delete_profile_action = QAction(\"&Delete Profile...\", self)\n            delete_profile_action.triggered.connect(self.on_delete_profile)\n            self.profile_menu.addAction(delete_profile_action)\n\n        def setup_status_bar(self):\n            \"\"\"Setup the status bar.\"\"\"\n            self.statusbar = QStatusBar()\n            self.setStatusBar(self.statusbar)\n\n            # Profile indicator\n            self.profile_label = QLabel()\n            self.statusbar.addPermanentWidget(self.profile_label)\n\n            # Quest count\n            self.quest_count_label = QLabel()\n            self.statusbar.addPermanentWidget(self.quest_count_label)\n\n        def update_profile_indicator(self):\n            \"\"\"Update the profile indicator in status bar.\"\"\"\n            active_profile = self.profile_manager.get_active_profile()\n            self.profile_label.setText(f\"Profile: {active_profile}\")\n            self.setWindowTitle(f\"QuestBoard Maestro - {active_profile}\")\n\n        def refresh_quest_list(self):\n            \"\"\"Refresh the quest list display.\"\"\"\n            self.quest_list.clear()\n\n            quests = self.quest_viewmodel.get_filtered_quests()\n\n            for quest in quests:\n                item = QListWidgetItem()\n                priority_icons = {1: \"\u25cb\", 2: \"\u25d0\", 3: \"\u25cf\", 4: \"\u25c9\"}\n                status_icons = {\n                    \"pending\": \"\u2b1c\",\n                    \"in_progress\": \"\ud83d\udd04\",\n                    \"completed\": \"\u2705\",\n                    \"archived\": \"\ud83d\udce6\"\n                }\n\n                priority_icon = priority_icons.get(quest.priority.value, \"\u25cb\")\n                status_icon = status_icons.get(quest.status.value, \"\u2b1c\")\n\n                item.setText(f\"{status_icon} {priority_icon} {quest.title}\")\n                item.setData(Qt.ItemDataRole.UserRole, quest.id)\n                self.quest_list.addItem(item)\n\n            # Update quest count\n            stats = self.quest_viewmodel.get_statistics()\n            self.quest_count_label.setText(\n                f\"Quests: {stats['total']} | Completed: {stats['completed']}\"\n            )\n\n        def on_quest_selected(self, item: QListWidgetItem):\n            \"\"\"Handle quest selection.\"\"\"\n            quest_id = item.data(Qt.ItemDataRole.UserRole)\n            quest = self.quest_viewmodel.get_quest_by_id(quest_id)\n\n            if quest:\n                self.display_quest_details(quest)\n                self.complete_button.setEnabled(quest.status != QuestStatus.COMPLETED)\n                self.delete_button.setEnabled(True)\n\n        def on_quest_double_clicked(self, item: QListWidgetItem):\n            \"\"\"Handle quest double-click for editing.\"\"\"\n            quest_id = item.data(Qt.ItemDataRole.UserRole)\n            quest = self.quest_viewmodel.get_quest_by_id(quest_id)\n\n            if quest:\n                self.edit_quest(quest)\n\n        def display_quest_details(self, quest: Quest):\n            \"\"\"Display quest details in the right panel.\"\"\"\n            self.detail_title.setText(quest.title)\n\n            priority_names = {1: \"Low\", 2: \"Medium\", 3: \"High\", 4: \"Critical\"}\n            self.detail_priority.setText(priority_names.get(quest.priority.value, \"Unknown\"))\n\n            status_names = {\n                \"pending\": \"Pending\",\n                \"in_progress\": \"In Progress\",\n                \"completed\": \"Completed\",\n                \"archived\": \"Archived\"\n            }\n            self.detail_status.setText(status_names.get(quest.status.value, \"Unknown\"))\n\n            self.detail_created.setText(quest.created_at[:10] if quest.created_at else \"-\")\n            self.detail_tags.setText(\", \".join(quest.tags) if quest.tags else \"-\")\n            self.detail_description.setText(quest.description or \"No description\")\n            self.detail_progress.setValue(quest.progress)\n\n        def on_add_quest(self):\n            \"\"\"Handle add quest action.\"\"\"\n            dialog = QuestDialog(self)\n            if dialog.exec() == QDialog.DialogCode.Accepted:\n                data = dialog.get_quest_data()\n                self.quest_viewmodel.add_quest(\n                    title=data['title'],\n                    description=data['description'],\n                    priority=data['priority'],\n                    tags=data['tags']\n                )\n\n        def edit_quest(self, quest: Quest):\n            \"\"\"Edit an existing quest.\"\"\"\n            dialog = QuestDialog(self, quest)\n            if dialog.exec() == QDialog.DialogCode.Accepted:\n                data = dialog.get_quest_data()\n                self.quest_viewmodel.update_quest(\n                    quest.id,\n                    title=data['title'],\n                    description=data['description'],\n                    priority=data['priority'],\n                    tags=data['tags']\n                )\n\n        def on_complete_quest(self):\n            \"\"\"Handle complete quest action.\"\"\"\n            current_item = self.quest_list.currentItem()\n            if current_item:\n                quest_id = current_item.data(Qt.ItemDataRole.UserRole)\n                self.quest_viewmodel.complete_quest(quest_id)\n\n        def on_delete_quest(self):\n            \"\"\"Handle delete quest action.\"\"\"\n            current_item = self.quest_list.currentItem()\n            if current_item:\n                quest_id = current_item.data(Qt.ItemDataRole.UserRole)\n                quest = self.quest_viewmodel.get_quest_by_id(quest_id)\n\n                reply = QMessageBox.question(\n                    self, \"Delete Quest\",\n                    f\"Are you sure you want to delete '{quest.title}'?\",\n                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n                )\n\n                if reply == QMessageBox.StandardButton.Yes:\n                    self.quest_viewmodel.delete_quest(quest_id)\n                    self.clear_quest_details()\n\n        def clear_quest_details(self):\n            \"\"\"Clear the quest details panel.\"\"\"\n            self.detail_title.setText(\"Select a quest\")\n            self.detail_priority.setText(\"-\")\n            self.detail_status.setText(\"-\")\n            self.detail_created.setText(\"-\")\n            self.detail_tags.setText(\"-\")\n            self.detail_description.setText(\"\")\n            self.detail_progress.setValue(0)\n            self.complete_button.setEnabled(False)\n            self.delete_button.setEnabled(False)\n\n        def on_search_changed(self, text: str):\n            \"\"\"Handle search text change.\"\"\"\n            self.quest_viewmodel.set_search_term(text)\n\n        def on_status_filter_changed(self, index: int):\n            \"\"\"Handle status filter change.\"\"\"\n            status_map = {\n                0: None,\n                1: QuestStatus.PENDING,\n                2: QuestStatus.IN_PROGRESS,\n                3: QuestStatus.COMPLETED,\n                4: QuestStatus.ARCHIVED\n            }\n            self.quest_viewmodel.set_filter_status(status_map.get(index))\n\n        def on_switch_profile(self, profile_name: str):\n            \"\"\"Handle profile switch.\"\"\"\n            if profile_name == self.profile_manager.get_active_profile():\n                return\n\n            if self.profile_manager.switch_profile(profile_name):\n                self.update_profile_menu()\n                self.update_profile_indicator()\n                self.clear_quest_details()\n                self.statusbar.showMessage(f\"Switched to profile: {profile_name}\", 3000)\n            else:\n                QMessageBox.warning(\n                    self, \"Profile Switch Failed\",\n                    f\"Failed to switch to profile '{profile_name}'.\"\n                )\n\n        def on_create_profile(self):\n            \"\"\"Handle create new profile action.\"\"\"\n            name, ok = QInputDialog.getText(\n                self, \"Create New Profile\",\n                \"Enter profile name:\"\n            )\n\n            if ok and name:\n                name = name.strip()\n                if not name:\n                    QMessageBox.warning(self, \"Invalid Name\", \"Profile name cannot be empty.\")\n                    return\n\n                if self.settings_service.profile_exists(name):\n                    QMessageBox.warning(\n                        self, \"Profile Exists\",\n                        f\"A profile named '{name}' already exists.\"\n                    )\n                    return\n\n                if self.profile_manager.create_profile(name):\n                    self.update_profile_menu()\n                    self.statusbar.showMessage(f\"Created profile: {name}\", 3000)\n\n                    # Ask if user wants to switch to new profile\n                    reply = QMessageBox.question(\n                        self, \"Switch Profile\",\n                        f\"Switch to the new profile '{name}'?\",\n                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n                    )\n\n                    if reply == QMessageBox.StandardButton.Yes:\n                        self.on_switch_profile(name)\n                else:\n                    QMessageBox.warning(\n                        self, \"Creation Failed\",\n                        f\"Failed to create profile '{name}'.\"\n                    )\n\n        def on_delete_profile(self):\n            \"\"\"Handle delete profile action.\"\"\"\n            profiles = self.profile_manager.get_profiles()\n            active_profile = self.profile_manager.get_active_profile()\n\n            # Can't delete if only one profile\n            if len(profiles) <= 1:\n                QMessageBox.warning(\n                    self, \"Cannot Delete\",\n                    \"Cannot delete the only remaining profile.\"\n                )\n                return\n\n            # Get profile to delete\n            deletable_profiles = [p for p in profiles if p != active_profile]\n            profile_name, ok = QInputDialog.getItem(\n                self, \"Delete Profile\",\n                \"Select profile to delete:\",\n                deletable_profiles, 0, False\n            )\n\n            if ok and profile_name:\n                reply = QMessageBox.question(\n                    self, \"Confirm Delete\",\n                    f\"Are you sure you want to delete profile '{profile_name}'?\n\"\n                    \"This will delete all quests and settings for this profile.\",\n                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n                )\n\n                if reply == QMessageBox.StandardButton.Yes:\n                    if self.settings_service.delete_profile(profile_name):\n                        self.update_profile_menu()\n                        self.statusbar.showMessage(f\"Deleted profile: {profile_name}\", 3000)\n                    else:\n                        QMessageBox.warning(\n                            self, \"Delete Failed\",\n                            f\"Failed to delete profile '{profile_name}'.\"\n                        )\n\n        def on_change_theme(self, theme_name: str):\n            \"\"\"Handle theme change.\"\"\"\n            if self.theme_service:\n                self.theme_service.set_theme(theme_name)\n                if self.settings_service:\n                    self.settings_service.set_theme(theme_name)\n\n        def on_theme_changed(self, theme):\n            \"\"\"Handle theme change callback.\"\"\"\n            stylesheet = theme.generate_stylesheet()\n            self.setStyleSheet(stylesheet)\n\n        def on_save(self):\n            \"\"\"Handle save action.\"\"\"\n            self.quest_viewmodel.save_quests()\n            self.settings_service.save_active_profile()\n            self.statusbar.showMessage(\"Saved successfully\", 3000)\n\n        def on_about(self):\n            \"\"\"Show about dialog.\"\"\"\n            QMessageBox.about(\n                self, \"About QuestBoard Maestro\",\n                \"QuestBoard Maestro\n\n\"\n                \"A productivity application for managing your quests and tasks.\n\n\"\n                \"Features:\n\"\n                \"- Multiple user profiles\n\"\n                \"- Quest management with priorities\n\"\n                \"- Theme customization\n\"\n                \"- Search and filtering\"\n            )\n\n        def closeEvent(self, event):\n            \"\"\"Handle window close event.\"\"\"\n            # Save current state\n            self.quest_viewmodel.save_quests()\n\n            if self.settings_service:\n                self.settings_service.save_active_profile()\n                # Save window geometry\n                geom = self.geometry()\n                self.settings_service.save_window_geometry(\n                    geom.x(), geom.y(), geom.width(), geom.height()\n                )\n\n            event.accept()\n\nelse:\n    # Fallback for non-PyQt6 environments\n    class MainWindow:\n        def __init__(self, settings_service=None, theme_service=None):\n            self.settings_service = settings_service\n            self.theme_service = theme_service\n            print(\"PyQt6 not available - MainWindow is a stub\")\n\n        def show(self):\n            print(\"MainWindow.show() called - PyQt6 not available\")\n",
          "QuestBoard_Maestro/src/main.py": "import sys\nimport os\n\n# Add parent directory to path for imports\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom services.settings_service import get_settings_service, reset_settings_service\nfrom services.theme_service import get_theme_service, reset_theme_service\n\ntry:\n    from PyQt6.QtWidgets import QApplication\n    from PyQt6.QtCore import Qt\n    HAS_PYQT6 = True\nexcept ImportError:\n    HAS_PYQT6 = False\n    print(\"PyQt6 not installed. Install with: pip install PyQt6\")\n\n\ndef initialize_application():\n    \"\"\"Initialize application services and ensure default profile exists.\"\"\"\n    # Get settings service singleton\n    settings_service = get_settings_service()\n\n    # Check if any profiles exist\n    profiles = settings_service.get_available_profiles()\n\n    if not profiles:\n        # First run - create default 'Primary' profile\n        print(\"First run detected - creating default 'Primary' profile\")\n        settings_service.create_profile('Primary')\n        settings_service.load_profile('Primary')\n    else:\n        # Load last active profile or first available\n        last_profile = settings_service.get_last_active_profile()\n\n        if last_profile and settings_service.profile_exists(last_profile):\n            print(f\"Loading last active profile: {last_profile}\")\n            settings_service.load_profile(last_profile)\n        else:\n            # Fallback to first available profile\n            print(f\"Loading first available profile: {profiles[0]}\")\n            settings_service.load_profile(profiles[0])\n\n    # Get theme service and link to settings\n    theme_service = get_theme_service()\n    theme_service.set_settings_service(settings_service)\n\n    return settings_service, theme_service\n\n\ndef main():\n    \"\"\"Main entry point for QuestBoard Maestro.\"\"\"\n    if not HAS_PYQT6:\n        print(\"Error: PyQt6 is required to run QuestBoard Maestro\")\n        print(\"Install with: pip install PyQt6\")\n        return 1\n\n    # Create application\n    app = QApplication(sys.argv)\n    app.setApplicationName(\"QuestBoard Maestro\")\n    app.setApplicationVersion(\"1.0.0\")\n    app.setOrganizationName(\"QuestBoard\")\n\n    # Enable high DPI scaling\n    try:\n        app.setHighDpiScaleFactorRoundingPolicy(\n            Qt.HighDpiScaleFactorRoundingPolicy.PassThrough\n        )\n    except AttributeError:\n        pass  # Not available in older PyQt6 versions\n\n    # Initialize services\n    settings_service, theme_service = initialize_application()\n\n    # Import and create main window\n    from src.ui.main_window import MainWindow\n\n    window = MainWindow(\n        settings_service=settings_service,\n        theme_service=theme_service\n    )\n\n    # Apply initial theme\n    theme_service.load_theme_from_profile()\n\n    # Show window\n    window.show()\n\n    # Run application event loop\n    return app.exec()\n\n\ndef run_headless_test():\n    \"\"\"Run a headless test of profile functionality.\"\"\"\n    print(\"Running headless profile test...\")\n\n    # Reset singletons for clean test\n    reset_settings_service()\n    reset_theme_service()\n\n    settings_service = get_settings_service()\n\n    # Test profile creation\n    print(\"\n1. Testing profile creation...\")\n    assert settings_service.create_profile('TestProfile1'), \"Failed to create TestProfile1\"\n    assert settings_service.create_profile('TestProfile2'), \"Failed to create TestProfile2\"\n    print(\"   Created TestProfile1 and TestProfile2\")\n\n    # Test profile listing\n    print(\"\n2. Testing profile listing...\")\n    profiles = settings_service.get_available_profiles()\n    print(f\"   Available profiles: {profiles}\")\n    assert 'TestProfile1' in profiles, \"TestProfile1 not in list\"\n    assert 'TestProfile2' in profiles, \"TestProfile2 not in list\"\n\n    # Test profile loading\n    print(\"\n3. Testing profile loading...\")\n    assert settings_service.load_profile('TestProfile1'), \"Failed to load TestProfile1\"\n    assert settings_service.active_profile_name == 'TestProfile1', \"Active profile mismatch\"\n    print(f\"   Loaded profile: {settings_service.active_profile_name}\")\n\n    # Test settings modification\n    print(\"\n4. Testing settings modification...\")\n    settings_service.set_theme('light')\n    assert settings_service.get_theme() == 'light', \"Theme not set correctly\"\n    print(f\"   Theme set to: {settings_service.get_theme()}\")\n\n    # Test profile switching\n    print(\"\n5. Testing profile switching...\")\n    assert settings_service.switch_profile('TestProfile2'), \"Failed to switch profile\"\n    assert settings_service.active_profile_name == 'TestProfile2', \"Profile switch failed\"\n    print(f\"   Switched to: {settings_service.active_profile_name}\")\n\n    # Verify settings are independent\n    print(\"\n6. Testing settings isolation...\")\n    assert settings_service.get_theme() == 'default', \"Profile settings not isolated\"\n    print(f\"   TestProfile2 theme: {settings_service.get_theme()} (expected: default)\")\n\n    # Test quest file paths\n    print(\"\n7. Testing quest file paths...\")\n    path1 = settings_service.get_quest_file_path('TestProfile1')\n    path2 = settings_service.get_quest_file_path('TestProfile2')\n    print(f\"   TestProfile1 quests: {path1}\")\n    print(f\"   TestProfile2 quests: {path2}\")\n    assert path1 != path2, \"Quest paths should be different\"\n\n    # Test theme service integration\n    print(\"\n8. Testing theme service integration...\")\n    theme_service = get_theme_service()\n    theme_service.set_settings_service(settings_service)\n    theme = theme_service.load_theme_from_profile()\n    print(f\"   Loaded theme: {theme.name}\")\n\n    # Cleanup - delete test profiles\n    print(\"\n9. Cleaning up test profiles...\")\n    settings_service.switch_profile('TestProfile1')\n    settings_service.delete_profile('TestProfile2')\n    print(\"   Deleted TestProfile2\")\n\n    print(\"\n\u2713 All tests passed!\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    # Check for test mode\n    if len(sys.argv) > 1 and sys.argv[1] == \"--test\":\n        sys.exit(run_headless_test())\n    else:\n        sys.exit(main())\n",
          "QuestBoard_Maestro/tests/test_profiles.py": "import unittest\nimport tempfile\nimport shutil\nimport os\nimport sys\n\n# Add parent directory to path\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom services.settings_service import SettingsService, ProfileSettings, reset_settings_service\nfrom services.theme_service import ThemeService, reset_theme_service\nfrom src.ui.quest_viewmodel import QuestViewModel, QuestPriority, QuestStatus\n\n\nclass TestSettingsService(unittest.TestCase):\n    \"\"\"Test cases for the SettingsService.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n        self.settings_service = SettingsService(self.test_dir)\n\n    def tearDown(self):\n        \"\"\"Clean up test fixtures.\"\"\"\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_create_profile(self):\n        \"\"\"Test profile creation.\"\"\"\n        result = self.settings_service.create_profile('TestProfile')\n        self.assertTrue(result)\n        self.assertIn('TestProfile', self.settings_service.get_available_profiles())\n\n    def test_create_duplicate_profile(self):\n        \"\"\"Test that duplicate profiles cannot be created.\"\"\"\n        self.settings_service.create_profile('TestProfile')\n        result = self.settings_service.create_profile('TestProfile')\n        self.assertFalse(result)\n\n    def test_load_profile(self):\n        \"\"\"Test profile loading.\"\"\"\n        self.settings_service.create_profile('TestProfile')\n        result = self.settings_service.load_profile('TestProfile')\n        self.assertTrue(result)\n        self.assertEqual(self.settings_service.active_profile_name, 'TestProfile')\n\n    def test_load_nonexistent_profile(self):\n        \"\"\"Test loading a profile that doesn't exist.\"\"\"\n        result = self.settings_service.load_profile('NonexistentProfile')\n        self.assertFalse(result)\n\n    def test_switch_profile(self):\n        \"\"\"Test switching between profiles.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.load_profile('Profile1')\n\n        result = self.settings_service.switch_profile('Profile2')\n        self.assertTrue(result)\n        self.assertEqual(self.settings_service.active_profile_name, 'Profile2')\n\n    def test_profile_settings_isolation(self):\n        \"\"\"Test that profile settings are isolated.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n\n        # Set theme for Profile1\n        self.settings_service.load_profile('Profile1')\n        self.settings_service.set_theme('light')\n\n        # Switch to Profile2 and verify default theme\n        self.settings_service.switch_profile('Profile2')\n        self.assertEqual(self.settings_service.get_theme(), 'default')\n\n        # Switch back to Profile1 and verify light theme\n        self.settings_service.switch_profile('Profile1')\n        self.assertEqual(self.settings_service.get_theme(), 'light')\n\n    def test_delete_profile(self):\n        \"\"\"Test profile deletion.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.load_profile('Profile1')\n\n        result = self.settings_service.delete_profile('Profile2')\n        self.assertTrue(result)\n        self.assertNotIn('Profile2', self.settings_service.get_available_profiles())\n\n    def test_cannot_delete_active_profile(self):\n        \"\"\"Test that active profile cannot be deleted.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.load_profile('Profile1')\n\n        result = self.settings_service.delete_profile('Profile1')\n        self.assertFalse(result)\n\n    def test_quest_file_paths_unique(self):\n        \"\"\"Test that quest file paths are unique per profile.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n\n        path1 = self.settings_service.get_quest_file_path('Profile1')\n        path2 = self.settings_service.get_quest_file_path('Profile2')\n\n        self.assertNotEqual(path1, path2)\n\n    def test_last_active_profile_saved(self):\n        \"\"\"Test that last active profile is saved.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.load_profile('Profile2')\n\n        # Create new service instance to test persistence\n        new_service = SettingsService(self.test_dir)\n        self.assertEqual(new_service.get_last_active_profile(), 'Profile2')\n\n\nclass TestQuestViewModelWithProfiles(unittest.TestCase):\n    \"\"\"Test cases for QuestViewModel with profile support.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n        self.settings_service = SettingsService(self.test_dir)\n        self.settings_service.create_profile('TestProfile')\n        self.settings_service.load_profile('TestProfile')\n\n        self.viewmodel = QuestViewModel(self.settings_service)\n\n    def tearDown(self):\n        \"\"\"Clean up test fixtures.\"\"\"\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_add_quest(self):\n        \"\"\"Test adding a quest.\"\"\"\n        quest = self.viewmodel.add_quest('Test Quest', 'Description')\n        self.assertIsNotNone(quest)\n        self.assertEqual(quest.title, 'Test Quest')\n\n    def test_quest_persistence(self):\n        \"\"\"Test that quests are persisted.\"\"\"\n        self.viewmodel.add_quest('Persistent Quest')\n        self.viewmodel.save_quests()\n\n        # Create new viewmodel and load\n        new_viewmodel = QuestViewModel(self.settings_service)\n        new_viewmodel.load_quests()\n\n        quests = new_viewmodel.get_all_quests()\n        self.assertEqual(len(quests), 1)\n        self.assertEqual(quests[0].title, 'Persistent Quest')\n\n    def test_quests_isolated_per_profile(self):\n        \"\"\"Test that quests are isolated per profile.\"\"\"\n        # Add quest to first profile\n        self.viewmodel.add_quest('Profile1 Quest')\n        self.viewmodel.save_quests()\n\n        # Create and switch to second profile\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.switch_profile('Profile2')\n\n        # Create new viewmodel for Profile2\n        viewmodel2 = QuestViewModel(self.settings_service)\n        viewmodel2.load_quests()\n\n        # Verify Profile2 has no quests\n        self.assertEqual(len(viewmodel2.get_all_quests()), 0)\n\n        # Add quest to Profile2\n        viewmodel2.add_quest('Profile2 Quest')\n        viewmodel2.save_quests()\n\n        # Switch back to Profile1 and verify original quest\n        self.settings_service.switch_profile('TestProfile')\n        self.viewmodel.load_quests()\n\n        quests = self.viewmodel.get_all_quests()\n        self.assertEqual(len(quests), 1)\n        self.assertEqual(quests[0].title, 'Profile1 Quest')\n\n\nclass TestThemeServiceWithProfiles(unittest.TestCase):\n    \"\"\"Test cases for ThemeService with profile support.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n        self.themes_dir = os.path.join(self.test_dir, 'themes')\n        os.makedirs(self.themes_dir)\n\n        self.settings_service = SettingsService(self.test_dir)\n        self.settings_service.create_profile('TestProfile')\n        self.settings_service.load_profile('TestProfile')\n\n        self.theme_service = ThemeService(self.themes_dir)\n        self.theme_service.set_settings_service(self.settings_service)\n\n    def tearDown(self):\n        \"\"\"Clean up test fixtures.\"\"\"\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_load_theme_from_profile(self):\n        \"\"\"Test loading theme from profile settings.\"\"\"\n        self.settings_service.set_theme('light')\n        theme = self.theme_service.load_theme_from_profile()\n        self.assertEqual(theme.name, 'light')\n\n    def test_theme_changes_with_profile_switch(self):\n        \"\"\"Test that theme changes when profile switches.\"\"\"\n        # Set light theme for first profile\n        self.settings_service.set_theme('light')\n\n        # Create second profile with default theme\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.switch_profile('Profile2')\n\n        # Load theme for Profile2\n        theme = self.theme_service.load_theme_from_profile()\n        self.assertEqual(theme.name, 'default')\n\n    def test_theme_change_callback(self):\n        \"\"\"Test theme change callback is called.\"\"\"\n        callback_called = [False]\n        received_theme = [None]\n\n        def callback(theme):\n            callback_called[0] = True\n            received_theme[0] = theme\n\n        self.theme_service.register_theme_change_callback(callback)\n        self.theme_service.set_theme('light')\n\n        self.assertTrue(callback_called[0])\n        self.assertEqual(received_theme[0].name, 'light')\n\n\nif __name__ == '__main__':\n    unittest.main()\n"
        },
        "generated_files": [
          "QuestBoard_Maestro/services/settings_service.py",
          "QuestBoard_Maestro/services/theme_service.py",
          "QuestBoard_Maestro/src/ui/quest_viewmodel.py",
          "QuestBoard_Maestro/src/ui/main_window.py",
          "QuestBoard_Maestro/src/main.py",
          "QuestBoard_Maestro/tests/test_profiles.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8202284061440256,
              "dependency_traversal_accuracy": 0.8505783920678032,
              "cross_file_reasoning_depth": 0.2352777777777778,
              "system_thinking_score": 0.5495065359477125,
              "robustness_score": 0.15449984321103793,
              "comprehensiveness_score": 0.6758216368767639,
              "innovation_score": 0.3,
              "solution_elegance_score": 0.5983058090738439
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.1025285507680032,
              "dependency_traversal_weighted": 0.1063222990084754,
              "cross_file_reasoning_weighted": 0.029409722222222226,
              "system_thinking_weighted": 0.06868831699346406,
              "robustness_weighted": 0.019312480401379742,
              "comprehensiveness_weighted": 0.08447770460959549,
              "innovation_weighted": 0.0375,
              "solution_elegance_weighted": 0.07478822613423049
            },
            "total_software_engineering_score": 0.5230273001373705
          },
          "functional_correctness_details": {
            "compilation": {
              "success": false,
              "score": 0.0,
              "execution_time": 0.40479588508605957,
              "errors": [
                "  File \"QuestBoard_Maestro/src/main.py\", line 104",
                "    print(\"",
                "          ^",
                "SyntaxError: unterminated string literal (detected at line 104)",
                "  File \"QuestBoard_Maestro/src/ui/main_window.py\", line 630",
                "    f\"Are you sure you want to delete profile '{profile_name}'?",
                "    ^",
                "SyntaxError: unterminated f-string literal (detected at line 630)"
              ],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "QuestBoard_Maestro/services/settings_service.py",
                "QuestBoard_Maestro/services/theme_service.py",
                "QuestBoard_Maestro/src/ui/quest_viewmodel.py",
                "QuestBoard_Maestro/src/ui/main_window.py",
                "QuestBoard_Maestro/src/main.py",
                "QuestBoard_Maestro/tests/test_profiles.py"
              ],
              "scoring_breakdown": {
                "no_credit": 0.0
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 6,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 6 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.3023837209302326,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.0,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.3023837209302326,
              "idc_weight": 0.2,
              "total_functional_score": 0.37047674418604654
            }
          },
          "code_quality_details": {
            "files_analyzed": 6,
            "quality_checks": {
              "QuestBoard_Maestro/services/settings_service.py": {
                "line_count": 281,
                "non_empty_lines": 227,
                "comment_lines": 1,
                "comment_ratio": 0.004405286343612335,
                "function_count": 31,
                "class_count": 3,
                "import_count": 10,
                "quality_score": 0.7999999999999999
              },
              "QuestBoard_Maestro/services/theme_service.py": {
                "line_count": 409,
                "non_empty_lines": 342,
                "comment_lines": 2,
                "comment_ratio": 0.005847953216374269,
                "function_count": 19,
                "class_count": 3,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "QuestBoard_Maestro/src/ui/quest_viewmodel.py": {
                "line_count": 307,
                "non_empty_lines": 260,
                "comment_lines": 1,
                "comment_ratio": 0.0038461538461538464,
                "function_count": 27,
                "class_count": 4,
                "import_count": 13,
                "quality_score": 0.7999999999999999
              },
              "QuestBoard_Maestro/src/ui/main_window.py": {
                "line_count": 710,
                "non_empty_lines": 567,
                "comment_lines": 44,
                "comment_ratio": 0.07760141093474426,
                "function_count": 37,
                "class_count": 6,
                "import_count": 12,
                "quality_score": 0.6
              },
              "QuestBoard_Maestro/src/main.py": {
                "line_count": 180,
                "non_empty_lines": 143,
                "comment_lines": 25,
                "comment_ratio": 0.17482517482517482,
                "function_count": 3,
                "class_count": 0,
                "import_count": 12,
                "quality_score": 0.9999999999999999
              },
              "QuestBoard_Maestro/tests/test_profiles.py": {
                "line_count": 239,
                "non_empty_lines": 181,
                "comment_lines": 15,
                "comment_ratio": 0.08287292817679558,
                "function_count": 23,
                "class_count": 3,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7999999999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8150000000000001,
              "multi_session_memory_retention": 0.7865909090909091
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.40750000000000003,
              "multi_session_memory_retention_weighted": 0.39329545454545456
            },
            "total_longcontext_utilization_score": 0.8007954545454545
          }
        },
        "timestamp": "2026-01-14T21:48:34.428612"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_web_social_easy_073_feature_implementation_expert_01",
        "scenario_title": "Implement Asynchronous User Mentions and Notifications",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5513875319394449,
        "functional_correctness_score": 0.6715414364640884,
        "code_quality_score": 0.7562499999999999,
        "longcontext_utilization_score": 0.8337705305447242,
        "total_score": 3.2832224838473847,
        "generation_time": 90.50688171386719,
        "code_files_generated": 8,
        "total_lines_generated": 926,
        "parsing_success": true,
        "solution_code": {
          "classpulse/models.py": "from datetime import datetime\nfrom sqlalchemy import Column, Integer, String, Text, Boolean, DateTime, ForeignKey\nfrom sqlalchemy.orm import relationship, declarative_base\n\nBase = declarative_base()\n\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    username = Column(String(50), unique=True, index=True, nullable=False)\n    email = Column(String(100), unique=True, index=True, nullable=False)\n    hashed_password = Column(String(255), nullable=False)\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    posts = relationship(\"Post\", back_populates=\"author\")\n    notifications_received = relationship(\n        \"Notification\",\n        foreign_keys=\"Notification.recipient_id\",\n        back_populates=\"recipient\"\n    )\n    notifications_sent = relationship(\n        \"Notification\",\n        foreign_keys=\"Notification.actor_id\",\n        back_populates=\"actor\"\n    )\n\n\nclass Session(Base):\n    __tablename__ = \"sessions\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    title = Column(String(200), nullable=False)\n    description = Column(Text)\n    code = Column(String(10), unique=True, index=True, nullable=False)\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    owner_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n\n    posts = relationship(\"Post\", back_populates=\"session\")\n\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    content = Column(Text, nullable=False)\n    is_anonymous = Column(Boolean, default=False)\n    upvotes = Column(Integer, default=0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    author_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    session_id = Column(Integer, ForeignKey(\"sessions.id\"), nullable=False)\n\n    author = relationship(\"User\", back_populates=\"posts\")\n    session = relationship(\"Session\", back_populates=\"posts\")\n    notifications = relationship(\"Notification\", back_populates=\"post\")\n\n\nclass Notification(Base):\n    __tablename__ = \"notifications\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    recipient_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    actor_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    post_id = Column(Integer, ForeignKey(\"posts.id\"), nullable=False)\n    type = Column(String(50), nullable=False, default=\"mention\")\n    is_read = Column(Boolean, default=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    recipient = relationship(\n        \"User\",\n        foreign_keys=[recipient_id],\n        back_populates=\"notifications_received\"\n    )\n    actor = relationship(\n        \"User\",\n        foreign_keys=[actor_id],\n        back_populates=\"notifications_sent\"\n    )\n    post = relationship(\"Post\", back_populates=\"notifications\")\n",
          "classpulse/repositories.py": "from typing import List, Optional\nfrom sqlalchemy.orm import Session as DBSession\nfrom classpulse.models import User, Session, Post, Notification\n\n\nclass UserRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(self, username: str, email: str, hashed_password: str) -> User:\n        user = User(\n            username=username,\n            email=email,\n            hashed_password=hashed_password\n        )\n        self.db.add(user)\n        self.db.commit()\n        self.db.refresh(user)\n        return user\n\n    def get_by_id(self, user_id: int) -> Optional[User]:\n        return self.db.query(User).filter(User.id == user_id).first()\n\n    def get_by_username(self, username: str) -> Optional[User]:\n        return self.db.query(User).filter(User.username == username).first()\n\n    def get_by_email(self, email: str) -> Optional[User]:\n        return self.db.query(User).filter(User.email == email).first()\n\n\nclass SessionRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(self, title: str, code: str, owner_id: int, description: str = None) -> Session:\n        session = Session(\n            title=title,\n            code=code,\n            owner_id=owner_id,\n            description=description\n        )\n        self.db.add(session)\n        self.db.commit()\n        self.db.refresh(session)\n        return session\n\n    def get_by_id(self, session_id: int) -> Optional[Session]:\n        return self.db.query(Session).filter(Session.id == session_id).first()\n\n    def get_by_code(self, code: str) -> Optional[Session]:\n        return self.db.query(Session).filter(Session.code == code).first()\n\n\nclass PostRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(self, content: str, author_id: int, session_id: int, is_anonymous: bool = False) -> Post:\n        post = Post(\n            content=content,\n            author_id=author_id,\n            session_id=session_id,\n            is_anonymous=is_anonymous\n        )\n        self.db.add(post)\n        self.db.commit()\n        self.db.refresh(post)\n        return post\n\n    def get_by_id(self, post_id: int) -> Optional[Post]:\n        return self.db.query(Post).filter(Post.id == post_id).first()\n\n    def get_by_session(self, session_id: int) -> List[Post]:\n        return self.db.query(Post).filter(Post.session_id == session_id).all()\n\n    def upvote(self, post_id: int) -> Optional[Post]:\n        post = self.get_by_id(post_id)\n        if post:\n            post.upvotes += 1\n            self.db.commit()\n            self.db.refresh(post)\n        return post\n\n\nclass NotificationRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(\n        self,\n        recipient_id: int,\n        actor_id: int,\n        post_id: int,\n        notification_type: str = \"mention\"\n    ) -> Notification:\n        notification = Notification(\n            recipient_id=recipient_id,\n            actor_id=actor_id,\n            post_id=post_id,\n            type=notification_type\n        )\n        self.db.add(notification)\n        self.db.commit()\n        self.db.refresh(notification)\n        return notification\n\n    def get_by_recipient(self, recipient_id: int) -> List[Notification]:\n        return (\n            self.db.query(Notification)\n            .filter(Notification.recipient_id == recipient_id)\n            .order_by(Notification.created_at.desc())\n            .all()\n        )\n\n    def get_by_id(self, notification_id: int) -> Optional[Notification]:\n        return self.db.query(Notification).filter(Notification.id == notification_id).first()\n\n    def mark_as_read(self, notification_id: int) -> Optional[Notification]:\n        notification = self.get_by_id(notification_id)\n        if notification:\n            notification.is_read = True\n            self.db.commit()\n            self.db.refresh(notification)\n        return notification\n",
          "classpulse/services.py": "import re\nfrom typing import Optional, List\nfrom classpulse.models import User, Session, Post\nfrom classpulse.repositories import UserRepository, SessionRepository, PostRepository\nfrom classpulse.events import EventDispatcher\nimport secrets\nimport hashlib\n\n\ndef hash_password(password: str) -> str:\n    return hashlib.sha256(password.encode()).hexdigest()\n\n\ndef verify_password(password: str, hashed: str) -> bool:\n    return hash_password(password) == hashed\n\n\ndef generate_session_code() -> str:\n    return secrets.token_urlsafe(6)[:8].upper()\n\n\ndef parse_mentions(content: str) -> List[str]:\n    \"\"\"Extract all @username mentions from content.\"\"\"\n    pattern = r'@(\\w+)'\n    matches = re.findall(pattern, content)\n    return list(set(matches))\n\n\ndef create_user(\n    user_repo: UserRepository,\n    username: str,\n    email: str,\n    password: str\n) -> User:\n    hashed_password = hash_password(password)\n    return user_repo.create(username, email, hashed_password)\n\n\ndef authenticate_user(\n    user_repo: UserRepository,\n    username: str,\n    password: str\n) -> Optional[User]:\n    user = user_repo.get_by_username(username)\n    if user and verify_password(password, user.hashed_password):\n        return user\n    return None\n\n\ndef create_session(\n    session_repo: SessionRepository,\n    title: str,\n    owner_id: int,\n    description: str = None\n) -> Session:\n    code = generate_session_code()\n    return session_repo.create(title, code, owner_id, description)\n\n\ndef create_post(\n    post_repo: PostRepository,\n    user_repo: UserRepository,\n    event_dispatcher: EventDispatcher,\n    content: str,\n    author_id: int,\n    session_id: int,\n    is_anonymous: bool = False\n) -> Post:\n    post = post_repo.create(content, author_id, session_id, is_anonymous)\n    \n    # Parse mentions and dispatch events\n    mentioned_usernames = parse_mentions(content)\n    for username in mentioned_usernames:\n        mentioned_user = user_repo.get_by_username(username)\n        if mentioned_user and mentioned_user.id != author_id:\n            event_dispatcher.dispatch(\n                \"user_mentioned\",\n                {\n                    \"actor_id\": author_id,\n                    \"recipient_id\": mentioned_user.id,\n                    \"post_id\": post.id\n                }\n            )\n    \n    return post\n\n\ndef upvote_post(post_repo: PostRepository, post_id: int) -> Optional[Post]:\n    return post_repo.upvote(post_id)\n",
          "classpulse/events.py": "from typing import Callable, Dict, List, Any\nfrom collections import defaultdict\n\n\nclass EventDispatcher:\n    _instance = None\n    _subscribers: Dict[str, List[Callable]] = defaultdict(list)\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._instance._subscribers = defaultdict(list)\n        return cls._instance\n\n    def subscribe(self, event_name: str, handler: Callable) -> None:\n        \"\"\"Subscribe a handler to an event.\"\"\"\n        self._subscribers[event_name].append(handler)\n\n    def dispatch(self, event_name: str, payload: Dict[str, Any]) -> None:\n        \"\"\"Dispatch an event to all subscribers.\"\"\"\n        for handler in self._subscribers[event_name]:\n            handler(payload)\n\n    def clear(self) -> None:\n        \"\"\"Clear all subscribers (useful for testing).\"\"\"\n        self._subscribers.clear()\n\n\n# Global event dispatcher instance\nevent_dispatcher = EventDispatcher()\n",
          "classpulse/worker.py": "import threading\nimport queue\nfrom typing import Dict, Any, Callable\nfrom classpulse.events import event_dispatcher\nfrom classpulse.repositories import NotificationRepository\nfrom classpulse.config import get_db_session\n\n\nclass BackgroundWorker:\n    def __init__(self):\n        self.task_queue = queue.Queue()\n        self.running = False\n        self.thread = None\n\n    def start(self):\n        \"\"\"Start the background worker thread.\"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._process_tasks, daemon=True)\n        self.thread.start()\n\n    def stop(self):\n        \"\"\"Stop the background worker.\"\"\"\n        self.running = False\n        if self.thread:\n            self.thread.join(timeout=5)\n\n    def enqueue(self, task: Callable, *args, **kwargs):\n        \"\"\"Add a task to the queue.\"\"\"\n        self.task_queue.put((task, args, kwargs))\n\n    def _process_tasks(self):\n        \"\"\"Process tasks from the queue.\"\"\"\n        while self.running:\n            try:\n                task, args, kwargs = self.task_queue.get(timeout=1)\n                task(*args, **kwargs)\n                self.task_queue.task_done()\n            except queue.Empty:\n                continue\n            except Exception as e:\n                print(f\"Error processing task: {e}\")\n\n\n# Global worker instance\nworker = BackgroundWorker()\n\n\ndef handle_user_mentioned(payload: Dict[str, Any]) -> None:\n    \"\"\"Handle user_mentioned event by creating a notification.\"\"\"\n    worker.enqueue(create_notification_task, payload)\n\n\ndef create_notification_task(payload: Dict[str, Any]) -> None:\n    \"\"\"Task to create a notification in the database.\"\"\"\n    db = get_db_session()\n    try:\n        notification_repo = NotificationRepository(db)\n        notification_repo.create(\n            recipient_id=payload[\"recipient_id\"],\n            actor_id=payload[\"actor_id\"],\n            post_id=payload[\"post_id\"],\n            notification_type=\"mention\"\n        )\n    finally:\n        db.close()\n\n\ndef setup_event_handlers():\n    \"\"\"Register event handlers with the event dispatcher.\"\"\"\n    event_dispatcher.subscribe(\"user_mentioned\", handle_user_mentioned)\n\n\ndef start_worker():\n    \"\"\"Initialize and start the background worker.\"\"\"\n    setup_event_handlers()\n    worker.start()\n\n\ndef stop_worker():\n    \"\"\"Stop the background worker.\"\"\"\n    worker.stop()\n",
          "classpulse/main.py": "from fastapi import FastAPI, Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse\nfrom pydantic import BaseModel\nfrom typing import Optional, List\nfrom datetime import datetime\nimport jwt\n\nfrom classpulse.config import get_db, SECRET_KEY, ALGORITHM\nfrom classpulse.repositories import (\n    UserRepository,\n    SessionRepository,\n    PostRepository,\n    NotificationRepository\n)\nfrom classpulse.services import (\n    create_user,\n    authenticate_user,\n    create_session,\n    create_post,\n    upvote_post\n)\nfrom classpulse.events import event_dispatcher\nfrom classpulse.worker import start_worker, stop_worker\n\napp = FastAPI(title=\"ClassPulse Live\", version=\"1.0.0\")\nsecurity = HTTPBearer()\n\n\n# Pydantic models\nclass UserCreate(BaseModel):\n    username: str\n    email: str\n    password: str\n\n\nclass UserLogin(BaseModel):\n    username: str\n    password: str\n\n\nclass SessionCreate(BaseModel):\n    title: str\n    description: Optional[str] = None\n\n\nclass PostCreate(BaseModel):\n    content: str\n    session_id: int\n    is_anonymous: bool = False\n\n\nclass TokenResponse(BaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n\n\nclass UserResponse(BaseModel):\n    id: int\n    username: str\n    email: str\n\n    class Config:\n        from_attributes = True\n\n\nclass SessionResponse(BaseModel):\n    id: int\n    title: str\n    description: Optional[str]\n    code: str\n    is_active: bool\n\n    class Config:\n        from_attributes = True\n\n\nclass PostResponse(BaseModel):\n    id: int\n    content: str\n    is_anonymous: bool\n    upvotes: int\n    created_at: datetime\n    author_id: int\n    session_id: int\n\n    class Config:\n        from_attributes = True\n\n\nclass NotificationResponse(BaseModel):\n    id: int\n    recipient_id: int\n    actor_id: int\n    post_id: int\n    type: str\n    is_read: bool\n    created_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\ndef create_token(user_id: int) -> str:\n    payload = {\"user_id\": user_id}\n    return jwt.encode(payload, SECRET_KEY, algorithm=ALGORITHM)\n\n\ndef get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security), db=Depends(get_db)):\n    try:\n        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])\n        user_id = payload.get(\"user_id\")\n        if user_id is None:\n            raise HTTPException(status_code=401, detail=\"Invalid token\")\n        user_repo = UserRepository(db)\n        user = user_repo.get_by_id(user_id)\n        if user is None:\n            raise HTTPException(status_code=401, detail=\"User not found\")\n        return user\n    except jwt.PyJWTError:\n        raise HTTPException(status_code=401, detail=\"Invalid token\")\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    start_worker()\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    stop_worker()\n\n\n@app.post(\"/api/v1/auth/register\", response_model=UserResponse)\ndef register(user_data: UserCreate, db=Depends(get_db)):\n    user_repo = UserRepository(db)\n    if user_repo.get_by_username(user_data.username):\n        raise HTTPException(status_code=400, detail=\"Username already exists\")\n    if user_repo.get_by_email(user_data.email):\n        raise HTTPException(status_code=400, detail=\"Email already exists\")\n    user = create_user(user_repo, user_data.username, user_data.email, user_data.password)\n    return user\n\n\n@app.post(\"/api/v1/auth/login\", response_model=TokenResponse)\ndef login(user_data: UserLogin, db=Depends(get_db)):\n    user_repo = UserRepository(db)\n    user = authenticate_user(user_repo, user_data.username, user_data.password)\n    if not user:\n        raise HTTPException(status_code=401, detail=\"Invalid credentials\")\n    token = create_token(user.id)\n    return TokenResponse(access_token=token)\n\n\n@app.post(\"/api/v1/sessions\", response_model=SessionResponse)\ndef create_new_session(\n    session_data: SessionCreate,\n    current_user=Depends(get_current_user),\n    db=Depends(get_db)\n):\n    session_repo = SessionRepository(db)\n    session = create_session(\n        session_repo,\n        session_data.title,\n        current_user.id,\n        session_data.description\n    )\n    return session\n\n\n@app.get(\"/api/v1/sessions/{code}\", response_model=SessionResponse)\ndef get_session(code: str, db=Depends(get_db)):\n    session_repo = SessionRepository(db)\n    session = session_repo.get_by_code(code)\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n    return session\n\n\n@app.post(\"/api/v1/posts\", response_model=PostResponse)\ndef create_new_post(\n    post_data: PostCreate,\n    current_user=Depends(get_current_user),\n    db=Depends(get_db)\n):\n    post_repo = PostRepository(db)\n    user_repo = UserRepository(db)\n    post = create_post(\n        post_repo,\n        user_repo,\n        event_dispatcher,\n        post_data.content,\n        current_user.id,\n        post_data.session_id,\n        post_data.is_anonymous\n    )\n    return post\n\n\n@app.get(\"/api/v1/sessions/{session_id}/posts\", response_model=List[PostResponse])\ndef get_session_posts(session_id: int, db=Depends(get_db)):\n    post_repo = PostRepository(db)\n    posts = post_repo.get_by_session(session_id)\n    return posts\n\n\n@app.post(\"/api/v1/posts/{post_id}/upvote\", response_model=PostResponse)\ndef upvote(post_id: int, db=Depends(get_db)):\n    post_repo = PostRepository(db)\n    post = upvote_post(post_repo, post_id)\n    if not post:\n        raise HTTPException(status_code=404, detail=\"Post not found\")\n    return post\n\n\n@app.get(\"/api/v1/notifications\", response_model=List[NotificationResponse])\ndef get_notifications(\n    current_user=Depends(get_current_user),\n    db=Depends(get_db)\n):\n    notification_repo = NotificationRepository(db)\n    notifications = notification_repo.get_by_recipient(current_user.id)\n    return notifications\n\n\n@app.get(\"/\")\ndef serve_frontend():\n    return FileResponse(\"static/index.html\")\n",
          "classpulse/config.py": "import os\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, Session\n\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./classpulse.db\")\nSECRET_KEY = os.getenv(\"SECRET_KEY\", \"your-secret-key-here\")\nALGORITHM = \"HS256\"\n\nengine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False})\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n\ndef get_db_session() -> Session:\n    \"\"\"Get a new database session (non-generator version for workers).\"\"\"\n    return SessionLocal()\n",
          "tests/test_services.py": "import pytest\nfrom unittest.mock import Mock, MagicMock, patch\nfrom classpulse.services import (\n    create_user,\n    authenticate_user,\n    create_post,\n    hash_password,\n    verify_password,\n    parse_mentions\n)\nfrom classpulse.models import User, Post\n\n\nclass TestPasswordHashing:\n    def test_hash_password(self):\n        password = \"testpassword123\"\n        hashed = hash_password(password)\n        assert hashed != password\n        assert len(hashed) == 64  # SHA256 produces 64 hex characters\n\n    def test_verify_password_correct(self):\n        password = \"testpassword123\"\n        hashed = hash_password(password)\n        assert verify_password(password, hashed) is True\n\n    def test_verify_password_incorrect(self):\n        password = \"testpassword123\"\n        hashed = hash_password(password)\n        assert verify_password(\"wrongpassword\", hashed) is False\n\n\nclass TestParseMentions:\n    def test_parse_single_mention(self):\n        content = \"Hello @john how are you?\"\n        mentions = parse_mentions(content)\n        assert mentions == [\"john\"]\n\n    def test_parse_multiple_mentions(self):\n        content = \"Hey @john and @jane, check this out!\"\n        mentions = parse_mentions(content)\n        assert set(mentions) == {\"john\", \"jane\"}\n\n    def test_parse_no_mentions(self):\n        content = \"Hello world, no mentions here.\"\n        mentions = parse_mentions(content)\n        assert mentions == []\n\n    def test_parse_duplicate_mentions(self):\n        content = \"@john said hi to @john\"\n        mentions = parse_mentions(content)\n        assert mentions == [\"john\"]\n\n\nclass TestCreateUser:\n    def test_create_user_success(self):\n        mock_repo = Mock()\n        mock_user = User(id=1, username=\"testuser\", email=\"test@test.com\")\n        mock_repo.create.return_value = mock_user\n\n        result = create_user(mock_repo, \"testuser\", \"test@test.com\", \"password123\")\n\n        assert result == mock_user\n        mock_repo.create.assert_called_once()\n\n\nclass TestAuthenticateUser:\n    def test_authenticate_user_success(self):\n        mock_repo = Mock()\n        password = \"password123\"\n        hashed = hash_password(password)\n        mock_user = Mock()\n        mock_user.hashed_password = hashed\n        mock_repo.get_by_username.return_value = mock_user\n\n        result = authenticate_user(mock_repo, \"testuser\", password)\n\n        assert result == mock_user\n\n    def test_authenticate_user_wrong_password(self):\n        mock_repo = Mock()\n        mock_user = Mock()\n        mock_user.hashed_password = hash_password(\"correctpassword\")\n        mock_repo.get_by_username.return_value = mock_user\n\n        result = authenticate_user(mock_repo, \"testuser\", \"wrongpassword\")\n\n        assert result is None\n\n    def test_authenticate_user_not_found(self):\n        mock_repo = Mock()\n        mock_repo.get_by_username.return_value = None\n\n        result = authenticate_user(mock_repo, \"nonexistent\", \"password\")\n\n        assert result is None\n\n\nclass TestCreatePost:\n    def test_create_post_success(self):\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 1\n        mock_post.content = \"Test post\"\n        mock_post_repo.create.return_value = mock_post\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Test post\",\n            author_id=1,\n            session_id=1,\n            is_anonymous=False\n        )\n\n        assert result == mock_post\n        mock_post_repo.create.assert_called_once_with(\"Test post\", 1, 1, False)\n\n    def test_create_post_with_mention_dispatches_event(self):\n        \"\"\"Test that creating a post with a valid @username mention dispatches the user_mentioned event.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        # Create mock post\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post.content = \"Hey @johndoe check this out!\"\n        mock_post_repo.create.return_value = mock_post\n\n        # Create mock mentioned user\n        mock_mentioned_user = Mock()\n        mock_mentioned_user.id = 5\n        mock_mentioned_user.username = \"johndoe\"\n        mock_user_repo.get_by_username.return_value = mock_mentioned_user\n\n        # Call create_post with content containing a mention\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Hey @johndoe check this out!\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Verify the post was created\n        assert result == mock_post\n        mock_post_repo.create.assert_called_once_with(\n            \"Hey @johndoe check this out!\", 1, 10, False\n        )\n\n        # Verify the user repository was queried for the mentioned username\n        mock_user_repo.get_by_username.assert_called_once_with(\"johndoe\")\n\n        # Verify the event dispatcher was called with the correct event and payload\n        mock_event_dispatcher.dispatch.assert_called_once_with(\n            \"user_mentioned\",\n            {\n                \"actor_id\": 1,\n                \"recipient_id\": 5,\n                \"post_id\": 42\n            }\n        )\n\n    def test_create_post_with_mention_self_no_event(self):\n        \"\"\"Test that mentioning yourself does not dispatch an event.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post_repo.create.return_value = mock_post\n\n        # Mentioned user is the same as author\n        mock_mentioned_user = Mock()\n        mock_mentioned_user.id = 1  # Same as author_id\n        mock_user_repo.get_by_username.return_value = mock_mentioned_user\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Talking to @myself\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Event should NOT be dispatched when mentioning yourself\n        mock_event_dispatcher.dispatch.assert_not_called()\n\n    def test_create_post_with_invalid_mention_no_event(self):\n        \"\"\"Test that mentioning a non-existent user does not dispatch an event.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post_repo.create.return_value = mock_post\n\n        # User not found\n        mock_user_repo.get_by_username.return_value = None\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Hey @nonexistent check this!\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Event should NOT be dispatched for non-existent users\n        mock_event_dispatcher.dispatch.assert_not_called()\n\n    def test_create_post_with_multiple_mentions_dispatches_multiple_events(self):\n        \"\"\"Test that multiple valid mentions dispatch multiple events.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post_repo.create.return_value = mock_post\n\n        # Setup two different users\n        mock_user1 = Mock()\n        mock_user1.id = 5\n        mock_user2 = Mock()\n        mock_user2.id = 6\n\n        def get_user_by_username(username):\n            if username == \"john\":\n                return mock_user1\n            elif username == \"jane\":\n                return mock_user2\n            return None\n\n        mock_user_repo.get_by_username.side_effect = get_user_by_username\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Hey @john and @jane!\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Should dispatch two events\n        assert mock_event_dispatcher.dispatch.call_count == 2\n"
        },
        "generated_files": [
          "classpulse/models.py",
          "classpulse/repositories.py",
          "classpulse/services.py",
          "classpulse/events.py",
          "classpulse/worker.py",
          "classpulse/main.py",
          "classpulse/config.py",
          "tests/test_services.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.8043126450116009,
              "dependency_traversal_accuracy": 0.7912090179103899,
              "cross_file_reasoning_depth": 0.17395833333333333,
              "system_thinking_score": 0.4253972035178362,
              "robustness_score": 0.4717467602591793,
              "comprehensiveness_score": 0.5179142668586513,
              "innovation_score": 0.3474487041036717,
              "solution_elegance_score": 0.8791133245208966
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.10053908062645012,
              "dependency_traversal_weighted": 0.09890112723879874,
              "cross_file_reasoning_weighted": 0.021744791666666666,
              "system_thinking_weighted": 0.05317465043972953,
              "robustness_weighted": 0.05896834503239741,
              "comprehensiveness_weighted": 0.06473928335733141,
              "innovation_weighted": 0.04343108801295896,
              "solution_elegance_weighted": 0.10988916556511208
            },
            "total_software_engineering_score": 0.5513875319394449
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.5197999477386475,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "classpulse/models.py",
                "classpulse/repositories.py",
                "classpulse/services.py",
                "classpulse/events.py",
                "classpulse/worker.py",
                "classpulse/main.py",
                "classpulse/config.py",
                "tests/test_services.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 8,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 8 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.45770718232044194,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.45770718232044194,
              "idc_weight": 0.2,
              "total_functional_score": 0.6715414364640884
            }
          },
          "code_quality_details": {
            "files_analyzed": 8,
            "quality_checks": {
              "classpulse/models.py": {
                "line_count": 83,
                "non_empty_lines": 65,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 0,
                "class_count": 5,
                "import_count": 6,
                "quality_score": 0.7
              },
              "classpulse/repositories.py": {
                "line_count": 125,
                "non_empty_lines": 101,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 19,
                "class_count": 4,
                "import_count": 6,
                "quality_score": 0.7999999999999999
              },
              "classpulse/services.py": {
                "line_count": 90,
                "non_empty_lines": 69,
                "comment_lines": 1,
                "comment_ratio": 0.014492753623188406,
                "function_count": 9,
                "class_count": 0,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "classpulse/events.py": {
                "line_count": 31,
                "non_empty_lines": 22,
                "comment_lines": 1,
                "comment_ratio": 0.045454545454545456,
                "function_count": 4,
                "class_count": 1,
                "import_count": 4,
                "quality_score": 0.6
              },
              "classpulse/worker.py": {
                "line_count": 82,
                "non_empty_lines": 63,
                "comment_lines": 1,
                "comment_ratio": 0.015873015873015872,
                "function_count": 10,
                "class_count": 1,
                "import_count": 11,
                "quality_score": 0.7999999999999999
              },
              "classpulse/main.py": {
                "line_count": 230,
                "non_empty_lines": 179,
                "comment_lines": 1,
                "comment_ratio": 0.00558659217877095,
                "function_count": 13,
                "class_count": 13,
                "import_count": 25,
                "quality_score": 0.7999999999999999
              },
              "classpulse/config.py": {
                "line_count": 24,
                "non_empty_lines": 17,
                "comment_lines": 0,
                "comment_ratio": 0.0,
                "function_count": 2,
                "class_count": 0,
                "import_count": 5,
                "quality_score": 0.6
              },
              "tests/test_services.py": {
                "line_count": 261,
                "non_empty_lines": 208,
                "comment_lines": 12,
                "comment_ratio": 0.057692307692307696,
                "function_count": 17,
                "class_count": 5,
                "import_count": 7,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.7562499999999999,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.8227106227106229,
              "multi_session_memory_retention": 0.8448304383788254
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.41135531135531145,
              "multi_session_memory_retention_weighted": 0.4224152191894127
            },
            "total_longcontext_utilization_score": 0.8337705305447242
          }
        },
        "timestamp": "2026-01-14T21:50:06.173516"
      },
      {
        "model_name": "claude-opus-4-5-20251101",
        "scenario_id": "python_ml_nlp_easy_017_feature_implementation_expert_01",
        "scenario_title": "Implement Shadow Deployment (A/B Testing) for Model Evaluation",
        "task_category": "feature_implementation",
        "difficulty": "expert",
        "software_engineering_score": 0.5339060076556738,
        "functional_correctness_score": 0.6278900169204737,
        "code_quality_score": 0.8233333333333331,
        "longcontext_utilization_score": 0.6386111111111111,
        "total_score": 3.152285929580947,
        "generation_time": 64.2057044506073,
        "code_files_generated": 3,
        "total_lines_generated": 510,
        "parsing_success": true,
        "solution_code": {
          "edu_vocab_coach/config.py": "import os\nfrom pathlib import Path\n\n# Base directory configuration\nBASE_DIR = Path(__file__).parent\nDATA_DIR = BASE_DIR / \"data\"\nMODEL_DIR = BASE_DIR / \"models\"\n\n# Ensure directories exist\nDATA_DIR.mkdir(exist_ok=True)\nMODEL_DIR.mkdir(exist_ok=True)\n\n# Database configuration\nDATABASE_PATH = DATA_DIR / \"vocabulary.db\"\n\n# Model configuration\nMODEL_PATH = MODEL_DIR / \"difficulty_model.pkl\"\n\n# Shadow Deployment / A/B Testing Configuration\nSHADOW_DEPLOYMENT_ENABLED = os.environ.get(\"SHADOW_DEPLOYMENT_ENABLED\", \"false\").lower() == \"true\"\n\n# Champion model is the current production model\nCHAMPION_MODEL_PATH = MODEL_DIR / \"difficulty_model.pkl\"\n\n# Challenger model is the newly trained model awaiting evaluation\nCHALLENGER_MODEL_PATH = MODEL_DIR / \"difficulty_model_challenger.pkl\"\n\n# Percentage of traffic to route to the challenger model (0-100)\n# Default is 10% to challenger, 90% to champion\nCHALLENGER_TRAFFIC_PERCENTAGE = int(os.environ.get(\"CHALLENGER_TRAFFIC_PERCENTAGE\", \"10\"))\n\n# Validate traffic percentage\nif CHALLENGER_TRAFFIC_PERCENTAGE < 0:\n    CHALLENGER_TRAFFIC_PERCENTAGE = 0\nelif CHALLENGER_TRAFFIC_PERCENTAGE > 100:\n    CHALLENGER_TRAFFIC_PERCENTAGE = 100\n\n# NLP Pipeline configuration\nNLP_MODEL_NAME = \"en_core_web_sm\"\n\n# API configuration\nAPI_HOST = os.environ.get(\"API_HOST\", \"0.0.0.0\")\nAPI_PORT = int(os.environ.get(\"API_PORT\", \"5000\"))\nDEBUG_MODE = os.environ.get(\"DEBUG_MODE\", \"false\").lower() == \"true\"\n\n# Retraining configuration\nRETRAIN_MIN_SAMPLES = int(os.environ.get(\"RETRAIN_MIN_SAMPLES\", \"100\"))\nRETRAIN_INTERVAL_HOURS = int(os.environ.get(\"RETRAIN_INTERVAL_HOURS\", \"24\"))\n\n# Logging configuration\nLOG_LEVEL = os.environ.get(\"LOG_LEVEL\", \"INFO\")\nLOG_FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
          "edu_vocab_coach/app.py": "import random\nimport logging\nfrom flask import Flask, request, jsonify, render_template\nfrom pathlib import Path\n\nimport config\nfrom src.eduvocab_coach.nlp_pipeline import NLPPipeline\n\n# Configure logging\nlogging.basicConfig(level=config.LOG_LEVEL, format=config.LOG_FORMAT)\nlogger = logging.getLogger(__name__)\n\napp = Flask(__name__)\n\n# Global model instances\nchampion_pipeline = None\nchallenger_pipeline = None\nchallenger_available = False\n\n\ndef load_models():\n    \"\"\"Load champion and optionally challenger models at startup.\"\"\"\n    global champion_pipeline, challenger_pipeline, challenger_available\n    \n    # Always load the champion model\n    champion_path = config.CHAMPION_MODEL_PATH\n    if champion_path.exists():\n        try:\n            champion_pipeline = NLPPipeline(model_path=str(champion_path))\n            logger.info(f\"Champion model loaded from {champion_path}\")\n        except Exception as e:\n            logger.error(f\"Failed to load champion model: {e}\")\n            champion_pipeline = NLPPipeline()  # Fallback to default/new pipeline\n            logger.info(\"Using default NLP pipeline as champion\")\n    else:\n        champion_pipeline = NLPPipeline()\n        logger.info(\"No champion model found, using default NLP pipeline\")\n    \n    # Load challenger model if shadow deployment is enabled\n    if config.SHADOW_DEPLOYMENT_ENABLED:\n        challenger_path = config.CHALLENGER_MODEL_PATH\n        if challenger_path.exists():\n            try:\n                challenger_pipeline = NLPPipeline(model_path=str(challenger_path))\n                challenger_available = True\n                logger.info(f\"Challenger model loaded from {challenger_path}\")\n                logger.info(f\"Shadow deployment enabled: {config.CHALLENGER_TRAFFIC_PERCENTAGE}% traffic to challenger\")\n            except Exception as e:\n                logger.warning(f\"Failed to load challenger model: {e}\")\n                challenger_available = False\n                logger.info(\"Shadow deployment enabled but challenger model not available\")\n        else:\n            challenger_available = False\n            logger.info(f\"Shadow deployment enabled but challenger model not found at {challenger_path}\")\n    else:\n        logger.info(\"Shadow deployment is disabled\")\n\n\ndef select_model():\n    \"\"\"Select which model to use for prediction based on traffic routing.\n    \n    Returns:\n        tuple: (pipeline, model_name) - the selected pipeline and its identifier\n    \"\"\"\n    global champion_pipeline, challenger_pipeline, challenger_available\n    \n    # If shadow deployment is disabled or challenger not available, use champion\n    if not config.SHADOW_DEPLOYMENT_ENABLED or not challenger_available:\n        return champion_pipeline, \"champion\"\n    \n    # Route traffic based on percentage\n    random_value = random.randint(1, 100)\n    if random_value <= config.CHALLENGER_TRAFFIC_PERCENTAGE:\n        return challenger_pipeline, \"challenger\"\n    else:\n        return champion_pipeline, \"champion\"\n\n\ndef reload_challenger_model():\n    \"\"\"Reload the challenger model if it exists. Called when a new model is trained.\"\"\"\n    global challenger_pipeline, challenger_available\n    \n    if not config.SHADOW_DEPLOYMENT_ENABLED:\n        return False\n    \n    challenger_path = config.CHALLENGER_MODEL_PATH\n    if challenger_path.exists():\n        try:\n            challenger_pipeline = NLPPipeline(model_path=str(challenger_path))\n            challenger_available = True\n            logger.info(f\"Challenger model reloaded from {challenger_path}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to reload challenger model: {e}\")\n            return False\n    return False\n\n\n@app.route(\"/\")\ndef index():\n    \"\"\"Render the main page.\"\"\"\n    return render_template(\"index.html\")\n\n\n@app.route(\"/api/predict\", methods=[\"POST\"])\ndef predict():\n    \"\"\"Predict difficulty for a given word or text.\n    \n    Expects JSON with 'text' field.\n    Returns prediction with model identifier for tracking.\n    \"\"\"\n    try:\n        data = request.get_json()\n        if not data or \"text\" not in data:\n            return jsonify({\"error\": \"Missing 'text' field in request\"}), 400\n        \n        text = data[\"text\"]\n        if not text or not text.strip():\n            return jsonify({\"error\": \"Empty text provided\"}), 400\n        \n        # Select model based on traffic routing\n        pipeline, model_name = select_model()\n        \n        # Make prediction\n        result = pipeline.predict_difficulty(text)\n        \n        # Add model identifier to response for tracking/monitoring\n        response = {\n            \"text\": text,\n            \"difficulty\": result.get(\"difficulty\"),\n            \"confidence\": result.get(\"confidence\"),\n            \"model_used\": model_name\n        }\n        \n        logger.debug(f\"Prediction made using {model_name} model for text: {text[:50]}...\")\n        \n        return jsonify(response)\n    \n    except Exception as e:\n        logger.error(f\"Prediction error: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route(\"/api/analyze\", methods=[\"POST\"])\ndef analyze():\n    \"\"\"Analyze text and return detailed NLP features.\n    \n    Expects JSON with 'text' field.\n    \"\"\"\n    try:\n        data = request.get_json()\n        if not data or \"text\" not in data:\n            return jsonify({\"error\": \"Missing 'text' field in request\"}), 400\n        \n        text = data[\"text\"]\n        if not text or not text.strip():\n            return jsonify({\"error\": \"Empty text provided\"}), 400\n        \n        # Select model based on traffic routing\n        pipeline, model_name = select_model()\n        \n        # Analyze text\n        result = pipeline.analyze_text(text)\n        result[\"model_used\"] = model_name\n        \n        return jsonify(result)\n    \n    except Exception as e:\n        logger.error(f\"Analysis error: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route(\"/api/health\", methods=[\"GET\"])\ndef health():\n    \"\"\"Health check endpoint.\"\"\"\n    status = {\n        \"status\": \"healthy\",\n        \"champion_model_loaded\": champion_pipeline is not None,\n        \"shadow_deployment_enabled\": config.SHADOW_DEPLOYMENT_ENABLED,\n        \"challenger_model_loaded\": challenger_available,\n        \"challenger_traffic_percentage\": config.CHALLENGER_TRAFFIC_PERCENTAGE if config.SHADOW_DEPLOYMENT_ENABLED else 0\n    }\n    return jsonify(status)\n\n\n@app.route(\"/api/model/status\", methods=[\"GET\"])\ndef model_status():\n    \"\"\"Get current model deployment status.\"\"\"\n    return jsonify({\n        \"shadow_deployment_enabled\": config.SHADOW_DEPLOYMENT_ENABLED,\n        \"champion_model_path\": str(config.CHAMPION_MODEL_PATH),\n        \"champion_model_exists\": config.CHAMPION_MODEL_PATH.exists(),\n        \"challenger_model_path\": str(config.CHALLENGER_MODEL_PATH),\n        \"challenger_model_exists\": config.CHALLENGER_MODEL_PATH.exists(),\n        \"challenger_available\": challenger_available,\n        \"challenger_traffic_percentage\": config.CHALLENGER_TRAFFIC_PERCENTAGE\n    })\n\n\n@app.route(\"/api/model/reload-challenger\", methods=[\"POST\"])\ndef reload_challenger():\n    \"\"\"Manually trigger a reload of the challenger model.\"\"\"\n    success = reload_challenger_model()\n    if success:\n        return jsonify({\"message\": \"Challenger model reloaded successfully\"})\n    else:\n        return jsonify({\"error\": \"Failed to reload challenger model\"}), 500\n\n\n# Load models when the module is imported\nload_models()\n\n\nif __name__ == \"__main__\":\n    app.run(\n        host=config.API_HOST,\n        port=config.API_PORT,\n        debug=config.DEBUG_MODE\n    )\n",
          "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py": "import logging\nimport pickle\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any, List, Tuple\n\nimport config\n\nlogger = logging.getLogger(__name__)\n\n\nclass Retrainer:\n    \"\"\"Handles model retraining and saving for the EduVocab Coach.\n    \n    When shadow deployment is enabled, newly trained models are saved\n    as challenger models rather than overwriting the production champion model.\n    \"\"\"\n    \n    def __init__(self, model_class=None):\n        \"\"\"Initialize the Retrainer.\n        \n        Args:\n            model_class: The model class to use for training. If None,\n                        a default model will be used.\n        \"\"\"\n        self.model_class = model_class\n        self.last_training_time: Optional[datetime] = None\n        self.training_history: List[Dict[str, Any]] = []\n        \n    def _get_save_path(self) -> Path:\n        \"\"\"Determine the appropriate path to save the trained model.\n        \n        If shadow deployment is enabled, saves to challenger path.\n        Otherwise, saves to the main model path (champion).\n        \n        Returns:\n            Path: The path where the model should be saved.\n        \"\"\"\n        if config.SHADOW_DEPLOYMENT_ENABLED:\n            return config.CHALLENGER_MODEL_PATH\n        else:\n            return config.CHAMPION_MODEL_PATH\n    \n    def prepare_training_data(self, raw_data: List[Dict[str, Any]]) -> Tuple[List, List]:\n        \"\"\"Prepare raw data for training.\n        \n        Args:\n            raw_data: List of dictionaries containing training samples.\n            \n        Returns:\n            Tuple of (features, labels) for training.\n        \"\"\"\n        features = []\n        labels = []\n        \n        for sample in raw_data:\n            if \"text\" in sample and \"difficulty\" in sample:\n                features.append(sample[\"text\"])\n                labels.append(sample[\"difficulty\"])\n        \n        return features, labels\n    \n    def train_model(self, features: List, labels: List) -> Any:\n        \"\"\"Train a new model on the provided data.\n        \n        Args:\n            features: List of feature data (texts).\n            labels: List of corresponding labels (difficulty scores).\n            \n        Returns:\n            The trained model object.\n        \"\"\"\n        if self.model_class is None:\n            # Use a simple default model for demonstration\n            from sklearn.feature_extraction.text import TfidfVectorizer\n            from sklearn.linear_model import LogisticRegression\n            from sklearn.pipeline import Pipeline\n            \n            model = Pipeline([\n                ('tfidf', TfidfVectorizer(max_features=5000)),\n                ('clf', LogisticRegression(max_iter=1000))\n            ])\n        else:\n            model = self.model_class()\n        \n        model.fit(features, labels)\n        return model\n    \n    def save_model(self, model: Any, path: Path) -> bool:\n        \"\"\"Save the trained model to disk.\n        \n        Args:\n            model: The trained model to save.\n            path: The path where the model should be saved.\n            \n        Returns:\n            bool: True if save was successful, False otherwise.\n        \"\"\"\n        try:\n            # Ensure parent directory exists\n            path.parent.mkdir(parents=True, exist_ok=True)\n            \n            with open(path, 'wb') as f:\n                pickle.dump(model, f)\n            \n            logger.info(f\"Model saved successfully to {path}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to save model to {path}: {e}\")\n            return False\n    \n    def train_and_save_model(self, training_data: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Train a new model and save it to the appropriate location.\n        \n        When shadow deployment is enabled, the model is saved as the challenger\n        model, allowing for A/B testing against the current champion.\n        \n        Args:\n            training_data: List of training samples with 'text' and 'difficulty' fields.\n            \n        Returns:\n            Dict containing training results and metadata.\n        \"\"\"\n        result = {\n            \"success\": False,\n            \"timestamp\": datetime.now().isoformat(),\n            \"samples_used\": 0,\n            \"model_path\": None,\n            \"is_challenger\": config.SHADOW_DEPLOYMENT_ENABLED,\n            \"error\": None\n        }\n        \n        try:\n            # Check minimum samples requirement\n            if len(training_data) < config.RETRAIN_MIN_SAMPLES:\n                result[\"error\"] = f\"Insufficient training data. Need at least {config.RETRAIN_MIN_SAMPLES} samples, got {len(training_data)}\"\n                logger.warning(result[\"error\"])\n                return result\n            \n            # Prepare data\n            features, labels = self.prepare_training_data(training_data)\n            result[\"samples_used\"] = len(features)\n            \n            if len(features) == 0:\n                result[\"error\"] = \"No valid training samples found in data\"\n                logger.warning(result[\"error\"])\n                return result\n            \n            # Train model\n            logger.info(f\"Training model with {len(features)} samples...\")\n            model = self.train_model(features, labels)\n            \n            # Determine save path based on shadow deployment setting\n            save_path = self._get_save_path()\n            result[\"model_path\"] = str(save_path)\n            \n            if config.SHADOW_DEPLOYMENT_ENABLED:\n                logger.info(f\"Shadow deployment enabled - saving as challenger model to {save_path}\")\n            else:\n                logger.info(f\"Shadow deployment disabled - saving as main model to {save_path}\")\n            \n            # Save model\n            if self.save_model(model, save_path):\n                result[\"success\"] = True\n                self.last_training_time = datetime.now()\n                \n                # Record in training history\n                self.training_history.append({\n                    \"timestamp\": result[\"timestamp\"],\n                    \"samples\": result[\"samples_used\"],\n                    \"path\": result[\"model_path\"],\n                    \"is_challenger\": result[\"is_challenger\"]\n                })\n                \n                logger.info(f\"Model training completed successfully. Saved to {save_path}\")\n            else:\n                result[\"error\"] = \"Failed to save model to disk\"\n                \n        except Exception as e:\n            result[\"error\"] = str(e)\n            logger.error(f\"Model training failed: {e}\")\n        \n        return result\n    \n    def promote_challenger_to_champion(self) -> bool:\n        \"\"\"Promote the current challenger model to champion.\n        \n        This copies the challenger model to the champion path,\n        effectively making it the new production model.\n        \n        Returns:\n            bool: True if promotion was successful, False otherwise.\n        \"\"\"\n        try:\n            challenger_path = config.CHALLENGER_MODEL_PATH\n            champion_path = config.CHAMPION_MODEL_PATH\n            \n            if not challenger_path.exists():\n                logger.error(\"No challenger model exists to promote\")\n                return False\n            \n            # Load challenger model\n            with open(challenger_path, 'rb') as f:\n                model = pickle.load(f)\n            \n            # Save as champion\n            with open(champion_path, 'wb') as f:\n                pickle.dump(model, f)\n            \n            logger.info(f\"Challenger model promoted to champion: {champion_path}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to promote challenger to champion: {e}\")\n            return False\n    \n    def get_training_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get the history of training runs.\n        \n        Returns:\n            List of training history records.\n        \"\"\"\n        return self.training_history.copy()\n    \n    def should_retrain(self) -> bool:\n        \"\"\"Check if enough time has passed since last training.\n        \n        Returns:\n            bool: True if retraining should occur, False otherwise.\n        \"\"\"\n        if self.last_training_time is None:\n            return True\n        \n        from datetime import timedelta\n        time_since_training = datetime.now() - self.last_training_time\n        return time_since_training >= timedelta(hours=config.RETRAIN_INTERVAL_HOURS)\n"
        },
        "generated_files": [
          "edu_vocab_coach/config.py",
          "edu_vocab_coach/app.py",
          "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py"
        ],
        "detailed_results": {
          "software_engineering_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "architectural_coherence_score",
              "dependency_traversal_accuracy",
              "cross_file_reasoning_depth",
              "system_thinking_score",
              "robustness_score",
              "comprehensiveness_score",
              "innovation_score",
              "solution_elegance_score"
            ],
            "individual_scores": {
              "architectural_coherence_score": 0.7385113268608415,
              "dependency_traversal_accuracy": 0.7517091822176568,
              "cross_file_reasoning_depth": 0.2877777777777778,
              "system_thinking_score": 0.5518790849673203,
              "robustness_score": 0.4446078431372549,
              "comprehensiveness_score": 0.5223202614379084,
              "innovation_score": 0.1875,
              "solution_elegance_score": 0.7869425848466307
            },
            "weighted_breakdown": {
              "architectural_coherence_weighted": 0.09231391585760519,
              "dependency_traversal_weighted": 0.0939636477772071,
              "cross_file_reasoning_weighted": 0.035972222222222225,
              "system_thinking_weighted": 0.06898488562091504,
              "robustness_weighted": 0.05557598039215686,
              "comprehensiveness_weighted": 0.06529003267973855,
              "innovation_weighted": 0.0234375,
              "solution_elegance_weighted": 0.09836782310582884
            },
            "total_software_engineering_score": 0.5339060076556738
          },
          "functional_correctness_details": {
            "compilation": {
              "success": true,
              "score": 0.9,
              "execution_time": 0.19878721237182617,
              "errors": [],
              "warnings": [],
              "binary_size": null,
              "files_tested": [
                "edu_vocab_coach/config.py",
                "edu_vocab_coach/app.py",
                "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py"
              ],
              "scoring_breakdown": {
                "base_success": 0.8,
                "fast_compilation_bonus": 0.1
              }
            },
            "unit_tests": {
              "test_pass_rate": 0.5,
              "tests_run": 4,
              "tests_passed": 2,
              "tests_failed": 2,
              "test_results": [
                {
                  "name": "function_signature_preservation",
                  "passed": true,
                  "description": "Public function signatures are preserved"
                },
                {
                  "name": "error_handling",
                  "passed": true,
                  "description": "Proper error handling for edge cases"
                },
                {
                  "name": "input_validation",
                  "passed": false,
                  "description": "Input validation works correctly"
                },
                {
                  "name": "output_correctness",
                  "passed": false,
                  "description": "Functions return expected outputs"
                }
              ],
              "errors": [],
              "overall_success": false
            },
            "integration": {
              "files_analyzed": 3,
              "multi_file_solution": true,
              "integration_score": 0.7999999999999999,
              "integration_indicators": [
                "Multi-file solution suggests integration capability",
                "Found imports in 3 files"
              ],
              "tests_defined": 3
            },
            "incremental_development": {
              "idc_score": 0.23945008460236888,
              "description": "Ability to build incrementally on previous work"
            },
            "overall_breakdown": {
              "compilation_score": 0.9,
              "compilation_weight": 0.3,
              "unit_test_score": 0.5,
              "unit_test_weight": 0.3,
              "integration_score": 0.7999999999999999,
              "integration_weight": 0.2,
              "idc_score": 0.23945008460236888,
              "idc_weight": 0.2,
              "total_functional_score": 0.6278900169204737
            }
          },
          "code_quality_details": {
            "files_analyzed": 3,
            "quality_checks": {
              "edu_vocab_coach/config.py": {
                "line_count": 53,
                "non_empty_lines": 39,
                "comment_lines": 14,
                "comment_ratio": 0.358974358974359,
                "function_count": 0,
                "class_count": 0,
                "import_count": 3,
                "quality_score": 0.8999999999999999
              },
              "edu_vocab_coach/app.py": {
                "line_count": 220,
                "non_empty_lines": 172,
                "comment_lines": 12,
                "comment_ratio": 0.06976744186046512,
                "function_count": 9,
                "class_count": 0,
                "import_count": 12,
                "quality_score": 0.7999999999999999
              },
              "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py": {
                "line_count": 237,
                "non_empty_lines": 183,
                "comment_lines": 10,
                "comment_ratio": 0.0546448087431694,
                "function_count": 9,
                "class_count": 4,
                "import_count": 17,
                "quality_score": 0.7999999999999999
              }
            },
            "security_analysis": {
              "security_score": 0.8,
              "vulnerabilities_found": [],
              "security_level": "medium"
            },
            "overall_quality_score": 0.8233333333333331,
            "issues_found": []
          },
          "longcontext_utilization_details": {
            "task_category": "feature_implementation",
            "metrics_applied": [
              "information_coverage_utilization",
              "multi_session_memory_retention"
            ],
            "individual_scores": {
              "information_coverage_utilization": 0.64,
              "multi_session_memory_retention": 0.6372222222222222
            },
            "weighted_breakdown": {
              "information_coverage_utilization_weighted": 0.32,
              "multi_session_memory_retention_weighted": 0.3186111111111111
            },
            "total_longcontext_utilization_score": 0.6386111111111111
          }
        },
        "timestamp": "2026-01-14T21:51:11.177797"
      }
    ]
  },
  "scenario_lookup": {
    "python_mobile_game_medium_096_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_mobile_game_medium_096_feature_implementation_expert_01",
          "scenario_title": "Implement Time-Sensitive Special Orders Feature",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5341221203221902,
          "functional_correctness_score": 0.3940485714285714,
          "code_quality_score": 0.7883333333333333,
          "longcontext_utilization_score": 0.9263667076167073,
          "total_score": 2.9108337849289248,
          "generation_time": 225.40432119369507,
          "code_files_generated": 12,
          "total_lines_generated": 2159,
          "parsing_success": true,
          "solution_code": {
            "tycoon_tactics/domain/special_order.py": "\"\"\"Special Order domain model for time-sensitive delivery contracts.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Dict\nfrom uuid import UUID, uuid4\n\n\nclass SpecialOrderStatus:\n    \"\"\"Status constants for special orders.\"\"\"\n    PENDING = \"PENDING\"\n    ACCEPTED = \"ACCEPTED\"\n    COMPLETED = \"COMPLETED\"\n    EXPIRED = \"EXPIRED\"\n\n\n@dataclass\nclass SpecialOrder:\n    \"\"\"Represents a time-sensitive special delivery order.\n    \n    Special orders are high-value contracts that appear periodically.\n    Players must fulfill them within a time limit to earn rewards.\n    \"\"\"\n    id: UUID\n    name: str\n    product_requirements: Dict[str, int]\n    destination_address: str\n    reward_cash: int\n    reward_reputation: int\n    time_to_live_seconds: int\n    created_at: datetime\n    status: str = field(default=SpecialOrderStatus.PENDING)\n    \n    @classmethod\n    def create(\n        cls,\n        name: str,\n        product_requirements: Dict[str, int],\n        destination_address: str,\n        reward_cash: int,\n        reward_reputation: int,\n        time_to_live_seconds: int = 3600,\n    ) -> \"SpecialOrder\":\n        \"\"\"Factory method to create a new special order.\"\"\"\n        return cls(\n            id=uuid4(),\n            name=name,\n            product_requirements=product_requirements,\n            destination_address=destination_address,\n            reward_cash=reward_cash,\n            reward_reputation=reward_reputation,\n            time_to_live_seconds=time_to_live_seconds,\n            created_at=datetime.utcnow(),\n            status=SpecialOrderStatus.PENDING,\n        )\n    \n    def is_expired(self) -> bool:\n        \"\"\"Check if the order has expired based on TTL.\"\"\"\n        elapsed = (datetime.utcnow() - self.created_at).total_seconds()\n        return elapsed > self.time_to_live_seconds\n    \n    def remaining_time_seconds(self) -> int:\n        \"\"\"Get remaining time in seconds before expiration.\"\"\"\n        elapsed = (datetime.utcnow() - self.created_at).total_seconds()\n        remaining = self.time_to_live_seconds - elapsed\n        return max(0, int(remaining))\n    \n    def accept(self) -> None:\n        \"\"\"Mark the order as accepted.\"\"\"\n        if self.status != SpecialOrderStatus.PENDING:\n            raise ValueError(f\"Cannot accept order with status: {self.status}\")\n        if self.is_expired():\n            self.status = SpecialOrderStatus.EXPIRED\n            raise ValueError(\"Cannot accept expired order\")\n        self.status = SpecialOrderStatus.ACCEPTED\n    \n    def complete(self) -> None:\n        \"\"\"Mark the order as completed.\"\"\"\n        if self.status != SpecialOrderStatus.ACCEPTED:\n            raise ValueError(f\"Cannot complete order with status: {self.status}\")\n        self.status = SpecialOrderStatus.COMPLETED\n    \n    def expire(self) -> None:\n        \"\"\"Mark the order as expired.\"\"\"\n        if self.status == SpecialOrderStatus.PENDING:\n            self.status = SpecialOrderStatus.EXPIRED\n",
            "tycoon_tactics/adapters/persistence/orm_models.py": "\"\"\"SQLAlchemy ORM models for persistence.\"\"\"\nfrom datetime import datetime\nfrom typing import Optional\nfrom uuid import UUID\n\nfrom sqlalchemy import (\n    Column,\n    DateTime,\n    Float,\n    ForeignKey,\n    Integer,\n    String,\n    Table,\n    Text,\n    JSON,\n    create_engine,\n)\nfrom sqlalchemy.orm import declarative_base, relationship\n\nBase = declarative_base()\n\n\nclass FranchiseOrm(Base):\n    \"\"\"ORM model for Franchise domain entity.\"\"\"\n    __tablename__ = \"franchises\"\n\n    id = Column(String(36), primary_key=True)\n    name = Column(String(255), nullable=False)\n    location = Column(String(255), nullable=False)\n    franchise_type = Column(String(100), nullable=False)\n    level = Column(Integer, default=1)\n    revenue = Column(Float, default=0.0)\n    expenses = Column(Float, default=0.0)\n    reputation = Column(Integer, default=50)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass SupplyChainOrm(Base):\n    \"\"\"ORM model for SupplyChain domain entity.\"\"\"\n    __tablename__ = \"supply_chains\"\n\n    id = Column(String(36), primary_key=True)\n    franchise_id = Column(String(36), ForeignKey(\"franchises.id\"), nullable=False)\n    inventory = Column(Text, default=\"{}\")  # JSON string of inventory\n    suppliers = Column(Text, default=\"[]\")  # JSON string of suppliers\n    logistics_efficiency = Column(Float, default=1.0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass MarketOrm(Base):\n    \"\"\"ORM model for Market domain entity.\"\"\"\n    __tablename__ = \"markets\"\n\n    id = Column(String(36), primary_key=True)\n    name = Column(String(255), nullable=False)\n    region = Column(String(255), nullable=False)\n    demand_level = Column(Float, default=1.0)\n    competition_level = Column(Float, default=1.0)\n    price_multiplier = Column(Float, default=1.0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass PlayerStatsOrm(Base):\n    \"\"\"ORM model for player statistics.\"\"\"\n    __tablename__ = \"player_stats\"\n\n    id = Column(String(36), primary_key=True)\n    player_id = Column(String(36), nullable=False, unique=True)\n    total_cash = Column(Integer, default=10000)\n    total_reputation = Column(Integer, default=0)\n    franchises_owned = Column(Integer, default=0)\n    orders_completed = Column(Integer, default=0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n\n\nclass SpecialOrderOrm(Base):\n    \"\"\"ORM model for SpecialOrder domain entity.\"\"\"\n    __tablename__ = \"special_orders\"\n\n    id = Column(String(36), primary_key=True)\n    name = Column(String(255), nullable=False)\n    product_requirements = Column(JSON, nullable=False)  # Dict[str, int]\n    destination_address = Column(String(500), nullable=False)\n    reward_cash = Column(Integer, nullable=False)\n    reward_reputation = Column(Integer, nullable=False)\n    time_to_live_seconds = Column(Integer, nullable=False)\n    created_at = Column(DateTime, nullable=False)\n    status = Column(String(50), nullable=False, default=\"PENDING\")\n\n\ndef create_tables(engine):\n    \"\"\"Create all tables in the database.\"\"\"\n    Base.metadata.create_all(engine)\n\n\ndef drop_tables(engine):\n    \"\"\"Drop all tables from the database.\"\"\"\n    Base.metadata.drop_all(engine)\n",
            "tycoon_tactics/domain/ports.py": "\"\"\"Port interfaces (abstract base classes) for the domain layer.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\nfrom uuid import UUID\n\nfrom tycoon_tactics.domain.franchise import Franchise\nfrom tycoon_tactics.domain.supply_chain import SupplyChain\nfrom tycoon_tactics.domain.market import Market\nfrom tycoon_tactics.domain.special_order import SpecialOrder\n\n\nclass AbstractRepository(ABC):\n    \"\"\"Abstract repository interface for domain persistence.\"\"\"\n\n    # Franchise methods\n    @abstractmethod\n    def add_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Add a new franchise to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_franchise(self, franchise_id: UUID) -> Optional[Franchise]:\n        \"\"\"Get a franchise by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_franchises(self) -> List[Franchise]:\n        \"\"\"List all franchises.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Update an existing franchise.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete_franchise(self, franchise_id: UUID) -> None:\n        \"\"\"Delete a franchise by its ID.\"\"\"\n        raise NotImplementedError\n\n    # SupplyChain methods\n    @abstractmethod\n    def add_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Add a new supply chain to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_supply_chain(self, supply_chain_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_supply_chain_by_franchise(self, franchise_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by franchise ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Update an existing supply chain.\"\"\"\n        raise NotImplementedError\n\n    # Market methods\n    @abstractmethod\n    def add_market(self, market: Market) -> None:\n        \"\"\"Add a new market to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_market(self, market_id: UUID) -> Optional[Market]:\n        \"\"\"Get a market by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_markets(self) -> List[Market]:\n        \"\"\"List all markets.\"\"\"\n        raise NotImplementedError\n\n    # Special Order methods\n    @abstractmethod\n    def add_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Add a new special order to the repository.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_special_order(self, order_id: UUID) -> Optional[SpecialOrder]:\n        \"\"\"Get a special order by its ID.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def list_active_special_orders(self) -> List[SpecialOrder]:\n        \"\"\"List all active (pending) special orders.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Update an existing special order.\"\"\"\n        raise NotImplementedError\n\n    # Player stats methods\n    @abstractmethod\n    def get_player_cash(self, player_id: UUID) -> int:\n        \"\"\"Get player's current cash.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_player_cash(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's cash by adding amount.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_player_reputation(self, player_id: UUID) -> int:\n        \"\"\"Get player's current reputation.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def update_player_reputation(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's reputation by adding amount.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractLocationService(ABC):\n    \"\"\"Abstract interface for location services.\"\"\"\n\n    @abstractmethod\n    def get_current_location(self) -> tuple[float, float]:\n        \"\"\"Get current GPS coordinates (latitude, longitude).\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def calculate_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n        \"\"\"Calculate distance between two coordinates in kilometers.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractPaymentService(ABC):\n    \"\"\"Abstract interface for in-app purchase services.\"\"\"\n\n    @abstractmethod\n    def purchase_item(self, item_id: str, price: float) -> bool:\n        \"\"\"Process an in-app purchase.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def restore_purchases(self) -> List[str]:\n        \"\"\"Restore previous purchases.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractAnalyticsService(ABC):\n    \"\"\"Abstract interface for analytics services.\"\"\"\n\n    @abstractmethod\n    def track_event(self, event_name: str, properties: dict) -> None:\n        \"\"\"Track an analytics event.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set_user_property(self, property_name: str, value: str) -> None:\n        \"\"\"Set a user property for analytics.\"\"\"\n        raise NotImplementedError\n\n\nclass AbstractCrashReportingService(ABC):\n    \"\"\"Abstract interface for crash reporting services.\"\"\"\n\n    @abstractmethod\n    def capture_exception(self, exception: Exception) -> None:\n        \"\"\"Capture and report an exception.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def add_breadcrumb(self, message: str, category: str) -> None:\n        \"\"\"Add a breadcrumb for debugging.\"\"\"\n        raise NotImplementedError\n",
            "tycoon_tactics/adapters/persistence/sqlite_repository.py": "\"\"\"SQLite implementation of the repository pattern.\"\"\"\nimport json\nfrom datetime import datetime\nfrom typing import List, Optional\nfrom uuid import UUID\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, Session\n\nfrom tycoon_tactics.domain.franchise import Franchise\nfrom tycoon_tactics.domain.supply_chain import SupplyChain\nfrom tycoon_tactics.domain.market import Market\nfrom tycoon_tactics.domain.special_order import SpecialOrder, SpecialOrderStatus\nfrom tycoon_tactics.domain.ports import AbstractRepository\nfrom tycoon_tactics.adapters.persistence.orm_models import (\n    Base,\n    FranchiseOrm,\n    SupplyChainOrm,\n    MarketOrm,\n    PlayerStatsOrm,\n    SpecialOrderOrm,\n    create_tables,\n)\n\n\nclass SQLiteRepository(AbstractRepository):\n    \"\"\"SQLite implementation of the abstract repository.\"\"\"\n\n    def __init__(self, db_path: str = \"tycoon_tactics.db\"):\n        \"\"\"Initialize the SQLite repository.\"\"\"\n        self.engine = create_engine(f\"sqlite:///{db_path}\", echo=False)\n        create_tables(self.engine)\n        self.SessionLocal = sessionmaker(bind=self.engine)\n\n    def _get_session(self) -> Session:\n        \"\"\"Get a new database session.\"\"\"\n        return self.SessionLocal()\n\n    # Franchise methods\n    def add_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Add a new franchise to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = FranchiseOrm(\n                id=str(franchise.id),\n                name=franchise.name,\n                location=franchise.location,\n                franchise_type=franchise.franchise_type,\n                level=franchise.level,\n                revenue=franchise.revenue,\n                expenses=franchise.expenses,\n                reputation=franchise.reputation,\n                created_at=franchise.created_at,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_franchise(self, franchise_id: UUID) -> Optional[Franchise]:\n        \"\"\"Get a franchise by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(FranchiseOrm).filter(\n                FranchiseOrm.id == str(franchise_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_franchise(orm_obj)\n            return None\n\n    def list_franchises(self) -> List[Franchise]:\n        \"\"\"List all franchises.\"\"\"\n        with self._get_session() as session:\n            orm_objects = session.query(FranchiseOrm).all()\n            return [self._orm_to_franchise(obj) for obj in orm_objects]\n\n    def update_franchise(self, franchise: Franchise) -> None:\n        \"\"\"Update an existing franchise.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(FranchiseOrm).filter(\n                FranchiseOrm.id == str(franchise.id)\n            ).first()\n            if orm_obj:\n                orm_obj.name = franchise.name\n                orm_obj.location = franchise.location\n                orm_obj.franchise_type = franchise.franchise_type\n                orm_obj.level = franchise.level\n                orm_obj.revenue = franchise.revenue\n                orm_obj.expenses = franchise.expenses\n                orm_obj.reputation = franchise.reputation\n                orm_obj.updated_at = datetime.utcnow()\n                session.commit()\n\n    def delete_franchise(self, franchise_id: UUID) -> None:\n        \"\"\"Delete a franchise by its ID.\"\"\"\n        with self._get_session() as session:\n            session.query(FranchiseOrm).filter(\n                FranchiseOrm.id == str(franchise_id)\n            ).delete()\n            session.commit()\n\n    def _orm_to_franchise(self, orm_obj: FranchiseOrm) -> Franchise:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return Franchise(\n            id=UUID(orm_obj.id),\n            name=orm_obj.name,\n            location=orm_obj.location,\n            franchise_type=orm_obj.franchise_type,\n            level=orm_obj.level,\n            revenue=orm_obj.revenue,\n            expenses=orm_obj.expenses,\n            reputation=orm_obj.reputation,\n            created_at=orm_obj.created_at,\n        )\n\n    # SupplyChain methods\n    def add_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Add a new supply chain to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = SupplyChainOrm(\n                id=str(supply_chain.id),\n                franchise_id=str(supply_chain.franchise_id),\n                inventory=json.dumps(supply_chain.inventory),\n                suppliers=json.dumps(supply_chain.suppliers),\n                logistics_efficiency=supply_chain.logistics_efficiency,\n                created_at=supply_chain.created_at,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_supply_chain(self, supply_chain_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SupplyChainOrm).filter(\n                SupplyChainOrm.id == str(supply_chain_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_supply_chain(orm_obj)\n            return None\n\n    def get_supply_chain_by_franchise(self, franchise_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by franchise ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SupplyChainOrm).filter(\n                SupplyChainOrm.franchise_id == str(franchise_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_supply_chain(orm_obj)\n            return None\n\n    def update_supply_chain(self, supply_chain: SupplyChain) -> None:\n        \"\"\"Update an existing supply chain.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SupplyChainOrm).filter(\n                SupplyChainOrm.id == str(supply_chain.id)\n            ).first()\n            if orm_obj:\n                orm_obj.inventory = json.dumps(supply_chain.inventory)\n                orm_obj.suppliers = json.dumps(supply_chain.suppliers)\n                orm_obj.logistics_efficiency = supply_chain.logistics_efficiency\n                orm_obj.updated_at = datetime.utcnow()\n                session.commit()\n\n    def _orm_to_supply_chain(self, orm_obj: SupplyChainOrm) -> SupplyChain:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return SupplyChain(\n            id=UUID(orm_obj.id),\n            franchise_id=UUID(orm_obj.franchise_id),\n            inventory=json.loads(orm_obj.inventory),\n            suppliers=json.loads(orm_obj.suppliers),\n            logistics_efficiency=orm_obj.logistics_efficiency,\n            created_at=orm_obj.created_at,\n        )\n\n    # Market methods\n    def add_market(self, market: Market) -> None:\n        \"\"\"Add a new market to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = MarketOrm(\n                id=str(market.id),\n                name=market.name,\n                region=market.region,\n                demand_level=market.demand_level,\n                competition_level=market.competition_level,\n                price_multiplier=market.price_multiplier,\n                created_at=market.created_at,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_market(self, market_id: UUID) -> Optional[Market]:\n        \"\"\"Get a market by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(MarketOrm).filter(\n                MarketOrm.id == str(market_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_market(orm_obj)\n            return None\n\n    def list_markets(self) -> List[Market]:\n        \"\"\"List all markets.\"\"\"\n        with self._get_session() as session:\n            orm_objects = session.query(MarketOrm).all()\n            return [self._orm_to_market(obj) for obj in orm_objects]\n\n    def _orm_to_market(self, orm_obj: MarketOrm) -> Market:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return Market(\n            id=UUID(orm_obj.id),\n            name=orm_obj.name,\n            region=orm_obj.region,\n            demand_level=orm_obj.demand_level,\n            competition_level=orm_obj.competition_level,\n            price_multiplier=orm_obj.price_multiplier,\n            created_at=orm_obj.created_at,\n        )\n\n    # Special Order methods\n    def add_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Add a new special order to the repository.\"\"\"\n        with self._get_session() as session:\n            orm_obj = SpecialOrderOrm(\n                id=str(order.id),\n                name=order.name,\n                product_requirements=order.product_requirements,\n                destination_address=order.destination_address,\n                reward_cash=order.reward_cash,\n                reward_reputation=order.reward_reputation,\n                time_to_live_seconds=order.time_to_live_seconds,\n                created_at=order.created_at,\n                status=order.status,\n            )\n            session.add(orm_obj)\n            session.commit()\n\n    def get_special_order(self, order_id: UUID) -> Optional[SpecialOrder]:\n        \"\"\"Get a special order by its ID.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SpecialOrderOrm).filter(\n                SpecialOrderOrm.id == str(order_id)\n            ).first()\n            if orm_obj:\n                return self._orm_to_special_order(orm_obj)\n            return None\n\n    def list_active_special_orders(self) -> List[SpecialOrder]:\n        \"\"\"List all active (pending) special orders.\"\"\"\n        with self._get_session() as session:\n            orm_objects = session.query(SpecialOrderOrm).filter(\n                SpecialOrderOrm.status == SpecialOrderStatus.PENDING\n            ).all()\n            orders = []\n            for orm_obj in orm_objects:\n                order = self._orm_to_special_order(orm_obj)\n                # Check if expired and update status\n                if order.is_expired():\n                    order.expire()\n                    self.update_special_order(order)\n                else:\n                    orders.append(order)\n            return orders\n\n    def update_special_order(self, order: SpecialOrder) -> None:\n        \"\"\"Update an existing special order.\"\"\"\n        with self._get_session() as session:\n            orm_obj = session.query(SpecialOrderOrm).filter(\n                SpecialOrderOrm.id == str(order.id)\n            ).first()\n            if orm_obj:\n                orm_obj.name = order.name\n                orm_obj.product_requirements = order.product_requirements\n                orm_obj.destination_address = order.destination_address\n                orm_obj.reward_cash = order.reward_cash\n                orm_obj.reward_reputation = order.reward_reputation\n                orm_obj.time_to_live_seconds = order.time_to_live_seconds\n                orm_obj.status = order.status\n                session.commit()\n\n    def _orm_to_special_order(self, orm_obj: SpecialOrderOrm) -> SpecialOrder:\n        \"\"\"Convert ORM object to domain entity.\"\"\"\n        return SpecialOrder(\n            id=UUID(orm_obj.id),\n            name=orm_obj.name,\n            product_requirements=orm_obj.product_requirements,\n            destination_address=orm_obj.destination_address,\n            reward_cash=orm_obj.reward_cash,\n            reward_reputation=orm_obj.reward_reputation,\n            time_to_live_seconds=orm_obj.time_to_live_seconds,\n            created_at=orm_obj.created_at,\n            status=orm_obj.status,\n        )\n\n    # Player stats methods\n    def _ensure_player_stats(self, session: Session, player_id: UUID) -> PlayerStatsOrm:\n        \"\"\"Ensure player stats exist, create if not.\"\"\"\n        stats = session.query(PlayerStatsOrm).filter(\n            PlayerStatsOrm.player_id == str(player_id)\n        ).first()\n        if not stats:\n            stats = PlayerStatsOrm(\n                id=str(player_id),\n                player_id=str(player_id),\n                total_cash=10000,\n                total_reputation=0,\n            )\n            session.add(stats)\n            session.commit()\n        return stats\n\n    def get_player_cash(self, player_id: UUID) -> int:\n        \"\"\"Get player's current cash.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            return stats.total_cash\n\n    def update_player_cash(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's cash by adding amount.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            stats.total_cash += amount\n            stats.updated_at = datetime.utcnow()\n            session.commit()\n\n    def get_player_reputation(self, player_id: UUID) -> int:\n        \"\"\"Get player's current reputation.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            return stats.total_reputation\n\n    def update_player_reputation(self, player_id: UUID, amount: int) -> None:\n        \"\"\"Update player's reputation by adding amount.\"\"\"\n        with self._get_session() as session:\n            stats = self._ensure_player_stats(session, player_id)\n            stats.total_reputation += amount\n            stats.updated_at = datetime.utcnow()\n            session.commit()\n",
            "tycoon_tactics/application/use_cases.py": "\"\"\"Application use cases for the game.\"\"\"\nimport random\nfrom dataclasses import dataclass\nfrom typing import List, Optional\nfrom uuid import UUID\n\nfrom tycoon_tactics.domain.franchise import Franchise\nfrom tycoon_tactics.domain.supply_chain import SupplyChain\nfrom tycoon_tactics.domain.market import Market\nfrom tycoon_tactics.domain.special_order import SpecialOrder, SpecialOrderStatus\nfrom tycoon_tactics.domain.ports import AbstractRepository\nfrom tycoon_tactics.application.event_bus import EventBus\nfrom tycoon_tactics.application.game_events import (\n    FranchiseCreatedEvent,\n    SupplyChainUpdatedEvent,\n)\n\n\nclass InsufficientInventoryError(Exception):\n    \"\"\"Raised when player doesn't have enough inventory to fulfill an order.\"\"\"\n    def __init__(self, missing_items: dict):\n        self.missing_items = missing_items\n        super().__init__(f\"Insufficient inventory: {missing_items}\")\n\n\nclass OrderNotFoundError(Exception):\n    \"\"\"Raised when a special order is not found.\"\"\"\n    pass\n\n\nclass InvalidOrderStatusError(Exception):\n    \"\"\"Raised when trying to perform an action on an order with invalid status.\"\"\"\n    pass\n\n\n@dataclass\nclass CreateFranchiseUseCase:\n    \"\"\"Use case for creating a new franchise.\"\"\"\n    repository: AbstractRepository\n    event_bus: EventBus\n\n    def execute(\n        self,\n        name: str,\n        location: str,\n        franchise_type: str,\n    ) -> Franchise:\n        \"\"\"Create a new franchise and persist it.\"\"\"\n        franchise = Franchise.create(\n            name=name,\n            location=location,\n            franchise_type=franchise_type,\n        )\n        self.repository.add_franchise(franchise)\n        \n        # Create associated supply chain\n        supply_chain = SupplyChain.create(franchise_id=franchise.id)\n        self.repository.add_supply_chain(supply_chain)\n        \n        # Publish event\n        self.event_bus.publish(FranchiseCreatedEvent(\n            franchise_id=franchise.id,\n            name=franchise.name,\n            location=franchise.location,\n        ))\n        \n        return franchise\n\n\n@dataclass\nclass GetFranchiseUseCase:\n    \"\"\"Use case for retrieving a franchise.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, franchise_id: UUID) -> Optional[Franchise]:\n        \"\"\"Get a franchise by ID.\"\"\"\n        return self.repository.get_franchise(franchise_id)\n\n\n@dataclass\nclass ListFranchisesUseCase:\n    \"\"\"Use case for listing all franchises.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self) -> List[Franchise]:\n        \"\"\"List all franchises.\"\"\"\n        return self.repository.list_franchises()\n\n\n@dataclass\nclass UpdateInventoryUseCase:\n    \"\"\"Use case for updating supply chain inventory.\"\"\"\n    repository: AbstractRepository\n    event_bus: EventBus\n\n    def execute(\n        self,\n        franchise_id: UUID,\n        product_name: str,\n        quantity: int,\n    ) -> SupplyChain:\n        \"\"\"Update inventory for a franchise's supply chain.\"\"\"\n        supply_chain = self.repository.get_supply_chain_by_franchise(franchise_id)\n        if not supply_chain:\n            raise ValueError(f\"Supply chain not found for franchise: {franchise_id}\")\n        \n        supply_chain.add_inventory(product_name, quantity)\n        self.repository.update_supply_chain(supply_chain)\n        \n        self.event_bus.publish(SupplyChainUpdatedEvent(\n            supply_chain_id=supply_chain.id,\n            franchise_id=franchise_id,\n            inventory=supply_chain.inventory,\n        ))\n        \n        return supply_chain\n\n\n@dataclass\nclass GetSupplyChainUseCase:\n    \"\"\"Use case for retrieving a supply chain.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, franchise_id: UUID) -> Optional[SupplyChain]:\n        \"\"\"Get a supply chain by franchise ID.\"\"\"\n        return self.repository.get_supply_chain_by_franchise(franchise_id)\n\n\n@dataclass\nclass ListMarketsUseCase:\n    \"\"\"Use case for listing all markets.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self) -> List[Market]:\n        \"\"\"List all available markets.\"\"\"\n        return self.repository.list_markets()\n\n\n# Special Order Use Cases\n\n@dataclass\nclass GenerateRandomSpecialOrderUseCase:\n    \"\"\"Use case for generating random special orders periodically.\"\"\"\n    repository: AbstractRepository\n\n    # Product pools for random generation\n    PRODUCT_NAMES = [\n        \"Electronics\", \"Clothing\", \"Food\", \"Beverages\", \"Furniture\",\n        \"Toys\", \"Books\", \"Sports Equipment\", \"Home Appliances\", \"Cosmetics\",\n        \"Pharmaceuticals\", \"Office Supplies\", \"Auto Parts\", \"Garden Supplies\", \"Pet Supplies\"\n    ]\n\n    DESTINATIONS = [\n        \"Downtown Distribution Center\", \"Northside Mall\", \"Westfield Shopping Plaza\",\n        \"Harbor Warehouse\", \"Airport Cargo Terminal\", \"Central Business District\",\n        \"Suburban Retail Park\", \"Industrial Zone Hub\", \"University Campus Store\",\n        \"Medical Center Supply Depot\", \"Tech Park Fulfillment Center\"\n    ]\n\n    ORDER_NAMES = [\n        \"Urgent Restock Order\", \"Premium Client Request\", \"Emergency Supply Run\",\n        \"VIP Customer Order\", \"Seasonal Rush Delivery\", \"Corporate Bulk Order\",\n        \"Flash Sale Fulfillment\", \"Holiday Special Order\", \"Clearance Redistribution\",\n        \"New Store Opening Supply\", \"Event Catering Supply\", \"Grand Opening Stock\"\n    ]\n\n    def execute(self) -> SpecialOrder:\n        \"\"\"Generate a new random special order and save it.\"\"\"\n        # Generate random requirements (1-3 products)\n        num_products = random.randint(1, 3)\n        products = random.sample(self.PRODUCT_NAMES, num_products)\n        product_requirements = {\n            product: random.randint(5, 50) for product in products\n        }\n\n        # Calculate rewards based on requirements\n        total_items = sum(product_requirements.values())\n        base_cash = total_items * random.randint(10, 25)\n        base_reputation = total_items // 5 + random.randint(5, 20)\n\n        # Random TTL between 30 minutes and 2 hours\n        ttl_seconds = random.randint(1800, 7200)\n\n        order = SpecialOrder.create(\n            name=random.choice(self.ORDER_NAMES),\n            product_requirements=product_requirements,\n            destination_address=random.choice(self.DESTINATIONS),\n            reward_cash=base_cash,\n            reward_reputation=base_reputation,\n            time_to_live_seconds=ttl_seconds,\n        )\n\n        self.repository.add_special_order(order)\n        return order\n\n\n@dataclass\nclass ListActiveSpecialOrdersUseCase:\n    \"\"\"Use case for listing all active special orders.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self) -> List[SpecialOrder]:\n        \"\"\"List all active (pending) special orders.\"\"\"\n        return self.repository.list_active_special_orders()\n\n\n@dataclass\nclass GetSpecialOrderUseCase:\n    \"\"\"Use case for retrieving a specific special order.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, order_id: UUID) -> Optional[SpecialOrder]:\n        \"\"\"Get a special order by ID.\"\"\"\n        return self.repository.get_special_order(order_id)\n\n\n@dataclass\nclass AcceptSpecialOrderUseCase:\n    \"\"\"Use case for accepting and fulfilling a special order.\"\"\"\n    repository: AbstractRepository\n    event_bus: EventBus\n    player_id: UUID\n\n    def execute(self, order_id: UUID, franchise_id: UUID) -> SpecialOrder:\n        \"\"\"Accept a special order if player has sufficient inventory.\n        \n        Args:\n            order_id: The ID of the special order to accept\n            franchise_id: The ID of the franchise whose inventory to use\n            \n        Returns:\n            The updated special order\n            \n        Raises:\n            OrderNotFoundError: If the order doesn't exist\n            InvalidOrderStatusError: If the order is not in PENDING status\n            InsufficientInventoryError: If player lacks required inventory\n        \"\"\"\n        # Fetch the order\n        order = self.repository.get_special_order(order_id)\n        if not order:\n            raise OrderNotFoundError(f\"Special order not found: {order_id}\")\n\n        # Check if order is expired\n        if order.is_expired():\n            order.expire()\n            self.repository.update_special_order(order)\n            raise InvalidOrderStatusError(\"Order has expired\")\n\n        # Verify order status is PENDING\n        if order.status != SpecialOrderStatus.PENDING:\n            raise InvalidOrderStatusError(\n                f\"Cannot accept order with status: {order.status}\"\n            )\n\n        # Get the player's supply chain inventory\n        supply_chain = self.repository.get_supply_chain_by_franchise(franchise_id)\n        if not supply_chain:\n            raise ValueError(f\"Supply chain not found for franchise: {franchise_id}\")\n\n        # Check if player has required inventory\n        missing_items = {}\n        for product, required_qty in order.product_requirements.items():\n            available_qty = supply_chain.inventory.get(product, 0)\n            if available_qty < required_qty:\n                missing_items[product] = required_qty - available_qty\n\n        if missing_items:\n            raise InsufficientInventoryError(missing_items)\n\n        # Deduct products from inventory\n        for product, required_qty in order.product_requirements.items():\n            supply_chain.remove_inventory(product, required_qty)\n        \n        self.repository.update_supply_chain(supply_chain)\n\n        # Update order status to ACCEPTED (and immediately COMPLETED since we're fulfilling it)\n        order.accept()\n        order.complete()\n        self.repository.update_special_order(order)\n\n        # Add rewards to player\n        self.repository.update_player_cash(self.player_id, order.reward_cash)\n        self.repository.update_player_reputation(self.player_id, order.reward_reputation)\n\n        return order\n\n\n@dataclass\nclass GetPlayerStatsUseCase:\n    \"\"\"Use case for retrieving player statistics.\"\"\"\n    repository: AbstractRepository\n\n    def execute(self, player_id: UUID) -> dict:\n        \"\"\"Get player's current stats.\"\"\"\n        return {\n            \"cash\": self.repository.get_player_cash(player_id),\n            \"reputation\": self.repository.get_player_reputation(player_id),\n        }\n",
            "tycoon_tactics/adapters/ui/screens.py": "\"\"\"UI Screens for the game using Kivy.\"\"\"\nfrom typing import Callable, List, Optional\nfrom uuid import UUID\n\nfrom kivy.uix.screenmanager import Screen\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.gridlayout import GridLayout\nfrom kivy.uix.scrollview import ScrollView\nfrom kivy.uix.label import Label\nfrom kivy.uix.button import Button\nfrom kivy.uix.popup import Popup\nfrom kivy.uix.textinput import TextInput\nfrom kivy.properties import ObjectProperty, StringProperty, NumericProperty\nfrom kivy.clock import Clock\n\n\nclass BaseScreen(Screen):\n    \"\"\"Base screen class with common functionality.\"\"\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.container = None\n\n    def show_error(self, message: str):\n        \"\"\"Display an error popup.\"\"\"\n        popup = Popup(\n            title=\"Error\",\n            content=Label(text=message),\n            size_hint=(0.8, 0.3),\n        )\n        popup.open()\n\n    def show_success(self, message: str):\n        \"\"\"Display a success popup.\"\"\"\n        popup = Popup(\n            title=\"Success\",\n            content=Label(text=message),\n            size_hint=(0.8, 0.3),\n        )\n        popup.open()\n\n\nclass MainMenuScreen(BaseScreen):\n    \"\"\"Main menu screen.\"\"\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(name=\"main_menu\", **kwargs)\n        self._build_ui()\n\n    def _build_ui(self):\n        \"\"\"Build the main menu UI.\"\"\"\n        layout = BoxLayout(orientation=\"vertical\", padding=20, spacing=10)\n        \n        title = Label(\n            text=\"Tycoon Tactics:\nFranchise Frontier\",\n            font_size=\"32sp\",\n            size_hint_y=0.3,\n            halign=\"center\",\n        )\n        layout.add_widget(title)\n\n        btn_new_game = Button(text=\"New Game\", size_hint_y=0.15)\n        btn_new_game.bind(on_press=lambda x: self._start_new_game())\n        layout.add_widget(btn_new_game)\n\n        btn_continue = Button(text=\"Continue\", size_hint_y=0.15)\n        btn_continue.bind(on_press=lambda x: self._continue_game())\n        layout.add_widget(btn_continue)\n\n        btn_settings = Button(text=\"Settings\", size_hint_y=0.15)\n        btn_settings.bind(on_press=lambda x: self._open_settings())\n        layout.add_widget(btn_settings)\n\n        btn_quit = Button(text=\"Quit\", size_hint_y=0.15)\n        btn_quit.bind(on_press=lambda x: self._quit_game())\n        layout.add_widget(btn_quit)\n\n        self.add_widget(layout)\n\n    def _start_new_game(self):\n        \"\"\"Start a new game.\"\"\"\n        self.manager.current = \"game\"\n\n    def _continue_game(self):\n        \"\"\"Continue existing game.\"\"\"\n        self.manager.current = \"game\"\n\n    def _open_settings(self):\n        \"\"\"Open settings screen.\"\"\"\n        self.manager.current = \"settings\"\n\n    def _quit_game(self):\n        \"\"\"Quit the game.\"\"\"\n        from kivy.app import App\n        App.get_running_app().stop()\n\n\nclass GameScreen(BaseScreen):\n    \"\"\"Main game screen.\"\"\"\n    \n    pending_orders_count = NumericProperty(0)\n    \n    def __init__(\n        self,\n        list_franchises_callback: Callable = None,\n        create_franchise_callback: Callable = None,\n        list_special_orders_callback: Callable = None,\n        get_player_stats_callback: Callable = None,\n        **kwargs\n    ):\n        super().__init__(name=\"game\", **kwargs)\n        self.list_franchises = list_franchises_callback\n        self.create_franchise = create_franchise_callback\n        self.list_special_orders = list_special_orders_callback\n        self.get_player_stats = get_player_stats_callback\n        self._build_ui()\n        # Schedule periodic refresh of pending orders count\n        Clock.schedule_interval(self._update_pending_orders_count, 30)\n\n    def _build_ui(self):\n        \"\"\"Build the game screen UI.\"\"\"\n        main_layout = BoxLayout(orientation=\"vertical\", padding=10, spacing=5)\n\n        # Header with player stats\n        header = BoxLayout(size_hint_y=0.1, spacing=10)\n        self.cash_label = Label(text=\"Cash: $10,000\", font_size=\"16sp\")\n        self.reputation_label = Label(text=\"Reputation: 0\", font_size=\"16sp\")\n        header.add_widget(self.cash_label)\n        header.add_widget(self.reputation_label)\n        main_layout.add_widget(header)\n\n        # Action buttons row\n        actions = BoxLayout(size_hint_y=0.1, spacing=10)\n        \n        btn_franchises = Button(text=\"Franchises\")\n        btn_franchises.bind(on_press=lambda x: self._show_franchises())\n        actions.add_widget(btn_franchises)\n\n        btn_supply = Button(text=\"Supply Chain\")\n        btn_supply.bind(on_press=lambda x: self._show_supply_chain())\n        actions.add_widget(btn_supply)\n\n        btn_market = Button(text=\"Market\")\n        btn_market.bind(on_press=lambda x: self._show_market())\n        actions.add_widget(btn_market)\n\n        # Special Orders button with badge\n        self.btn_special_orders = Button(text=\"Special Orders (0)\")\n        self.btn_special_orders.bind(on_press=lambda x: self._show_special_orders())\n        actions.add_widget(self.btn_special_orders)\n\n        main_layout.add_widget(actions)\n\n        # Main content area\n        self.content_area = BoxLayout(orientation=\"vertical\", size_hint_y=0.7)\n        welcome_label = Label(\n            text=\"Welcome to Tycoon Tactics!\n\nSelect an option above to get started.\",\n            halign=\"center\",\n        )\n        self.content_area.add_widget(welcome_label)\n        main_layout.add_widget(self.content_area)\n\n        # Bottom navigation\n        bottom_nav = BoxLayout(size_hint_y=0.1, spacing=10)\n        \n        btn_back = Button(text=\"Main Menu\")\n        btn_back.bind(on_press=lambda x: self._go_to_main_menu())\n        bottom_nav.add_widget(btn_back)\n\n        main_layout.add_widget(bottom_nav)\n\n        self.add_widget(main_layout)\n\n    def on_enter(self):\n        \"\"\"Called when screen is entered.\"\"\"\n        self._update_player_stats()\n        self._update_pending_orders_count()\n\n    def _update_player_stats(self):\n        \"\"\"Update player stats display.\"\"\"\n        if self.get_player_stats:\n            try:\n                stats = self.get_player_stats()\n                self.cash_label.text = f\"Cash: ${stats.get('cash', 0):}\"\n                self.reputation_label.text = f\"Reputation: {stats.get('reputation', 0)}\"\n            except Exception:\n                pass\n\n    def _update_pending_orders_count(self, dt=None):\n        \"\"\"Update the pending orders count badge.\"\"\"\n        if self.list_special_orders:\n            try:\n                orders = self.list_special_orders()\n                self.pending_orders_count = len(orders)\n                self.btn_special_orders.text = f\"Special Orders ({self.pending_orders_count})\"\n            except Exception:\n                self.btn_special_orders.text = \"Special Orders (0)\"\n\n    def _show_franchises(self):\n        \"\"\"Display franchises list.\"\"\"\n        self.content_area.clear_widgets()\n        \n        layout = BoxLayout(orientation=\"vertical\", spacing=5)\n        \n        # Header\n        header = BoxLayout(size_hint_y=0.1)\n        header.add_widget(Label(text=\"Your Franchises\", font_size=\"20sp\"))\n        btn_add = Button(text=\"+ Add New\", size_hint_x=0.3)\n        btn_add.bind(on_press=lambda x: self._show_create_franchise_dialog())\n        header.add_widget(btn_add)\n        layout.add_widget(header)\n\n        # Franchise list\n        scroll = ScrollView(size_hint_y=0.9)\n        franchise_list = GridLayout(cols=1, spacing=5, size_hint_y=None)\n        franchise_list.bind(minimum_height=franchise_list.setter(\"height\"))\n\n        if self.list_franchises:\n            franchises = self.list_franchises()\n            for franchise in franchises:\n                item = BoxLayout(size_hint_y=None, height=60)\n                item.add_widget(Label(text=franchise.name))\n                item.add_widget(Label(text=f\"Level: {franchise.level}\"))\n                item.add_widget(Label(text=f\"Rep: {franchise.reputation}\"))\n                franchise_list.add_widget(item)\n\n        if not franchise_list.children:\n            franchise_list.add_widget(\n                Label(text=\"No franchises yet. Create one!\", size_hint_y=None, height=60)\n            )\n\n        scroll.add_widget(franchise_list)\n        layout.add_widget(scroll)\n        \n        self.content_area.add_widget(layout)\n\n    def _show_create_franchise_dialog(self):\n        \"\"\"Show dialog to create a new franchise.\"\"\"\n        content = BoxLayout(orientation=\"vertical\", spacing=10, padding=10)\n        \n        content.add_widget(Label(text=\"Franchise Name:\"))\n        name_input = TextInput(multiline=False)\n        content.add_widget(name_input)\n\n        content.add_widget(Label(text=\"Location:\"))\n        location_input = TextInput(multiline=False)\n        content.add_widget(location_input)\n\n        content.add_widget(Label(text=\"Type (restaurant/retail/service):\"))\n        type_input = TextInput(multiline=False)\n        content.add_widget(type_input)\n\n        buttons = BoxLayout(size_hint_y=0.3, spacing=10)\n        \n        popup = Popup(\n            title=\"Create New Franchise\",\n            content=content,\n            size_hint=(0.9, 0.7),\n        )\n\n        btn_cancel = Button(text=\"Cancel\")\n        btn_cancel.bind(on_press=lambda x: popup.dismiss())\n        buttons.add_widget(btn_cancel)\n\n        btn_create = Button(text=\"Create\")\n        btn_create.bind(on_press=lambda x: self._do_create_franchise(\n            popup, name_input.text, location_input.text, type_input.text\n        ))\n        buttons.add_widget(btn_create)\n\n        content.add_widget(buttons)\n        popup.open()\n\n    def _do_create_franchise(self, popup, name: str, location: str, franchise_type: str):\n        \"\"\"Execute franchise creation.\"\"\"\n        if not name or not location or not franchise_type:\n            self.show_error(\"Please fill in all fields\")\n            return\n\n        if self.create_franchise:\n            try:\n                self.create_franchise(name, location, franchise_type)\n                popup.dismiss()\n                self.show_success(f\"Franchise '{name}' created!\")\n                self._show_franchises()\n            except Exception as e:\n                self.show_error(str(e))\n\n    def _show_supply_chain(self):\n        \"\"\"Display supply chain management.\"\"\"\n        self.content_area.clear_widgets()\n        self.content_area.add_widget(\n            Label(text=\"Supply Chain Management\n\nComing soon...\")\n        )\n\n    def _show_market(self):\n        \"\"\"Display market information.\"\"\"\n        self.content_area.clear_widgets()\n        self.content_area.add_widget(\n            Label(text=\"Market Overview\n\nComing soon...\")\n        )\n\n    def _show_special_orders(self):\n        \"\"\"Navigate to special orders screen.\"\"\"\n        self.manager.current = \"special_orders\"\n\n    def _go_to_main_menu(self):\n        \"\"\"Return to main menu.\"\"\"\n        self.manager.current = \"main_menu\"\n\n\nclass SpecialOrdersScreen(BaseScreen):\n    \"\"\"Screen for displaying and managing special orders.\"\"\"\n    \n    def __init__(\n        self,\n        list_orders_callback: Callable = None,\n        accept_order_callback: Callable = None,\n        get_franchises_callback: Callable = None,\n        **kwargs\n    ):\n        super().__init__(name=\"special_orders\", **kwargs)\n        self.list_orders = list_orders_callback\n        self.accept_order = accept_order_callback\n        self.get_franchises = get_franchises_callback\n        self._build_ui()\n\n    def _build_ui(self):\n        \"\"\"Build the special orders screen UI.\"\"\"\n        main_layout = BoxLayout(orientation=\"vertical\", padding=10, spacing=5)\n\n        # Header\n        header = BoxLayout(size_hint_y=0.1, spacing=10)\n        header.add_widget(Label(text=\"Special Orders\", font_size=\"24sp\"))\n        btn_refresh = Button(text=\"Refresh\", size_hint_x=0.3)\n        btn_refresh.bind(on_press=lambda x: self._refresh_orders())\n        header.add_widget(btn_refresh)\n        main_layout.add_widget(header)\n\n        # Orders list\n        self.orders_scroll = ScrollView(size_hint_y=0.8)\n        self.orders_list = GridLayout(cols=1, spacing=10, size_hint_y=None, padding=5)\n        self.orders_list.bind(minimum_height=self.orders_list.setter(\"height\"))\n        self.orders_scroll.add_widget(self.orders_list)\n        main_layout.add_widget(self.orders_scroll)\n\n        # Bottom navigation\n        bottom_nav = BoxLayout(size_hint_y=0.1, spacing=10)\n        btn_back = Button(text=\"Back to Game\")\n        btn_back.bind(on_press=lambda x: self._go_back())\n        bottom_nav.add_widget(btn_back)\n        main_layout.add_widget(bottom_nav)\n\n        self.add_widget(main_layout)\n\n    def on_enter(self):\n        \"\"\"Called when screen is entered.\"\"\"\n        self._refresh_orders()\n\n    def _refresh_orders(self):\n        \"\"\"Refresh the orders list.\"\"\"\n        self.orders_list.clear_widgets()\n\n        if not self.list_orders:\n            self.orders_list.add_widget(\n                Label(text=\"Orders not available\", size_hint_y=None, height=60)\n            )\n            return\n\n        try:\n            orders = self.list_orders()\n            \n            if not orders:\n                self.orders_list.add_widget(\n                    Label(\n                        text=\"No special orders available.\nCheck back later!\",\n                        size_hint_y=None,\n                        height=100,\n                        halign=\"center\",\n                    )\n                )\n                return\n\n            for order in orders:\n                order_widget = self._create_order_widget(order)\n                self.orders_list.add_widget(order_widget)\n\n        except Exception as e:\n            self.orders_list.add_widget(\n                Label(text=f\"Error loading orders: {e}\", size_hint_y=None, height=60)\n            )\n\n    def _create_order_widget(self, order) -> BoxLayout:\n        \"\"\"Create a widget for displaying a single order.\"\"\"\n        container = BoxLayout(\n            orientation=\"vertical\",\n            size_hint_y=None,\n            height=200,\n            padding=10,\n            spacing=5,\n        )\n\n        # Order name and time remaining\n        header = BoxLayout(size_hint_y=0.2)\n        header.add_widget(Label(text=order.name, font_size=\"18sp\", bold=True))\n        remaining = order.remaining_time_seconds()\n        minutes = remaining // 60\n        seconds = remaining % 60\n        time_label = Label(\n            text=f\"Time: {minutes}m {seconds}s\",\n            color=(1, 0.5, 0, 1) if remaining < 600 else (0, 1, 0, 1),\n        )\n        header.add_widget(time_label)\n        container.add_widget(header)\n\n        # Destination\n        container.add_widget(\n            Label(text=f\"Deliver to: {order.destination_address}\", size_hint_y=0.15)\n        )\n\n        # Requirements\n        req_text = \"Required: \" + \", \".join(\n            f\"{qty}x {product}\" for product, qty in order.product_requirements.items()\n        )\n        container.add_widget(Label(text=req_text, size_hint_y=0.2))\n\n        # Rewards\n        rewards = BoxLayout(size_hint_y=0.2)\n        rewards.add_widget(Label(text=f\"Cash: ${order.reward_cash:}\", color=(0, 1, 0, 1)))\n        rewards.add_widget(Label(text=f\"Reputation: +{order.reward_reputation}\", color=(0, 0.7, 1, 1)))\n        container.add_widget(rewards)\n\n        # Accept button\n        btn_accept = Button(\n            text=\"Accept Order\",\n            size_hint_y=0.25,\n            background_color=(0, 0.7, 0, 1),\n        )\n        btn_accept.bind(on_press=lambda x, o=order: self._show_accept_dialog(o))\n        container.add_widget(btn_accept)\n\n        return container\n\n    def _show_accept_dialog(self, order):\n        \"\"\"Show dialog to select franchise for order fulfillment.\"\"\"\n        content = BoxLayout(orientation=\"vertical\", spacing=10, padding=10)\n        \n        content.add_widget(Label(text=\"Select franchise to fulfill order:\"))\n\n        franchises = []\n        if self.get_franchises:\n            try:\n                franchises = self.get_franchises()\n            except Exception:\n                pass\n\n        popup = Popup(\n            title=f\"Accept: {order.name}\",\n            content=content,\n            size_hint=(0.9, 0.6),\n        )\n\n        if not franchises:\n            content.add_widget(Label(text=\"No franchises available!\"))\n            btn_close = Button(text=\"Close\", size_hint_y=0.3)\n            btn_close.bind(on_press=lambda x: popup.dismiss())\n            content.add_widget(btn_close)\n        else:\n            scroll = ScrollView(size_hint_y=0.7)\n            franchise_list = GridLayout(cols=1, spacing=5, size_hint_y=None)\n            franchise_list.bind(minimum_height=franchise_list.setter(\"height\"))\n\n            for franchise in franchises:\n                btn = Button(\n                    text=f\"{franchise.name} ({franchise.location})\",\n                    size_hint_y=None,\n                    height=50,\n                )\n                btn.bind(on_press=lambda x, f=franchise, o=order, p=popup: self._do_accept_order(p, o, f))\n                franchise_list.add_widget(btn)\n\n            scroll.add_widget(franchise_list)\n            content.add_widget(scroll)\n\n            btn_cancel = Button(text=\"Cancel\", size_hint_y=0.2)\n            btn_cancel.bind(on_press=lambda x: popup.dismiss())\n            content.add_widget(btn_cancel)\n\n        popup.open()\n\n    def _do_accept_order(self, popup, order, franchise):\n        \"\"\"Execute order acceptance.\"\"\"\n        popup.dismiss()\n\n        if not self.accept_order:\n            self.show_error(\"Order acceptance not available\")\n            return\n\n        try:\n            self.accept_order(order.id, franchise.id)\n            self.show_success(\n                f\"Order completed!\n\n\"\n                f\"Earned: ${order.reward_cash:}\n\"\n                f\"Reputation: +{order.reward_reputation}\"\n            )\n            self._refresh_orders()\n        except Exception as e:\n            error_msg = str(e)\n            if \"Insufficient\" in error_msg:\n                self.show_error(f\"Not enough inventory!\n{error_msg}\")\n            elif \"expired\" in error_msg.lower():\n                self.show_error(\"This order has expired!\")\n                self._refresh_orders()\n            else:\n                self.show_error(f\"Failed to accept order:\n{error_msg}\")\n\n    def _go_back(self):\n        \"\"\"Return to game screen.\"\"\"\n        self.manager.current = \"game\"\n\n\nclass SettingsScreen(BaseScreen):\n    \"\"\"Settings screen.\"\"\"\n    \n    def __init__(self, **kwargs):\n        super().__init__(name=\"settings\", **kwargs)\n        self._build_ui()\n\n    def _build_ui(self):\n        \"\"\"Build the settings screen UI.\"\"\"\n        layout = BoxLayout(orientation=\"vertical\", padding=20, spacing=10)\n        \n        layout.add_widget(Label(text=\"Settings\", font_size=\"24sp\", size_hint_y=0.1))\n\n        settings_area = GridLayout(cols=2, spacing=10, size_hint_y=0.7)\n        \n        settings_area.add_widget(Label(text=\"Sound Effects:\"))\n        btn_sound = Button(text=\"On\")\n        settings_area.add_widget(btn_sound)\n\n        settings_area.add_widget(Label(text=\"Music:\"))\n        btn_music = Button(text=\"On\")\n        settings_area.add_widget(btn_music)\n\n        settings_area.add_widget(Label(text=\"Notifications:\"))\n        btn_notif = Button(text=\"On\")\n        settings_area.add_widget(btn_notif)\n\n        layout.add_widget(settings_area)\n\n        btn_back = Button(text=\"Back\", size_hint_y=0.1)\n        btn_back.bind(on_press=lambda x: self._go_back())\n        layout.add_widget(btn_back)\n\n        self.add_widget(layout)\n\n    def _go_back(self):\n        \"\"\"Return to main menu.\"\"\"\n        self.manager.current = \"main_menu\"\n",
            "tycoon_tactics/adapters/ui/main_app.py": "\"\"\"Main Kivy application for Tycoon Tactics.\"\"\"\nfrom uuid import UUID, uuid4\n\nfrom kivy.app import App\nfrom kivy.uix.screenmanager import ScreenManager\nfrom kivy.clock import Clock\n\nfrom tycoon_tactics.adapters.ui.screens import (\n    MainMenuScreen,\n    GameScreen,\n    SpecialOrdersScreen,\n    SettingsScreen,\n)\nfrom tycoon_tactics.config.containers import Container\n\n\nclass TycoonTacticsApp(App):\n    \"\"\"Main application class for Tycoon Tactics: Franchise Frontier.\"\"\"\n    \n    title = \"Tycoon Tactics: Franchise Frontier\"\n    \n    def __init__(self, container: Container = None, **kwargs):\n        super().__init__(**kwargs)\n        self.container = container or Container()\n        # Default player ID (in real app, this would come from auth)\n        self.player_id = uuid4()\n        self._special_order_generation_event = None\n\n    def build(self):\n        \"\"\"Build and return the root widget.\"\"\"\n        self.screen_manager = ScreenManager()\n        \n        # Create screens with callbacks\n        main_menu = MainMenuScreen()\n        \n        game_screen = GameScreen(\n            list_franchises_callback=self._list_franchises,\n            create_franchise_callback=self._create_franchise,\n            list_special_orders_callback=self._list_special_orders,\n            get_player_stats_callback=self._get_player_stats,\n        )\n        \n        special_orders_screen = SpecialOrdersScreen(\n            list_orders_callback=self._list_special_orders,\n            accept_order_callback=self._accept_special_order,\n            get_franchises_callback=self._list_franchises,\n        )\n        \n        settings_screen = SettingsScreen()\n\n        # Add screens to manager\n        self.screen_manager.add_widget(main_menu)\n        self.screen_manager.add_widget(game_screen)\n        self.screen_manager.add_widget(special_orders_screen)\n        self.screen_manager.add_widget(settings_screen)\n\n        # Schedule periodic special order generation (every 5 minutes = 300 seconds)\n        self._special_order_generation_event = Clock.schedule_interval(\n            self._generate_special_order,\n            300  # 5 minutes\n        )\n        \n        # Generate an initial special order on startup\n        Clock.schedule_once(self._generate_special_order, 5)\n\n        return self.screen_manager\n\n    def on_stop(self):\n        \"\"\"Called when the application is stopping.\"\"\"\n        if self._special_order_generation_event:\n            self._special_order_generation_event.cancel()\n\n    # Callback methods that bridge UI to use cases\n    \n    def _list_franchises(self):\n        \"\"\"List all franchises.\"\"\"\n        use_case = self.container.list_franchises_use_case()\n        return use_case.execute()\n\n    def _create_franchise(self, name: str, location: str, franchise_type: str):\n        \"\"\"Create a new franchise.\"\"\"\n        use_case = self.container.create_franchise_use_case()\n        return use_case.execute(name, location, franchise_type)\n\n    def _list_special_orders(self):\n        \"\"\"List active special orders.\"\"\"\n        use_case = self.container.list_active_special_orders_use_case()\n        return use_case.execute()\n\n    def _accept_special_order(self, order_id: UUID, franchise_id: UUID):\n        \"\"\"Accept a special order.\"\"\"\n        use_case = self.container.accept_special_order_use_case(self.player_id)\n        return use_case.execute(order_id, franchise_id)\n\n    def _get_player_stats(self):\n        \"\"\"Get player statistics.\"\"\"\n        use_case = self.container.get_player_stats_use_case()\n        return use_case.execute(self.player_id)\n\n    def _generate_special_order(self, dt=None):\n        \"\"\"Generate a new random special order.\"\"\"\n        try:\n            use_case = self.container.generate_random_special_order_use_case()\n            order = use_case.execute()\n            print(f\"Generated special order: {order.name}\")\n        except Exception as e:\n            print(f\"Error generating special order: {e}\")\n\n\ndef run_app():\n    \"\"\"Run the application.\"\"\"\n    app = TycoonTacticsApp()\n    app.run()\n\n\nif __name__ == \"__main__\":\n    run_app()\n",
            "tycoon_tactics/config/containers.py": "\"\"\"Dependency injection container configuration.\"\"\"\nfrom uuid import UUID\n\nfrom tycoon_tactics.adapters.persistence.sqlite_repository import SQLiteRepository\nfrom tycoon_tactics.application.event_bus import EventBus\nfrom tycoon_tactics.application.use_cases import (\n    CreateFranchiseUseCase,\n    GetFranchiseUseCase,\n    ListFranchisesUseCase,\n    UpdateInventoryUseCase,\n    GetSupplyChainUseCase,\n    ListMarketsUseCase,\n    GenerateRandomSpecialOrderUseCase,\n    ListActiveSpecialOrdersUseCase,\n    GetSpecialOrderUseCase,\n    AcceptSpecialOrderUseCase,\n    GetPlayerStatsUseCase,\n)\n\n\nclass Container:\n    \"\"\"Dependency injection container for the application.\"\"\"\n    \n    def __init__(self, db_path: str = \"tycoon_tactics.db\"):\n        \"\"\"Initialize the container with dependencies.\"\"\"\n        self._db_path = db_path\n        self._repository = None\n        self._event_bus = None\n\n    @property\n    def repository(self) -> SQLiteRepository:\n        \"\"\"Get or create the repository singleton.\"\"\"\n        if self._repository is None:\n            self._repository = SQLiteRepository(self._db_path)\n        return self._repository\n\n    @property\n    def event_bus(self) -> EventBus:\n        \"\"\"Get or create the event bus singleton.\"\"\"\n        if self._event_bus is None:\n            self._event_bus = EventBus()\n        return self._event_bus\n\n    # Franchise use cases\n    def create_franchise_use_case(self) -> CreateFranchiseUseCase:\n        \"\"\"Create a CreateFranchiseUseCase instance.\"\"\"\n        return CreateFranchiseUseCase(\n            repository=self.repository,\n            event_bus=self.event_bus,\n        )\n\n    def get_franchise_use_case(self) -> GetFranchiseUseCase:\n        \"\"\"Create a GetFranchiseUseCase instance.\"\"\"\n        return GetFranchiseUseCase(repository=self.repository)\n\n    def list_franchises_use_case(self) -> ListFranchisesUseCase:\n        \"\"\"Create a ListFranchisesUseCase instance.\"\"\"\n        return ListFranchisesUseCase(repository=self.repository)\n\n    # Supply chain use cases\n    def update_inventory_use_case(self) -> UpdateInventoryUseCase:\n        \"\"\"Create an UpdateInventoryUseCase instance.\"\"\"\n        return UpdateInventoryUseCase(\n            repository=self.repository,\n            event_bus=self.event_bus,\n        )\n\n    def get_supply_chain_use_case(self) -> GetSupplyChainUseCase:\n        \"\"\"Create a GetSupplyChainUseCase instance.\"\"\"\n        return GetSupplyChainUseCase(repository=self.repository)\n\n    # Market use cases\n    def list_markets_use_case(self) -> ListMarketsUseCase:\n        \"\"\"Create a ListMarketsUseCase instance.\"\"\"\n        return ListMarketsUseCase(repository=self.repository)\n\n    # Special Order use cases\n    def generate_random_special_order_use_case(self) -> GenerateRandomSpecialOrderUseCase:\n        \"\"\"Create a GenerateRandomSpecialOrderUseCase instance.\"\"\"\n        return GenerateRandomSpecialOrderUseCase(repository=self.repository)\n\n    def list_active_special_orders_use_case(self) -> ListActiveSpecialOrdersUseCase:\n        \"\"\"Create a ListActiveSpecialOrdersUseCase instance.\"\"\"\n        return ListActiveSpecialOrdersUseCase(repository=self.repository)\n\n    def get_special_order_use_case(self) -> GetSpecialOrderUseCase:\n        \"\"\"Create a GetSpecialOrderUseCase instance.\"\"\"\n        return GetSpecialOrderUseCase(repository=self.repository)\n\n    def accept_special_order_use_case(self, player_id: UUID) -> AcceptSpecialOrderUseCase:\n        \"\"\"Create an AcceptSpecialOrderUseCase instance.\"\"\"\n        return AcceptSpecialOrderUseCase(\n            repository=self.repository,\n            event_bus=self.event_bus,\n            player_id=player_id,\n        )\n\n    # Player stats use case\n    def get_player_stats_use_case(self) -> GetPlayerStatsUseCase:\n        \"\"\"Create a GetPlayerStatsUseCase instance.\"\"\"\n        return GetPlayerStatsUseCase(repository=self.repository)\n",
            "tycoon_tactics/domain/supply_chain.py": "\"\"\"Supply Chain domain model.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Dict, List\nfrom uuid import UUID, uuid4\n\n\n@dataclass\nclass SupplyChain:\n    \"\"\"Represents a franchise's supply chain.\"\"\"\n    id: UUID\n    franchise_id: UUID\n    inventory: Dict[str, int] = field(default_factory=dict)\n    suppliers: List[str] = field(default_factory=list)\n    logistics_efficiency: float = 1.0\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n    @classmethod\n    def create(cls, franchise_id: UUID) -> \"SupplyChain\":\n        \"\"\"Factory method to create a new supply chain.\"\"\"\n        return cls(\n            id=uuid4(),\n            franchise_id=franchise_id,\n            inventory={},\n            suppliers=[],\n            logistics_efficiency=1.0,\n            created_at=datetime.utcnow(),\n        )\n\n    def add_inventory(self, product_name: str, quantity: int) -> None:\n        \"\"\"Add items to inventory.\"\"\"\n        if quantity < 0:\n            raise ValueError(\"Quantity must be non-negative\")\n        current = self.inventory.get(product_name, 0)\n        self.inventory[product_name] = current + quantity\n\n    def remove_inventory(self, product_name: str, quantity: int) -> None:\n        \"\"\"Remove items from inventory.\"\"\"\n        if quantity < 0:\n            raise ValueError(\"Quantity must be non-negative\")\n        current = self.inventory.get(product_name, 0)\n        if current < quantity:\n            raise ValueError(\n                f\"Insufficient inventory for {product_name}: have {current}, need {quantity}\"\n            )\n        self.inventory[product_name] = current - quantity\n        # Clean up zero quantities\n        if self.inventory[product_name] == 0:\n            del self.inventory[product_name]\n\n    def get_inventory(self, product_name: str) -> int:\n        \"\"\"Get current inventory for a product.\"\"\"\n        return self.inventory.get(product_name, 0)\n\n    def add_supplier(self, supplier_name: str) -> None:\n        \"\"\"Add a supplier to the supply chain.\"\"\"\n        if supplier_name not in self.suppliers:\n            self.suppliers.append(supplier_name)\n\n    def remove_supplier(self, supplier_name: str) -> None:\n        \"\"\"Remove a supplier from the supply chain.\"\"\"\n        if supplier_name in self.suppliers:\n            self.suppliers.remove(supplier_name)\n\n    def improve_logistics(self, improvement: float) -> None:\n        \"\"\"Improve logistics efficiency.\"\"\"\n        if improvement < 0:\n            raise ValueError(\"Improvement must be non-negative\")\n        self.logistics_efficiency += improvement\n",
            "tycoon_tactics/application/game_events.py": "\"\"\"Game events for the event bus.\"\"\"\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Dict, Any\nfrom uuid import UUID\n\n\n@dataclass\nclass GameEvent:\n    \"\"\"Base class for game events.\"\"\"\n    timestamp: datetime = None\n\n    def __post_init__(self):\n        if self.timestamp is None:\n            self.timestamp = datetime.utcnow()\n\n\n@dataclass\nclass FranchiseCreatedEvent(GameEvent):\n    \"\"\"Event fired when a franchise is created.\"\"\"\n    franchise_id: UUID = None\n    name: str = \"\"\n    location: str = \"\"\n\n\n@dataclass\nclass FranchiseUpgradedEvent(GameEvent):\n    \"\"\"Event fired when a franchise is upgraded.\"\"\"\n    franchise_id: UUID = None\n    new_level: int = 0\n\n\n@dataclass\nclass SupplyChainUpdatedEvent(GameEvent):\n    \"\"\"Event fired when a supply chain is updated.\"\"\"\n    supply_chain_id: UUID = None\n    franchise_id: UUID = None\n    inventory: Dict[str, int] = None\n\n\n@dataclass\nclass MarketConditionsChangedEvent(GameEvent):\n    \"\"\"Event fired when market conditions change.\"\"\"\n    market_id: UUID = None\n    demand_level: float = 0.0\n    price_multiplier: float = 0.0\n\n\n@dataclass\nclass SpecialOrderCreatedEvent(GameEvent):\n    \"\"\"Event fired when a special order is created.\"\"\"\n    order_id: UUID = None\n    name: str = \"\"\n    reward_cash: int = 0\n    reward_reputation: int = 0\n\n\n@dataclass\nclass SpecialOrderAcceptedEvent(GameEvent):\n    \"\"\"Event fired when a special order is accepted.\"\"\"\n    order_id: UUID = None\n    player_id: UUID = None\n    franchise_id: UUID = None\n\n\n@dataclass\nclass SpecialOrderCompletedEvent(GameEvent):\n    \"\"\"Event fired when a special order is completed.\"\"\"\n    order_id: UUID = None\n    player_id: UUID = None\n    cash_earned: int = 0\n    reputation_earned: int = 0\n\n\n@dataclass\nclass SpecialOrderExpiredEvent(GameEvent):\n    \"\"\"Event fired when a special order expires.\"\"\"\n    order_id: UUID = None\n",
            "main.py": "\"\"\"Main entry point for Tycoon Tactics: Franchise Frontier.\"\"\"\nimport os\nimport sys\n\n# Add the project root to the path\nsys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\nfrom tycoon_tactics.adapters.ui.main_app import TycoonTacticsApp\nfrom tycoon_tactics.config.containers import Container\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    # Initialize the dependency injection container\n    container = Container(db_path=\"tycoon_tactics.db\")\n    \n    # Create and run the application\n    app = TycoonTacticsApp(container=container)\n    app.run()\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "tests/unit/test_special_orders.py": "\"\"\"Unit tests for Special Orders feature.\"\"\"\nimport pytest\nfrom datetime import datetime, timedelta\nfrom uuid import uuid4\n\nfrom tycoon_tactics.domain.special_order import SpecialOrder, SpecialOrderStatus\nfrom tycoon_tactics.application.use_cases import (\n    GenerateRandomSpecialOrderUseCase,\n    AcceptSpecialOrderUseCase,\n    ListActiveSpecialOrdersUseCase,\n    InsufficientInventoryError,\n    OrderNotFoundError,\n    InvalidOrderStatusError,\n)\n\n\nclass TestSpecialOrderDomain:\n    \"\"\"Tests for SpecialOrder domain model.\"\"\"\n\n    def test_create_special_order(self):\n        \"\"\"Test creating a special order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10, \"Food\": 5},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n            time_to_live_seconds=3600,\n        )\n        \n        assert order.name == \"Test Order\"\n        assert order.product_requirements == {\"Electronics\": 10, \"Food\": 5}\n        assert order.destination_address == \"Test Address\"\n        assert order.reward_cash == 1000\n        assert order.reward_reputation == 50\n        assert order.time_to_live_seconds == 3600\n        assert order.status == SpecialOrderStatus.PENDING\n        assert order.id is not None\n        assert order.created_at is not None\n\n    def test_order_not_expired_initially(self):\n        \"\"\"Test that a new order is not expired.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n            time_to_live_seconds=3600,\n        )\n        \n        assert not order.is_expired()\n        assert order.remaining_time_seconds() > 0\n\n    def test_accept_order(self):\n        \"\"\"Test accepting an order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.accept()\n        assert order.status == SpecialOrderStatus.ACCEPTED\n\n    def test_complete_order(self):\n        \"\"\"Test completing an order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.accept()\n        order.complete()\n        assert order.status == SpecialOrderStatus.COMPLETED\n\n    def test_cannot_accept_non_pending_order(self):\n        \"\"\"Test that accepting a non-pending order raises an error.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.accept()\n        \n        with pytest.raises(ValueError):\n            order.accept()\n\n    def test_cannot_complete_non_accepted_order(self):\n        \"\"\"Test that completing a non-accepted order raises an error.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        with pytest.raises(ValueError):\n            order.complete()\n\n    def test_expire_order(self):\n        \"\"\"Test expiring an order.\"\"\"\n        order = SpecialOrder.create(\n            name=\"Test Order\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Test Address\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        \n        order.expire()\n        assert order.status == SpecialOrderStatus.EXPIRED\n\n\nclass TestSpecialOrderUseCases:\n    \"\"\"Tests for Special Order use cases.\"\"\"\n\n    def test_generate_random_special_order(self, mock_repository):\n        \"\"\"Test generating a random special order.\"\"\"\n        use_case = GenerateRandomSpecialOrderUseCase(repository=mock_repository)\n        order = use_case.execute()\n        \n        assert order is not None\n        assert order.name in GenerateRandomSpecialOrderUseCase.ORDER_NAMES\n        assert len(order.product_requirements) >= 1\n        assert order.reward_cash > 0\n        assert order.reward_reputation > 0\n        assert order.status == SpecialOrderStatus.PENDING\n\n    def test_list_active_special_orders(self, mock_repository):\n        \"\"\"Test listing active special orders.\"\"\"\n        # Add some orders\n        order1 = SpecialOrder.create(\n            name=\"Order 1\",\n            product_requirements={\"Electronics\": 10},\n            destination_address=\"Address 1\",\n            reward_cash=1000,\n            reward_reputation=50,\n        )\n        order2 = SpecialOrder.create(\n            name=\"Order 2\",\n            product_requirements={\"Food\": 20},\n            destination_address=\"Address 2\",\n            reward_cash=2000,\n            reward_reputation=100,\n        )\n        mock_repository.add_special_order(order1)\n        mock_repository.add_special_order(order2)\n        \n        use_case = ListActiveSpecialOrdersUseCase(repository=mock_repository)\n        orders = use_case.execute()\n        \n        assert len(orders) == 2\n\n\n@pytest.fixture\ndef mock_repository():\n    \"\"\"Create a mock repository for testing.\"\"\"\n    from unittest.mock import MagicMock\n    from tycoon_tactics.domain.supply_chain import SupplyChain\n    \n    repo = MagicMock()\n    repo._orders = {}\n    repo._supply_chains = {}\n    repo._player_cash = {}\n    repo._player_reputation = {}\n    \n    def add_special_order(order):\n        repo._orders[order.id] = order\n    \n    def get_special_order(order_id):\n        return repo._orders.get(order_id)\n    \n    def list_active_special_orders():\n        return [o for o in repo._orders.values() if o.status == SpecialOrderStatus.PENDING]\n    \n    def update_special_order(order):\n        repo._orders[order.id] = order\n    \n    repo.add_special_order = add_special_order\n    repo.get_special_order = get_special_order\n    repo.list_active_special_orders = list_active_special_orders\n    repo.update_special_order = update_special_order\n    \n    return repo\n"
          },
          "generated_files": [
            "tycoon_tactics/domain/special_order.py",
            "tycoon_tactics/adapters/persistence/orm_models.py",
            "tycoon_tactics/domain/ports.py",
            "tycoon_tactics/adapters/persistence/sqlite_repository.py",
            "tycoon_tactics/application/use_cases.py",
            "tycoon_tactics/adapters/ui/screens.py",
            "tycoon_tactics/adapters/ui/main_app.py",
            "tycoon_tactics/config/containers.py",
            "tycoon_tactics/domain/supply_chain.py",
            "tycoon_tactics/application/game_events.py",
            "main.py",
            "tests/unit/test_special_orders.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8165511551155116,
                "dependency_traversal_accuracy": 0.8064165186699307,
                "cross_file_reasoning_depth": 0.3772916666666667,
                "system_thinking_score": 0.5078651782558038,
                "robustness_score": 0.12431681333950903,
                "comprehensiveness_score": 0.7239179872284528,
                "innovation_score": 0.275,
                "solution_elegance_score": 0.6416176433016468
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.10206889438943895,
                "dependency_traversal_weighted": 0.10080206483374134,
                "cross_file_reasoning_weighted": 0.047161458333333336,
                "system_thinking_weighted": 0.06348314728197547,
                "robustness_weighted": 0.015539601667438629,
                "comprehensiveness_weighted": 0.0904897484035566,
                "innovation_weighted": 0.034375,
                "solution_elegance_weighted": 0.08020220541270585
              },
              "total_software_engineering_score": 0.5341221203221902
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.7799184322357178,
                "errors": [
                  "  File \"tycoon_tactics/adapters/ui/screens.py\", line 55",
                  "    text=\"Tycoon Tactics:",
                  "         ^",
                  "SyntaxError: unterminated string literal (detected at line 55)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "tycoon_tactics/domain/special_order.py",
                  "tycoon_tactics/adapters/persistence/orm_models.py",
                  "tycoon_tactics/domain/ports.py",
                  "tycoon_tactics/adapters/persistence/sqlite_repository.py",
                  "tycoon_tactics/application/use_cases.py",
                  "tycoon_tactics/adapters/ui/screens.py",
                  "tycoon_tactics/adapters/ui/main_app.py",
                  "tycoon_tactics/config/containers.py",
                  "tycoon_tactics/domain/supply_chain.py",
                  "tycoon_tactics/application/game_events.py",
                  "main.py",
                  "tests/unit/test_special_orders.py"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 12,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 12 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.2702428571428571,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.2702428571428571,
                "idc_weight": 0.2,
                "total_functional_score": 0.3940485714285714
              }
            },
            "code_quality_details": {
              "files_analyzed": 12,
              "quality_checks": {
                "tycoon_tactics/domain/special_order.py": {
                  "line_count": 86,
                  "non_empty_lines": 74,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 6,
                  "class_count": 2,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/adapters/persistence/orm_models.py": {
                  "line_count": 103,
                  "non_empty_lines": 81,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 2,
                  "class_count": 6,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/domain/ports.py": {
                  "line_count": 175,
                  "non_empty_lines": 135,
                  "comment_lines": 5,
                  "comment_ratio": 0.037037037037037035,
                  "function_count": 28,
                  "class_count": 5,
                  "import_count": 14,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/adapters/persistence/sqlite_repository.py": {
                  "line_count": 334,
                  "non_empty_lines": 302,
                  "comment_lines": 6,
                  "comment_ratio": 0.019867549668874173,
                  "function_count": 27,
                  "class_count": 2,
                  "import_count": 23,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/application/use_cases.py": {
                  "line_count": 300,
                  "non_empty_lines": 232,
                  "comment_lines": 15,
                  "comment_ratio": 0.06465517241379311,
                  "function_count": 12,
                  "class_count": 14,
                  "import_count": 22,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/adapters/ui/screens.py": {
                  "line_count": 573,
                  "non_empty_lines": 457,
                  "comment_lines": 16,
                  "comment_ratio": 0.0350109409190372,
                  "function_count": 32,
                  "class_count": 6,
                  "import_count": 26,
                  "quality_score": 0.6
                },
                "tycoon_tactics/adapters/ui/main_app.py": {
                  "line_count": 118,
                  "non_empty_lines": 90,
                  "comment_lines": 6,
                  "comment_ratio": 0.06666666666666667,
                  "function_count": 10,
                  "class_count": 2,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/config/containers.py": {
                  "line_count": 102,
                  "non_empty_lines": 84,
                  "comment_lines": 5,
                  "comment_ratio": 0.05952380952380952,
                  "function_count": 14,
                  "class_count": 1,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/domain/supply_chain.py": {
                  "line_count": 70,
                  "non_empty_lines": 60,
                  "comment_lines": 1,
                  "comment_ratio": 0.016666666666666666,
                  "function_count": 7,
                  "class_count": 1,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "tycoon_tactics/application/game_events.py": {
                  "line_count": 79,
                  "non_empty_lines": 59,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 1,
                  "class_count": 10,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "main.py": {
                  "line_count": 24,
                  "non_empty_lines": 16,
                  "comment_lines": 3,
                  "comment_ratio": 0.1875,
                  "function_count": 1,
                  "class_count": 0,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "tests/unit/test_special_orders.py": {
                  "line_count": 195,
                  "non_empty_lines": 160,
                  "comment_lines": 1,
                  "comment_ratio": 0.00625,
                  "function_count": 14,
                  "class_count": 2,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7883333333333333,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.9246621621621619,
                "multi_session_memory_retention": 0.9280712530712527
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.46233108108108095,
                "multi_session_memory_retention_weighted": 0.46403562653562636
              },
              "total_longcontext_utilization_score": 0.9263667076167073
            }
          },
          "timestamp": "2026-01-14T20:51:11.467922"
        }
      }
    },
    "python_system_monitoring_medium_061_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_system_monitoring_medium_061_feature_implementation_expert_01",
          "scenario_title": "Implement Automated Deployment Rollback based on Performance Degradation",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.505444062230777,
          "functional_correctness_score": 0.6771423948220066,
          "code_quality_score": 0.8233333333333334,
          "longcontext_utilization_score": 0.79375,
          "total_score": 3.2468100500278974,
          "generation_time": 141.7461552619934,
          "code_files_generated": 6,
          "total_lines_generated": 1259,
          "parsing_success": true,
          "solution_code": {
            "PulseLink_SocialOps_Monitor/shared/events.py": "from dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any\nimport uuid\n\n\n@dataclass\nclass BaseEvent:\n    \"\"\"Base class for all events in the system.\"\"\"\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    source_service: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"event_id\": self.event_id,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"source_service\": self.source_service,\n            \"event_type\": self.__class__.__name__\n        }\n\n\n@dataclass\nclass DeploymentStartedEvent(BaseEvent):\n    \"\"\"Emitted when a deployment process begins.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    version: str = \"\"\n    environment: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"version\": self.version,\n            \"environment\": self.environment\n        })\n        return data\n\n\n@dataclass\nclass DeploymentSucceededEvent(BaseEvent):\n    \"\"\"Emitted when a deployment completes successfully.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    version: str = \"\"\n    environment: str = \"\"\n    duration_seconds: float = 0.0\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"version\": self.version,\n            \"environment\": self.environment,\n            \"duration_seconds\": self.duration_seconds\n        })\n        return data\n\n\n@dataclass\nclass DeploymentFailedEvent(BaseEvent):\n    \"\"\"Emitted when a deployment fails.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    version: str = \"\"\n    environment: str = \"\"\n    error_message: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"version\": self.version,\n            \"environment\": self.environment,\n            \"error_message\": self.error_message\n        })\n        return data\n\n\n@dataclass\nclass CriticalPerformanceDegradationDetectedEvent(BaseEvent):\n    \"\"\"Emitted when critical performance degradation is detected after a deployment.\"\"\"\n    deployment_id: str = \"\"\n    service_name: str = \"\"\n    reason: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"deployment_id\": self.deployment_id,\n            \"service_name\": self.service_name,\n            \"reason\": self.reason\n        })\n        return data\n\n\n@dataclass\nclass ConfigurationChangedEvent(BaseEvent):\n    \"\"\"Emitted when configuration is changed.\"\"\"\n    config_key: str = \"\"\n    old_value: Optional[str] = None\n    new_value: Optional[str] = None\n    changed_by: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"config_key\": self.config_key,\n            \"old_value\": self.old_value,\n            \"new_value\": self.new_value,\n            \"changed_by\": self.changed_by\n        })\n        return data\n\n\n@dataclass\nclass SecurityAlertEvent(BaseEvent):\n    \"\"\"Emitted when a security issue is detected.\"\"\"\n    alert_id: str = \"\"\n    severity: str = \"\"\n    description: str = \"\"\n    affected_resource: str = \"\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"alert_id\": self.alert_id,\n            \"severity\": self.severity,\n            \"description\": self.description,\n            \"affected_resource\": self.affected_resource\n        })\n        return data\n\n\n@dataclass\nclass LogAnomalyDetectedEvent(BaseEvent):\n    \"\"\"Emitted when an anomaly is detected in logs.\"\"\"\n    anomaly_id: str = \"\"\n    log_source: str = \"\"\n    pattern: str = \"\"\n    severity: str = \"\"\n    sample_entries: list = field(default_factory=list)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"anomaly_id\": self.anomaly_id,\n            \"log_source\": self.log_source,\n            \"pattern\": self.pattern,\n            \"severity\": self.severity,\n            \"sample_entries\": self.sample_entries\n        })\n        return data\n\n\n@dataclass\nclass PerformanceMetricEvent(BaseEvent):\n    \"\"\"Emitted when performance metrics are collected.\"\"\"\n    metric_name: str = \"\"\n    value: float = 0.0\n    unit: str = \"\"\n    tags: Dict[str, str] = field(default_factory=dict)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        data = super().to_dict()\n        data.update({\n            \"metric_name\": self.metric_name,\n            \"value\": self.value,\n            \"unit\": self.unit,\n            \"tags\": self.tags\n        })\n        return data\n",
            "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py": "import logging\nfrom typing import Dict, Any, Optional, List, Callable\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nimport threading\nimport time\n\nfrom shared.events import (\n    BaseEvent,\n    PerformanceMetricEvent,\n    DeploymentSucceededEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass PerformanceThresholds:\n    \"\"\"Configuration for performance thresholds.\"\"\"\n    p99_latency_ms: float = 500.0\n    error_rate_percent: float = 5.0\n\n\n@dataclass\nclass PostDeploymentMonitoringState:\n    \"\"\"Tracks post-deployment monitoring state for a service.\"\"\"\n    deployment_id: str\n    service_name: str\n    start_time: datetime\n    end_time: datetime\n    is_active: bool = True\n\n\n@dataclass\nclass CurrentMetrics:\n    \"\"\"Current performance metrics for a service.\"\"\"\n    p99_latency_ms: float = 0.0\n    error_rate_percent: float = 0.0\n    request_count: int = 0\n    error_count: int = 0\n    last_updated: datetime = field(default_factory=datetime.utcnow)\n\n\nclass PerfPulseService:\n    \"\"\"Service for monitoring system performance metrics.\"\"\"\n    \n    def __init__(\n        self,\n        event_bus: EventBus,\n        thresholds: Optional[PerformanceThresholds] = None,\n        post_deployment_monitoring_duration_minutes: int = 5\n    ):\n        self.event_bus = event_bus\n        self.thresholds = thresholds or PerformanceThresholds()\n        self.post_deployment_monitoring_duration_minutes = post_deployment_monitoring_duration_minutes\n        \n        # Track post-deployment monitoring states by service name\n        self._monitoring_states: Dict[str, PostDeploymentMonitoringState] = {}\n        self._monitoring_lock = threading.Lock()\n        \n        # Current metrics by service name\n        self._current_metrics: Dict[str, CurrentMetrics] = {}\n        self._metrics_lock = threading.Lock()\n        \n        # Service state\n        self._running = False\n        self._monitor_thread: Optional[threading.Thread] = None\n        \n        # Subscribe to deployment events\n        self.event_bus.subscribe(DeploymentSucceededEvent, self._handle_deployment_succeeded)\n        \n        logger.info(\"PerfPulseService initialized with thresholds: P99 latency=%sms, error rate=%s%%\",\n                    self.thresholds.p99_latency_ms, self.thresholds.error_rate_percent)\n    \n    def start(self):\n        \"\"\"Start the performance monitoring service.\"\"\"\n        self._running = True\n        self._monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)\n        self._monitor_thread.start()\n        logger.info(\"PerfPulseService started\")\n    \n    def stop(self):\n        \"\"\"Stop the performance monitoring service.\"\"\"\n        self._running = False\n        if self._monitor_thread:\n            self._monitor_thread.join(timeout=5)\n        logger.info(\"PerfPulseService stopped\")\n    \n    def _handle_deployment_succeeded(self, event: DeploymentSucceededEvent):\n        \"\"\"Handle a successful deployment event by starting post-deployment monitoring.\"\"\"\n        logger.info(\"Received DeploymentSucceededEvent for service '%s', deployment_id='%s'\",\n                    event.service_name, event.deployment_id)\n        \n        now = datetime.utcnow()\n        monitoring_state = PostDeploymentMonitoringState(\n            deployment_id=event.deployment_id,\n            service_name=event.service_name,\n            start_time=now,\n            end_time=now + timedelta(minutes=self.post_deployment_monitoring_duration_minutes),\n            is_active=True\n        )\n        \n        with self._monitoring_lock:\n            self._monitoring_states[event.service_name] = monitoring_state\n        \n        logger.info(\"Started post-deployment monitoring for service '%s' until %s\",\n                    event.service_name, monitoring_state.end_time.isoformat())\n    \n    def update_metrics(self, service_name: str, p99_latency_ms: float, error_rate_percent: float):\n        \"\"\"Update current metrics for a service.\"\"\"\n        with self._metrics_lock:\n            self._current_metrics[service_name] = CurrentMetrics(\n                p99_latency_ms=p99_latency_ms,\n                error_rate_percent=error_rate_percent,\n                last_updated=datetime.utcnow()\n            )\n        \n        # Check if we need to emit a degradation event\n        self._check_post_deployment_thresholds(service_name)\n    \n    def record_request(self, service_name: str, latency_ms: float, is_error: bool = False):\n        \"\"\"Record a request for metrics calculation.\"\"\"\n        with self._metrics_lock:\n            if service_name not in self._current_metrics:\n                self._current_metrics[service_name] = CurrentMetrics()\n            \n            metrics = self._current_metrics[service_name]\n            metrics.request_count += 1\n            if is_error:\n                metrics.error_count += 1\n            \n            # Update error rate\n            if metrics.request_count > 0:\n                metrics.error_rate_percent = (metrics.error_count / metrics.request_count) * 100\n            \n            # Update P99 latency (simplified - in production would use a proper percentile calculation)\n            # For simplicity, we update if this latency is higher\n            if latency_ms > metrics.p99_latency_ms:\n                metrics.p99_latency_ms = latency_ms\n            \n            metrics.last_updated = datetime.utcnow()\n        \n        # Check thresholds\n        self._check_post_deployment_thresholds(service_name)\n    \n    def _check_post_deployment_thresholds(self, service_name: str):\n        \"\"\"Check if metrics breach thresholds during post-deployment monitoring.\"\"\"\n        with self._monitoring_lock:\n            monitoring_state = self._monitoring_states.get(service_name)\n            if not monitoring_state or not monitoring_state.is_active:\n                return\n            \n            # Check if monitoring period has expired\n            now = datetime.utcnow()\n            if now > monitoring_state.end_time:\n                monitoring_state.is_active = False\n                logger.info(\"Post-deployment monitoring period ended for service '%s'\", service_name)\n                return\n        \n        with self._metrics_lock:\n            metrics = self._current_metrics.get(service_name)\n            if not metrics:\n                return\n        \n        # Check thresholds\n        reasons = []\n        if metrics.p99_latency_ms > self.thresholds.p99_latency_ms:\n            reasons.append(f\"P99 latency {metrics.p99_latency_ms}ms exceeds threshold {self.thresholds.p99_latency_ms}ms\")\n        \n        if metrics.error_rate_percent > self.thresholds.error_rate_percent:\n            reasons.append(f\"Error rate {metrics.error_rate_percent}% exceeds threshold {self.thresholds.error_rate_percent}%\")\n        \n        if reasons:\n            # Stop monitoring and emit degradation event\n            with self._monitoring_lock:\n                monitoring_state = self._monitoring_states.get(service_name)\n                if monitoring_state and monitoring_state.is_active:\n                    monitoring_state.is_active = False\n                    \n                    reason = \"; \".join(reasons)\n                    degradation_event = CriticalPerformanceDegradationDetectedEvent(\n                        deployment_id=monitoring_state.deployment_id,\n                        service_name=service_name,\n                        reason=reason,\n                        source_service=\"perf_pulse\"\n                    )\n                    \n                    logger.warning(\n                        \"Critical performance degradation detected for service '%s' (deployment_id='%s'): %s\",\n                        service_name, monitoring_state.deployment_id, reason\n                    )\n                    \n                    self.event_bus.publish(degradation_event)\n    \n    def _monitoring_loop(self):\n        \"\"\"Background loop for continuous monitoring.\"\"\"\n        while self._running:\n            try:\n                # Clean up expired monitoring states\n                now = datetime.utcnow()\n                with self._monitoring_lock:\n                    for service_name, state in list(self._monitoring_states.items()):\n                        if state.is_active and now > state.end_time:\n                            state.is_active = False\n                            logger.info(\"Post-deployment monitoring period ended for service '%s'\", service_name)\n                \n                time.sleep(1)  # Check every second\n            except Exception as e:\n                logger.error(\"Error in monitoring loop: %s\", e)\n    \n    def get_monitoring_state(self, service_name: str) -> Optional[PostDeploymentMonitoringState]:\n        \"\"\"Get the current monitoring state for a service.\"\"\"\n        with self._monitoring_lock:\n            return self._monitoring_states.get(service_name)\n    \n    def get_current_metrics(self, service_name: str) -> Optional[CurrentMetrics]:\n        \"\"\"Get current metrics for a service.\"\"\"\n        with self._metrics_lock:\n            return self._current_metrics.get(service_name)\n    \n    def collect_metrics(self) -> Dict[str, Any]:\n        \"\"\"Collect and return all current metrics.\"\"\"\n        with self._metrics_lock:\n            return {\n                service: {\n                    \"p99_latency_ms\": m.p99_latency_ms,\n                    \"error_rate_percent\": m.error_rate_percent,\n                    \"request_count\": m.request_count,\n                    \"error_count\": m.error_count,\n                    \"last_updated\": m.last_updated.isoformat()\n                }\n                for service, m in self._current_metrics.items()\n            }\n    \n    def emit_metric_event(self, metric_name: str, value: float, unit: str, tags: Optional[Dict[str, str]] = None):\n        \"\"\"Emit a performance metric event.\"\"\"\n        event = PerformanceMetricEvent(\n            metric_name=metric_name,\n            value=value,\n            unit=unit,\n            tags=tags or {},\n            source_service=\"perf_pulse\"\n        )\n        self.event_bus.publish(event)\n        logger.debug(\"Emitted metric event: %s=%s%s\", metric_name, value, unit)\n",
            "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py": "import logging\nfrom typing import Dict, Any, Optional, List\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\nfrom shared.events import (\n    BaseEvent,\n    DeploymentStartedEvent,\n    DeploymentSucceededEvent,\n    DeploymentFailedEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\nlogger = logging.getLogger(__name__)\n\n\nclass DeploymentStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    SUCCEEDED = \"succeeded\"\n    FAILED = \"failed\"\n    ROLLED_BACK = \"rolled_back\"\n\n\n@dataclass\nclass Deployment:\n    \"\"\"Represents a deployment.\"\"\"\n    deployment_id: str\n    service_name: str\n    version: str\n    environment: str\n    status: DeploymentStatus\n    previous_version: Optional[str] = None\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n    rollback_reason: Optional[str] = None\n\n\nclass DeployFlowService:\n    \"\"\"Service for managing deployments.\"\"\"\n    \n    def __init__(self, event_bus: EventBus):\n        self.event_bus = event_bus\n        self._deployments: Dict[str, Deployment] = {}\n        self._service_versions: Dict[str, str] = {}  # Track current version per service\n        \n        # Subscribe to performance degradation events for auto-rollback\n        self.event_bus.subscribe(\n            CriticalPerformanceDegradationDetectedEvent,\n            self._handle_performance_degradation\n        )\n        \n        logger.info(\"DeployFlowService initialized\")\n    \n    def create_deployment(\n        self,\n        service_name: str,\n        version: str,\n        environment: str = \"production\"\n    ) -> Deployment:\n        \"\"\"Create a new deployment.\"\"\"\n        deployment_id = str(uuid.uuid4())\n        previous_version = self._service_versions.get(service_name)\n        \n        deployment = Deployment(\n            deployment_id=deployment_id,\n            service_name=service_name,\n            version=version,\n            environment=environment,\n            status=DeploymentStatus.PENDING,\n            previous_version=previous_version\n        )\n        \n        self._deployments[deployment_id] = deployment\n        logger.info(\"Created deployment %s for service '%s' version '%s'\",\n                    deployment_id, service_name, version)\n        \n        return deployment\n    \n    def start_deployment(self, deployment_id: str) -> Deployment:\n        \"\"\"Start a deployment.\"\"\"\n        deployment = self._deployments.get(deployment_id)\n        if not deployment:\n            raise ValueError(f\"Deployment {deployment_id} not found\")\n        \n        if deployment.status != DeploymentStatus.PENDING:\n            raise ValueError(f\"Deployment {deployment_id} is not in pending state\")\n        \n        deployment.status = DeploymentStatus.IN_PROGRESS\n        deployment.started_at = datetime.utcnow()\n        \n        # Emit deployment started event\n        event = DeploymentStartedEvent(\n            deployment_id=deployment_id,\n            service_name=deployment.service_name,\n            version=deployment.version,\n            environment=deployment.environment,\n            source_service=\"deploy_flow\"\n        )\n        self.event_bus.publish(event)\n        \n        logger.info(\"Started deployment %s\", deployment_id)\n        return deployment\n    \n    def complete_deployment(self, deployment_id: str, success: bool = True, error_message: Optional[str] = None) -> Deployment:\n        \"\"\"Complete a deployment.\"\"\"\n        deployment = self._deployments.get(deployment_id)\n        if not deployment:\n            raise ValueError(f\"Deployment {deployment_id} not found\")\n        \n        if deployment.status != DeploymentStatus.IN_PROGRESS:\n            raise ValueError(f\"Deployment {deployment_id} is not in progress\")\n        \n        deployment.completed_at = datetime.utcnow()\n        \n        if success:\n            deployment.status = DeploymentStatus.SUCCEEDED\n            # Update the current version for the service\n            self._service_versions[deployment.service_name] = deployment.version\n            \n            # Emit deployment succeeded event\n            duration = (deployment.completed_at - deployment.started_at).total_seconds() if deployment.started_at else 0\n            event = DeploymentSucceededEvent(\n                deployment_id=deployment_id,\n                service_name=deployment.service_name,\n                version=deployment.version,\n                environment=deployment.environment,\n                duration_seconds=duration,\n                source_service=\"deploy_flow\"\n            )\n            self.event_bus.publish(event)\n            logger.info(\"Deployment %s succeeded\", deployment_id)\n        else:\n            deployment.status = DeploymentStatus.FAILED\n            deployment.error_message = error_message\n            \n            # Emit deployment failed event\n            event = DeploymentFailedEvent(\n                deployment_id=deployment_id,\n                service_name=deployment.service_name,\n                version=deployment.version,\n                environment=deployment.environment,\n                error_message=error_message or \"Unknown error\",\n                source_service=\"deploy_flow\"\n            )\n            self.event_bus.publish(event)\n            logger.error(\"Deployment %s failed: %s\", deployment_id, error_message)\n        \n        return deployment\n    \n    def rollback_deployment(self, deployment_id: str, reason: Optional[str] = None) -> Deployment:\n        \"\"\"Rollback a deployment to the previous version.\"\"\"\n        deployment = self._deployments.get(deployment_id)\n        if not deployment:\n            raise ValueError(f\"Deployment {deployment_id} not found\")\n        \n        if deployment.status not in [DeploymentStatus.SUCCEEDED, DeploymentStatus.IN_PROGRESS]:\n            raise ValueError(f\"Deployment {deployment_id} cannot be rolled back from state {deployment.status}\")\n        \n        if not deployment.previous_version:\n            raise ValueError(f\"No previous version available for rollback of deployment {deployment_id}\")\n        \n        logger.warning(\"Rolling back deployment %s for service '%s' from version '%s' to '%s'. Reason: %s\",\n                       deployment_id, deployment.service_name, deployment.version,\n                       deployment.previous_version, reason or \"Not specified\")\n        \n        # Update the service version back to previous\n        self._service_versions[deployment.service_name] = deployment.previous_version\n        \n        deployment.status = DeploymentStatus.ROLLED_BACK\n        deployment.rollback_reason = reason\n        deployment.completed_at = datetime.utcnow()\n        \n        logger.info(\"Deployment %s rolled back successfully\", deployment_id)\n        return deployment\n    \n    def _handle_performance_degradation(self, event: CriticalPerformanceDegradationDetectedEvent):\n        \"\"\"Handle critical performance degradation by triggering rollback.\"\"\"\n        logger.warning(\n            \"Received CriticalPerformanceDegradationDetectedEvent for deployment '%s' service '%s': %s\",\n            event.deployment_id, event.service_name, event.reason\n        )\n        \n        try:\n            deployment = self._deployments.get(event.deployment_id)\n            if not deployment:\n                logger.error(\"Cannot rollback: deployment %s not found\", event.deployment_id)\n                return\n            \n            if deployment.status == DeploymentStatus.ROLLED_BACK:\n                logger.info(\"Deployment %s already rolled back, ignoring\", event.deployment_id)\n                return\n            \n            self.rollback_deployment(\n                deployment_id=event.deployment_id,\n                reason=f\"Auto-rollback due to performance degradation: {event.reason}\"\n            )\n            \n        except Exception as e:\n            logger.error(\"Failed to rollback deployment %s: %s\", event.deployment_id, e)\n    \n    def get_deployment(self, deployment_id: str) -> Optional[Deployment]:\n        \"\"\"Get a deployment by ID.\"\"\"\n        return self._deployments.get(deployment_id)\n    \n    def get_deployments_for_service(self, service_name: str) -> List[Deployment]:\n        \"\"\"Get all deployments for a service.\"\"\"\n        return [\n            d for d in self._deployments.values()\n            if d.service_name == service_name\n        ]\n    \n    def get_current_version(self, service_name: str) -> Optional[str]:\n        \"\"\"Get the current deployed version for a service.\"\"\"\n        return self._service_versions.get(service_name)\n",
            "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py": "import unittest\nfrom unittest.mock import Mock, MagicMock, patch\nfrom datetime import datetime, timedelta\nimport time\n\nfrom services.perf_pulse.service import (\n    PerfPulseService,\n    PerformanceThresholds,\n    PostDeploymentMonitoringState,\n    CurrentMetrics\n)\nfrom shared.events import (\n    DeploymentSucceededEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\n\nclass TestPerfPulseService(unittest.TestCase):\n    \"\"\"Tests for PerfPulseService.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.event_bus = Mock(spec=EventBus)\n        self.event_bus.subscribe = Mock()\n        self.event_bus.publish = Mock()\n        \n        self.service = PerfPulseService(\n            event_bus=self.event_bus,\n            thresholds=PerformanceThresholds(\n                p99_latency_ms=500.0,\n                error_rate_percent=5.0\n            ),\n            post_deployment_monitoring_duration_minutes=5\n        )\n    \n    def tearDown(self):\n        \"\"\"Clean up after tests.\"\"\"\n        if self.service._running:\n            self.service.stop()\n    \n    def test_subscribes_to_deployment_succeeded_event(self):\n        \"\"\"Test that service subscribes to DeploymentSucceededEvent.\"\"\"\n        # Check that subscribe was called with DeploymentSucceededEvent\n        subscribe_calls = self.event_bus.subscribe.call_args_list\n        event_types = [call[0][0] for call in subscribe_calls]\n        self.assertIn(DeploymentSucceededEvent, event_types)\n    \n    def test_handle_deployment_succeeded_starts_monitoring(self):\n        \"\"\"Test that receiving DeploymentSucceededEvent starts post-deployment monitoring.\"\"\"\n        event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-123\",\n            service_name=\"test-service\",\n            version=\"1.0.0\",\n            environment=\"production\",\n            duration_seconds=60.0,\n            source_service=\"deploy_flow\"\n        )\n        \n        # Simulate receiving the event\n        self.service._handle_deployment_succeeded(event)\n        \n        # Check that monitoring state was created\n        state = self.service.get_monitoring_state(\"test-service\")\n        self.assertIsNotNone(state)\n        self.assertEqual(state.deployment_id, \"deploy-123\")\n        self.assertEqual(state.service_name, \"test-service\")\n        self.assertTrue(state.is_active)\n    \n    def test_emits_degradation_event_on_high_latency(self):\n        \"\"\"Test that CriticalPerformanceDegradationDetectedEvent is emitted when P99 latency exceeds threshold.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-456\",\n            service_name=\"latency-test-service\",\n            version=\"2.0.0\",\n            environment=\"production\",\n            duration_seconds=30.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Update metrics with high latency (above 500ms threshold)\n        self.service.update_metrics(\n            service_name=\"latency-test-service\",\n            p99_latency_ms=600.0,  # Above threshold\n            error_rate_percent=1.0  # Below threshold\n        )\n        \n        # Verify degradation event was published\n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, CriticalPerformanceDegradationDetectedEvent)\n        self.assertEqual(published_event.deployment_id, \"deploy-456\")\n        self.assertEqual(published_event.service_name, \"latency-test-service\")\n        self.assertIn(\"P99 latency\", published_event.reason)\n        self.assertIn(\"600.0ms\", published_event.reason)\n    \n    def test_emits_degradation_event_on_high_error_rate(self):\n        \"\"\"Test that CriticalPerformanceDegradationDetectedEvent is emitted when error rate exceeds threshold.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-789\",\n            service_name=\"error-test-service\",\n            version=\"3.0.0\",\n            environment=\"production\",\n            duration_seconds=45.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Update metrics with high error rate (above 5% threshold)\n        self.service.update_metrics(\n            service_name=\"error-test-service\",\n            p99_latency_ms=200.0,  # Below threshold\n            error_rate_percent=10.0  # Above threshold\n        )\n        \n        # Verify degradation event was published\n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, CriticalPerformanceDegradationDetectedEvent)\n        self.assertEqual(published_event.deployment_id, \"deploy-789\")\n        self.assertEqual(published_event.service_name, \"error-test-service\")\n        self.assertIn(\"Error rate\", published_event.reason)\n        self.assertIn(\"10.0%\", published_event.reason)\n    \n    def test_emits_degradation_event_with_both_thresholds_breached(self):\n        \"\"\"Test that reason includes both metrics when both thresholds are breached.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-both\",\n            service_name=\"both-test-service\",\n            version=\"4.0.0\",\n            environment=\"production\",\n            duration_seconds=20.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Update metrics with both thresholds breached\n        self.service.update_metrics(\n            service_name=\"both-test-service\",\n            p99_latency_ms=750.0,  # Above threshold\n            error_rate_percent=8.0  # Above threshold\n        )\n        \n        # Verify degradation event contains both reasons\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIn(\"P99 latency\", published_event.reason)\n        self.assertIn(\"Error rate\", published_event.reason)\n    \n    def test_no_event_when_metrics_below_thresholds(self):\n        \"\"\"Test that no degradation event is emitted when metrics are below thresholds.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-ok\",\n            service_name=\"ok-service\",\n            version=\"5.0.0\",\n            environment=\"production\",\n            duration_seconds=15.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Reset mock to clear the deployment event subscription call\n        self.event_bus.publish.reset_mock()\n        \n        # Update metrics below thresholds\n        self.service.update_metrics(\n            service_name=\"ok-service\",\n            p99_latency_ms=300.0,  # Below threshold\n            error_rate_percent=2.0  # Below threshold\n        )\n        \n        # Verify no degradation event was published\n        self.event_bus.publish.assert_not_called()\n    \n    def test_no_event_when_not_in_monitoring_period(self):\n        \"\"\"Test that no degradation event is emitted when not in post-deployment monitoring.\"\"\"\n        # Don't start monitoring - just update metrics\n        self.event_bus.publish.reset_mock()\n        \n        self.service.update_metrics(\n            service_name=\"no-monitoring-service\",\n            p99_latency_ms=1000.0,  # Way above threshold\n            error_rate_percent=50.0  # Way above threshold\n        )\n        \n        # Verify no degradation event was published\n        self.event_bus.publish.assert_not_called()\n    \n    def test_monitoring_stops_after_degradation_detected(self):\n        \"\"\"Test that monitoring stops after degradation is detected.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-stop\",\n            service_name=\"stop-test-service\",\n            version=\"6.0.0\",\n            environment=\"production\",\n            duration_seconds=10.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Trigger degradation\n        self.service.update_metrics(\n            service_name=\"stop-test-service\",\n            p99_latency_ms=600.0,\n            error_rate_percent=1.0\n        )\n        \n        # Verify monitoring is no longer active\n        state = self.service.get_monitoring_state(\"stop-test-service\")\n        self.assertFalse(state.is_active)\n        \n        # Reset mock and try to trigger again\n        self.event_bus.publish.reset_mock()\n        self.service.update_metrics(\n            service_name=\"stop-test-service\",\n            p99_latency_ms=800.0,\n            error_rate_percent=20.0\n        )\n        \n        # Verify no additional event was published\n        self.event_bus.publish.assert_not_called()\n    \n    def test_record_request_updates_metrics(self):\n        \"\"\"Test that record_request properly updates metrics.\"\"\"\n        # Start monitoring\n        deployment_event = DeploymentSucceededEvent(\n            deployment_id=\"deploy-record\",\n            service_name=\"record-service\",\n            version=\"7.0.0\",\n            environment=\"production\",\n            duration_seconds=5.0,\n            source_service=\"deploy_flow\"\n        )\n        self.service._handle_deployment_succeeded(deployment_event)\n        \n        # Record some requests\n        self.service.record_request(\"record-service\", latency_ms=100.0, is_error=False)\n        self.service.record_request(\"record-service\", latency_ms=200.0, is_error=False)\n        self.service.record_request(\"record-service\", latency_ms=150.0, is_error=True)\n        \n        # Check metrics\n        metrics = self.service.get_current_metrics(\"record-service\")\n        self.assertIsNotNone(metrics)\n        self.assertEqual(metrics.request_count, 3)\n        self.assertEqual(metrics.error_count, 1)\n        self.assertAlmostEqual(metrics.error_rate_percent, 33.33, places=1)\n        self.assertEqual(metrics.p99_latency_ms, 200.0)\n    \n    def test_collect_metrics_returns_all_services(self):\n        \"\"\"Test that collect_metrics returns metrics for all services.\"\"\"\n        self.service.update_metrics(\"service-a\", 100.0, 1.0)\n        self.service.update_metrics(\"service-b\", 200.0, 2.0)\n        \n        all_metrics = self.service.collect_metrics()\n        \n        self.assertIn(\"service-a\", all_metrics)\n        self.assertIn(\"service-b\", all_metrics)\n        self.assertEqual(all_metrics[\"service-a\"][\"p99_latency_ms\"], 100.0)\n        self.assertEqual(all_metrics[\"service-b\"][\"p99_latency_ms\"], 200.0)\n\n\nclass TestPerformanceThresholds(unittest.TestCase):\n    \"\"\"Tests for PerformanceThresholds.\"\"\"\n    \n    def test_default_thresholds(self):\n        \"\"\"Test default threshold values.\"\"\"\n        thresholds = PerformanceThresholds()\n        self.assertEqual(thresholds.p99_latency_ms, 500.0)\n        self.assertEqual(thresholds.error_rate_percent, 5.0)\n    \n    def test_custom_thresholds(self):\n        \"\"\"Test custom threshold values.\"\"\"\n        thresholds = PerformanceThresholds(\n            p99_latency_ms=1000.0,\n            error_rate_percent=10.0\n        )\n        self.assertEqual(thresholds.p99_latency_ms, 1000.0)\n        self.assertEqual(thresholds.error_rate_percent, 10.0)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
            "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py": "import unittest\nfrom unittest.mock import Mock, MagicMock, patch, call\nfrom datetime import datetime\n\nfrom services.deploy_flow.service import (\n    DeployFlowService,\n    Deployment,\n    DeploymentStatus\n)\nfrom shared.events import (\n    DeploymentStartedEvent,\n    DeploymentSucceededEvent,\n    DeploymentFailedEvent,\n    CriticalPerformanceDegradationDetectedEvent\n)\nfrom shared.messaging import EventBus\n\n\nclass TestDeployFlowService(unittest.TestCase):\n    \"\"\"Tests for DeployFlowService.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.event_bus = Mock(spec=EventBus)\n        self.event_bus.subscribe = Mock()\n        self.event_bus.publish = Mock()\n        \n        self.service = DeployFlowService(event_bus=self.event_bus)\n    \n    def test_subscribes_to_performance_degradation_event(self):\n        \"\"\"Test that service subscribes to CriticalPerformanceDegradationDetectedEvent.\"\"\"\n        subscribe_calls = self.event_bus.subscribe.call_args_list\n        event_types = [call[0][0] for call in subscribe_calls]\n        self.assertIn(CriticalPerformanceDegradationDetectedEvent, event_types)\n    \n    def test_create_deployment(self):\n        \"\"\"Test creating a new deployment.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\",\n            environment=\"production\"\n        )\n        \n        self.assertIsNotNone(deployment.deployment_id)\n        self.assertEqual(deployment.service_name, \"test-service\")\n        self.assertEqual(deployment.version, \"1.0.0\")\n        self.assertEqual(deployment.environment, \"production\")\n        self.assertEqual(deployment.status, DeploymentStatus.PENDING)\n    \n    def test_start_deployment_emits_event(self):\n        \"\"\"Test that starting a deployment emits DeploymentStartedEvent.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        \n        self.service.start_deployment(deployment.deployment_id)\n        \n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, DeploymentStartedEvent)\n        self.assertEqual(published_event.deployment_id, deployment.deployment_id)\n    \n    def test_complete_deployment_success_emits_event(self):\n        \"\"\"Test that completing a deployment successfully emits DeploymentSucceededEvent.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.event_bus.publish.reset_mock()\n        \n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, DeploymentSucceededEvent)\n        self.assertEqual(published_event.deployment_id, deployment.deployment_id)\n    \n    def test_complete_deployment_failure_emits_event(self):\n        \"\"\"Test that a failed deployment emits DeploymentFailedEvent.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.event_bus.publish.reset_mock()\n        \n        self.service.complete_deployment(\n            deployment.deployment_id,\n            success=False,\n            error_message=\"Deployment failed\"\n        )\n        \n        self.event_bus.publish.assert_called()\n        published_event = self.event_bus.publish.call_args[0][0]\n        self.assertIsInstance(published_event, DeploymentFailedEvent)\n        self.assertEqual(published_event.error_message, \"Deployment failed\")\n    \n    def test_rollback_deployment(self):\n        \"\"\"Test rolling back a deployment.\"\"\"\n        # First deployment\n        self.service._service_versions[\"test-service\"] = \"0.9.0\"\n        \n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        # Rollback\n        rolled_back = self.service.rollback_deployment(\n            deployment.deployment_id,\n            reason=\"Performance issues\"\n        )\n        \n        self.assertEqual(rolled_back.status, DeploymentStatus.ROLLED_BACK)\n        self.assertEqual(rolled_back.rollback_reason, \"Performance issues\")\n        self.assertEqual(self.service.get_current_version(\"test-service\"), \"0.9.0\")\n    \n    def test_handle_performance_degradation_triggers_rollback(self):\n        \"\"\"Test that receiving CriticalPerformanceDegradationDetectedEvent triggers rollback.\"\"\"\n        # Set up a previous version\n        self.service._service_versions[\"degraded-service\"] = \"0.8.0\"\n        \n        # Create and complete a deployment\n        deployment = self.service.create_deployment(\n            service_name=\"degraded-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        # Verify deployment succeeded\n        self.assertEqual(deployment.status, DeploymentStatus.SUCCEEDED)\n        self.assertEqual(self.service.get_current_version(\"degraded-service\"), \"1.0.0\")\n        \n        # Simulate receiving performance degradation event\n        degradation_event = CriticalPerformanceDegradationDetectedEvent(\n            deployment_id=deployment.deployment_id,\n            service_name=\"degraded-service\",\n            reason=\"P99 latency 600.0ms exceeds threshold 500.0ms\",\n            source_service=\"perf_pulse\"\n        )\n        \n        self.service._handle_performance_degradation(degradation_event)\n        \n        # Verify rollback occurred\n        updated_deployment = self.service.get_deployment(deployment.deployment_id)\n        self.assertEqual(updated_deployment.status, DeploymentStatus.ROLLED_BACK)\n        self.assertIn(\"Auto-rollback\", updated_deployment.rollback_reason)\n        self.assertIn(\"P99 latency\", updated_deployment.rollback_reason)\n        self.assertEqual(self.service.get_current_version(\"degraded-service\"), \"0.8.0\")\n    \n    def test_handle_performance_degradation_ignores_unknown_deployment(self):\n        \"\"\"Test that unknown deployment IDs are handled gracefully.\"\"\"\n        degradation_event = CriticalPerformanceDegradationDetectedEvent(\n            deployment_id=\"unknown-deployment-id\",\n            service_name=\"unknown-service\",\n            reason=\"Some reason\",\n            source_service=\"perf_pulse\"\n        )\n        \n        # Should not raise an exception\n        self.service._handle_performance_degradation(degradation_event)\n    \n    def test_handle_performance_degradation_ignores_already_rolled_back(self):\n        \"\"\"Test that already rolled back deployments are ignored.\"\"\"\n        # Set up a previous version\n        self.service._service_versions[\"test-service\"] = \"0.7.0\"\n        \n        # Create, complete, and rollback a deployment\n        deployment = self.service.create_deployment(\n            service_name=\"test-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        self.service.rollback_deployment(deployment.deployment_id, reason=\"Manual rollback\")\n        \n        # Try to trigger another rollback via event\n        degradation_event = CriticalPerformanceDegradationDetectedEvent(\n            deployment_id=deployment.deployment_id,\n            service_name=\"test-service\",\n            reason=\"Some reason\",\n            source_service=\"perf_pulse\"\n        )\n        \n        # Should not raise an exception and should remain in rolled back state\n        self.service._handle_performance_degradation(degradation_event)\n        self.assertEqual(deployment.status, DeploymentStatus.ROLLED_BACK)\n        self.assertEqual(deployment.rollback_reason, \"Manual rollback\")  # Original reason preserved\n    \n    def test_rollback_requires_previous_version(self):\n        \"\"\"Test that rollback fails if no previous version exists.\"\"\"\n        deployment = self.service.create_deployment(\n            service_name=\"new-service\",\n            version=\"1.0.0\"\n        )\n        self.service.start_deployment(deployment.deployment_id)\n        self.service.complete_deployment(deployment.deployment_id, success=True)\n        \n        with self.assertRaises(ValueError) as context:\n            self.service.rollback_deployment(deployment.deployment_id)\n        \n        self.assertIn(\"No previous version\", str(context.exception))\n    \n    def test_get_deployments_for_service(self):\n        \"\"\"Test retrieving all deployments for a service.\"\"\"\n        self.service.create_deployment(\"service-a\", \"1.0.0\")\n        self.service.create_deployment(\"service-a\", \"1.1.0\")\n        self.service.create_deployment(\"service-b\", \"2.0.0\")\n        \n        deployments_a = self.service.get_deployments_for_service(\"service-a\")\n        deployments_b = self.service.get_deployments_for_service(\"service-b\")\n        \n        self.assertEqual(len(deployments_a), 2)\n        self.assertEqual(len(deployments_b), 1)\n    \n    def test_deployment_tracks_previous_version(self):\n        \"\"\"Test that deployments track the previous version.\"\"\"\n        # Set initial version\n        self.service._service_versions[\"versioned-service\"] = \"0.5.0\"\n        \n        deployment = self.service.create_deployment(\n            service_name=\"versioned-service\",\n            version=\"1.0.0\"\n        )\n        \n        self.assertEqual(deployment.previous_version, \"0.5.0\")\n\n\nclass TestDeploymentStatus(unittest.TestCase):\n    \"\"\"Tests for DeploymentStatus enum.\"\"\"\n    \n    def test_status_values(self):\n        \"\"\"Test that all expected status values exist.\"\"\"\n        self.assertEqual(DeploymentStatus.PENDING.value, \"pending\")\n        self.assertEqual(DeploymentStatus.IN_PROGRESS.value, \"in_progress\")\n        self.assertEqual(DeploymentStatus.SUCCEEDED.value, \"succeeded\")\n        self.assertEqual(DeploymentStatus.FAILED.value, \"failed\")\n        self.assertEqual(DeploymentStatus.ROLLED_BACK.value, \"rolled_back\")\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
            "PulseLink_SocialOps_Monitor/shared/messaging.py": "import logging\nfrom typing import Dict, List, Callable, Type, Any\nfrom collections import defaultdict\nimport threading\n\nfrom shared.events import BaseEvent\n\nlogger = logging.getLogger(__name__)\n\n\nclass EventBus:\n    \"\"\"Simple event bus for publishing and subscribing to events.\"\"\"\n    \n    def __init__(self):\n        self._subscribers: Dict[Type[BaseEvent], List[Callable]] = defaultdict(list)\n        self._lock = threading.Lock()\n    \n    def subscribe(self, event_type: Type[BaseEvent], handler: Callable[[BaseEvent], None]):\n        \"\"\"Subscribe a handler to an event type.\"\"\"\n        with self._lock:\n            self._subscribers[event_type].append(handler)\n            logger.debug(\"Subscribed handler %s to event type %s\",\n                        handler.__name__ if hasattr(handler, '__name__') else str(handler),\n                        event_type.__name__)\n    \n    def unsubscribe(self, event_type: Type[BaseEvent], handler: Callable[[BaseEvent], None]):\n        \"\"\"Unsubscribe a handler from an event type.\"\"\"\n        with self._lock:\n            if handler in self._subscribers[event_type]:\n                self._subscribers[event_type].remove(handler)\n                logger.debug(\"Unsubscribed handler from event type %s\", event_type.__name__)\n    \n    def publish(self, event: BaseEvent):\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        event_type = type(event)\n        \n        with self._lock:\n            handlers = list(self._subscribers[event_type])\n        \n        logger.debug(\"Publishing event %s to %d handlers\", event_type.__name__, len(handlers))\n        \n        for handler in handlers:\n            try:\n                handler(event)\n            except Exception as e:\n                logger.error(\"Error in event handler for %s: %s\", event_type.__name__, e)\n    \n    def get_subscriber_count(self, event_type: Type[BaseEvent]) -> int:\n        \"\"\"Get the number of subscribers for an event type.\"\"\"\n        with self._lock:\n            return len(self._subscribers[event_type])\n    \n    def clear_subscribers(self, event_type: Type[BaseEvent] = None):\n        \"\"\"Clear subscribers for a specific event type or all event types.\"\"\"\n        with self._lock:\n            if event_type:\n                self._subscribers[event_type] = []\n            else:\n                self._subscribers.clear()\n\n\n# Global event bus instance\n_global_event_bus: EventBus = None\n\n\ndef get_event_bus() -> EventBus:\n    \"\"\"Get the global event bus instance.\"\"\"\n    global _global_event_bus\n    if _global_event_bus is None:\n        _global_event_bus = EventBus()\n    return _global_event_bus\n\n\ndef reset_event_bus():\n    \"\"\"Reset the global event bus (mainly for testing).\"\"\"\n    global _global_event_bus\n    _global_event_bus = None\n"
          },
          "generated_files": [
            "PulseLink_SocialOps_Monitor/shared/events.py",
            "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py",
            "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py",
            "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py",
            "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py",
            "PulseLink_SocialOps_Monitor/shared/messaging.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8383903830480848,
                "dependency_traversal_accuracy": 0.7570618377212007,
                "cross_file_reasoning_depth": 0.29680555555555554,
                "system_thinking_score": 0.3347075241269396,
                "robustness_score": 0.09023154499723206,
                "comprehensiveness_score": 0.6576790743013937,
                "innovation_score": 0.20110702938840352,
                "solution_elegance_score": 0.8675695487074062
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.1047987978810106,
                "dependency_traversal_weighted": 0.09463272971515009,
                "cross_file_reasoning_weighted": 0.03710069444444444,
                "system_thinking_weighted": 0.04183844051586745,
                "robustness_weighted": 0.011278943124654007,
                "comprehensiveness_weighted": 0.08220988428767421,
                "innovation_weighted": 0.02513837867355044,
                "solution_elegance_weighted": 0.10844619358842578
              },
              "total_software_engineering_score": 0.505444062230777
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.4018986225128174,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "PulseLink_SocialOps_Monitor/shared/events.py",
                  "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py",
                  "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py",
                  "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py",
                  "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py",
                  "PulseLink_SocialOps_Monitor/shared/messaging.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 6,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 6 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.48571197411003236,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.48571197411003236,
                "idc_weight": 0.2,
                "total_functional_score": 0.6771423948220066
              }
            },
            "code_quality_details": {
              "files_analyzed": 6,
              "quality_checks": {
                "PulseLink_SocialOps_Monitor/shared/events.py": {
                  "line_count": 177,
                  "non_empty_lines": 149,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 9,
                  "class_count": 10,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "PulseLink_SocialOps_Monitor/services/perf_pulse/service.py": {
                  "line_count": 248,
                  "non_empty_lines": 202,
                  "comment_lines": 13,
                  "comment_ratio": 0.06435643564356436,
                  "function_count": 12,
                  "class_count": 4,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "PulseLink_SocialOps_Monitor/services/deploy_flow/service.py": {
                  "line_count": 220,
                  "non_empty_lines": 177,
                  "comment_lines": 6,
                  "comment_ratio": 0.03389830508474576,
                  "function_count": 9,
                  "class_count": 3,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "PulseLink_SocialOps_Monitor/services/perf_pulse/tests/test_service.py": {
                  "line_count": 288,
                  "non_empty_lines": 244,
                  "comment_lines": 26,
                  "comment_ratio": 0.10655737704918032,
                  "function_count": 14,
                  "class_count": 2,
                  "import_count": 12,
                  "quality_score": 0.9999999999999999
                },
                "PulseLink_SocialOps_Monitor/services/deploy_flow/tests/test_service.py": {
                  "line_count": 248,
                  "non_empty_lines": 200,
                  "comment_lines": 13,
                  "comment_ratio": 0.065,
                  "function_count": 14,
                  "class_count": 2,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "PulseLink_SocialOps_Monitor/shared/messaging.py": {
                  "line_count": 78,
                  "non_empty_lines": 58,
                  "comment_lines": 1,
                  "comment_ratio": 0.017241379310344827,
                  "function_count": 8,
                  "class_count": 5,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.8233333333333334,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8083333333333333,
                "multi_session_memory_retention": 0.7791666666666666
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4041666666666667,
                "multi_session_memory_retention_weighted": 0.3895833333333333
              },
              "total_longcontext_utilization_score": 0.79375
            }
          },
          "timestamp": "2026-01-14T20:56:35.264532"
        }
      }
    },
    "python_system_automation_medium_098_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_system_automation_medium_098_feature_implementation_expert_01",
          "scenario_title": "Implement Canary Deployment Strategy with Automated Rollback",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5375254033962729,
          "functional_correctness_score": 0.40073200210194426,
          "code_quality_score": 0.7809090909090908,
          "longcontext_utilization_score": 0.8657697876447877,
          "total_score": 2.889942794676947,
          "generation_time": 226.27062439918518,
          "code_files_generated": 11,
          "total_lines_generated": 2172,
          "parsing_success": true,
          "solution_code": {
            "vitalops_orchestrator/config.yaml": "# VitalOps Orchestrator Configuration\n\nserver:\n  host: \"0.0.0.0\"\n  port: 8080\n  debug: false\n\nlogging:\n  level: \"INFO\"\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  file: \"logs/vitalops.log\"\n\nmetrics:\n  collection_interval: 60\n  retention_days: 30\n  enabled_collectors:\n    - cpu\n    - memory\n    - disk\n    - network\n\nnotifications:\n  enabled: true\n  channels:\n    - email\n    - slack\n  email:\n    smtp_host: \"smtp.example.com\"\n    smtp_port: 587\n    from_address: \"alerts@vitalops.io\"\n  slack:\n    webhook_url: \"https://hooks.slack.com/services/xxx\"\n\npolicy_engine:\n  evaluation_interval: 30\n  max_retries: 3\n\ndeployment:\n  default_timeout: 600\n  max_concurrent: 5\n  rollback_on_failure: true\n\ndeployment_strategies:\n  canary:\n    subset_percentage: 10\n    bake_time_seconds: 300\n    health_thresholds:\n      max_cpu_usage: 80.0\n      max_error_rate: 5.0\n      max_memory_usage: 85.0\n      min_success_rate: 95.0\n\nrecovery:\n  auto_recovery: true\n  max_recovery_attempts: 3\n  recovery_cooldown: 300\n",
            "vitalops_orchestrator/vitalops/models/domain.py": "\"\"\"Domain models for VitalOps Orchestrator.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\nimport uuid\n\n\nclass NodeStatus(Enum):\n    \"\"\"Status of a managed node.\"\"\"\n    HEALTHY = \"healthy\"\n    UNHEALTHY = \"unhealthy\"\n    DEGRADED = \"degraded\"\n    OFFLINE = \"offline\"\n    MAINTENANCE = \"maintenance\"\n\n\nclass DeploymentStatus(Enum):\n    \"\"\"Status of a deployment job.\"\"\"\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n    # Canary-specific states\n    CANARY_DEPLOY = \"canary_deploy\"\n    CANARY_MONITORING = \"canary_monitoring\"\n    CANARY_FAILED = \"canary_failed\"\n    PROMOTING = \"promoting\"\n    ROLLED_BACK = \"rolled_back\"\n\n\nclass DeploymentStrategy(Enum):\n    \"\"\"Deployment strategy types.\"\"\"\n    STANDARD = \"standard\"\n    CANARY = \"canary\"\n\n\nclass AlertSeverity(Enum):\n    \"\"\"Severity levels for alerts.\"\"\"\n    INFO = \"info\"\n    WARNING = \"warning\"\n    ERROR = \"error\"\n    CRITICAL = \"critical\"\n\n\n@dataclass\nclass Node:\n    \"\"\"Represents a managed node in the infrastructure.\"\"\"\n    id: str\n    hostname: str\n    ip_address: str\n    status: NodeStatus = NodeStatus.HEALTHY\n    labels: Dict[str, str] = field(default_factory=dict)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    last_heartbeat: Optional[datetime] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n    def __post_init__(self):\n        if not self.id:\n            self.id = str(uuid.uuid4())\n\n\n@dataclass\nclass Application:\n    \"\"\"Represents a deployable application.\"\"\"\n    id: str\n    name: str\n    version: str\n    artifact_url: str\n    config: Dict[str, Any] = field(default_factory=dict)\n    health_check_endpoint: Optional[str] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n\n\n@dataclass\nclass DeploymentJob:\n    \"\"\"Represents a deployment job.\"\"\"\n    id: str\n    application_id: str\n    version: str\n    target_nodes: List[str]\n    status: DeploymentStatus = DeploymentStatus.PENDING\n    strategy: DeploymentStrategy = DeploymentStrategy.STANDARD\n    previous_version: Optional[str] = None\n    canary_nodes: List[str] = field(default_factory=list)\n    promoted_nodes: List[str] = field(default_factory=list)\n    rolled_back_nodes: List[str] = field(default_factory=list)\n    progress: float = 0.0\n    error_message: Optional[str] = None\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def __post_init__(self):\n        if not self.id:\n            self.id = str(uuid.uuid4())\n\n\n@dataclass\nclass MetricPoint:\n    \"\"\"Represents a single metric data point.\"\"\"\n    name: str\n    value: float\n    timestamp: datetime\n    node_id: str\n    labels: Dict[str, str] = field(default_factory=dict)\n\n\n@dataclass\nclass Alert:\n    \"\"\"Represents an alert.\"\"\"\n    id: str\n    title: str\n    message: str\n    severity: AlertSeverity\n    source: str\n    node_id: Optional[str] = None\n    acknowledged: bool = False\n    resolved: bool = False\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def __post_init__(self):\n        if not self.id:\n            self.id = str(uuid.uuid4())\n\n\n@dataclass\nclass Policy:\n    \"\"\"Represents a policy rule.\"\"\"\n    id: str\n    name: str\n    description: str\n    condition: str\n    action: str\n    enabled: bool = True\n    priority: int = 0\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass CanaryHealthResult:\n    \"\"\"Result of canary health evaluation.\"\"\"\n    passed: bool\n    metrics: Dict[str, float]\n    thresholds: Dict[str, float]\n    violations: List[str] = field(default_factory=list)\n    message: str = \"\"\n",
            "vitalops_orchestrator/vitalops/interfaces/api.py": "\"\"\"REST API interface for VitalOps Orchestrator.\"\"\"\n\nfrom flask import Flask, request, jsonify\nfrom typing import Any, Dict, Optional\nimport logging\n\nfrom vitalops.coordinators.deployment import DeploymentCoordinator\nfrom vitalops.coordinators.recovery import RecoveryCoordinator\nfrom vitalops.coordinators.performance import PerformanceCoordinator\nfrom vitalops.models.domain import DeploymentStrategy\n\nlogger = logging.getLogger(__name__)\n\napp = Flask(__name__)\n\n# Coordinator instances (initialized at startup)\ndeployment_coordinator: Optional[DeploymentCoordinator] = None\nrecovery_coordinator: Optional[RecoveryCoordinator] = None\nperformance_coordinator: Optional[PerformanceCoordinator] = None\n\n\ndef init_coordinators(config: Dict[str, Any]):\n    \"\"\"Initialize coordinators with configuration.\"\"\"\n    global deployment_coordinator, recovery_coordinator, performance_coordinator\n    deployment_coordinator = DeploymentCoordinator(config)\n    recovery_coordinator = RecoveryCoordinator(config)\n    performance_coordinator = PerformanceCoordinator(config)\n\n\n@app.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return jsonify({\"status\": \"healthy\", \"service\": \"vitalops-orchestrator\"})\n\n\n@app.route('/api/v1/deployments', methods=['POST'])\ndef create_deployment():\n    \"\"\"Create a new deployment job.\n    \n    Request body:\n        application_id (str): ID of the application to deploy\n        version (str): Version to deploy\n        target_nodes (list): List of node IDs to deploy to\n        deployment_strategy (str, optional): 'standard' or 'canary' (default: 'standard')\n        previous_version (str, optional): Previous version for rollback purposes\n    \n    Returns:\n        JSON response with deployment job details\n    \"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({\"error\": \"Request body is required\"}), 400\n        \n        # Validate required fields\n        required_fields = ['application_id', 'version', 'target_nodes']\n        for field in required_fields:\n            if field not in data:\n                return jsonify({\"error\": f\"Missing required field: {field}\"}), 400\n        \n        # Parse deployment strategy (default to 'standard' for backward compatibility)\n        strategy_str = data.get('deployment_strategy', 'standard').lower()\n        try:\n            strategy = DeploymentStrategy(strategy_str)\n        except ValueError:\n            return jsonify({\n                \"error\": f\"Invalid deployment_strategy: {strategy_str}. Must be 'standard' or 'canary'\"\n            }), 400\n        \n        # Create deployment job\n        job = deployment_coordinator.create_deployment(\n            application_id=data['application_id'],\n            version=data['version'],\n            target_nodes=data['target_nodes'],\n            strategy=strategy,\n            previous_version=data.get('previous_version')\n        )\n        \n        return jsonify({\n            \"id\": job.id,\n            \"application_id\": job.application_id,\n            \"version\": job.version,\n            \"target_nodes\": job.target_nodes,\n            \"strategy\": job.strategy.value,\n            \"status\": job.status.value,\n            \"created_at\": job.created_at.isoformat()\n        }), 201\n        \n    except Exception as e:\n        logger.error(f\"Error creating deployment: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/deployments/<deployment_id>', methods=['GET'])\ndef get_deployment(deployment_id: str):\n    \"\"\"Get deployment job status.\"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        job = deployment_coordinator.get_deployment(deployment_id)\n        if not job:\n            return jsonify({\"error\": \"Deployment not found\"}), 404\n        \n        return jsonify({\n            \"id\": job.id,\n            \"application_id\": job.application_id,\n            \"version\": job.version,\n            \"target_nodes\": job.target_nodes,\n            \"strategy\": job.strategy.value,\n            \"status\": job.status.value,\n            \"progress\": job.progress,\n            \"canary_nodes\": job.canary_nodes,\n            \"promoted_nodes\": job.promoted_nodes,\n            \"rolled_back_nodes\": job.rolled_back_nodes,\n            \"error_message\": job.error_message,\n            \"started_at\": job.started_at.isoformat() if job.started_at else None,\n            \"completed_at\": job.completed_at.isoformat() if job.completed_at else None,\n            \"created_at\": job.created_at.isoformat()\n        })\n        \n    except Exception as e:\n        logger.error(f\"Error getting deployment: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/deployments/<deployment_id>/cancel', methods=['POST'])\ndef cancel_deployment(deployment_id: str):\n    \"\"\"Cancel a deployment job.\"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        success = deployment_coordinator.cancel_deployment(deployment_id)\n        if not success:\n            return jsonify({\"error\": \"Failed to cancel deployment\"}), 400\n        \n        return jsonify({\"message\": \"Deployment cancelled\"})\n        \n    except Exception as e:\n        logger.error(f\"Error cancelling deployment: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/nodes', methods=['GET'])\ndef list_nodes():\n    \"\"\"List all managed nodes.\"\"\"\n    if not deployment_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        nodes = deployment_coordinator.list_nodes()\n        return jsonify({\n            \"nodes\": [\n                {\n                    \"id\": node.id,\n                    \"hostname\": node.hostname,\n                    \"ip_address\": node.ip_address,\n                    \"status\": node.status.value,\n                    \"labels\": node.labels\n                }\n                for node in nodes\n            ]\n        })\n        \n    except Exception as e:\n        logger.error(f\"Error listing nodes: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/metrics/<node_id>', methods=['GET'])\ndef get_node_metrics(node_id: str):\n    \"\"\"Get metrics for a specific node.\"\"\"\n    if not performance_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        metrics = performance_coordinator.get_node_metrics(node_id)\n        return jsonify({\"node_id\": node_id, \"metrics\": metrics})\n        \n    except Exception as e:\n        logger.error(f\"Error getting metrics: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route('/api/v1/recovery/<node_id>', methods=['POST'])\ndef trigger_recovery(node_id: str):\n    \"\"\"Trigger recovery for a node.\"\"\"\n    if not recovery_coordinator:\n        return jsonify({\"error\": \"Service not initialized\"}), 503\n    \n    try:\n        result = recovery_coordinator.trigger_recovery(node_id)\n        return jsonify(result)\n        \n    except Exception as e:\n        logger.error(f\"Error triggering recovery: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\ndef create_app(config: Dict[str, Any]) -> Flask:\n    \"\"\"Create and configure the Flask application.\"\"\"\n    init_coordinators(config)\n    return app\n",
            "vitalops_orchestrator/vitalops/coordinators/deployment.py": "\"\"\"Deployment coordinator for VitalOps Orchestrator.\"\"\"\n\nimport logging\nimport math\nimport time\nimport threading\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\nimport uuid\n\nfrom vitalops.models.domain import (\n    DeploymentJob, DeploymentStatus, DeploymentStrategy,\n    Node, NodeStatus, CanaryHealthResult\n)\nfrom vitalops.services.metric_collector import MetricCollector\nfrom vitalops.services.notification_gateway import NotificationGateway\nfrom vitalops.policy_engine.handlers import CanaryHealthPolicyHandler\nfrom vitalops.core.eventing import EventBus, Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass DeploymentCoordinator:\n    \"\"\"Coordinates deployment operations across the infrastructure.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.deployments: Dict[str, DeploymentJob] = {}\n        self.nodes: Dict[str, Node] = {}\n        self.node_versions: Dict[str, str] = {}  # Track deployed versions per node\n        self._lock = threading.Lock()\n        \n        # Initialize services\n        self.metric_collector = MetricCollector(config)\n        self.notification_gateway = NotificationGateway(config)\n        self.event_bus = EventBus()\n        \n        # Canary configuration\n        canary_config = config.get('deployment_strategies', {}).get('canary', {})\n        self.canary_subset_percentage = canary_config.get('subset_percentage', 10)\n        self.canary_bake_time_seconds = canary_config.get('bake_time_seconds', 300)\n        self.health_thresholds = canary_config.get('health_thresholds', {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0,\n            'max_memory_usage': 85.0,\n            'min_success_rate': 95.0\n        })\n        \n        # Initialize canary health policy handler\n        self.canary_health_handler = CanaryHealthPolicyHandler(self.health_thresholds)\n        \n        logger.info(\"DeploymentCoordinator initialized\")\n    \n    def register_node(self, node: Node) -> None:\n        \"\"\"Register a node with the coordinator.\"\"\"\n        with self._lock:\n            self.nodes[node.id] = node\n            logger.info(f\"Registered node: {node.id}\")\n    \n    def list_nodes(self) -> List[Node]:\n        \"\"\"List all registered nodes.\"\"\"\n        with self._lock:\n            return list(self.nodes.values())\n    \n    def create_deployment(\n        self,\n        application_id: str,\n        version: str,\n        target_nodes: List[str],\n        strategy: DeploymentStrategy = DeploymentStrategy.STANDARD,\n        previous_version: Optional[str] = None\n    ) -> DeploymentJob:\n        \"\"\"Create a new deployment job.\"\"\"\n        job = DeploymentJob(\n            id=str(uuid.uuid4()),\n            application_id=application_id,\n            version=version,\n            target_nodes=target_nodes,\n            strategy=strategy,\n            previous_version=previous_version\n        )\n        \n        with self._lock:\n            self.deployments[job.id] = job\n        \n        logger.info(f\"Created deployment job {job.id} with strategy {strategy.value}\")\n        \n        # Start deployment in background thread\n        thread = threading.Thread(target=self._execute_deployment, args=(job.id,))\n        thread.daemon = True\n        thread.start()\n        \n        return job\n    \n    def get_deployment(self, deployment_id: str) -> Optional[DeploymentJob]:\n        \"\"\"Get a deployment job by ID.\"\"\"\n        with self._lock:\n            return self.deployments.get(deployment_id)\n    \n    def cancel_deployment(self, deployment_id: str) -> bool:\n        \"\"\"Cancel a deployment job.\"\"\"\n        with self._lock:\n            job = self.deployments.get(deployment_id)\n            if not job:\n                return False\n            \n            if job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED,\n                             DeploymentStatus.CANCELLED, DeploymentStatus.ROLLED_BACK]:\n                return False\n            \n            job.status = DeploymentStatus.CANCELLED\n            job.completed_at = datetime.utcnow()\n            logger.info(f\"Cancelled deployment {deployment_id}\")\n            return True\n    \n    def _execute_deployment(self, deployment_id: str) -> None:\n        \"\"\"Execute a deployment job.\"\"\"\n        job = self.get_deployment(deployment_id)\n        if not job:\n            return\n        \n        try:\n            job.started_at = datetime.utcnow()\n            \n            if job.strategy == DeploymentStrategy.CANARY:\n                self._execute_canary_deployment(job)\n            else:\n                self._execute_standard_deployment(job)\n                \n        except Exception as e:\n            logger.error(f\"Deployment {deployment_id} failed: {e}\")\n            job.status = DeploymentStatus.FAILED\n            job.error_message = str(e)\n            job.completed_at = datetime.utcnow()\n            \n            self._send_deployment_notification(\n                job,\n                f\"Deployment {deployment_id} failed: {e}\",\n                severity=\"error\"\n            )\n    \n    def _execute_standard_deployment(self, job: DeploymentJob) -> None:\n        \"\"\"Execute a standard (all-at-once) deployment.\"\"\"\n        job.status = DeploymentStatus.IN_PROGRESS\n        logger.info(f\"Starting standard deployment {job.id}\")\n        \n        total_nodes = len(job.target_nodes)\n        deployed_count = 0\n        \n        for node_id in job.target_nodes:\n            if job.status == DeploymentStatus.CANCELLED:\n                return\n            \n            success = self._deploy_to_node(node_id, job.application_id, job.version)\n            if success:\n                deployed_count += 1\n                job.progress = (deployed_count / total_nodes) * 100\n                job.promoted_nodes.append(node_id)\n            else:\n                job.status = DeploymentStatus.FAILED\n                job.error_message = f\"Failed to deploy to node {node_id}\"\n                job.completed_at = datetime.utcnow()\n                return\n        \n        job.status = DeploymentStatus.COMPLETED\n        job.progress = 100.0\n        job.completed_at = datetime.utcnow()\n        logger.info(f\"Standard deployment {job.id} completed successfully\")\n    \n    def _execute_canary_deployment(self, job: DeploymentJob) -> None:\n        \"\"\"Execute a canary deployment.\"\"\"\n        logger.info(f\"Starting canary deployment {job.id}\")\n        \n        # Phase 1: Deploy to canary nodes\n        job.status = DeploymentStatus.CANARY_DEPLOY\n        canary_nodes = self._select_canary_nodes(job.target_nodes)\n        job.canary_nodes = canary_nodes\n        \n        logger.info(f\"Selected {len(canary_nodes)} canary nodes: {canary_nodes}\")\n        \n        # Deploy to canary nodes\n        for node_id in canary_nodes:\n            if job.status == DeploymentStatus.CANCELLED:\n                return\n            \n            success = self._deploy_to_node(node_id, job.application_id, job.version)\n            if not success:\n                job.status = DeploymentStatus.CANARY_FAILED\n                job.error_message = f\"Failed to deploy to canary node {node_id}\"\n                self._rollback_canary(job)\n                return\n        \n        job.progress = (len(canary_nodes) / len(job.target_nodes)) * 100\n        \n        # Phase 2: Monitor canary nodes (bake time)\n        job.status = DeploymentStatus.CANARY_MONITORING\n        logger.info(f\"Entering canary monitoring phase for {self.canary_bake_time_seconds} seconds\")\n        \n        health_result = self._monitor_canary_health(job)\n        \n        if not health_result.passed:\n            logger.warning(f\"Canary health check failed: {health_result.message}\")\n            job.status = DeploymentStatus.CANARY_FAILED\n            job.error_message = health_result.message\n            self._rollback_canary(job)\n            return\n        \n        logger.info(f\"Canary health check passed: {health_result.message}\")\n        \n        # Phase 3: Promote to remaining nodes\n        job.status = DeploymentStatus.PROMOTING\n        remaining_nodes = [n for n in job.target_nodes if n not in canary_nodes]\n        \n        logger.info(f\"Promoting to {len(remaining_nodes)} remaining nodes\")\n        \n        for node_id in remaining_nodes:\n            if job.status == DeploymentStatus.CANCELLED:\n                return\n            \n            success = self._deploy_to_node(node_id, job.application_id, job.version)\n            if success:\n                job.promoted_nodes.append(node_id)\n                job.progress = ((len(canary_nodes) + len(job.promoted_nodes)) / len(job.target_nodes)) * 100\n            else:\n                job.status = DeploymentStatus.FAILED\n                job.error_message = f\"Failed to deploy to node {node_id} during promotion\"\n                job.completed_at = datetime.utcnow()\n                return\n        \n        # Mark canary nodes as promoted too\n        job.promoted_nodes.extend(canary_nodes)\n        job.status = DeploymentStatus.COMPLETED\n        job.progress = 100.0\n        job.completed_at = datetime.utcnow()\n        \n        logger.info(f\"Canary deployment {job.id} completed successfully\")\n        self._send_deployment_notification(\n            job,\n            f\"Canary deployment {job.id} completed successfully\",\n            severity=\"info\"\n        )\n    \n    def _select_canary_nodes(self, target_nodes: List[str]) -> List[str]:\n        \"\"\"Select a subset of nodes for canary deployment.\"\"\"\n        num_canary = max(1, math.ceil(len(target_nodes) * self.canary_subset_percentage / 100))\n        return target_nodes[:num_canary]\n    \n    def _deploy_to_node(self, node_id: str, application_id: str, version: str) -> bool:\n        \"\"\"Deploy application version to a specific node.\"\"\"\n        try:\n            logger.info(f\"Deploying {application_id}:{version} to node {node_id}\")\n            \n            # Store current version as previous before updating\n            with self._lock:\n                self.node_versions[node_id] = version\n            \n            # Simulate deployment (in real implementation, this would SSH/API call to node)\n            time.sleep(0.1)  # Simulate deployment time\n            \n            # Emit deployment event\n            self.event_bus.publish(Event(\n                event_type=\"deployment.node.completed\",\n                data={\n                    \"node_id\": node_id,\n                    \"application_id\": application_id,\n                    \"version\": version\n                }\n            ))\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to deploy to node {node_id}: {e}\")\n            return False\n    \n    def _monitor_canary_health(self, job: DeploymentJob) -> CanaryHealthResult:\n        \"\"\"Monitor canary nodes during bake time and evaluate health.\"\"\"\n        start_time = time.time()\n        check_interval = min(30, self.canary_bake_time_seconds / 5)  # Check at least 5 times\n        \n        all_metrics: Dict[str, List[float]] = {\n            'cpu_usage': [],\n            'error_rate': [],\n            'memory_usage': [],\n            'success_rate': []\n        }\n        \n        while time.time() - start_time < self.canary_bake_time_seconds:\n            if job.status == DeploymentStatus.CANCELLED:\n                return CanaryHealthResult(\n                    passed=False,\n                    metrics={},\n                    thresholds=self.health_thresholds,\n                    message=\"Deployment cancelled\"\n                )\n            \n            # Collect metrics from canary nodes\n            for node_id in job.canary_nodes:\n                metrics = self.metric_collector.collect_metrics(node_id)\n                for metric_name, value in metrics.items():\n                    if metric_name in all_metrics:\n                        all_metrics[metric_name].append(value)\n            \n            time.sleep(check_interval)\n        \n        # Calculate average metrics\n        avg_metrics = {}\n        for metric_name, values in all_metrics.items():\n            if values:\n                avg_metrics[metric_name] = sum(values) / len(values)\n            else:\n                avg_metrics[metric_name] = 0.0\n        \n        # Evaluate health using policy handler\n        return self.canary_health_handler.evaluate(avg_metrics)\n    \n    def _rollback_canary(self, job: DeploymentJob) -> None:\n        \"\"\"Rollback canary nodes to previous version.\"\"\"\n        logger.warning(f\"Rolling back canary deployment {job.id}\")\n        \n        previous_version = job.previous_version or \"stable\"\n        \n        for node_id in job.canary_nodes:\n            try:\n                success = self._deploy_to_node(node_id, job.application_id, previous_version)\n                if success:\n                    job.rolled_back_nodes.append(node_id)\n                    logger.info(f\"Rolled back node {node_id} to version {previous_version}\")\n                else:\n                    logger.error(f\"Failed to rollback node {node_id}\")\n            except Exception as e:\n                logger.error(f\"Error rolling back node {node_id}: {e}\")\n        \n        job.status = DeploymentStatus.ROLLED_BACK\n        job.completed_at = datetime.utcnow()\n        \n        # Send rollback notification\n        self._send_deployment_notification(\n            job,\n            f\"Canary deployment {job.id} rolled back due to health check failure: {job.error_message}\",\n            severity=\"warning\"\n        )\n    \n    def _send_deployment_notification(self, job: DeploymentJob, message: str, severity: str = \"info\") -> None:\n        \"\"\"Send deployment notification.\"\"\"\n        try:\n            self.notification_gateway.send_notification(\n                title=f\"Deployment {job.status.value}: {job.application_id}\",\n                message=message,\n                severity=severity,\n                metadata={\n                    \"deployment_id\": job.id,\n                    \"application_id\": job.application_id,\n                    \"version\": job.version,\n                    \"strategy\": job.strategy.value,\n                    \"status\": job.status.value\n                }\n            )\n        except Exception as e:\n            logger.error(f\"Failed to send notification: {e}\")\n",
            "vitalops_orchestrator/vitalops/policy_engine/handlers.py": "\"\"\"Policy handlers for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\n\nfrom vitalops.models.domain import CanaryHealthResult\n\nlogger = logging.getLogger(__name__)\n\n\nclass PolicyHandler(ABC):\n    \"\"\"Abstract base class for policy handlers.\"\"\"\n    \n    @abstractmethod\n    def evaluate(self, context: Dict[str, Any]) -> Any:\n        \"\"\"Evaluate the policy against the given context.\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_name(self) -> str:\n        \"\"\"Get the handler name.\"\"\"\n        pass\n\n\nclass ResourceThresholdHandler(PolicyHandler):\n    \"\"\"Handler for resource threshold policies.\"\"\"\n    \n    def __init__(self, thresholds: Dict[str, float]):\n        self.thresholds = thresholds\n    \n    def get_name(self) -> str:\n        return \"resource_threshold\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate resource metrics against thresholds.\"\"\"\n        violations = []\n        metrics = context.get('metrics', {})\n        \n        for metric_name, threshold in self.thresholds.items():\n            if metric_name in metrics:\n                value = metrics[metric_name]\n                if value > threshold:\n                    violations.append({\n                        'metric': metric_name,\n                        'value': value,\n                        'threshold': threshold\n                    })\n        \n        return {\n            'passed': len(violations) == 0,\n            'violations': violations\n        }\n\n\nclass HealthCheckHandler(PolicyHandler):\n    \"\"\"Handler for health check policies.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or {}\n        self.timeout = self.config.get('timeout', 30)\n        self.retries = self.config.get('retries', 3)\n    \n    def get_name(self) -> str:\n        return \"health_check\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate health check status.\"\"\"\n        node_status = context.get('node_status', 'unknown')\n        health_endpoint = context.get('health_endpoint')\n        \n        is_healthy = node_status in ['healthy', 'ok', 'running']\n        \n        return {\n            'passed': is_healthy,\n            'status': node_status,\n            'health_endpoint': health_endpoint\n        }\n\n\nclass CanaryHealthPolicyHandler(PolicyHandler):\n    \"\"\"Handler for canary deployment health evaluation.\n    \n    This handler evaluates metrics collected from canary nodes against\n    configurable thresholds to determine if the canary deployment is healthy.\n    \"\"\"\n    \n    def __init__(self, thresholds: Dict[str, float]):\n        \"\"\"Initialize the canary health policy handler.\n        \n        Args:\n            thresholds: Dictionary of threshold values:\n                - max_cpu_usage: Maximum allowed CPU usage percentage\n                - max_error_rate: Maximum allowed error rate percentage\n                - max_memory_usage: Maximum allowed memory usage percentage\n                - min_success_rate: Minimum required success rate percentage\n        \"\"\"\n        self.thresholds = thresholds\n        logger.info(f\"CanaryHealthPolicyHandler initialized with thresholds: {thresholds}\")\n    \n    def get_name(self) -> str:\n        return \"canary_health\"\n    \n    def evaluate(self, metrics: Dict[str, float]) -> CanaryHealthResult:\n        \"\"\"Evaluate canary metrics against health thresholds.\n        \n        Args:\n            metrics: Dictionary of collected metrics:\n                - cpu_usage: Average CPU usage percentage\n                - error_rate: Average error rate percentage\n                - memory_usage: Average memory usage percentage\n                - success_rate: Average success rate percentage\n        \n        Returns:\n            CanaryHealthResult indicating pass/fail and details\n        \"\"\"\n        violations: List[str] = []\n        \n        # Check CPU usage\n        max_cpu = self.thresholds.get('max_cpu_usage', 80.0)\n        cpu_usage = metrics.get('cpu_usage', 0.0)\n        if cpu_usage > max_cpu:\n            violations.append(f\"CPU usage {cpu_usage:.1f}% exceeds threshold {max_cpu:.1f}%\")\n        \n        # Check error rate\n        max_error_rate = self.thresholds.get('max_error_rate', 5.0)\n        error_rate = metrics.get('error_rate', 0.0)\n        if error_rate > max_error_rate:\n            violations.append(f\"Error rate {error_rate:.1f}% exceeds threshold {max_error_rate:.1f}%\")\n        \n        # Check memory usage\n        max_memory = self.thresholds.get('max_memory_usage', 85.0)\n        memory_usage = metrics.get('memory_usage', 0.0)\n        if memory_usage > max_memory:\n            violations.append(f\"Memory usage {memory_usage:.1f}% exceeds threshold {max_memory:.1f}%\")\n        \n        # Check success rate (minimum threshold)\n        min_success_rate = self.thresholds.get('min_success_rate', 95.0)\n        success_rate = metrics.get('success_rate', 100.0)\n        if success_rate < min_success_rate:\n            violations.append(f\"Success rate {success_rate:.1f}% below threshold {min_success_rate:.1f}%\")\n        \n        passed = len(violations) == 0\n        \n        if passed:\n            message = \"All health metrics within acceptable thresholds\"\n        else:\n            message = f\"Health check failed: {'; '.join(violations)}\"\n        \n        logger.info(f\"Canary health evaluation: passed={passed}, metrics={metrics}\")\n        \n        return CanaryHealthResult(\n            passed=passed,\n            metrics=metrics,\n            thresholds=self.thresholds,\n            violations=violations,\n            message=message\n        )\n\n\nclass AutoScalingHandler(PolicyHandler):\n    \"\"\"Handler for auto-scaling policies.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or {}\n        self.scale_up_threshold = self.config.get('scale_up_threshold', 80)\n        self.scale_down_threshold = self.config.get('scale_down_threshold', 20)\n        self.min_instances = self.config.get('min_instances', 1)\n        self.max_instances = self.config.get('max_instances', 10)\n    \n    def get_name(self) -> str:\n        return \"auto_scaling\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate scaling decision based on metrics.\"\"\"\n        current_load = context.get('load', 0)\n        current_instances = context.get('instances', 1)\n        \n        action = 'none'\n        target_instances = current_instances\n        \n        if current_load > self.scale_up_threshold and current_instances < self.max_instances:\n            action = 'scale_up'\n            target_instances = min(current_instances + 1, self.max_instances)\n        elif current_load < self.scale_down_threshold and current_instances > self.min_instances:\n            action = 'scale_down'\n            target_instances = max(current_instances - 1, self.min_instances)\n        \n        return {\n            'action': action,\n            'current_instances': current_instances,\n            'target_instances': target_instances,\n            'current_load': current_load\n        }\n\n\nclass AlertingHandler(PolicyHandler):\n    \"\"\"Handler for alerting policies.\"\"\"\n    \n    def __init__(self, rules: Optional[List[Dict[str, Any]]] = None):\n        self.rules = rules or []\n    \n    def get_name(self) -> str:\n        return \"alerting\"\n    \n    def evaluate(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Evaluate alerting rules.\"\"\"\n        triggered_alerts = []\n        metrics = context.get('metrics', {})\n        \n        for rule in self.rules:\n            metric_name = rule.get('metric')\n            condition = rule.get('condition', 'gt')  # gt, lt, eq\n            threshold = rule.get('threshold', 0)\n            severity = rule.get('severity', 'warning')\n            \n            if metric_name in metrics:\n                value = metrics[metric_name]\n                triggered = False\n                \n                if condition == 'gt' and value > threshold:\n                    triggered = True\n                elif condition == 'lt' and value < threshold:\n                    triggered = True\n                elif condition == 'eq' and value == threshold:\n                    triggered = True\n                \n                if triggered:\n                    triggered_alerts.append({\n                        'rule': rule.get('name', metric_name),\n                        'metric': metric_name,\n                        'value': value,\n                        'threshold': threshold,\n                        'severity': severity\n                    })\n        \n        return {\n            'alerts': triggered_alerts,\n            'alert_count': len(triggered_alerts)\n        }\n",
            "vitalops_orchestrator/vitalops/services/metric_collector.py": "\"\"\"Metric collection service for VitalOps Orchestrator.\"\"\"\n\nimport logging\nimport random\nimport time\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom vitalops.models.domain import MetricPoint\n\nlogger = logging.getLogger(__name__)\n\n\nclass MetricCollector:\n    \"\"\"Service for collecting metrics from nodes.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.metrics_config = config.get('metrics', {})\n        self.collection_interval = self.metrics_config.get('collection_interval', 60)\n        self.enabled_collectors = self.metrics_config.get('enabled_collectors', ['cpu', 'memory', 'disk', 'network'])\n        \n        # Store for simulated/cached metrics\n        self._metrics_cache: Dict[str, Dict[str, float]] = {}\n        self._simulate_metrics = config.get('simulate_metrics', True)\n        \n        logger.info(f\"MetricCollector initialized with collectors: {self.enabled_collectors}\")\n    \n    def collect_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Collect all enabled metrics from a node.\n        \n        Args:\n            node_id: ID of the node to collect metrics from\n            \n        Returns:\n            Dictionary of metric name to value\n        \"\"\"\n        metrics = {}\n        \n        try:\n            if self._simulate_metrics:\n                metrics = self._simulate_node_metrics(node_id)\n            else:\n                metrics = self._collect_real_metrics(node_id)\n            \n            # Cache the metrics\n            self._metrics_cache[node_id] = metrics\n            \n            logger.debug(f\"Collected metrics from node {node_id}: {metrics}\")\n            \n        except Exception as e:\n            logger.error(f\"Error collecting metrics from node {node_id}: {e}\")\n            # Return cached metrics if available\n            if node_id in self._metrics_cache:\n                return self._metrics_cache[node_id]\n        \n        return metrics\n    \n    def collect_metric(self, node_id: str, metric_name: str) -> Optional[float]:\n        \"\"\"Collect a specific metric from a node.\n        \n        Args:\n            node_id: ID of the node\n            metric_name: Name of the metric to collect\n            \n        Returns:\n            Metric value or None if not available\n        \"\"\"\n        metrics = self.collect_metrics(node_id)\n        return metrics.get(metric_name)\n    \n    def collect_metrics_batch(self, node_ids: List[str]) -> Dict[str, Dict[str, float]]:\n        \"\"\"Collect metrics from multiple nodes.\n        \n        Args:\n            node_ids: List of node IDs\n            \n        Returns:\n            Dictionary mapping node ID to metrics\n        \"\"\"\n        results = {}\n        for node_id in node_ids:\n            results[node_id] = self.collect_metrics(node_id)\n        return results\n    \n    def get_metric_history(self, node_id: str, metric_name: str, \n                          duration_seconds: int = 3600) -> List[MetricPoint]:\n        \"\"\"Get historical metric data for a node.\n        \n        Args:\n            node_id: ID of the node\n            metric_name: Name of the metric\n            duration_seconds: How far back to retrieve data\n            \n        Returns:\n            List of MetricPoint objects\n        \"\"\"\n        # In a real implementation, this would query a time-series database\n        # For now, return simulated historical data\n        points = []\n        current_time = datetime.utcnow()\n        \n        if self._simulate_metrics:\n            # Generate simulated historical data\n            num_points = min(duration_seconds // self.collection_interval, 100)\n            for i in range(num_points):\n                timestamp = datetime.fromtimestamp(\n                    current_time.timestamp() - (i * self.collection_interval)\n                )\n                value = self._simulate_single_metric(metric_name)\n                points.append(MetricPoint(\n                    name=metric_name,\n                    value=value,\n                    timestamp=timestamp,\n                    node_id=node_id\n                ))\n        \n        return points\n    \n    def set_simulated_metrics(self, node_id: str, metrics: Dict[str, float]) -> None:\n        \"\"\"Set simulated metrics for testing purposes.\n        \n        Args:\n            node_id: ID of the node\n            metrics: Dictionary of metric values to simulate\n        \"\"\"\n        self._metrics_cache[node_id] = metrics\n        logger.debug(f\"Set simulated metrics for node {node_id}: {metrics}\")\n    \n    def _simulate_node_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Generate simulated metrics for a node.\"\"\"\n        # Check if we have pre-set metrics for this node\n        if node_id in self._metrics_cache:\n            cached = self._metrics_cache[node_id]\n            # Add some variance to cached metrics\n            return {\n                k: v + random.uniform(-2, 2) if isinstance(v, (int, float)) else v\n                for k, v in cached.items()\n            }\n        \n        # Generate random but realistic metrics\n        metrics = {\n            'cpu_usage': random.uniform(20, 60),\n            'memory_usage': random.uniform(30, 70),\n            'disk_usage': random.uniform(40, 80),\n            'network_in': random.uniform(100, 1000),\n            'network_out': random.uniform(50, 500),\n            'error_rate': random.uniform(0, 3),\n            'success_rate': random.uniform(97, 100),\n            'request_latency': random.uniform(10, 100),\n            'active_connections': random.randint(10, 200)\n        }\n        \n        return metrics\n    \n    def _simulate_single_metric(self, metric_name: str) -> float:\n        \"\"\"Generate a simulated value for a single metric.\"\"\"\n        defaults = {\n            'cpu_usage': (20, 60),\n            'memory_usage': (30, 70),\n            'disk_usage': (40, 80),\n            'error_rate': (0, 3),\n            'success_rate': (97, 100),\n            'request_latency': (10, 100)\n        }\n        \n        if metric_name in defaults:\n            low, high = defaults[metric_name]\n            return random.uniform(low, high)\n        \n        return random.uniform(0, 100)\n    \n    def _collect_real_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Collect real metrics from a node (placeholder for actual implementation).\"\"\"\n        # In a real implementation, this would:\n        # 1. Connect to the node via SSH or agent\n        # 2. Execute metric collection commands\n        # 3. Parse and return the results\n        \n        # For now, fall back to simulation\n        logger.warning(f\"Real metric collection not implemented, using simulation for node {node_id}\")\n        return self._simulate_node_metrics(node_id)\n",
            "vitalops_orchestrator/vitalops/services/notification_gateway.py": "\"\"\"Notification gateway service for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\nimport uuid\n\nfrom vitalops.models.domain import Alert, AlertSeverity\n\nlogger = logging.getLogger(__name__)\n\n\nclass NotificationGateway:\n    \"\"\"Service for sending notifications through various channels.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.notifications_config = config.get('notifications', {})\n        self.enabled = self.notifications_config.get('enabled', True)\n        self.channels = self.notifications_config.get('channels', ['email', 'slack'])\n        \n        # Email configuration\n        self.email_config = self.notifications_config.get('email', {})\n        \n        # Slack configuration\n        self.slack_config = self.notifications_config.get('slack', {})\n        \n        # Store sent notifications for testing/auditing\n        self._sent_notifications: List[Dict[str, Any]] = []\n        \n        logger.info(f\"NotificationGateway initialized with channels: {self.channels}\")\n    \n    def send_notification(\n        self,\n        title: str,\n        message: str,\n        severity: str = \"info\",\n        channels: Optional[List[str]] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> bool:\n        \"\"\"Send a notification through configured channels.\n        \n        Args:\n            title: Notification title\n            message: Notification message body\n            severity: Severity level (info, warning, error, critical)\n            channels: Specific channels to use (defaults to all configured)\n            metadata: Additional metadata to include\n            \n        Returns:\n            True if notification was sent successfully\n        \"\"\"\n        if not self.enabled:\n            logger.debug(\"Notifications disabled, skipping\")\n            return True\n        \n        target_channels = channels or self.channels\n        notification_id = str(uuid.uuid4())\n        \n        notification_record = {\n            'id': notification_id,\n            'title': title,\n            'message': message,\n            'severity': severity,\n            'channels': target_channels,\n            'metadata': metadata or {},\n            'timestamp': datetime.utcnow().isoformat(),\n            'status': 'pending'\n        }\n        \n        success = True\n        \n        for channel in target_channels:\n            try:\n                if channel == 'email':\n                    self._send_email(title, message, severity, metadata)\n                elif channel == 'slack':\n                    self._send_slack(title, message, severity, metadata)\n                elif channel == 'webhook':\n                    self._send_webhook(title, message, severity, metadata)\n                else:\n                    logger.warning(f\"Unknown notification channel: {channel}\")\n                    \n            except Exception as e:\n                logger.error(f\"Failed to send notification via {channel}: {e}\")\n                success = False\n        \n        notification_record['status'] = 'sent' if success else 'failed'\n        self._sent_notifications.append(notification_record)\n        \n        logger.info(f\"Notification {notification_id} sent: {title} [{severity}]\")\n        \n        return success\n    \n    def send_alert(self, alert: Alert) -> bool:\n        \"\"\"Send an alert notification.\n        \n        Args:\n            alert: Alert object to send\n            \n        Returns:\n            True if alert was sent successfully\n        \"\"\"\n        return self.send_notification(\n            title=alert.title,\n            message=alert.message,\n            severity=alert.severity.value,\n            metadata={\n                'alert_id': alert.id,\n                'source': alert.source,\n                'node_id': alert.node_id,\n                **alert.metadata\n            }\n        )\n    \n    def send_deployment_notification(\n        self,\n        deployment_id: str,\n        status: str,\n        application_id: str,\n        version: str,\n        message: str\n    ) -> bool:\n        \"\"\"Send a deployment-specific notification.\n        \n        Args:\n            deployment_id: ID of the deployment\n            status: Deployment status\n            application_id: Application being deployed\n            version: Version being deployed\n            message: Notification message\n            \n        Returns:\n            True if notification was sent successfully\n        \"\"\"\n        severity = 'info'\n        if status in ['failed', 'canary_failed']:\n            severity = 'error'\n        elif status in ['rolled_back']:\n            severity = 'warning'\n        \n        return self.send_notification(\n            title=f\"Deployment {status}: {application_id} v{version}\",\n            message=message,\n            severity=severity,\n            metadata={\n                'deployment_id': deployment_id,\n                'application_id': application_id,\n                'version': version,\n                'status': status\n            }\n        )\n    \n    def get_sent_notifications(self) -> List[Dict[str, Any]]:\n        \"\"\"Get list of sent notifications (for testing/auditing).\"\"\"\n        return self._sent_notifications.copy()\n    \n    def clear_notifications(self) -> None:\n        \"\"\"Clear the sent notifications list.\"\"\"\n        self._sent_notifications.clear()\n    \n    def _send_email(self, title: str, message: str, severity: str, \n                    metadata: Optional[Dict[str, Any]]) -> None:\n        \"\"\"Send notification via email.\"\"\"\n        smtp_host = self.email_config.get('smtp_host')\n        smtp_port = self.email_config.get('smtp_port', 587)\n        from_address = self.email_config.get('from_address')\n        \n        # In a real implementation, this would use smtplib to send email\n        logger.debug(f\"Email notification: {title} (would send via {smtp_host}:{smtp_port})\")\n    \n    def _send_slack(self, title: str, message: str, severity: str,\n                    metadata: Optional[Dict[str, Any]]) -> None:\n        \"\"\"Send notification via Slack.\"\"\"\n        webhook_url = self.slack_config.get('webhook_url')\n        \n        # Map severity to Slack color\n        color_map = {\n            'info': '#36a64f',\n            'warning': '#ffcc00',\n            'error': '#ff0000',\n            'critical': '#8b0000'\n        }\n        color = color_map.get(severity, '#808080')\n        \n        # In a real implementation, this would POST to the Slack webhook\n        logger.debug(f\"Slack notification: {title} (would send to webhook)\")\n    \n    def _send_webhook(self, title: str, message: str, severity: str,\n                      metadata: Optional[Dict[str, Any]]) -> None:\n        \"\"\"Send notification via generic webhook.\"\"\"\n        # In a real implementation, this would POST to a configured webhook URL\n        logger.debug(f\"Webhook notification: {title}\")\n",
            "vitalops_orchestrator/tests/test_coordinators.py": "\"\"\"Tests for VitalOps coordinators.\"\"\"\n\nimport pytest\nimport time\nimport threading\nfrom unittest.mock import Mock, patch, MagicMock\nfrom datetime import datetime\n\nfrom vitalops.coordinators.deployment import DeploymentCoordinator\nfrom vitalops.coordinators.recovery import RecoveryCoordinator\nfrom vitalops.coordinators.performance import PerformanceCoordinator\nfrom vitalops.models.domain import (\n    DeploymentJob, DeploymentStatus, DeploymentStrategy,\n    Node, NodeStatus, CanaryHealthResult\n)\nfrom vitalops.services.metric_collector import MetricCollector\nfrom vitalops.services.notification_gateway import NotificationGateway\nfrom vitalops.policy_engine.handlers import CanaryHealthPolicyHandler\n\n\n@pytest.fixture\ndef test_config():\n    \"\"\"Test configuration fixture.\"\"\"\n    return {\n        'deployment': {\n            'default_timeout': 600,\n            'max_concurrent': 5,\n            'rollback_on_failure': True\n        },\n        'deployment_strategies': {\n            'canary': {\n                'subset_percentage': 20,\n                'bake_time_seconds': 1,  # Short for testing\n                'health_thresholds': {\n                    'max_cpu_usage': 80.0,\n                    'max_error_rate': 5.0,\n                    'max_memory_usage': 85.0,\n                    'min_success_rate': 95.0\n                }\n            }\n        },\n        'metrics': {\n            'collection_interval': 60,\n            'enabled_collectors': ['cpu', 'memory']\n        },\n        'notifications': {\n            'enabled': True,\n            'channels': ['email', 'slack']\n        },\n        'simulate_metrics': True\n    }\n\n\n@pytest.fixture\ndef deployment_coordinator(test_config):\n    \"\"\"Create a deployment coordinator for testing.\"\"\"\n    coordinator = DeploymentCoordinator(test_config)\n    \n    # Register test nodes\n    for i in range(5):\n        node = Node(\n            id=f\"node-{i}\",\n            hostname=f\"server-{i}.example.com\",\n            ip_address=f\"192.168.1.{10 + i}\",\n            status=NodeStatus.HEALTHY\n        )\n        coordinator.register_node(node)\n    \n    return coordinator\n\n\nclass TestDeploymentCoordinator:\n    \"\"\"Tests for DeploymentCoordinator.\"\"\"\n    \n    def test_create_standard_deployment(self, deployment_coordinator):\n        \"\"\"Test creating a standard deployment.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\", \"node-1\"],\n            strategy=DeploymentStrategy.STANDARD\n        )\n        \n        assert job is not None\n        assert job.application_id == \"test-app\"\n        assert job.version == \"1.0.0\"\n        assert job.strategy == DeploymentStrategy.STANDARD\n        assert len(job.target_nodes) == 2\n    \n    def test_create_canary_deployment(self, deployment_coordinator):\n        \"\"\"Test creating a canary deployment.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"2.0.0\",\n            target_nodes=[\"node-0\", \"node-1\", \"node-2\", \"node-3\", \"node-4\"],\n            strategy=DeploymentStrategy.CANARY,\n            previous_version=\"1.0.0\"\n        )\n        \n        assert job is not None\n        assert job.application_id == \"test-app\"\n        assert job.version == \"2.0.0\"\n        assert job.strategy == DeploymentStrategy.CANARY\n        assert job.previous_version == \"1.0.0\"\n    \n    def test_get_deployment(self, deployment_coordinator):\n        \"\"\"Test retrieving a deployment by ID.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\"]\n        )\n        \n        retrieved = deployment_coordinator.get_deployment(job.id)\n        assert retrieved is not None\n        assert retrieved.id == job.id\n    \n    def test_get_nonexistent_deployment(self, deployment_coordinator):\n        \"\"\"Test retrieving a non-existent deployment.\"\"\"\n        result = deployment_coordinator.get_deployment(\"nonexistent-id\")\n        assert result is None\n    \n    def test_cancel_deployment(self, deployment_coordinator):\n        \"\"\"Test cancelling a deployment.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\", \"node-1\"]\n        )\n        \n        # Give it a moment to start\n        time.sleep(0.1)\n        \n        success = deployment_coordinator.cancel_deployment(job.id)\n        assert success is True\n        \n        updated_job = deployment_coordinator.get_deployment(job.id)\n        assert updated_job.status == DeploymentStatus.CANCELLED\n    \n    def test_list_nodes(self, deployment_coordinator):\n        \"\"\"Test listing registered nodes.\"\"\"\n        nodes = deployment_coordinator.list_nodes()\n        assert len(nodes) == 5\n    \n    def test_standard_deployment_completes(self, deployment_coordinator):\n        \"\"\"Test that a standard deployment completes successfully.\"\"\"\n        job = deployment_coordinator.create_deployment(\n            application_id=\"test-app\",\n            version=\"1.0.0\",\n            target_nodes=[\"node-0\"],\n            strategy=DeploymentStrategy.STANDARD\n        )\n        \n        # Wait for deployment to complete\n        timeout = 5\n        start = time.time()\n        while time.time() - start < timeout:\n            updated_job = deployment_coordinator.get_deployment(job.id)\n            if updated_job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED]:\n                break\n            time.sleep(0.1)\n        \n        updated_job = deployment_coordinator.get_deployment(job.id)\n        assert updated_job.status == DeploymentStatus.COMPLETED\n        assert updated_job.progress == 100.0\n\n\nclass TestCanaryDeployment:\n    \"\"\"Tests specifically for canary deployment functionality.\"\"\"\n    \n    def test_canary_deployment_success_promotion(self, test_config):\n        \"\"\"Test successful canary deployment with promotion to all nodes.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Register test nodes\n        target_nodes = []\n        for i in range(5):\n            node = Node(\n                id=f\"node-{i}\",\n                hostname=f\"server-{i}.example.com\",\n                ip_address=f\"192.168.1.{10 + i}\",\n                status=NodeStatus.HEALTHY\n            )\n            coordinator.register_node(node)\n            target_nodes.append(node.id)\n        \n        # Mock metric collector to return healthy metrics\n        healthy_metrics = {\n            'cpu_usage': 45.0,\n            'error_rate': 1.0,\n            'memory_usage': 50.0,\n            'success_rate': 99.0\n        }\n        \n        with patch.object(coordinator.metric_collector, 'collect_metrics', return_value=healthy_metrics):\n            job = coordinator.create_deployment(\n                application_id=\"test-app\",\n                version=\"2.0.0\",\n                target_nodes=target_nodes,\n                strategy=DeploymentStrategy.CANARY,\n                previous_version=\"1.0.0\"\n            )\n            \n            # Wait for deployment to complete\n            timeout = 10\n            start = time.time()\n            while time.time() - start < timeout:\n                updated_job = coordinator.get_deployment(job.id)\n                if updated_job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED, \n                                          DeploymentStatus.ROLLED_BACK, DeploymentStatus.CANARY_FAILED]:\n                    break\n                time.sleep(0.2)\n            \n            final_job = coordinator.get_deployment(job.id)\n            \n            # Verify successful completion\n            assert final_job.status == DeploymentStatus.COMPLETED\n            assert final_job.progress == 100.0\n            assert len(final_job.canary_nodes) > 0\n            assert len(final_job.promoted_nodes) == len(target_nodes)\n            assert len(final_job.rolled_back_nodes) == 0\n    \n    def test_canary_deployment_failure_rollback(self, test_config):\n        \"\"\"Test canary deployment failure triggers rollback.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Register test nodes\n        target_nodes = []\n        for i in range(5):\n            node = Node(\n                id=f\"node-{i}\",\n                hostname=f\"server-{i}.example.com\",\n                ip_address=f\"192.168.1.{10 + i}\",\n                status=NodeStatus.HEALTHY\n            )\n            coordinator.register_node(node)\n            target_nodes.append(node.id)\n        \n        # Mock metric collector to return unhealthy metrics (high error rate)\n        unhealthy_metrics = {\n            'cpu_usage': 95.0,  # Exceeds 80% threshold\n            'error_rate': 15.0,  # Exceeds 5% threshold\n            'memory_usage': 90.0,  # Exceeds 85% threshold\n            'success_rate': 80.0  # Below 95% threshold\n        }\n        \n        with patch.object(coordinator.metric_collector, 'collect_metrics', return_value=unhealthy_metrics):\n            job = coordinator.create_deployment(\n                application_id=\"test-app\",\n                version=\"2.0.0\",\n                target_nodes=target_nodes,\n                strategy=DeploymentStrategy.CANARY,\n                previous_version=\"1.0.0\"\n            )\n            \n            # Wait for deployment to complete (with rollback)\n            timeout = 10\n            start = time.time()\n            while time.time() - start < timeout:\n                updated_job = coordinator.get_deployment(job.id)\n                if updated_job.status in [DeploymentStatus.COMPLETED, DeploymentStatus.FAILED,\n                                          DeploymentStatus.ROLLED_BACK, DeploymentStatus.CANARY_FAILED]:\n                    break\n                time.sleep(0.2)\n            \n            final_job = coordinator.get_deployment(job.id)\n            \n            # Verify rollback occurred\n            assert final_job.status == DeploymentStatus.ROLLED_BACK\n            assert len(final_job.canary_nodes) > 0\n            assert len(final_job.rolled_back_nodes) == len(final_job.canary_nodes)\n            assert final_job.error_message is not None\n            assert 'threshold' in final_job.error_message.lower() or 'health' in final_job.error_message.lower()\n    \n    def test_canary_node_selection(self, test_config):\n        \"\"\"Test that canary selects correct percentage of nodes.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # With 20% canary percentage and 10 nodes, should select 2 nodes\n        target_nodes = [f\"node-{i}\" for i in range(10)]\n        \n        canary_nodes = coordinator._select_canary_nodes(target_nodes)\n        \n        # 20% of 10 = 2 nodes\n        assert len(canary_nodes) == 2\n        assert all(node in target_nodes for node in canary_nodes)\n    \n    def test_canary_node_selection_minimum_one(self, test_config):\n        \"\"\"Test that at least one canary node is selected.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Even with small percentage, should select at least 1 node\n        target_nodes = [\"node-0\", \"node-1\"]\n        \n        canary_nodes = coordinator._select_canary_nodes(target_nodes)\n        \n        assert len(canary_nodes) >= 1\n    \n    def test_canary_notification_on_rollback(self, test_config):\n        \"\"\"Test that notification is sent when canary deployment rolls back.\"\"\"\n        coordinator = DeploymentCoordinator(test_config)\n        \n        # Register test nodes\n        target_nodes = []\n        for i in range(3):\n            node = Node(\n                id=f\"node-{i}\",\n                hostname=f\"server-{i}.example.com\",\n                ip_address=f\"192.168.1.{10 + i}\"\n            )\n            coordinator.register_node(node)\n            target_nodes.append(node.id)\n        \n        # Mock unhealthy metrics\n        unhealthy_metrics = {\n            'cpu_usage': 95.0,\n            'error_rate': 20.0,\n            'memory_usage': 95.0,\n            'success_rate': 70.0\n        }\n        \n        # Clear any previous notifications\n        coordinator.notification_gateway.clear_notifications()\n        \n        with patch.object(coordinator.metric_collector, 'collect_metrics', return_value=unhealthy_metrics):\n            job = coordinator.create_deployment(\n                application_id=\"test-app\",\n                version=\"2.0.0\",\n                target_nodes=target_nodes,\n                strategy=DeploymentStrategy.CANARY,\n                previous_version=\"1.0.0\"\n            )\n            \n            # Wait for rollback\n            timeout = 10\n            start = time.time()\n            while time.time() - start < timeout:\n                updated_job = coordinator.get_deployment(job.id)\n                if updated_job.status == DeploymentStatus.ROLLED_BACK:\n                    break\n                time.sleep(0.2)\n            \n            # Check notifications were sent\n            notifications = coordinator.notification_gateway.get_sent_notifications()\n            \n            # Should have at least one notification about the rollback\n            assert len(notifications) > 0\n            rollback_notifications = [\n                n for n in notifications \n                if 'rollback' in n.get('message', '').lower() or \n                   n.get('severity') in ['warning', 'error']\n            ]\n            assert len(rollback_notifications) > 0\n\n\nclass TestCanaryHealthPolicyHandler:\n    \"\"\"Tests for CanaryHealthPolicyHandler.\"\"\"\n    \n    def test_healthy_metrics_pass(self):\n        \"\"\"Test that healthy metrics pass the health check.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0,\n            'max_memory_usage': 85.0,\n            'min_success_rate': 95.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 50.0,\n            'error_rate': 2.0,\n            'memory_usage': 60.0,\n            'success_rate': 98.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is True\n        assert len(result.violations) == 0\n    \n    def test_high_cpu_fails(self):\n        \"\"\"Test that high CPU usage fails the health check.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 95.0,\n            'error_rate': 2.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 1\n        assert 'cpu' in result.violations[0].lower()\n    \n    def test_high_error_rate_fails(self):\n        \"\"\"Test that high error rate fails the health check.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 50.0,\n            'error_rate': 15.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 1\n        assert 'error' in result.violations[0].lower()\n    \n    def test_low_success_rate_fails(self):\n        \"\"\"Test that low success rate fails the health check.\"\"\"\n        thresholds = {\n            'min_success_rate': 95.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'success_rate': 85.0\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 1\n        assert 'success' in result.violations[0].lower()\n    \n    def test_multiple_violations(self):\n        \"\"\"Test that multiple threshold violations are all reported.\"\"\"\n        thresholds = {\n            'max_cpu_usage': 80.0,\n            'max_error_rate': 5.0,\n            'max_memory_usage': 85.0,\n            'min_success_rate': 95.0\n        }\n        handler = CanaryHealthPolicyHandler(thresholds)\n        \n        metrics = {\n            'cpu_usage': 95.0,  # Violation\n            'error_rate': 15.0,  # Violation\n            'memory_usage': 95.0,  # Violation\n            'success_rate': 80.0  # Violation\n        }\n        \n        result = handler.evaluate(metrics)\n        \n        assert result.passed is False\n        assert len(result.violations) == 4\n    \n    def test_handler_name(self):\n        \"\"\"Test that handler returns correct name.\"\"\"\n        handler = CanaryHealthPolicyHandler({})\n        assert handler.get_name() == \"canary_health\"\n\n\nclass TestMetricCollector:\n    \"\"\"Tests for MetricCollector.\"\"\"\n    \n    def test_collect_metrics(self, test_config):\n        \"\"\"Test metric collection.\"\"\"\n        collector = MetricCollector(test_config)\n        \n        metrics = collector.collect_metrics(\"node-0\")\n        \n        assert 'cpu_usage' in metrics\n        assert 'memory_usage' in metrics\n        assert 'error_rate' in metrics\n    \n    def test_set_simulated_metrics(self, test_config):\n        \"\"\"Test setting simulated metrics.\"\"\"\n        collector = MetricCollector(test_config)\n        \n        custom_metrics = {\n            'cpu_usage': 75.0,\n            'error_rate': 3.0\n        }\n        \n        collector.set_simulated_metrics(\"node-0\", custom_metrics)\n        \n        # Collected metrics should be close to set values (with some variance)\n        metrics = collector.collect_metrics(\"node-0\")\n        assert abs(metrics['cpu_usage'] - 75.0) < 5\n        assert abs(metrics['error_rate'] - 3.0) < 5\n\n\nclass TestNotificationGateway:\n    \"\"\"Tests for NotificationGateway.\"\"\"\n    \n    def test_send_notification(self, test_config):\n        \"\"\"Test sending a notification.\"\"\"\n        gateway = NotificationGateway(test_config)\n        \n        result = gateway.send_notification(\n            title=\"Test Alert\",\n            message=\"This is a test\",\n            severity=\"warning\"\n        )\n        \n        assert result is True\n        \n        notifications = gateway.get_sent_notifications()\n        assert len(notifications) == 1\n        assert notifications[0]['title'] == \"Test Alert\"\n        assert notifications[0]['severity'] == \"warning\"\n    \n    def test_send_deployment_notification(self, test_config):\n        \"\"\"Test sending a deployment notification.\"\"\"\n        gateway = NotificationGateway(test_config)\n        \n        result = gateway.send_deployment_notification(\n            deployment_id=\"deploy-123\",\n            status=\"rolled_back\",\n            application_id=\"test-app\",\n            version=\"2.0.0\",\n            message=\"Deployment rolled back due to health check failure\"\n        )\n        \n        assert result is True\n        \n        notifications = gateway.get_sent_notifications()\n        assert len(notifications) == 1\n        assert 'rolled_back' in notifications[0]['title'].lower()\n        assert notifications[0]['severity'] == 'warning'\n\n\nclass TestRecoveryCoordinator:\n    \"\"\"Tests for RecoveryCoordinator.\"\"\"\n    \n    def test_recovery_coordinator_init(self, test_config):\n        \"\"\"Test RecoveryCoordinator initialization.\"\"\"\n        coordinator = RecoveryCoordinator(test_config)\n        assert coordinator is not None\n\n\nclass TestPerformanceCoordinator:\n    \"\"\"Tests for PerformanceCoordinator.\"\"\"\n    \n    def test_performance_coordinator_init(self, test_config):\n        \"\"\"Test PerformanceCoordinator initialization.\"\"\"\n        coordinator = PerformanceCoordinator(test_config)\n        assert coordinator is not None\n",
            "vitalops_orchestrator/vitalops/core/eventing.py": "\"\"\"Event bus and eventing system for VitalOps Orchestrator.\"\"\"\n\nimport logging\nimport threading\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Any, Callable, Dict, List, Optional\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Event:\n    \"\"\"Represents an event in the system.\"\"\"\n    event_type: str\n    data: Dict[str, Any] = field(default_factory=dict)\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    source: Optional[str] = None\n\n\nclass EventBus:\n    \"\"\"Simple event bus for publishing and subscribing to events.\"\"\"\n    \n    def __init__(self):\n        self._subscribers: Dict[str, List[Callable[[Event], None]]] = {}\n        self._lock = threading.Lock()\n        logger.info(\"EventBus initialized\")\n    \n    def subscribe(self, event_type: str, handler: Callable[[Event], None]) -> None:\n        \"\"\"Subscribe to events of a specific type.\n        \n        Args:\n            event_type: Type of event to subscribe to (supports wildcards with '*')\n            handler: Callback function to handle the event\n        \"\"\"\n        with self._lock:\n            if event_type not in self._subscribers:\n                self._subscribers[event_type] = []\n            self._subscribers[event_type].append(handler)\n            logger.debug(f\"Subscribed handler to event type: {event_type}\")\n    \n    def unsubscribe(self, event_type: str, handler: Callable[[Event], None]) -> None:\n        \"\"\"Unsubscribe from events of a specific type.\n        \n        Args:\n            event_type: Type of event to unsubscribe from\n            handler: Handler to remove\n        \"\"\"\n        with self._lock:\n            if event_type in self._subscribers:\n                try:\n                    self._subscribers[event_type].remove(handler)\n                    logger.debug(f\"Unsubscribed handler from event type: {event_type}\")\n                except ValueError:\n                    pass\n    \n    def publish(self, event: Event) -> None:\n        \"\"\"Publish an event to all subscribers.\n        \n        Args:\n            event: Event to publish\n        \"\"\"\n        handlers_to_call = []\n        \n        with self._lock:\n            # Get exact match subscribers\n            if event.event_type in self._subscribers:\n                handlers_to_call.extend(self._subscribers[event.event_type])\n            \n            # Get wildcard subscribers\n            for pattern, handlers in self._subscribers.items():\n                if '*' in pattern:\n                    if self._matches_pattern(event.event_type, pattern):\n                        handlers_to_call.extend(handlers)\n        \n        # Call handlers outside the lock\n        for handler in handlers_to_call:\n            try:\n                handler(event)\n            except Exception as e:\n                logger.error(f\"Error in event handler for {event.event_type}: {e}\")\n    \n    def _matches_pattern(self, event_type: str, pattern: str) -> bool:\n        \"\"\"Check if event type matches a wildcard pattern.\"\"\"\n        if pattern == '*':\n            return True\n        \n        pattern_parts = pattern.split('.')\n        type_parts = event_type.split('.')\n        \n        if len(pattern_parts) != len(type_parts):\n            return False\n        \n        for p, t in zip(pattern_parts, type_parts):\n            if p != '*' and p != t:\n                return False\n        \n        return True\n",
            "vitalops_orchestrator/vitalops/coordinators/recovery.py": "\"\"\"Recovery coordinator for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass RecoveryCoordinator:\n    \"\"\"Coordinates recovery operations for unhealthy nodes.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.recovery_config = config.get('recovery', {})\n        self.auto_recovery = self.recovery_config.get('auto_recovery', True)\n        self.max_attempts = self.recovery_config.get('max_recovery_attempts', 3)\n        self.cooldown = self.recovery_config.get('recovery_cooldown', 300)\n        \n        self._recovery_attempts: Dict[str, int] = {}\n        \n        logger.info(\"RecoveryCoordinator initialized\")\n    \n    def trigger_recovery(self, node_id: str) -> Dict[str, Any]:\n        \"\"\"Trigger recovery for a specific node.\n        \n        Args:\n            node_id: ID of the node to recover\n            \n        Returns:\n            Dictionary with recovery result\n        \"\"\"\n        attempts = self._recovery_attempts.get(node_id, 0)\n        \n        if attempts >= self.max_attempts:\n            logger.warning(f\"Max recovery attempts reached for node {node_id}\")\n            return {\n                'success': False,\n                'node_id': node_id,\n                'message': 'Max recovery attempts reached',\n                'attempts': attempts\n            }\n        \n        self._recovery_attempts[node_id] = attempts + 1\n        \n        # Perform recovery (placeholder for actual implementation)\n        logger.info(f\"Triggering recovery for node {node_id} (attempt {attempts + 1})\")\n        \n        return {\n            'success': True,\n            'node_id': node_id,\n            'message': 'Recovery triggered',\n            'attempts': attempts + 1\n        }\n    \n    def reset_attempts(self, node_id: str) -> None:\n        \"\"\"Reset recovery attempts for a node.\"\"\"\n        if node_id in self._recovery_attempts:\n            del self._recovery_attempts[node_id]\n",
            "vitalops_orchestrator/vitalops/coordinators/performance.py": "\"\"\"Performance coordinator for VitalOps Orchestrator.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, List, Optional\n\nfrom vitalops.services.metric_collector import MetricCollector\n\nlogger = logging.getLogger(__name__)\n\n\nclass PerformanceCoordinator:\n    \"\"\"Coordinates performance monitoring and analysis.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.metric_collector = MetricCollector(config)\n        \n        logger.info(\"PerformanceCoordinator initialized\")\n    \n    def get_node_metrics(self, node_id: str) -> Dict[str, float]:\n        \"\"\"Get current metrics for a node.\n        \n        Args:\n            node_id: ID of the node\n            \n        Returns:\n            Dictionary of metric values\n        \"\"\"\n        return self.metric_collector.collect_metrics(node_id)\n    \n    def get_cluster_metrics(self, node_ids: List[str]) -> Dict[str, Any]:\n        \"\"\"Get aggregated metrics for a cluster of nodes.\n        \n        Args:\n            node_ids: List of node IDs\n            \n        Returns:\n            Dictionary with aggregated metrics\n        \"\"\"\n        all_metrics = self.metric_collector.collect_metrics_batch(node_ids)\n        \n        # Aggregate metrics\n        aggregated = {}\n        metric_names = set()\n        \n        for node_metrics in all_metrics.values():\n            metric_names.update(node_metrics.keys())\n        \n        for metric_name in metric_names:\n            values = [\n                m.get(metric_name, 0) \n                for m in all_metrics.values() \n                if metric_name in m\n            ]\n            if values:\n                aggregated[metric_name] = {\n                    'avg': sum(values) / len(values),\n                    'min': min(values),\n                    'max': max(values)\n                }\n        \n        return {\n            'node_count': len(node_ids),\n            'metrics': aggregated\n        }\n"
          },
          "generated_files": [
            "vitalops_orchestrator/config.yaml",
            "vitalops_orchestrator/vitalops/models/domain.py",
            "vitalops_orchestrator/vitalops/interfaces/api.py",
            "vitalops_orchestrator/vitalops/coordinators/deployment.py",
            "vitalops_orchestrator/vitalops/policy_engine/handlers.py",
            "vitalops_orchestrator/vitalops/services/metric_collector.py",
            "vitalops_orchestrator/vitalops/services/notification_gateway.py",
            "vitalops_orchestrator/tests/test_coordinators.py",
            "vitalops_orchestrator/vitalops/core/eventing.py",
            "vitalops_orchestrator/vitalops/coordinators/recovery.py",
            "vitalops_orchestrator/vitalops/coordinators/performance.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7705016775842787,
                "dependency_traversal_accuracy": 0.7445406288926719,
                "cross_file_reasoning_depth": 0.33257575757575764,
                "system_thinking_score": 0.645662270433035,
                "robustness_score": 0.17366482504604053,
                "comprehensiveness_score": 0.7212946780922314,
                "innovation_score": 0.4131560773480663,
                "solution_elegance_score": 0.4988073121981015
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09631270969803483,
                "dependency_traversal_weighted": 0.09306757861158399,
                "cross_file_reasoning_weighted": 0.041571969696969704,
                "system_thinking_weighted": 0.08070778380412938,
                "robustness_weighted": 0.021708103130755066,
                "comprehensiveness_weighted": 0.09016183476152892,
                "innovation_weighted": 0.05164450966850829,
                "solution_elegance_weighted": 0.062350914024762685
              },
              "total_software_engineering_score": 0.5375254033962729
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.6958315372467041,
                "errors": [
                  "  File \"vitalops_orchestrator/config.py\", line 3",
                  "    server:",
                  "           ^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "vitalops_orchestrator/config.yaml",
                  "vitalops_orchestrator/vitalops/models/domain.py",
                  "vitalops_orchestrator/vitalops/interfaces/api.py",
                  "vitalops_orchestrator/vitalops/coordinators/deployment.py",
                  "vitalops_orchestrator/vitalops/policy_engine/handlers.py",
                  "vitalops_orchestrator/vitalops/services/metric_collector.py",
                  "vitalops_orchestrator/vitalops/services/notification_gateway.py",
                  "vitalops_orchestrator/tests/test_coordinators.py",
                  "vitalops_orchestrator/vitalops/core/eventing.py",
                  "vitalops_orchestrator/vitalops/coordinators/recovery.py",
                  "vitalops_orchestrator/vitalops/coordinators/performance.py"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 11,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 11 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.30366001050972147,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.30366001050972147,
                "idc_weight": 0.2,
                "total_functional_score": 0.40073200210194426
              }
            },
            "code_quality_details": {
              "files_analyzed": 11,
              "quality_checks": {
                "vitalops_orchestrator/config.yaml": {
                  "line_count": 57,
                  "non_empty_lines": 48,
                  "comment_lines": 1,
                  "comment_ratio": 0.020833333333333332,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.7
                },
                "vitalops_orchestrator/vitalops/models/domain.py": {
                  "line_count": 152,
                  "non_empty_lines": 125,
                  "comment_lines": 1,
                  "comment_ratio": 0.008,
                  "function_count": 3,
                  "class_count": 11,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/interfaces/api.py": {
                  "line_count": 208,
                  "non_empty_lines": 164,
                  "comment_lines": 4,
                  "comment_ratio": 0.024390243902439025,
                  "function_count": 9,
                  "class_count": 0,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/coordinators/deployment.py": {
                  "line_count": 361,
                  "non_empty_lines": 293,
                  "comment_lines": 16,
                  "comment_ratio": 0.05460750853242321,
                  "function_count": 14,
                  "class_count": 1,
                  "import_count": 20,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/policy_engine/handlers.py": {
                  "line_count": 241,
                  "non_empty_lines": 184,
                  "comment_lines": 4,
                  "comment_ratio": 0.021739130434782608,
                  "function_count": 17,
                  "class_count": 7,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/services/metric_collector.py": {
                  "line_count": 183,
                  "non_empty_lines": 145,
                  "comment_lines": 14,
                  "comment_ratio": 0.09655172413793103,
                  "function_count": 9,
                  "class_count": 1,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/services/notification_gateway.py": {
                  "line_count": 194,
                  "non_empty_lines": 157,
                  "comment_lines": 7,
                  "comment_ratio": 0.044585987261146494,
                  "function_count": 9,
                  "class_count": 1,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/tests/test_coordinators.py": {
                  "line_count": 550,
                  "non_empty_lines": 444,
                  "comment_lines": 21,
                  "comment_ratio": 0.0472972972972973,
                  "function_count": 26,
                  "class_count": 7,
                  "import_count": 21,
                  "quality_score": 0.6
                },
                "vitalops_orchestrator/vitalops/core/eventing.py": {
                  "line_count": 101,
                  "non_empty_lines": 79,
                  "comment_lines": 3,
                  "comment_ratio": 0.0379746835443038,
                  "function_count": 5,
                  "class_count": 6,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/coordinators/recovery.py": {
                  "line_count": 59,
                  "non_empty_lines": 43,
                  "comment_lines": 1,
                  "comment_ratio": 0.023255813953488372,
                  "function_count": 3,
                  "class_count": 1,
                  "import_count": 3,
                  "quality_score": 0.7999999999999999
                },
                "vitalops_orchestrator/vitalops/coordinators/performance.py": {
                  "line_count": 66,
                  "non_empty_lines": 48,
                  "comment_lines": 1,
                  "comment_ratio": 0.020833333333333332,
                  "function_count": 3,
                  "class_count": 1,
                  "import_count": 5,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7809090909090908,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8776785714285715,
                "multi_session_memory_retention": 0.8538610038610039
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.43883928571428577,
                "multi_session_memory_retention_weighted": 0.42693050193050197
              },
              "total_longcontext_utilization_score": 0.8657697876447877
            }
          },
          "timestamp": "2026-01-14T21:25:56.780151"
        }
      }
    },
    "python_api_rest_easy_078_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_api_rest_easy_078_feature_implementation_expert_01",
          "scenario_title": "Implement Per-Client Rate Limiting for API Endpoints",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.4961628741401457,
          "functional_correctness_score": 0.41559210526315793,
          "code_quality_score": 0.7999999999999999,
          "longcontext_utilization_score": 0.5665104166666668,
          "total_score": 2.698969114508362,
          "generation_time": 48.27198314666748,
          "code_files_generated": 4,
          "total_lines_generated": 389,
          "parsing_success": true,
          "solution_code": {
            "utilichain/middleware/__init__.py": "\"\"\"Middleware package for UtiliChain API Hub.\"\"\"\n\nfrom utilichain.middleware.rate_limiter import RateLimiter, RateLimitMiddleware\n\n__all__ = [\"RateLimiter\", \"RateLimitMiddleware\"]\n",
            "utilichain/middleware/rate_limiter.py": "\"\"\"Rate limiting middleware for UtiliChain API Hub.\n\nImplements a fixed-window counter algorithm for per-client rate limiting.\n\"\"\"\n\nimport os\nimport time\nfrom typing import Dict, Tuple, Optional\nfrom fastapi import Request, Response\nfrom fastapi.responses import JSONResponse\nfrom starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\n\n\nclass RateLimiter:\n    \"\"\"Fixed-window counter rate limiter.\n    \n    Tracks request counts per client identifier (API key or IP address)\n    within a 60-second window.\n    \"\"\"\n    \n    WINDOW_SIZE_SECONDS = 60\n    \n    def __init__(self, requests_per_minute: int = 60):\n        \"\"\"Initialize the rate limiter.\n        \n        Args:\n            requests_per_minute: Maximum number of requests allowed per minute.\n        \"\"\"\n        self.requests_per_minute = requests_per_minute\n        # Storage format: {client_id: (request_count, window_start_timestamp)}\n        self._storage: Dict[str, Tuple[int, float]] = {}\n    \n    def _get_window_start(self, current_time: float) -> float:\n        \"\"\"Calculate the start of the current window.\n        \n        Args:\n            current_time: Current Unix timestamp.\n            \n        Returns:\n            Unix timestamp of the window start.\n        \"\"\"\n        return (current_time // self.WINDOW_SIZE_SECONDS) * self.WINDOW_SIZE_SECONDS\n    \n    def _cleanup_expired(self, current_time: float) -> None:\n        \"\"\"Remove expired entries from storage.\n        \n        Args:\n            current_time: Current Unix timestamp.\n        \"\"\"\n        current_window = self._get_window_start(current_time)\n        expired_keys = [\n            key for key, (_, window_start) in self._storage.items()\n            if window_start < current_window\n        ]\n        for key in expired_keys:\n            del self._storage[key]\n    \n    def check_rate_limit(self, client_id: str) -> Tuple[bool, int, int, int]:\n        \"\"\"Check if a client has exceeded their rate limit.\n        \n        Args:\n            client_id: Unique identifier for the client (API key or IP).\n            \n        Returns:\n            Tuple of (is_allowed, limit, remaining, reset_timestamp)\n        \"\"\"\n        current_time = time.time()\n        current_window = self._get_window_start(current_time)\n        reset_timestamp = int(current_window + self.WINDOW_SIZE_SECONDS)\n        \n        # Periodic cleanup\n        self._cleanup_expired(current_time)\n        \n        # Get current count for client\n        if client_id in self._storage:\n            count, window_start = self._storage[client_id]\n            \n            # Check if we're in a new window\n            if window_start < current_window:\n                # Reset for new window\n                count = 0\n                window_start = current_window\n        else:\n            count = 0\n            window_start = current_window\n        \n        # Check if limit exceeded\n        if count >= self.requests_per_minute:\n            remaining = 0\n            return (False, self.requests_per_minute, remaining, reset_timestamp)\n        \n        # Increment count\n        count += 1\n        self._storage[client_id] = (count, window_start)\n        \n        remaining = max(0, self.requests_per_minute - count)\n        return (True, self.requests_per_minute, remaining, reset_timestamp)\n    \n    def get_client_identifier(self, request: Request) -> str:\n        \"\"\"Extract client identifier from request.\n        \n        Uses API key if present, otherwise falls back to IP address.\n        \n        Args:\n            request: The incoming FastAPI request.\n            \n        Returns:\n            Client identifier string.\n        \"\"\"\n        # Check for API key in header\n        api_key = request.headers.get(\"X-API-Key\")\n        if api_key:\n            return f\"api_key:{api_key}\"\n        \n        # Fall back to IP address\n        # Handle X-Forwarded-For for proxied requests\n        forwarded_for = request.headers.get(\"X-Forwarded-For\")\n        if forwarded_for:\n            # Take the first IP in the chain (original client)\n            client_ip = forwarded_for.split(\",\")[0].strip()\n        else:\n            client_ip = request.client.host if request.client else \"unknown\"\n        \n        return f\"ip:{client_ip}\"\n\n\nclass RateLimitMiddleware(BaseHTTPMiddleware):\n    \"\"\"FastAPI middleware for rate limiting.\"\"\"\n    \n    def __init__(self, app, rate_limiter: Optional[RateLimiter] = None):\n        \"\"\"Initialize the middleware.\n        \n        Args:\n            app: The FastAPI application.\n            rate_limiter: Optional RateLimiter instance. If not provided,\n                         creates one using RATE_LIMIT_PER_MINUTE env var.\n        \"\"\"\n        super().__init__(app)\n        \n        if rate_limiter is None:\n            # Get rate limit from environment variable\n            rate_limit = int(os.getenv(\"RATE_LIMIT_PER_MINUTE\", \"60\"))\n            self.rate_limiter = RateLimiter(requests_per_minute=rate_limit)\n        else:\n            self.rate_limiter = rate_limiter\n    \n    async def dispatch(\n        self, request: Request, call_next: RequestResponseEndpoint\n    ) -> Response:\n        \"\"\"Process the request and apply rate limiting.\n        \n        Args:\n            request: The incoming request.\n            call_next: The next middleware/endpoint to call.\n            \n        Returns:\n            The response with rate limit headers or 429 if limit exceeded.\n        \"\"\"\n        # Get client identifier\n        client_id = self.rate_limiter.get_client_identifier(request)\n        \n        # Check rate limit\n        is_allowed, limit, remaining, reset_timestamp = self.rate_limiter.check_rate_limit(\n            client_id\n        )\n        \n        if not is_allowed:\n            # Return 429 Too Many Requests\n            response = JSONResponse(\n                status_code=429,\n                content={\"detail\": \"Too Many Requests\"}\n            )\n            response.headers[\"X-RateLimit-Limit\"] = str(limit)\n            response.headers[\"X-RateLimit-Remaining\"] = str(remaining)\n            response.headers[\"X-RateLimit-Reset\"] = str(reset_timestamp)\n            return response\n        \n        # Process the request\n        response = await call_next(request)\n        \n        # Add rate limit headers to successful response\n        response.headers[\"X-RateLimit-Limit\"] = str(limit)\n        response.headers[\"X-RateLimit-Remaining\"] = str(remaining)\n        response.headers[\"X-RateLimit-Reset\"] = str(reset_timestamp)\n        \n        return response\n",
            "utilichain/main.py": "\"\"\"Main application module for UtiliChain API Hub.\n\nThis module initializes and configures the FastAPI application,\nincluding middleware, routers, and startup/shutdown events.\n\"\"\"\n\nimport os\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom utilichain.middleware.rate_limiter import RateLimitMiddleware\n\n# Application metadata\nAPP_TITLE = \"UtiliChain API Hub\"\nAPP_DESCRIPTION = \"A unified API gateway for utility chain services\"\nAPP_VERSION = \"0.1.0\"\n\n# Initialize FastAPI application\napp = FastAPI(\n    title=APP_TITLE,\n    description=APP_DESCRIPTION,\n    version=APP_VERSION,\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\",\n    openapi_url=\"/openapi.json\"\n)\n\n# Configure CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=os.getenv(\"CORS_ORIGINS\", \"*\").split(\",\"),\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add rate limiting middleware\napp.add_middleware(RateLimitMiddleware)\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Handle application startup tasks.\"\"\"\n    print(f\"Starting {APP_TITLE} v{APP_VERSION}\")\n    rate_limit = os.getenv(\"RATE_LIMIT_PER_MINUTE\", \"60\")\n    print(f\"Rate limiting enabled: {rate_limit} requests per minute\")\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    \"\"\"Handle application shutdown tasks.\"\"\"\n    print(f\"Shutting down {APP_TITLE}\")\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint returning API information.\"\"\"\n    return {\n        \"name\": APP_TITLE,\n        \"version\": APP_VERSION,\n        \"status\": \"operational\"\n    }\n\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint for monitoring.\"\"\"\n    return {\"status\": \"healthy\"}\n",
            "docs/api_reference.md": "# API Reference\n\nThis document provides detailed information about the UtiliChain API Hub endpoints and features.\n\n## Base URL\n\nThe API is available at the following base URL:\n\n- **Development**: `http://localhost:8000`\n- **Production**: `https://api.utilichain.example.com`\n\n## Authentication\n\nThe API supports authentication via API keys. Include your API key in the request header:\n\n```\nX-API-Key: your-api-key-here\n```\n\n## Rate Limiting\n\nThe UtiliChain API Hub implements rate limiting to ensure fair usage and protect against abuse.\n\n### How It Works\n\nRate limiting uses a **fixed-window counter** algorithm with a 60-second window. Each client is allowed a maximum number of requests within each window period.\n\n### Rate Limit Configuration\n\n- **Default Limit**: 60 requests per minute\n- **Window Size**: 60 seconds (1 minute)\n\nThe rate limit can be configured via the `RATE_LIMIT_PER_MINUTE` environment variable.\n\n### Client Identification\n\n- **Authenticated Requests**: Rate limits are applied per API key (identified by the `X-API-Key` header)\n- **Unauthenticated Requests**: Rate limits are applied per client IP address\n\n### Rate Limit Response Headers\n\nEvery API response includes the following headers to help you track your rate limit status:\n\n| Header | Description |\n|--------|-------------|\n| `X-RateLimit-Limit` | The maximum number of requests allowed in the current window |\n| `X-RateLimit-Remaining` | The number of requests remaining in the current window |\n| `X-RateLimit-Reset` | Unix timestamp (in seconds) indicating when the rate limit window resets |\n\n### Rate Limit Exceeded Response\n\nWhen you exceed the rate limit, the API responds with:\n\n- **HTTP Status Code**: `429 Too Many Requests`\n- **Response Body**:\n\n```json\n{\n    \"detail\": \"Too Many Requests\"\n}\n```\n\n### Best Practices\n\n1. **Monitor Headers**: Check the `X-RateLimit-Remaining` header to track your usage\n2. **Implement Backoff**: If you receive a 429 response, wait until the `X-RateLimit-Reset` timestamp before retrying\n3. **Cache Responses**: Where possible, cache API responses to reduce the number of requests\n4. **Use API Keys**: Authenticated requests with API keys have their own rate limit quota, separate from IP-based limits\n\n## Endpoints\n\n### Root Endpoint\n\n```\nGET /\n```\n\nReturns basic API information.\n\n**Response:**\n\n```json\n{\n    \"name\": \"UtiliChain API Hub\",\n    \"version\": \"0.1.0\",\n    \"status\": \"operational\"\n}\n```\n\n### Health Check\n\n```\nGET /health\n```\n\nReturns the health status of the API.\n\n**Response:**\n\n```json\n{\n    \"status\": \"healthy\"\n}\n```\n\n## Error Responses\n\nThe API uses standard HTTP status codes to indicate the success or failure of requests.\n\n| Status Code | Description |\n|-------------|-------------|\n| 200 | Success |\n| 400 | Bad Request - Invalid parameters |\n| 401 | Unauthorized - Invalid or missing API key |\n| 403 | Forbidden - Access denied |\n| 404 | Not Found - Resource does not exist |\n| 429 | Too Many Requests - Rate limit exceeded |\n| 500 | Internal Server Error |\n\n## OpenAPI Specification\n\nThe complete OpenAPI specification is available at:\n\n- **Swagger UI**: `/docs`\n- **ReDoc**: `/redoc`\n- **OpenAPI JSON**: `/openapi.json`\n"
          },
          "generated_files": [
            "utilichain/middleware/__init__.py",
            "utilichain/middleware/rate_limiter.py",
            "utilichain/main.py",
            "docs/api_reference.md"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.6703571428571429,
                "dependency_traversal_accuracy": 0.6372489239598278,
                "cross_file_reasoning_depth": 0.4641666666666667,
                "system_thinking_score": 0.47016472184417896,
                "robustness_score": 0.356426735218509,
                "comprehensiveness_score": 0.584293059125964,
                "innovation_score": 0.24587082262210797,
                "solution_elegance_score": 0.5407749208267685
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.08379464285714286,
                "dependency_traversal_weighted": 0.07965611549497847,
                "cross_file_reasoning_weighted": 0.05802083333333334,
                "system_thinking_weighted": 0.05877059023052237,
                "robustness_weighted": 0.04455334190231362,
                "comprehensiveness_weighted": 0.0730366323907455,
                "innovation_weighted": 0.030733852827763496,
                "solution_elegance_weighted": 0.06759686510334606
              },
              "total_software_engineering_score": 0.4961628741401457
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.2547798156738281,
                "errors": [
                  "  File \"docs/api_reference.py\", line 3",
                  "    This document provides detailed information about the UtiliChain API Hub endpoints and features.",
                  "         ^^^^^^^^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "utilichain/middleware/__init__.py",
                  "utilichain/middleware/rate_limiter.py",
                  "utilichain/main.py",
                  "docs/api_reference.md"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 4,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 4 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.3779605263157895,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.3779605263157895,
                "idc_weight": 0.2,
                "total_functional_score": 0.41559210526315793
              }
            },
            "code_quality_details": {
              "files_analyzed": 4,
              "quality_checks": {
                "utilichain/middleware/__init__.py": {
                  "line_count": 6,
                  "non_empty_lines": 3,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 2,
                  "quality_score": 0.5
                },
                "utilichain/middleware/rate_limiter.py": {
                  "line_count": 187,
                  "non_empty_lines": 145,
                  "comment_lines": 17,
                  "comment_ratio": 0.11724137931034483,
                  "function_count": 7,
                  "class_count": 2,
                  "import_count": 13,
                  "quality_score": 0.9999999999999999
                },
                "utilichain/main.py": {
                  "line_count": 69,
                  "non_empty_lines": 53,
                  "comment_lines": 4,
                  "comment_ratio": 0.07547169811320754,
                  "function_count": 4,
                  "class_count": 0,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "docs/api_reference.md": {
                  "line_count": 127,
                  "non_empty_lines": 84,
                  "comment_lines": 15,
                  "comment_ratio": 0.17857142857142858,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 1,
                  "quality_score": 0.8999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7999999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.5329166666666667,
                "multi_session_memory_retention": 0.6001041666666668
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.26645833333333335,
                "multi_session_memory_retention_weighted": 0.3000520833333334
              },
              "total_longcontext_utilization_score": 0.5665104166666668
            }
          },
          "timestamp": "2026-01-14T21:00:42.685032"
        }
      }
    },
    "python_game_simulation_medium_033_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_game_simulation_medium_033_feature_implementation_expert_01",
          "scenario_title": "Implement Programmable Force Fields",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.4910993182490914,
          "functional_correctness_score": 0.35524200229135455,
          "code_quality_score": 0.8099999999999998,
          "longcontext_utilization_score": 0.8286609299516907,
          "total_score": 2.73939210491106,
          "generation_time": 220.02771925926208,
          "code_files_generated": 7,
          "total_lines_generated": 2009,
          "parsing_success": true,
          "solution_code": {
            "physage_academy/src/physage_academy/engine/scene.py": "\"\"\"Scene management for PhySage Academy.\"\"\"\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Any, Optional\nimport uuid\n\n\n@dataclass\nclass Vec2d:\n    \"\"\"Simple 2D vector class.\"\"\"\n    x: float = 0.0\n    y: float = 0.0\n    \n    def __add__(self, other: 'Vec2d') -> 'Vec2d':\n        return Vec2d(self.x + other.x, self.y + other.y)\n    \n    def __sub__(self, other: 'Vec2d') -> 'Vec2d':\n        return Vec2d(self.x - other.x, self.y - other.y)\n    \n    def __mul__(self, scalar: float) -> 'Vec2d':\n        return Vec2d(self.x * scalar, self.y * scalar)\n    \n    def __rmul__(self, scalar: float) -> 'Vec2d':\n        return self.__mul__(scalar)\n    \n    @property\n    def length_sq(self) -> float:\n        \"\"\"Return squared length of vector.\"\"\"\n        return self.x * self.x + self.y * self.y\n    \n    @property\n    def length(self) -> float:\n        \"\"\"Return length of vector.\"\"\"\n        import math\n        return math.sqrt(self.length_sq)\n    \n    def normalized(self) -> 'Vec2d':\n        \"\"\"Return normalized vector.\"\"\"\n        l = self.length\n        if l == 0:\n            return Vec2d(0, 0)\n        return Vec2d(self.x / l, self.y / l)\n    \n    def distance_to(self, other: 'Vec2d') -> float:\n        \"\"\"Return distance to another vector.\"\"\"\n        return (self - other).length\n\n\n@dataclass\nclass PhysicsBody:\n    \"\"\"Represents a physics body in the scene.\"\"\"\n    id: str\n    position: Vec2d\n    velocity: Vec2d = field(default_factory=lambda: Vec2d(0, 0))\n    mass: float = 1.0\n    is_static: bool = False\n    shape_type: str = \"circle\"\n    radius: float = 10.0\n    width: float = 20.0\n    height: float = 20.0\n    restitution: float = 0.5\n    friction: float = 0.3\n    \n    def apply_force(self, force: Vec2d) -> None:\n        \"\"\"Apply a force to this body.\"\"\"\n        if not self.is_static and self.mass > 0:\n            acceleration = Vec2d(force.x / self.mass, force.y / self.mass)\n            self.velocity = self.velocity + acceleration\n\n\n@dataclass\nclass ForceField:\n    \"\"\"Represents a programmable force field in the scene.\"\"\"\n    id: str\n    position: Vec2d\n    radius: float\n    script_path: str\n    enabled: bool = True\n    \n    def contains(self, point: Vec2d) -> bool:\n        \"\"\"Check if a point is within the force field radius.\"\"\"\n        return self.position.distance_to(point) <= self.radius\n\n\n@dataclass\nclass SceneObject:\n    \"\"\"Represents a generic scene object.\"\"\"\n    id: str\n    name: str\n    position: Vec2d\n    rotation: float = 0.0\n    scale: Vec2d = field(default_factory=lambda: Vec2d(1.0, 1.0))\n    visible: bool = True\n    layer: int = 0\n    tags: List[str] = field(default_factory=list)\n    properties: Dict[str, Any] = field(default_factory=dict)\n    physics_body: Optional[PhysicsBody] = None\n\n\nclass Scene:\n    \"\"\"Manages all objects and entities in a scene.\"\"\"\n    \n    def __init__(self, name: str = \"Untitled Scene\"):\n        self.name = name\n        self.id = str(uuid.uuid4())\n        self._objects: Dict[str, SceneObject] = {}\n        self._physics_bodies: Dict[str, PhysicsBody] = {}\n        self._force_fields: Dict[str, ForceField] = {}\n        self._layers: Dict[int, List[str]] = {}\n        self.gravity = Vec2d(0, 9.8)\n        self.bounds = (800, 600)\n    \n    def add_object(self, obj: SceneObject) -> None:\n        \"\"\"Add a scene object.\"\"\"\n        self._objects[obj.id] = obj\n        if obj.layer not in self._layers:\n            self._layers[obj.layer] = []\n        self._layers[obj.layer].append(obj.id)\n        \n        if obj.physics_body:\n            self._physics_bodies[obj.physics_body.id] = obj.physics_body\n    \n    def remove_object(self, object_id: str) -> Optional[SceneObject]:\n        \"\"\"Remove a scene object by ID.\"\"\"\n        if object_id in self._objects:\n            obj = self._objects.pop(object_id)\n            if obj.layer in self._layers and object_id in self._layers[obj.layer]:\n                self._layers[obj.layer].remove(object_id)\n            if obj.physics_body and obj.physics_body.id in self._physics_bodies:\n                del self._physics_bodies[obj.physics_body.id]\n            return obj\n        return None\n    \n    def get_object(self, object_id: str) -> Optional[SceneObject]:\n        \"\"\"Get a scene object by ID.\"\"\"\n        return self._objects.get(object_id)\n    \n    def get_all_objects(self) -> List[SceneObject]:\n        \"\"\"Get all scene objects.\"\"\"\n        return list(self._objects.values())\n    \n    def add_physics_body(self, body: PhysicsBody) -> None:\n        \"\"\"Add a physics body directly.\"\"\"\n        self._physics_bodies[body.id] = body\n    \n    def remove_physics_body(self, body_id: str) -> Optional[PhysicsBody]:\n        \"\"\"Remove a physics body by ID.\"\"\"\n        return self._physics_bodies.pop(body_id, None)\n    \n    def get_physics_body(self, body_id: str) -> Optional[PhysicsBody]:\n        \"\"\"Get a physics body by ID.\"\"\"\n        return self._physics_bodies.get(body_id)\n    \n    def get_all_physics_bodies(self) -> List[PhysicsBody]:\n        \"\"\"Get all physics bodies.\"\"\"\n        return list(self._physics_bodies.values())\n    \n    def get_dynamic_bodies(self) -> List[PhysicsBody]:\n        \"\"\"Get all dynamic (non-static) physics bodies.\"\"\"\n        return [b for b in self._physics_bodies.values() if not b.is_static]\n    \n    def add_force_field(self, force_field: ForceField) -> None:\n        \"\"\"Add a force field to the scene.\"\"\"\n        self._force_fields[force_field.id] = force_field\n    \n    def remove_force_field(self, field_id: str) -> Optional[ForceField]:\n        \"\"\"Remove a force field by ID.\"\"\"\n        return self._force_fields.pop(field_id, None)\n    \n    def get_force_field(self, field_id: str) -> Optional[ForceField]:\n        \"\"\"Get a force field by ID.\"\"\"\n        return self._force_fields.get(field_id)\n    \n    def get_all_force_fields(self) -> List[ForceField]:\n        \"\"\"Get all force fields.\"\"\"\n        return list(self._force_fields.values())\n    \n    def clear(self) -> None:\n        \"\"\"Clear all objects from the scene.\"\"\"\n        self._objects.clear()\n        self._physics_bodies.clear()\n        self._force_fields.clear()\n        self._layers.clear()\n    \n    def find_objects_by_tag(self, tag: str) -> List[SceneObject]:\n        \"\"\"Find all objects with a specific tag.\"\"\"\n        return [obj for obj in self._objects.values() if tag in obj.tags]\n    \n    def find_objects_in_layer(self, layer: int) -> List[SceneObject]:\n        \"\"\"Find all objects in a specific layer.\"\"\"\n        if layer not in self._layers:\n            return []\n        return [self._objects[oid] for oid in self._layers[layer] if oid in self._objects]\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Serialize scene to dictionary.\"\"\"\n        return {\n            \"name\": self.name,\n            \"id\": self.id,\n            \"gravity\": {\"x\": self.gravity.x, \"y\": self.gravity.y},\n            \"bounds\": self.bounds,\n            \"objects\": [self._serialize_object(obj) for obj in self._objects.values()],\n            \"force_fields\": [self._serialize_force_field(ff) for ff in self._force_fields.values()]\n        }\n    \n    def _serialize_object(self, obj: SceneObject) -> Dict[str, Any]:\n        \"\"\"Serialize a scene object.\"\"\"\n        data = {\n            \"id\": obj.id,\n            \"name\": obj.name,\n            \"position\": {\"x\": obj.position.x, \"y\": obj.position.y},\n            \"rotation\": obj.rotation,\n            \"scale\": {\"x\": obj.scale.x, \"y\": obj.scale.y},\n            \"visible\": obj.visible,\n            \"layer\": obj.layer,\n            \"tags\": obj.tags,\n            \"properties\": obj.properties\n        }\n        if obj.physics_body:\n            data[\"physics_body\"] = self._serialize_physics_body(obj.physics_body)\n        return data\n    \n    def _serialize_physics_body(self, body: PhysicsBody) -> Dict[str, Any]:\n        \"\"\"Serialize a physics body.\"\"\"\n        return {\n            \"id\": body.id,\n            \"position\": {\"x\": body.position.x, \"y\": body.position.y},\n            \"velocity\": {\"x\": body.velocity.x, \"y\": body.velocity.y},\n            \"mass\": body.mass,\n            \"is_static\": body.is_static,\n            \"shape_type\": body.shape_type,\n            \"radius\": body.radius,\n            \"width\": body.width,\n            \"height\": body.height,\n            \"restitution\": body.restitution,\n            \"friction\": body.friction\n        }\n    \n    def _serialize_force_field(self, ff: ForceField) -> Dict[str, Any]:\n        \"\"\"Serialize a force field.\"\"\"\n        return {\n            \"id\": ff.id,\n            \"position\": {\"x\": ff.position.x, \"y\": ff.position.y},\n            \"radius\": ff.radius,\n            \"script_path\": ff.script_path,\n            \"enabled\": ff.enabled\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Scene':\n        \"\"\"Deserialize scene from dictionary.\"\"\"\n        scene = cls(name=data.get(\"name\", \"Untitled Scene\"))\n        scene.id = data.get(\"id\", str(uuid.uuid4()))\n        \n        if \"gravity\" in data:\n            scene.gravity = Vec2d(data[\"gravity\"][\"x\"], data[\"gravity\"][\"y\"])\n        if \"bounds\" in data:\n            scene.bounds = tuple(data[\"bounds\"])\n        \n        for obj_data in data.get(\"objects\", []):\n            scene.add_object(cls._deserialize_object(obj_data))\n        \n        for ff_data in data.get(\"force_fields\", []):\n            scene.add_force_field(cls._deserialize_force_field(ff_data))\n        \n        return scene\n    \n    @classmethod\n    def _deserialize_object(cls, data: Dict[str, Any]) -> SceneObject:\n        \"\"\"Deserialize a scene object.\"\"\"\n        physics_body = None\n        if \"physics_body\" in data:\n            physics_body = cls._deserialize_physics_body(data[\"physics_body\"])\n        \n        return SceneObject(\n            id=data[\"id\"],\n            name=data[\"name\"],\n            position=Vec2d(data[\"position\"][\"x\"], data[\"position\"][\"y\"]),\n            rotation=data.get(\"rotation\", 0.0),\n            scale=Vec2d(data.get(\"scale\", {}).get(\"x\", 1.0), data.get(\"scale\", {}).get(\"y\", 1.0)),\n            visible=data.get(\"visible\", True),\n            layer=data.get(\"layer\", 0),\n            tags=data.get(\"tags\", []),\n            properties=data.get(\"properties\", {}),\n            physics_body=physics_body\n        )\n    \n    @classmethod\n    def _deserialize_physics_body(cls, data: Dict[str, Any]) -> PhysicsBody:\n        \"\"\"Deserialize a physics body.\"\"\"\n        return PhysicsBody(\n            id=data[\"id\"],\n            position=Vec2d(data[\"position\"][\"x\"], data[\"position\"][\"y\"]),\n            velocity=Vec2d(data.get(\"velocity\", {}).get(\"x\", 0), data.get(\"velocity\", {}).get(\"y\", 0)),\n            mass=data.get(\"mass\", 1.0),\n            is_static=data.get(\"is_static\", False),\n            shape_type=data.get(\"shape_type\", \"circle\"),\n            radius=data.get(\"radius\", 10.0),\n            width=data.get(\"width\", 20.0),\n            height=data.get(\"height\", 20.0),\n            restitution=data.get(\"restitution\", 0.5),\n            friction=data.get(\"friction\", 0.3)\n        )\n    \n    @classmethod\n    def _deserialize_force_field(cls, data: Dict[str, Any]) -> ForceField:\n        \"\"\"Deserialize a force field.\"\"\"\n        return ForceField(\n            id=data[\"id\"],\n            position=Vec2d(data[\"position\"][\"x\"], data[\"position\"][\"y\"]),\n            radius=data[\"radius\"],\n            script_path=data[\"script_path\"],\n            enabled=data.get(\"enabled\", True)\n        )\n",
            "physage_academy/src/physage_academy/editor/commands.py": "\"\"\"Command pattern implementation for editor operations.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\nfrom dataclasses import dataclass\nimport uuid\n\nfrom physage_academy.engine.scene import Scene, SceneObject, PhysicsBody, ForceField, Vec2d\n\n\nclass Command(ABC):\n    \"\"\"Abstract base class for all commands.\"\"\"\n    \n    @abstractmethod\n    def execute(self) -> Any:\n        \"\"\"Execute the command.\"\"\"\n        pass\n    \n    @abstractmethod\n    def undo(self) -> None:\n        \"\"\"Undo the command.\"\"\"\n        pass\n    \n    @abstractmethod\n    def redo(self) -> None:\n        \"\"\"Redo the command.\"\"\"\n        pass\n\n\nclass CommandHistory:\n    \"\"\"Manages command history for undo/redo functionality.\"\"\"\n    \n    def __init__(self, max_history: int = 100):\n        self._history: List[Command] = []\n        self._redo_stack: List[Command] = []\n        self._max_history = max_history\n    \n    def execute(self, command: Command) -> Any:\n        \"\"\"Execute a command and add it to history.\"\"\"\n        result = command.execute()\n        self._history.append(command)\n        self._redo_stack.clear()\n        \n        if len(self._history) > self._max_history:\n            self._history.pop(0)\n        \n        return result\n    \n    def undo(self) -> bool:\n        \"\"\"Undo the last command.\"\"\"\n        if not self._history:\n            return False\n        \n        command = self._history.pop()\n        command.undo()\n        self._redo_stack.append(command)\n        return True\n    \n    def redo(self) -> bool:\n        \"\"\"Redo the last undone command.\"\"\"\n        if not self._redo_stack:\n            return False\n        \n        command = self._redo_stack.pop()\n        command.redo()\n        self._history.append(command)\n        return True\n    \n    def can_undo(self) -> bool:\n        \"\"\"Check if undo is available.\"\"\"\n        return len(self._history) > 0\n    \n    def can_redo(self) -> bool:\n        \"\"\"Check if redo is available.\"\"\"\n        return len(self._redo_stack) > 0\n    \n    def clear(self) -> None:\n        \"\"\"Clear all history.\"\"\"\n        self._history.clear()\n        self._redo_stack.clear()\n\n\nclass CreateObjectCommand(Command):\n    \"\"\"Command to create a new scene object.\"\"\"\n    \n    def __init__(self, scene: Scene, name: str, position: Vec2d, **kwargs):\n        self._scene = scene\n        self._name = name\n        self._position = position\n        self._kwargs = kwargs\n        self._object_id: Optional[str] = None\n        self._created_object: Optional[SceneObject] = None\n    \n    def execute(self) -> SceneObject:\n        \"\"\"Create and add the object to the scene.\"\"\"\n        self._object_id = str(uuid.uuid4())\n        self._created_object = SceneObject(\n            id=self._object_id,\n            name=self._name,\n            position=self._position,\n            **self._kwargs\n        )\n        self._scene.add_object(self._created_object)\n        return self._created_object\n    \n    def undo(self) -> None:\n        \"\"\"Remove the created object.\"\"\"\n        if self._object_id:\n            self._scene.remove_object(self._object_id)\n    \n    def redo(self) -> None:\n        \"\"\"Re-add the object.\"\"\"\n        if self._created_object:\n            self._scene.add_object(self._created_object)\n\n\nclass DeleteObjectCommand(Command):\n    \"\"\"Command to delete a scene object.\"\"\"\n    \n    def __init__(self, scene: Scene, object_id: str):\n        self._scene = scene\n        self._object_id = object_id\n        self._deleted_object: Optional[SceneObject] = None\n    \n    def execute(self) -> bool:\n        \"\"\"Delete the object from the scene.\"\"\"\n        self._deleted_object = self._scene.remove_object(self._object_id)\n        return self._deleted_object is not None\n    \n    def undo(self) -> None:\n        \"\"\"Restore the deleted object.\"\"\"\n        if self._deleted_object:\n            self._scene.add_object(self._deleted_object)\n    \n    def redo(self) -> None:\n        \"\"\"Re-delete the object.\"\"\"\n        self._scene.remove_object(self._object_id)\n\n\nclass MoveObjectCommand(Command):\n    \"\"\"Command to move a scene object.\"\"\"\n    \n    def __init__(self, scene: Scene, object_id: str, new_position: Vec2d):\n        self._scene = scene\n        self._object_id = object_id\n        self._new_position = new_position\n        self._old_position: Optional[Vec2d] = None\n    \n    def execute(self) -> bool:\n        \"\"\"Move the object to the new position.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj:\n            self._old_position = Vec2d(obj.position.x, obj.position.y)\n            obj.position = self._new_position\n            if obj.physics_body:\n                obj.physics_body.position = self._new_position\n            return True\n        return False\n    \n    def undo(self) -> None:\n        \"\"\"Move the object back to its original position.\"\"\"\n        if self._old_position:\n            obj = self._scene.get_object(self._object_id)\n            if obj:\n                obj.position = self._old_position\n                if obj.physics_body:\n                    obj.physics_body.position = self._old_position\n    \n    def redo(self) -> None:\n        \"\"\"Re-apply the move.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj:\n            obj.position = self._new_position\n            if obj.physics_body:\n                obj.physics_body.position = self._new_position\n\n\nclass CreatePhysicsBodyCommand(Command):\n    \"\"\"Command to create a physics body.\"\"\"\n    \n    def __init__(self, scene: Scene, position: Vec2d, mass: float = 1.0,\n                 is_static: bool = False, shape_type: str = \"circle\", **kwargs):\n        self._scene = scene\n        self._position = position\n        self._mass = mass\n        self._is_static = is_static\n        self._shape_type = shape_type\n        self._kwargs = kwargs\n        self._body_id: Optional[str] = None\n        self._created_body: Optional[PhysicsBody] = None\n    \n    def execute(self) -> PhysicsBody:\n        \"\"\"Create and add the physics body.\"\"\"\n        self._body_id = str(uuid.uuid4())\n        self._created_body = PhysicsBody(\n            id=self._body_id,\n            position=self._position,\n            mass=self._mass,\n            is_static=self._is_static,\n            shape_type=self._shape_type,\n            **self._kwargs\n        )\n        self._scene.add_physics_body(self._created_body)\n        return self._created_body\n    \n    def undo(self) -> None:\n        \"\"\"Remove the created physics body.\"\"\"\n        if self._body_id:\n            self._scene.remove_physics_body(self._body_id)\n    \n    def redo(self) -> None:\n        \"\"\"Re-add the physics body.\"\"\"\n        if self._created_body:\n            self._scene.add_physics_body(self._created_body)\n\n\nclass CreateForceFieldCommand(Command):\n    \"\"\"Command to create a programmable force field.\"\"\"\n    \n    def __init__(self, scene: Scene, position: Vec2d, radius: float, script_path: str):\n        self._scene = scene\n        self._position = position\n        self._radius = radius\n        self._script_path = script_path\n        self._field_id: Optional[str] = None\n        self._created_field: Optional[ForceField] = None\n    \n    def execute(self) -> ForceField:\n        \"\"\"Create and add the force field to the scene.\"\"\"\n        self._field_id = str(uuid.uuid4())\n        self._created_field = ForceField(\n            id=self._field_id,\n            position=self._position,\n            radius=self._radius,\n            script_path=self._script_path,\n            enabled=True\n        )\n        self._scene.add_force_field(self._created_field)\n        return self._created_field\n    \n    def undo(self) -> None:\n        \"\"\"Remove the created force field.\"\"\"\n        if self._field_id:\n            self._scene.remove_force_field(self._field_id)\n    \n    def redo(self) -> None:\n        \"\"\"Re-add the force field.\"\"\"\n        if self._created_field:\n            self._scene.add_force_field(self._created_field)\n\n\nclass DeleteForceFieldCommand(Command):\n    \"\"\"Command to delete a force field.\"\"\"\n    \n    def __init__(self, scene: Scene, field_id: str):\n        self._scene = scene\n        self._field_id = field_id\n        self._deleted_field: Optional[ForceField] = None\n    \n    def execute(self) -> bool:\n        \"\"\"Delete the force field from the scene.\"\"\"\n        self._deleted_field = self._scene.remove_force_field(self._field_id)\n        return self._deleted_field is not None\n    \n    def undo(self) -> None:\n        \"\"\"Restore the deleted force field.\"\"\"\n        if self._deleted_field:\n            self._scene.add_force_field(self._deleted_field)\n    \n    def redo(self) -> None:\n        \"\"\"Re-delete the force field.\"\"\"\n        self._scene.remove_force_field(self._field_id)\n\n\nclass ModifyPropertyCommand(Command):\n    \"\"\"Command to modify an object's property.\"\"\"\n    \n    def __init__(self, scene: Scene, object_id: str, property_name: str, new_value: Any):\n        self._scene = scene\n        self._object_id = object_id\n        self._property_name = property_name\n        self._new_value = new_value\n        self._old_value: Any = None\n    \n    def execute(self) -> bool:\n        \"\"\"Modify the property.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj and hasattr(obj, self._property_name):\n            self._old_value = getattr(obj, self._property_name)\n            setattr(obj, self._property_name, self._new_value)\n            return True\n        return False\n    \n    def undo(self) -> None:\n        \"\"\"Restore the old property value.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj and self._old_value is not None:\n            setattr(obj, self._property_name, self._old_value)\n    \n    def redo(self) -> None:\n        \"\"\"Re-apply the property change.\"\"\"\n        obj = self._scene.get_object(self._object_id)\n        if obj:\n            setattr(obj, self._property_name, self._new_value)\n\n\nclass BatchCommand(Command):\n    \"\"\"Command that executes multiple commands as a single unit.\"\"\"\n    \n    def __init__(self, commands: List[Command]):\n        self._commands = commands\n        self._executed = False\n    \n    def execute(self) -> List[Any]:\n        \"\"\"Execute all commands.\"\"\"\n        results = []\n        for cmd in self._commands:\n            results.append(cmd.execute())\n        self._executed = True\n        return results\n    \n    def undo(self) -> None:\n        \"\"\"Undo all commands in reverse order.\"\"\"\n        for cmd in reversed(self._commands):\n            cmd.undo()\n        self._executed = False\n    \n    def redo(self) -> None:\n        \"\"\"Redo all commands.\"\"\"\n        for cmd in self._commands:\n            cmd.redo()\n        self._executed = True\n",
            "physage_academy/src/physage_academy/editor/service.py": "\"\"\"Editor service for PhySage Academy.\"\"\"\nfrom typing import Any, Dict, List, Optional, Tuple\nimport json\nimport os\n\nfrom physage_academy.engine.scene import Scene, SceneObject, PhysicsBody, ForceField, Vec2d\nfrom physage_academy.editor.commands import (\n    Command,\n    CommandHistory,\n    CreateObjectCommand,\n    DeleteObjectCommand,\n    MoveObjectCommand,\n    CreatePhysicsBodyCommand,\n    CreateForceFieldCommand,\n    DeleteForceFieldCommand,\n    ModifyPropertyCommand,\n    BatchCommand\n)\n\n\nclass EditorService:\n    \"\"\"Main editor service that provides high-level editing operations.\"\"\"\n    \n    def __init__(self):\n        self._scene: Optional[Scene] = None\n        self._command_history = CommandHistory()\n        self._selection: List[str] = []\n        self._clipboard: List[SceneObject] = []\n        self._grid_size = 16\n        self._snap_to_grid = False\n        self._is_modified = False\n        self._current_file_path: Optional[str] = None\n    \n    @property\n    def scene(self) -> Optional[Scene]:\n        \"\"\"Get the current scene.\"\"\"\n        return self._scene\n    \n    @property\n    def is_modified(self) -> bool:\n        \"\"\"Check if the scene has unsaved changes.\"\"\"\n        return self._is_modified\n    \n    def new_scene(self, name: str = \"Untitled Scene\") -> Scene:\n        \"\"\"Create a new empty scene.\"\"\"\n        self._scene = Scene(name=name)\n        self._command_history.clear()\n        self._selection.clear()\n        self._is_modified = False\n        self._current_file_path = None\n        return self._scene\n    \n    def load_scene(self, file_path: str) -> Scene:\n        \"\"\"Load a scene from a file.\"\"\"\n        with open(file_path, 'r') as f:\n            data = json.load(f)\n        \n        self._scene = Scene.from_dict(data)\n        self._command_history.clear()\n        self._selection.clear()\n        self._is_modified = False\n        self._current_file_path = file_path\n        return self._scene\n    \n    def save_scene(self, file_path: Optional[str] = None) -> bool:\n        \"\"\"Save the current scene to a file.\"\"\"\n        if not self._scene:\n            return False\n        \n        path = file_path or self._current_file_path\n        if not path:\n            return False\n        \n        with open(path, 'w') as f:\n            json.dump(self._scene.to_dict(), f, indent=2)\n        \n        self._is_modified = False\n        self._current_file_path = path\n        return True\n    \n    def create_object(self, name: str, x: float, y: float, **kwargs) -> Optional[SceneObject]:\n        \"\"\"Create a new scene object.\"\"\"\n        if not self._scene:\n            return None\n        \n        position = self._apply_grid_snap(Vec2d(x, y))\n        command = CreateObjectCommand(self._scene, name, position, **kwargs)\n        obj = self._command_history.execute(command)\n        self._is_modified = True\n        return obj\n    \n    def delete_object(self, object_id: str) -> bool:\n        \"\"\"Delete a scene object.\"\"\"\n        if not self._scene:\n            return False\n        \n        command = DeleteObjectCommand(self._scene, object_id)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n            if object_id in self._selection:\n                self._selection.remove(object_id)\n        return result\n    \n    def move_object(self, object_id: str, x: float, y: float) -> bool:\n        \"\"\"Move a scene object to a new position.\"\"\"\n        if not self._scene:\n            return False\n        \n        new_position = self._apply_grid_snap(Vec2d(x, y))\n        command = MoveObjectCommand(self._scene, object_id, new_position)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n        return result\n    \n    def create_physics_body(self, x: float, y: float, mass: float = 1.0,\n                           is_static: bool = False, shape_type: str = \"circle\",\n                           **kwargs) -> Optional[PhysicsBody]:\n        \"\"\"Create a new physics body.\"\"\"\n        if not self._scene:\n            return None\n        \n        position = self._apply_grid_snap(Vec2d(x, y))\n        command = CreatePhysicsBodyCommand(\n            self._scene, position, mass, is_static, shape_type, **kwargs\n        )\n        body = self._command_history.execute(command)\n        self._is_modified = True\n        return body\n    \n    def create_force_field(self, x: float, y: float, radius: float,\n                          script_path: str) -> Optional[ForceField]:\n        \"\"\"Create a new programmable force field.\n        \n        Args:\n            x: X position of the force field center\n            y: Y position of the force field center\n            radius: Radius of effect for the force field\n            script_path: Path to the Python script defining the force behavior\n        \n        Returns:\n            The created ForceField object, or None if no scene is loaded\n        \"\"\"\n        if not self._scene:\n            return None\n        \n        position = self._apply_grid_snap(Vec2d(x, y))\n        command = CreateForceFieldCommand(self._scene, position, radius, script_path)\n        field = self._command_history.execute(command)\n        self._is_modified = True\n        return field\n    \n    def delete_force_field(self, field_id: str) -> bool:\n        \"\"\"Delete a force field.\"\"\"\n        if not self._scene:\n            return False\n        \n        command = DeleteForceFieldCommand(self._scene, field_id)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n        return result\n    \n    def modify_property(self, object_id: str, property_name: str, value: Any) -> bool:\n        \"\"\"Modify a property of a scene object.\"\"\"\n        if not self._scene:\n            return False\n        \n        command = ModifyPropertyCommand(self._scene, object_id, property_name, value)\n        result = self._command_history.execute(command)\n        if result:\n            self._is_modified = True\n        return result\n    \n    def undo(self) -> bool:\n        \"\"\"Undo the last command.\"\"\"\n        result = self._command_history.undo()\n        if result:\n            self._is_modified = True\n        return result\n    \n    def redo(self) -> bool:\n        \"\"\"Redo the last undone command.\"\"\"\n        result = self._command_history.redo()\n        if result:\n            self._is_modified = True\n        return result\n    \n    def can_undo(self) -> bool:\n        \"\"\"Check if undo is available.\"\"\"\n        return self._command_history.can_undo()\n    \n    def can_redo(self) -> bool:\n        \"\"\"Check if redo is available.\"\"\"\n        return self._command_history.can_redo()\n    \n    def select(self, object_id: str, add_to_selection: bool = False) -> None:\n        \"\"\"Select an object.\"\"\"\n        if not add_to_selection:\n            self._selection.clear()\n        if object_id not in self._selection:\n            self._selection.append(object_id)\n    \n    def deselect(self, object_id: str) -> None:\n        \"\"\"Deselect an object.\"\"\"\n        if object_id in self._selection:\n            self._selection.remove(object_id)\n    \n    def clear_selection(self) -> None:\n        \"\"\"Clear all selections.\"\"\"\n        self._selection.clear()\n    \n    def get_selection(self) -> List[str]:\n        \"\"\"Get the current selection.\"\"\"\n        return self._selection.copy()\n    \n    def set_grid_size(self, size: int) -> None:\n        \"\"\"Set the grid size for snapping.\"\"\"\n        self._grid_size = max(1, size)\n    \n    def set_snap_to_grid(self, enabled: bool) -> None:\n        \"\"\"Enable or disable snap to grid.\"\"\"\n        self._snap_to_grid = enabled\n    \n    def _apply_grid_snap(self, position: Vec2d) -> Vec2d:\n        \"\"\"Apply grid snapping to a position if enabled.\"\"\"\n        if not self._snap_to_grid:\n            return position\n        \n        return Vec2d(\n            round(position.x / self._grid_size) * self._grid_size,\n            round(position.y / self._grid_size) * self._grid_size\n        )\n    \n    def get_object_at(self, x: float, y: float) -> Optional[SceneObject]:\n        \"\"\"Get the topmost object at a screen position.\"\"\"\n        if not self._scene:\n            return None\n        \n        point = Vec2d(x, y)\n        for obj in reversed(self._scene.get_all_objects()):\n            if self._point_in_object(point, obj):\n                return obj\n        return None\n    \n    def _point_in_object(self, point: Vec2d, obj: SceneObject) -> bool:\n        \"\"\"Check if a point is inside an object's bounds.\"\"\"\n        if obj.physics_body:\n            body = obj.physics_body\n            if body.shape_type == \"circle\":\n                return point.distance_to(obj.position) <= body.radius\n            else:\n                half_w = body.width / 2\n                half_h = body.height / 2\n                return (abs(point.x - obj.position.x) <= half_w and\n                        abs(point.y - obj.position.y) <= half_h)\n        return point.distance_to(obj.position) <= 20\n    \n    def duplicate_selection(self) -> List[SceneObject]:\n        \"\"\"Duplicate all selected objects.\"\"\"\n        if not self._scene:\n            return []\n        \n        duplicates = []\n        commands = []\n        \n        for obj_id in self._selection:\n            obj = self._scene.get_object(obj_id)\n            if obj:\n                offset = Vec2d(20, 20)\n                new_pos = obj.position + offset\n                cmd = CreateObjectCommand(\n                    self._scene,\n                    f\"{obj.name} (copy)\",\n                    new_pos,\n                    rotation=obj.rotation,\n                    scale=obj.scale,\n                    visible=obj.visible,\n                    layer=obj.layer,\n                    tags=obj.tags.copy(),\n                    properties=obj.properties.copy()\n                )\n                commands.append(cmd)\n        \n        if commands:\n            batch = BatchCommand(commands)\n            duplicates = self._command_history.execute(batch)\n            self._is_modified = True\n        \n        return duplicates\n",
            "physage_academy/src/physage_academy/scripting/engine.py": "\"\"\"Scripting engine for PhySage Academy.\"\"\"\nfrom typing import Any, Dict, Optional, Callable, Tuple\nimport os\nimport sys\nimport traceback\nfrom pathlib import Path\n\n\nclass ScriptContext:\n    \"\"\"Context object passed to scripts during execution.\"\"\"\n    \n    def __init__(self, variables: Dict[str, Any] = None):\n        self._variables = variables or {}\n    \n    def get(self, name: str, default: Any = None) -> Any:\n        \"\"\"Get a variable from the context.\"\"\"\n        return self._variables.get(name, default)\n    \n    def set(self, name: str, value: Any) -> None:\n        \"\"\"Set a variable in the context.\"\"\"\n        self._variables[name] = value\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert context to dictionary.\"\"\"\n        return self._variables.copy()\n\n\nclass ScriptResult:\n    \"\"\"Result of script execution.\"\"\"\n    \n    def __init__(self, success: bool, return_value: Any = None, error: str = None):\n        self.success = success\n        self.return_value = return_value\n        self.error = error\n\n\nclass ScriptingEngine:\n    \"\"\"Engine for executing user scripts safely.\"\"\"\n    \n    def __init__(self):\n        self._scripts: Dict[str, str] = {}\n        self._compiled_scripts: Dict[str, Any] = {}\n        self._global_context = ScriptContext()\n        self._script_callbacks: Dict[str, Callable] = {}\n        self._allowed_imports = {\n            'math', 'random', 'time', 'collections', 'itertools', 'functools'\n        }\n        self._script_cache: Dict[str, str] = {}\n    \n    def load_script(self, script_path: str) -> bool:\n        \"\"\"Load a script from a file.\"\"\"\n        try:\n            path = Path(script_path)\n            if not path.exists():\n                return False\n            \n            with open(path, 'r') as f:\n                script_content = f.read()\n            \n            self._scripts[script_path] = script_content\n            self._script_cache[script_path] = script_content\n            return True\n        except Exception as e:\n            print(f\"Error loading script {script_path}: {e}\")\n            return False\n    \n    def execute_script(self, script_path: str, context: Dict[str, Any] = None) -> ScriptResult:\n        \"\"\"Execute a script with the given context.\"\"\"\n        if script_path not in self._scripts:\n            if not self.load_script(script_path):\n                return ScriptResult(False, error=f\"Script not found: {script_path}\")\n        \n        script_content = self._scripts[script_path]\n        return self._execute_code(script_content, context or {})\n    \n    def execute_code(self, code: str, context: Dict[str, Any] = None) -> ScriptResult:\n        \"\"\"Execute arbitrary code with the given context.\"\"\"\n        return self._execute_code(code, context or {})\n    \n    def execute_force_script(self, script_path: str, field: Any, target_body: Any) -> Tuple[float, float]:\n        \"\"\"Execute a force field script and return the force vector.\n        \n        This method is specifically designed for force field scripts.\n        It executes the script with the force field and target body in context,\n        and expects the script to return a force vector as (fx, fy).\n        \n        Args:\n            script_path: Path to the force field script\n            field: The ForceField object\n            target_body: The PhysicsBody object being affected\n        \n        Returns:\n            A tuple (fx, fy) representing the force to apply, or (0, 0) on error\n        \"\"\"\n        context = {\n            'field': field,\n            'target_body': target_body\n        }\n        \n        result = self.execute_script(script_path, context)\n        \n        if result.success and result.return_value is not None:\n            try:\n                if isinstance(result.return_value, (tuple, list)) and len(result.return_value) >= 2:\n                    return (float(result.return_value[0]), float(result.return_value[1]))\n            except (TypeError, ValueError) as e:\n                print(f\"Force script returned invalid value: {e}\")\n        \n        return (0.0, 0.0)\n    \n    def _execute_code(self, code: str, context: Dict[str, Any]) -> ScriptResult:\n        \"\"\"Internal method to execute code.\"\"\"\n        try:\n            # Create a restricted global namespace\n            safe_globals = self._create_safe_globals()\n            \n            # Add context variables to local namespace\n            local_vars = context.copy()\n            \n            # Add helper functions\n            local_vars['__builtins__'] = safe_globals['__builtins__']\n            \n            # Execute the code\n            exec(compile(code, '<script>', 'exec'), safe_globals, local_vars)\n            \n            # Check for return value (scripts can set __return__ or use return in a function)\n            return_value = local_vars.get('__return__', None)\n            \n            return ScriptResult(True, return_value=return_value)\n        except SyntaxError as e:\n            return ScriptResult(False, error=f\"Syntax error: {e}\")\n        except Exception as e:\n            tb = traceback.format_exc()\n            return ScriptResult(False, error=f\"Runtime error: {e}\n{tb}\")\n    \n    def _create_safe_globals(self) -> Dict[str, Any]:\n        \"\"\"Create a safe global namespace for script execution.\"\"\"\n        import math\n        import random\n        \n        safe_builtins = {\n            'abs': abs,\n            'all': all,\n            'any': any,\n            'bool': bool,\n            'dict': dict,\n            'enumerate': enumerate,\n            'filter': filter,\n            'float': float,\n            'int': int,\n            'len': len,\n            'list': list,\n            'map': map,\n            'max': max,\n            'min': min,\n            'print': print,\n            'range': range,\n            'round': round,\n            'set': set,\n            'sorted': sorted,\n            'str': str,\n            'sum': sum,\n            'tuple': tuple,\n            'zip': zip,\n            'True': True,\n            'False': False,\n            'None': None,\n        }\n        \n        return {\n            '__builtins__': safe_builtins,\n            'math': math,\n            'random': random,\n        }\n    \n    def register_callback(self, name: str, callback: Callable) -> None:\n        \"\"\"Register a callback function that scripts can call.\"\"\"\n        self._script_callbacks[name] = callback\n    \n    def unregister_callback(self, name: str) -> None:\n        \"\"\"Unregister a callback function.\"\"\"\n        if name in self._script_callbacks:\n            del self._script_callbacks[name]\n    \n    def set_global_variable(self, name: str, value: Any) -> None:\n        \"\"\"Set a global variable accessible to all scripts.\"\"\"\n        self._global_context.set(name, value)\n    \n    def get_global_variable(self, name: str, default: Any = None) -> Any:\n        \"\"\"Get a global variable.\"\"\"\n        return self._global_context.get(name, default)\n    \n    def clear_cache(self) -> None:\n        \"\"\"Clear the script cache.\"\"\"\n        self._scripts.clear()\n        self._compiled_scripts.clear()\n        self._script_cache.clear()\n    \n    def reload_script(self, script_path: str) -> bool:\n        \"\"\"Reload a script from disk.\"\"\"\n        if script_path in self._scripts:\n            del self._scripts[script_path]\n        if script_path in self._compiled_scripts:\n            del self._compiled_scripts[script_path]\n        if script_path in self._script_cache:\n            del self._script_cache[script_path]\n        return self.load_script(script_path)\n",
            "physage_academy/src/physage_academy/physics/engine.py": "\"\"\"Physics engine for PhySage Academy.\"\"\"\nfrom typing import List, Dict, Optional, Tuple, Any, Callable\nimport math\n\nfrom physage_academy.engine.scene import Scene, PhysicsBody, ForceField, Vec2d\nfrom physage_academy.scripting.engine import ScriptingEngine\n\n\nclass CollisionInfo:\n    \"\"\"Information about a collision between two bodies.\"\"\"\n    \n    def __init__(self, body_a: PhysicsBody, body_b: PhysicsBody,\n                 normal: Vec2d, penetration: float, contact_point: Vec2d):\n        self.body_a = body_a\n        self.body_b = body_b\n        self.normal = normal\n        self.penetration = penetration\n        self.contact_point = contact_point\n\n\nclass PhysicsEngine:\n    \"\"\"Main physics simulation engine.\"\"\"\n    \n    def __init__(self, scene: Optional[Scene] = None):\n        self._scene = scene\n        self._gravity = Vec2d(0, 980)  # pixels per second squared\n        self._time_step = 1.0 / 60.0\n        self._velocity_iterations = 8\n        self._position_iterations = 3\n        self._collision_callbacks: List[Callable[[CollisionInfo], None]] = []\n        self._scripting_engine: Optional[ScriptingEngine] = None\n        self._paused = False\n    \n    @property\n    def scene(self) -> Optional[Scene]:\n        \"\"\"Get the current scene.\"\"\"\n        return self._scene\n    \n    @scene.setter\n    def scene(self, value: Scene) -> None:\n        \"\"\"Set the current scene.\"\"\"\n        self._scene = value\n    \n    @property\n    def gravity(self) -> Vec2d:\n        \"\"\"Get gravity vector.\"\"\"\n        return self._gravity\n    \n    @gravity.setter\n    def gravity(self, value: Vec2d) -> None:\n        \"\"\"Set gravity vector.\"\"\"\n        self._gravity = value\n    \n    @property\n    def time_step(self) -> float:\n        \"\"\"Get the simulation time step.\"\"\"\n        return self._time_step\n    \n    @time_step.setter\n    def time_step(self, value: float) -> None:\n        \"\"\"Set the simulation time step.\"\"\"\n        self._time_step = max(0.001, value)\n    \n    @property\n    def scripting_engine(self) -> Optional[ScriptingEngine]:\n        \"\"\"Get the scripting engine.\"\"\"\n        return self._scripting_engine\n    \n    @scripting_engine.setter\n    def scripting_engine(self, value: ScriptingEngine) -> None:\n        \"\"\"Set the scripting engine for force field scripts.\"\"\"\n        self._scripting_engine = value\n    \n    def pause(self) -> None:\n        \"\"\"Pause the simulation.\"\"\"\n        self._paused = True\n    \n    def resume(self) -> None:\n        \"\"\"Resume the simulation.\"\"\"\n        self._paused = False\n    \n    def is_paused(self) -> bool:\n        \"\"\"Check if simulation is paused.\"\"\"\n        return self._paused\n    \n    def step(self, dt: Optional[float] = None) -> None:\n        \"\"\"Perform one physics simulation step.\"\"\"\n        if self._paused or not self._scene:\n            return\n        \n        time_step = dt if dt is not None else self._time_step\n        bodies = self._scene.get_dynamic_bodies()\n        \n        # Apply gravity to all dynamic bodies\n        for body in bodies:\n            if not body.is_static:\n                gravity_force = Vec2d(\n                    self._gravity.x * body.mass,\n                    self._gravity.y * body.mass\n                )\n                self._apply_force(body, gravity_force, time_step)\n        \n        # Apply force fields\n        self._apply_force_fields(bodies, time_step)\n        \n        # Integrate velocities\n        for body in bodies:\n            if not body.is_static:\n                body.position = Vec2d(\n                    body.position.x + body.velocity.x * time_step,\n                    body.position.y + body.velocity.y * time_step\n                )\n        \n        # Detect and resolve collisions\n        collisions = self._detect_collisions()\n        for collision in collisions:\n            self._resolve_collision(collision)\n            for callback in self._collision_callbacks:\n                callback(collision)\n        \n        # Apply bounds constraints\n        self._apply_bounds_constraints(bodies)\n    \n    def _apply_force_fields(self, bodies: List[PhysicsBody], time_step: float) -> None:\n        \"\"\"Apply force fields to all bodies within their radius.\"\"\"\n        if not self._scene or not self._scripting_engine:\n            return\n        \n        force_fields = self._scene.get_all_force_fields()\n        \n        for field in force_fields:\n            if not field.enabled:\n                continue\n            \n            for body in bodies:\n                if body.is_static:\n                    continue\n                \n                # Check if body is within force field radius\n                distance = field.position.distance_to(body.position)\n                if distance <= field.radius:\n                    # Execute the force field script\n                    force_tuple = self._scripting_engine.execute_force_script(\n                        field.script_path,\n                        field,\n                        body\n                    )\n                    \n                    # Apply the returned force\n                    if force_tuple and (force_tuple[0] != 0 or force_tuple[1] != 0):\n                        force = Vec2d(force_tuple[0], force_tuple[1])\n                        self._apply_force(body, force, time_step)\n    \n    def _apply_force(self, body: PhysicsBody, force: Vec2d, dt: float) -> None:\n        \"\"\"Apply a force to a body.\"\"\"\n        if body.is_static or body.mass <= 0:\n            return\n        \n        acceleration = Vec2d(force.x / body.mass, force.y / body.mass)\n        body.velocity = Vec2d(\n            body.velocity.x + acceleration.x * dt,\n            body.velocity.y + acceleration.y * dt\n        )\n    \n    def _detect_collisions(self) -> List[CollisionInfo]:\n        \"\"\"Detect collisions between all bodies.\"\"\"\n        if not self._scene:\n            return []\n        \n        collisions = []\n        bodies = self._scene.get_all_physics_bodies()\n        \n        for i, body_a in enumerate(bodies):\n            for body_b in bodies[i + 1:]:\n                collision = self._check_collision(body_a, body_b)\n                if collision:\n                    collisions.append(collision)\n        \n        return collisions\n    \n    def _check_collision(self, body_a: PhysicsBody, body_b: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check for collision between two bodies.\"\"\"\n        if body_a.shape_type == \"circle\" and body_b.shape_type == \"circle\":\n            return self._check_circle_circle(body_a, body_b)\n        elif body_a.shape_type == \"box\" and body_b.shape_type == \"box\":\n            return self._check_box_box(body_a, body_b)\n        else:\n            return self._check_circle_box(body_a, body_b)\n    \n    def _check_circle_circle(self, a: PhysicsBody, b: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check collision between two circles.\"\"\"\n        diff = Vec2d(b.position.x - a.position.x, b.position.y - a.position.y)\n        dist_sq = diff.length_sq\n        radius_sum = a.radius + b.radius\n        \n        if dist_sq >= radius_sum * radius_sum:\n            return None\n        \n        dist = math.sqrt(dist_sq) if dist_sq > 0 else 0.001\n        normal = Vec2d(diff.x / dist, diff.y / dist) if dist > 0 else Vec2d(1, 0)\n        penetration = radius_sum - dist\n        contact = Vec2d(\n            a.position.x + normal.x * a.radius,\n            a.position.y + normal.y * a.radius\n        )\n        \n        return CollisionInfo(a, b, normal, penetration, contact)\n    \n    def _check_box_box(self, a: PhysicsBody, b: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check collision between two boxes (AABB).\"\"\"\n        a_half_w, a_half_h = a.width / 2, a.height / 2\n        b_half_w, b_half_h = b.width / 2, b.height / 2\n        \n        dx = b.position.x - a.position.x\n        dy = b.position.y - a.position.y\n        \n        overlap_x = a_half_w + b_half_w - abs(dx)\n        overlap_y = a_half_h + b_half_h - abs(dy)\n        \n        if overlap_x <= 0 or overlap_y <= 0:\n            return None\n        \n        if overlap_x < overlap_y:\n            normal = Vec2d(1 if dx > 0 else -1, 0)\n            penetration = overlap_x\n        else:\n            normal = Vec2d(0, 1 if dy > 0 else -1)\n            penetration = overlap_y\n        \n        contact = Vec2d(\n            (a.position.x + b.position.x) / 2,\n            (a.position.y + b.position.y) / 2\n        )\n        \n        return CollisionInfo(a, b, normal, penetration, contact)\n    \n    def _check_circle_box(self, circle: PhysicsBody, box: PhysicsBody) -> Optional[CollisionInfo]:\n        \"\"\"Check collision between a circle and a box.\"\"\"\n        if circle.shape_type != \"circle\":\n            circle, box = box, circle\n        \n        half_w, half_h = box.width / 2, box.height / 2\n        \n        closest_x = max(box.position.x - half_w,\n                       min(circle.position.x, box.position.x + half_w))\n        closest_y = max(box.position.y - half_h,\n                       min(circle.position.y, box.position.y + half_h))\n        \n        dx = circle.position.x - closest_x\n        dy = circle.position.y - closest_y\n        dist_sq = dx * dx + dy * dy\n        \n        if dist_sq >= circle.radius * circle.radius:\n            return None\n        \n        dist = math.sqrt(dist_sq) if dist_sq > 0 else 0.001\n        normal = Vec2d(dx / dist, dy / dist) if dist > 0 else Vec2d(1, 0)\n        penetration = circle.radius - dist\n        contact = Vec2d(closest_x, closest_y)\n        \n        return CollisionInfo(circle, box, normal, penetration, contact)\n    \n    def _resolve_collision(self, collision: CollisionInfo) -> None:\n        \"\"\"Resolve a collision between two bodies.\"\"\"\n        a, b = collision.body_a, collision.body_b\n        \n        if a.is_static and b.is_static:\n            return\n        \n        # Calculate relative velocity\n        rel_vel = Vec2d(\n            b.velocity.x - a.velocity.x,\n            b.velocity.y - a.velocity.y\n        )\n        \n        # Calculate relative velocity along collision normal\n        vel_along_normal = (\n            rel_vel.x * collision.normal.x +\n            rel_vel.y * collision.normal.y\n        )\n        \n        # Don't resolve if velocities are separating\n        if vel_along_normal > 0:\n            return\n        \n        # Calculate restitution (bounciness)\n        restitution = min(a.restitution, b.restitution)\n        \n        # Calculate impulse scalar\n        inv_mass_a = 0 if a.is_static else 1 / a.mass\n        inv_mass_b = 0 if b.is_static else 1 / b.mass\n        \n        j = -(1 + restitution) * vel_along_normal\n        j /= inv_mass_a + inv_mass_b\n        \n        # Apply impulse\n        impulse = Vec2d(\n            j * collision.normal.x,\n            j * collision.normal.y\n        )\n        \n        if not a.is_static:\n            a.velocity = Vec2d(\n                a.velocity.x - inv_mass_a * impulse.x,\n                a.velocity.y - inv_mass_a * impulse.y\n            )\n        \n        if not b.is_static:\n            b.velocity = Vec2d(\n                b.velocity.x + inv_mass_b * impulse.x,\n                b.velocity.y + inv_mass_b * impulse.y\n            )\n        \n        # Positional correction to prevent sinking\n        correction_percent = 0.8\n        slop = 0.01\n        correction_mag = max(collision.penetration - slop, 0) / (inv_mass_a + inv_mass_b) * correction_percent\n        correction = Vec2d(\n            correction_mag * collision.normal.x,\n            correction_mag * collision.normal.y\n        )\n        \n        if not a.is_static:\n            a.position = Vec2d(\n                a.position.x - inv_mass_a * correction.x,\n                a.position.y - inv_mass_a * correction.y\n            )\n        \n        if not b.is_static:\n            b.position = Vec2d(\n                b.position.x + inv_mass_b * correction.x,\n                b.position.y + inv_mass_b * correction.y\n            )\n    \n    def _apply_bounds_constraints(self, bodies: List[PhysicsBody]) -> None:\n        \"\"\"Keep bodies within scene bounds.\"\"\"\n        if not self._scene:\n            return\n        \n        width, height = self._scene.bounds\n        \n        for body in bodies:\n            if body.is_static:\n                continue\n            \n            radius = body.radius if body.shape_type == \"circle\" else max(body.width, body.height) / 2\n            \n            # Left bound\n            if body.position.x - radius < 0:\n                body.position = Vec2d(radius, body.position.y)\n                body.velocity = Vec2d(-body.velocity.x * body.restitution, body.velocity.y)\n            \n            # Right bound\n            if body.position.x + radius > width:\n                body.position = Vec2d(width - radius, body.position.y)\n                body.velocity = Vec2d(-body.velocity.x * body.restitution, body.velocity.y)\n            \n            # Top bound\n            if body.position.y - radius < 0:\n                body.position = Vec2d(body.position.x, radius)\n                body.velocity = Vec2d(body.velocity.x, -body.velocity.y * body.restitution)\n            \n            # Bottom bound\n            if body.position.y + radius > height:\n                body.position = Vec2d(body.position.x, height - radius)\n                body.velocity = Vec2d(body.velocity.x, -body.velocity.y * body.restitution)\n    \n    def add_collision_callback(self, callback: Callable[[CollisionInfo], None]) -> None:\n        \"\"\"Add a callback to be called on collisions.\"\"\"\n        self._collision_callbacks.append(callback)\n    \n    def remove_collision_callback(self, callback: Callable[[CollisionInfo], None]) -> None:\n        \"\"\"Remove a collision callback.\"\"\"\n        if callback in self._collision_callbacks:\n            self._collision_callbacks.remove(callback)\n    \n    def raycast(self, origin: Vec2d, direction: Vec2d, max_distance: float = 1000) -> Optional[Tuple[PhysicsBody, Vec2d, float]]:\n        \"\"\"Cast a ray and return the first body hit.\"\"\"\n        if not self._scene:\n            return None\n        \n        closest_hit = None\n        closest_dist = max_distance\n        \n        dir_normalized = direction.normalized()\n        \n        for body in self._scene.get_all_physics_bodies():\n            hit = self._raycast_body(origin, dir_normalized, body, closest_dist)\n            if hit and hit[1] < closest_dist:\n                closest_hit = (body, hit[0], hit[1])\n                closest_dist = hit[1]\n        \n        return closest_hit\n    \n    def _raycast_body(self, origin: Vec2d, direction: Vec2d, body: PhysicsBody, max_dist: float) -> Optional[Tuple[Vec2d, float]]:\n        \"\"\"Raycast against a single body.\"\"\"\n        if body.shape_type == \"circle\":\n            return self._raycast_circle(origin, direction, body.position, body.radius, max_dist)\n        else:\n            return self._raycast_box(origin, direction, body, max_dist)\n    \n    def _raycast_circle(self, origin: Vec2d, direction: Vec2d, center: Vec2d, radius: float, max_dist: float) -> Optional[Tuple[Vec2d, float]]:\n        \"\"\"Raycast against a circle.\"\"\"\n        oc = Vec2d(origin.x - center.x, origin.y - center.y)\n        \n        a = direction.x * direction.x + direction.y * direction.y\n        b = 2 * (oc.x * direction.x + oc.y * direction.y)\n        c = oc.x * oc.x + oc.y * oc.y - radius * radius\n        \n        discriminant = b * b - 4 * a * c\n        \n        if discriminant < 0:\n            return None\n        \n        t = (-b - math.sqrt(discriminant)) / (2 * a)\n        \n        if t < 0 or t > max_dist:\n            return None\n        \n        hit_point = Vec2d(origin.x + direction.x * t, origin.y + direction.y * t)\n        return (hit_point, t)\n    \n    def _raycast_box(self, origin: Vec2d, direction: Vec2d, body: PhysicsBody, max_dist: float) -> Optional[Tuple[Vec2d, float]]:\n        \"\"\"Raycast against a box (AABB).\"\"\"\n        half_w, half_h = body.width / 2, body.height / 2\n        min_x = body.position.x - half_w\n        max_x = body.position.x + half_w\n        min_y = body.position.y - half_h\n        max_y = body.position.y + half_h\n        \n        t_min = 0.0\n        t_max = max_dist\n        \n        for i, (o, d, mn, mx) in enumerate([\n            (origin.x, direction.x, min_x, max_x),\n            (origin.y, direction.y, min_y, max_y)\n        ]):\n            if abs(d) < 1e-8:\n                if o < mn or o > mx:\n                    return None\n            else:\n                t1 = (mn - o) / d\n                t2 = (mx - o) / d\n                if t1 > t2:\n                    t1, t2 = t2, t1\n                t_min = max(t_min, t1)\n                t_max = min(t_max, t2)\n                if t_min > t_max:\n                    return None\n        \n        if t_min < 0:\n            return None\n        \n        hit_point = Vec2d(origin.x + direction.x * t_min, origin.y + direction.y * t_min)\n        return (hit_point, t_min)\n",
            "scripts/attractor_field.py": "# Attractor Force Field Script\n# This script implements a gravity-like attractive force.\n# The context provides 'field' (ForceField) and 'target_body' (PhysicsBody).\n\nimport math\n\n# Calculate direction vector from body to field center\ndx = field.position.x - target_body.position.x\ndy = field.position.y - target_body.position.y\n\n# Calculate squared distance\ndistance_sq = dx * dx + dy * dy\n\n# Avoid singularity at the center\nif distance_sq < 1.0:\n    __return__ = (0, 0)\nelse:\n    # Calculate distance\n    distance = math.sqrt(distance_sq)\n    \n    # Normalize direction\n    norm_x = dx / distance\n    norm_y = dy / distance\n    \n    # Force magnitude using inverse square law\n    # F = G * m1 * m2 / r^2 (simplified: G * m / r^2)\n    force_magnitude = (10000.0 * target_body.mass) / distance_sq\n    \n    # Calculate force vector\n    fx = norm_x * force_magnitude\n    fy = norm_y * force_magnitude\n    \n    # Return force vector\n    __return__ = (fx, fy)\n",
            "physage_academy/tests/test_integration.py": "\"\"\"Integration tests for PhySage Academy.\"\"\"\nimport unittest\nimport os\nimport sys\nimport tempfile\nimport math\n\n# Add source directory to path\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))\n\nfrom physage_academy.editor.service import EditorService\nfrom physage_academy.physics.engine import PhysicsEngine\nfrom physage_academy.scripting.engine import ScriptingEngine\nfrom physage_academy.engine.scene import Scene, Vec2d, PhysicsBody, ForceField\n\n\nclass TestEditorPhysicsIntegration(unittest.TestCase):\n    \"\"\"Test integration between editor and physics systems.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.editor = EditorService()\n        self.editor.new_scene(\"Test Scene\")\n        self.physics = PhysicsEngine(self.editor.scene)\n        self.scripting = ScriptingEngine()\n        self.physics.scripting_engine = self.scripting\n    \n    def test_create_and_simulate_physics_body(self):\n        \"\"\"Test creating a physics body and simulating it.\"\"\"\n        # Create a dynamic body\n        body = self.editor.create_physics_body(100, 100, mass=1.0, is_static=False)\n        self.assertIsNotNone(body)\n        \n        initial_y = body.position.y\n        \n        # Run simulation for a few steps\n        for _ in range(10):\n            self.physics.step(1/60)\n        \n        # Body should have fallen due to gravity\n        self.assertGreater(body.position.y, initial_y)\n    \n    def test_static_body_does_not_move(self):\n        \"\"\"Test that static bodies don't move.\"\"\"\n        body = self.editor.create_physics_body(100, 100, mass=1.0, is_static=True)\n        self.assertIsNotNone(body)\n        \n        initial_pos = Vec2d(body.position.x, body.position.y)\n        \n        # Run simulation\n        for _ in range(10):\n            self.physics.step(1/60)\n        \n        # Static body should not have moved\n        self.assertEqual(body.position.x, initial_pos.x)\n        self.assertEqual(body.position.y, initial_pos.y)\n    \n    def test_undo_redo_physics_body_creation(self):\n        \"\"\"Test undo/redo for physics body creation.\"\"\"\n        body = self.editor.create_physics_body(100, 100, mass=1.0)\n        body_id = body.id\n        \n        # Body should exist\n        self.assertIsNotNone(self.editor.scene.get_physics_body(body_id))\n        \n        # Undo creation\n        self.assertTrue(self.editor.undo())\n        self.assertIsNone(self.editor.scene.get_physics_body(body_id))\n        \n        # Redo creation\n        self.assertTrue(self.editor.redo())\n        self.assertIsNotNone(self.editor.scene.get_physics_body(body_id))\n\n\nclass TestForceFieldIntegration(unittest.TestCase):\n    \"\"\"Test programmable force field integration.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.editor = EditorService()\n        self.editor.new_scene(\"Force Field Test Scene\")\n        self.physics = PhysicsEngine(self.editor.scene)\n        self.scripting = ScriptingEngine()\n        self.physics.scripting_engine = self.scripting\n        # Disable gravity for cleaner force field tests\n        self.physics.gravity = Vec2d(0, 0)\n    \n    def test_programmable_force_field_attractor(self):\n        \"\"\"Test that an attractor force field pulls objects toward it.\"\"\"\n        # Create a dynamic physics body at position (100, 0)\n        body = self.editor.create_physics_body(\n            x=100.0, y=0.0,\n            mass=1.0,\n            is_static=False,\n            shape_type=\"circle\",\n            radius=5.0\n        )\n        self.assertIsNotNone(body)\n        \n        # Record initial position\n        initial_x = body.position.x\n        initial_y = body.position.y\n        \n        # Get the path to the attractor script\n        # The script should be at the project root in scripts/attractor_field.py\n        script_path = os.path.join(\n            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),\n            'scripts', 'attractor_field.py'\n        )\n        \n        # If script doesn't exist at that path, create a temporary one\n        if not os.path.exists(script_path):\n            script_dir = os.path.dirname(script_path)\n            os.makedirs(script_dir, exist_ok=True)\n            with open(script_path, 'w') as f:\n                f.write('''# Attractor Force Field Script\nimport math\n\ndx = field.position.x - target_body.position.x\ndy = field.position.y - target_body.position.y\ndistance_sq = dx * dx + dy * dy\n\nif distance_sq < 1.0:\n    __return__ = (0, 0)\nelse:\n    distance = math.sqrt(distance_sq)\n    norm_x = dx / distance\n    norm_y = dy / distance\n    force_magnitude = (10000.0 * target_body.mass) / distance_sq\n    fx = norm_x * force_magnitude\n    fy = norm_y * force_magnitude\n    __return__ = (fx, fy)\n''')\n        \n        # Create an attractive force field at origin (0, 0) with large radius\n        force_field = self.editor.create_force_field(\n            x=0.0, y=0.0,\n            radius=500.0,\n            script_path=script_path\n        )\n        self.assertIsNotNone(force_field)\n        self.assertEqual(force_field.position.x, 0.0)\n        self.assertEqual(force_field.position.y, 0.0)\n        self.assertEqual(force_field.radius, 500.0)\n        \n        # Run simulation for 100 steps\n        for _ in range(100):\n            self.physics.step(1/60)\n        \n        # The body should have moved toward the origin\n        # Since it started at (100, 0) and the attractor is at (0, 0),\n        # the x position should have decreased (moved left toward origin)\n        final_x = body.position.x\n        \n        # Assert that the object moved toward the origin\n        self.assertLess(final_x, initial_x, \n            f\"Body should have moved toward origin. Initial x: {initial_x}, Final x: {final_x}\")\n        \n        # Calculate distance to origin\n        initial_distance = math.sqrt(initial_x**2 + initial_y**2)\n        final_distance = math.sqrt(final_x**2 + body.position.y**2)\n        \n        self.assertLess(final_distance, initial_distance,\n            f\"Body should be closer to origin. Initial distance: {initial_distance}, Final distance: {final_distance}\")\n    \n    def test_force_field_creation_and_deletion(self):\n        \"\"\"Test creating and deleting force fields.\"\"\"\n        # Create a force field\n        field = self.editor.create_force_field(\n            x=50.0, y=50.0,\n            radius=100.0,\n            script_path=\"dummy_script.py\"\n        )\n        self.assertIsNotNone(field)\n        field_id = field.id\n        \n        # Verify it exists in the scene\n        self.assertIsNotNone(self.editor.scene.get_force_field(field_id))\n        self.assertEqual(len(self.editor.scene.get_all_force_fields()), 1)\n        \n        # Delete the force field\n        result = self.editor.delete_force_field(field_id)\n        self.assertTrue(result)\n        \n        # Verify it's gone\n        self.assertIsNone(self.editor.scene.get_force_field(field_id))\n        self.assertEqual(len(self.editor.scene.get_all_force_fields()), 0)\n    \n    def test_force_field_undo_redo(self):\n        \"\"\"Test undo/redo for force field operations.\"\"\"\n        # Create a force field\n        field = self.editor.create_force_field(\n            x=25.0, y=25.0,\n            radius=50.0,\n            script_path=\"test_script.py\"\n        )\n        field_id = field.id\n        \n        # Undo creation\n        self.assertTrue(self.editor.undo())\n        self.assertIsNone(self.editor.scene.get_force_field(field_id))\n        \n        # Redo creation\n        self.assertTrue(self.editor.redo())\n        self.assertIsNotNone(self.editor.scene.get_force_field(field_id))\n    \n    def test_force_field_contains_point(self):\n        \"\"\"Test force field containment check.\"\"\"\n        field = ForceField(\n            id=\"test-field\",\n            position=Vec2d(0, 0),\n            radius=100.0,\n            script_path=\"test.py\"\n        )\n        \n        # Point inside\n        self.assertTrue(field.contains(Vec2d(50, 50)))\n        self.assertTrue(field.contains(Vec2d(0, 0)))\n        self.assertTrue(field.contains(Vec2d(99, 0)))\n        \n        # Point outside\n        self.assertFalse(field.contains(Vec2d(150, 0)))\n        self.assertFalse(field.contains(Vec2d(0, 150)))\n    \n    def test_repulsor_force_field(self):\n        \"\"\"Test a repulsor (opposite of attractor) force field.\"\"\"\n        # Create a dynamic body near the origin\n        body = self.editor.create_physics_body(\n            x=20.0, y=0.0,\n            mass=1.0,\n            is_static=False\n        )\n        initial_x = body.position.x\n        \n        # Create a temporary repulsor script\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write('''import math\ndx = target_body.position.x - field.position.x\ndy = target_body.position.y - field.position.y\ndistance_sq = dx * dx + dy * dy\nif distance_sq < 1.0:\n    __return__ = (0, 0)\nelse:\n    distance = math.sqrt(distance_sq)\n    norm_x = dx / distance\n    norm_y = dy / distance\n    force_magnitude = (5000.0 * target_body.mass) / distance_sq\n    __return__ = (norm_x * force_magnitude, norm_y * force_magnitude)\n''')\n            script_path = f.name\n        \n        try:\n            # Create repulsor at origin\n            self.editor.create_force_field(\n                x=0.0, y=0.0,\n                radius=200.0,\n                script_path=script_path\n            )\n            \n            # Run simulation\n            for _ in range(50):\n                self.physics.step(1/60)\n            \n            # Body should have moved away from origin\n            self.assertGreater(body.position.x, initial_x,\n                \"Body should have been pushed away from origin\")\n        finally:\n            os.unlink(script_path)\n\n\nclass TestSceneSerializationIntegration(unittest.TestCase):\n    \"\"\"Test scene serialization with force fields.\"\"\"\n    \n    def test_scene_with_force_fields_serialization(self):\n        \"\"\"Test that scenes with force fields can be serialized and deserialized.\"\"\"\n        # Create a scene with various objects\n        scene = Scene(name=\"Serialization Test\")\n        \n        # Add a physics body\n        body = PhysicsBody(\n            id=\"body-1\",\n            position=Vec2d(100, 100),\n            mass=2.0\n        )\n        scene.add_physics_body(body)\n        \n        # Add a force field\n        field = ForceField(\n            id=\"field-1\",\n            position=Vec2d(50, 50),\n            radius=150.0,\n            script_path=\"scripts/attractor_field.py\"\n        )\n        scene.add_force_field(field)\n        \n        # Serialize\n        data = scene.to_dict()\n        \n        # Verify serialization\n        self.assertEqual(data[\"name\"], \"Serialization Test\")\n        self.assertEqual(len(data[\"force_fields\"]), 1)\n        self.assertEqual(data[\"force_fields\"][0][\"id\"], \"field-1\")\n        self.assertEqual(data[\"force_fields\"][0][\"radius\"], 150.0)\n        \n        # Deserialize\n        restored_scene = Scene.from_dict(data)\n        \n        # Verify restoration\n        self.assertEqual(restored_scene.name, \"Serialization Test\")\n        restored_fields = restored_scene.get_all_force_fields()\n        self.assertEqual(len(restored_fields), 1)\n        self.assertEqual(restored_fields[0].id, \"field-1\")\n        self.assertEqual(restored_fields[0].radius, 150.0)\n        self.assertEqual(restored_fields[0].script_path, \"scripts/attractor_field.py\")\n\n\nclass TestMultipleForceFields(unittest.TestCase):\n    \"\"\"Test scenarios with multiple force fields.\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.editor = EditorService()\n        self.editor.new_scene(\"Multi Force Field Test\")\n        self.physics = PhysicsEngine(self.editor.scene)\n        self.scripting = ScriptingEngine()\n        self.physics.scripting_engine = self.scripting\n        self.physics.gravity = Vec2d(0, 0)\n    \n    def test_multiple_force_fields_affect_body(self):\n        \"\"\"Test that multiple force fields can affect a single body.\"\"\"\n        # Create a body\n        body = self.editor.create_physics_body(\n            x=50.0, y=50.0,\n            mass=1.0,\n            is_static=False\n        )\n        \n        # Create a simple constant force script\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write('__return__ = (100, 0)\n')  # Push right\n            script1 = f.name\n        \n        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n            f.write('__return__ = (0, 100)\n')  # Push down\n            script2 = f.name\n        \n        try:\n            # Create two force fields with different forces\n            self.editor.create_force_field(x=0, y=0, radius=200, script_path=script1)\n            self.editor.create_force_field(x=100, y=100, radius=200, script_path=script2)\n            \n            initial_x = body.position.x\n            initial_y = body.position.y\n            \n            # Run simulation\n            for _ in range(20):\n                self.physics.step(1/60)\n            \n            # Body should have moved in both x and y directions\n            self.assertGreater(body.position.x, initial_x)\n            self.assertGreater(body.position.y, initial_y)\n        finally:\n            os.unlink(script1)\n            os.unlink(script2)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"
          },
          "generated_files": [
            "physage_academy/src/physage_academy/engine/scene.py",
            "physage_academy/src/physage_academy/editor/commands.py",
            "physage_academy/src/physage_academy/editor/service.py",
            "physage_academy/src/physage_academy/scripting/engine.py",
            "physage_academy/src/physage_academy/physics/engine.py",
            "scripts/attractor_field.py",
            "physage_academy/tests/test_integration.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.722687941743414,
                "dependency_traversal_accuracy": 0.8492739951069457,
                "cross_file_reasoning_depth": 0.18107142857142858,
                "system_thinking_score": 0.35030510064530734,
                "robustness_score": 0.2549776007964161,
                "comprehensiveness_score": 0.7231843546147598,
                "innovation_score": 0.25,
                "solution_elegance_score": 0.5972941245144602
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09033599271792675,
                "dependency_traversal_weighted": 0.10615924938836821,
                "cross_file_reasoning_weighted": 0.022633928571428572,
                "system_thinking_weighted": 0.04378813758066342,
                "robustness_weighted": 0.031872200099552016,
                "comprehensiveness_weighted": 0.09039804432684498,
                "innovation_weighted": 0.03125,
                "solution_elegance_weighted": 0.07466176556430752
              },
              "total_software_engineering_score": 0.4910993182490914
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.0,
                "execution_time": 0.43689465522766113,
                "errors": [
                  "  File \"physage_academy/src/physage_academy/scripting/engine.py\", line 134",
                  "    return ScriptResult(False, error=f\"Runtime error: {e}",
                  "                                     ^",
                  "SyntaxError: unterminated f-string literal (detected at line 134)",
                  "  File \"physage_academy/tests/test_integration.py\", line 340",
                  "    f.write('__return__ = (100, 0)",
                  "            ^",
                  "SyntaxError: unterminated string literal (detected at line 340)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "physage_academy/src/physage_academy/engine/scene.py",
                  "physage_academy/src/physage_academy/editor/commands.py",
                  "physage_academy/src/physage_academy/editor/service.py",
                  "physage_academy/src/physage_academy/scripting/engine.py",
                  "physage_academy/src/physage_academy/physics/engine.py",
                  "scripts/attractor_field.py",
                  "physage_academy/tests/test_integration.py"
                ],
                "scoring_breakdown": {
                  "no_credit": 0.0
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 7,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 7 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.2262100114567727,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.0,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.2262100114567727,
                "idc_weight": 0.2,
                "total_functional_score": 0.35524200229135455
              }
            },
            "code_quality_details": {
              "files_analyzed": 7,
              "quality_checks": {
                "physage_academy/src/physage_academy/engine/scene.py": {
                  "line_count": 314,
                  "non_empty_lines": 262,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 35,
                  "class_count": 5,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "physage_academy/src/physage_academy/editor/commands.py": {
                  "line_count": 332,
                  "non_empty_lines": 264,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 42,
                  "class_count": 12,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "physage_academy/src/physage_academy/editor/service.py": {
                  "line_count": 292,
                  "non_empty_lines": 242,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 27,
                  "class_count": 2,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "physage_academy/src/physage_academy/scripting/engine.py": {
                  "line_count": 209,
                  "non_empty_lines": 168,
                  "comment_lines": 5,
                  "comment_ratio": 0.02976190476190476,
                  "function_count": 18,
                  "class_count": 3,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "physage_academy/src/physage_academy/physics/engine.py": {
                  "line_count": 456,
                  "non_empty_lines": 357,
                  "comment_lines": 19,
                  "comment_ratio": 0.05322128851540616,
                  "function_count": 29,
                  "class_count": 9,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "scripts/attractor_field.py": {
                  "line_count": 35,
                  "non_empty_lines": 26,
                  "comment_lines": 12,
                  "comment_ratio": 0.46153846153846156,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 2,
                  "quality_score": 0.7
                },
                "physage_academy/tests/test_integration.py": {
                  "line_count": 371,
                  "non_empty_lines": 302,
                  "comment_lines": 48,
                  "comment_ratio": 0.15894039735099338,
                  "function_count": 13,
                  "class_count": 4,
                  "import_count": 17,
                  "quality_score": 0.9999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.8099999999999998,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.818070652173913,
                "multi_session_memory_retention": 0.8392512077294685
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4090353260869565,
                "multi_session_memory_retention_weighted": 0.41962560386473424
              },
              "total_longcontext_utilization_score": 0.8286609299516907
            }
          },
          "timestamp": "2026-01-14T20:43:14.175880"
        }
      }
    },
    "python_data_streaming_hard_013_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_data_streaming_hard_013_feature_implementation_expert_01",
          "scenario_title": "Implement Dynamic Backpressure for Stream Pipelines",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5107846745397264,
          "functional_correctness_score": 0.4237717497556207,
          "code_quality_score": 0.8116666666666665,
          "longcontext_utilization_score": 0.631858497253234,
          "total_score": 2.7848228890061675,
          "generation_time": 240.27305436134338,
          "code_files_generated": 6,
          "total_lines_generated": 1699,
          "parsing_success": true,
          "solution_code": {
            "src/config.py": "\"\"\"Configuration module for ChatterStream Nexus platform.\n\nThis module contains all configuration settings for the streaming platform,\nincluding pipeline settings, processing parameters, and backpressure configuration.\n\"\"\"\n\nimport os\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass BackpressureConfig:\n    \"\"\"Configuration for dynamic backpressure mechanism.\n    \n    Attributes:\n        enabled: Whether backpressure is active.\n        monitoring_interval_seconds: How often to check queue sizes.\n        high_watermark_threshold: Queue fullness percentage that triggers throttling.\n        low_watermark_threshold: Queue fullness percentage below which to ramp up.\n        throttle_factor: Multiplier for reducing rate when throttling.\n        ramp_up_factor: Multiplier for increasing rate when ramping up.\n        min_emission_rate: Minimum allowed emission rate (events/sec).\n        max_emission_rate: Maximum allowed emission rate (events/sec).\n    \"\"\"\n    enabled: bool = True\n    monitoring_interval_seconds: int = 5\n    high_watermark_threshold: float = 0.85\n    low_watermark_threshold: float = 0.25\n    throttle_factor: float = 0.9\n    ramp_up_factor: float = 1.1\n    min_emission_rate: float = 1.0\n    max_emission_rate: float = 10000.0\n\n\n@dataclass\nclass PipelineConfig:\n    \"\"\"Configuration for stream pipeline settings.\"\"\"\n    max_workers: int = 4\n    buffer_size: int = 1000\n    batch_size: int = 100\n    timeout_seconds: int = 30\n\n\n@dataclass\nclass MonitoringConfig:\n    \"\"\"Configuration for monitoring and metrics.\"\"\"\n    enabled: bool = True\n    metrics_port: int = 9090\n    log_level: str = \"INFO\"\n    health_check_interval: int = 10\n\n\n@dataclass\nclass Config:\n    \"\"\"Main configuration container for the platform.\n    \n    Aggregates all configuration sections including pipeline,\n    monitoring, and backpressure settings.\n    \"\"\"\n    pipeline: PipelineConfig = field(default_factory=PipelineConfig)\n    monitoring: MonitoringConfig = field(default_factory=MonitoringConfig)\n    backpressure: BackpressureConfig = field(default_factory=BackpressureConfig)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Config':\n        \"\"\"Create configuration from dictionary.\"\"\"\n        pipeline_data = data.get('pipeline', {})\n        monitoring_data = data.get('monitoring', {})\n        backpressure_data = data.get('backpressure', {})\n        \n        return cls(\n            pipeline=PipelineConfig(**pipeline_data),\n            monitoring=MonitoringConfig(**monitoring_data),\n            backpressure=BackpressureConfig(**backpressure_data)\n        )\n    \n    @classmethod\n    def from_env(cls) -> 'Config':\n        \"\"\"Create configuration from environment variables.\"\"\"\n        config = cls()\n        \n        # Backpressure settings from environment\n        if os.getenv('BACKPRESSURE_ENABLED'):\n            config.backpressure.enabled = os.getenv('BACKPRESSURE_ENABLED', 'true').lower() == 'true'\n        if os.getenv('BACKPRESSURE_MONITORING_INTERVAL'):\n            config.backpressure.monitoring_interval_seconds = int(os.getenv('BACKPRESSURE_MONITORING_INTERVAL', '5'))\n        if os.getenv('BACKPRESSURE_HIGH_WATERMARK'):\n            config.backpressure.high_watermark_threshold = float(os.getenv('BACKPRESSURE_HIGH_WATERMARK', '0.85'))\n        if os.getenv('BACKPRESSURE_LOW_WATERMARK'):\n            config.backpressure.low_watermark_threshold = float(os.getenv('BACKPRESSURE_LOW_WATERMARK', '0.25'))\n        if os.getenv('BACKPRESSURE_THROTTLE_FACTOR'):\n            config.backpressure.throttle_factor = float(os.getenv('BACKPRESSURE_THROTTLE_FACTOR', '0.9'))\n        if os.getenv('BACKPRESSURE_RAMP_UP_FACTOR'):\n            config.backpressure.ramp_up_factor = float(os.getenv('BACKPRESSURE_RAMP_UP_FACTOR', '1.1'))\n        \n        return config\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert configuration to dictionary.\"\"\"\n        return {\n            'pipeline': {\n                'max_workers': self.pipeline.max_workers,\n                'buffer_size': self.pipeline.buffer_size,\n                'batch_size': self.pipeline.batch_size,\n                'timeout_seconds': self.pipeline.timeout_seconds,\n            },\n            'monitoring': {\n                'enabled': self.monitoring.enabled,\n                'metrics_port': self.monitoring.metrics_port,\n                'log_level': self.monitoring.log_level,\n                'health_check_interval': self.monitoring.health_check_interval,\n            },\n            'backpressure': {\n                'enabled': self.backpressure.enabled,\n                'monitoring_interval_seconds': self.backpressure.monitoring_interval_seconds,\n                'high_watermark_threshold': self.backpressure.high_watermark_threshold,\n                'low_watermark_threshold': self.backpressure.low_watermark_threshold,\n                'throttle_factor': self.backpressure.throttle_factor,\n                'ramp_up_factor': self.backpressure.ramp_up_factor,\n                'min_emission_rate': self.backpressure.min_emission_rate,\n                'max_emission_rate': self.backpressure.max_emission_rate,\n            }\n        }\n\n\n# Global configuration instance\n_config: Optional[Config] = None\n\n\ndef get_config() -> Config:\n    \"\"\"Get the global configuration instance.\"\"\"\n    global _config\n    if _config is None:\n        _config = Config.from_env()\n    return _config\n\n\ndef set_config(config: Config) -> None:\n    \"\"\"Set the global configuration instance.\"\"\"\n    global _config\n    _config = config\n\n\ndef reset_config() -> None:\n    \"\"\"Reset the global configuration to defaults.\"\"\"\n    global _config\n    _config = None\n",
            "src/module_1.py": "\"\"\"Primary data source module for ChatterStream Nexus.\n\nThis module implements the main data source generator that produces\nevents for the stream processing pipeline.\n\"\"\"\n\nimport time\nimport threading\nimport queue\nfrom typing import Any, Dict, Optional, Callable, Iterator, List\nfrom dataclasses import dataclass, field\nimport logging\nimport random\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass DataEvent:\n    \"\"\"Represents a single data event from the source.\"\"\"\n    event_id: str\n    timestamp: float\n    payload: Dict[str, Any]\n    source_id: str\n    sequence_number: int\n\n\nclass DataSourceOne:\n    \"\"\"Primary data source generator for the streaming platform.\n    \n    This class generates data events at a configurable rate and supports\n    dynamic rate adjustment for backpressure handling.\n    \n    Attributes:\n        source_id: Unique identifier for this source.\n        initial_rate: Starting emission rate in events per second.\n        current_rate: Current emission rate (can be adjusted dynamically).\n    \"\"\"\n    \n    def __init__(\n        self,\n        source_id: str = \"source_1\",\n        initial_rate: float = 100.0,\n        max_rate: float = 10000.0,\n        min_rate: float = 1.0\n    ):\n        \"\"\"Initialize the data source.\n        \n        Args:\n            source_id: Unique identifier for this source.\n            initial_rate: Initial emission rate in events/second.\n            max_rate: Maximum allowed emission rate.\n            min_rate: Minimum allowed emission rate.\n        \"\"\"\n        self.source_id = source_id\n        self.initial_rate = initial_rate\n        self._current_rate = initial_rate\n        self._max_rate = max_rate\n        self._min_rate = min_rate\n        self._sequence_counter = 0\n        self._running = False\n        self._lock = threading.RLock()\n        self._output_queue: Optional[queue.Queue] = None\n        self._emission_thread: Optional[threading.Thread] = None\n        self._callbacks: List[Callable[[DataEvent], None]] = []\n        \n        logger.info(f\"DataSourceOne initialized: {source_id}, rate={initial_rate}\")\n    \n    @property\n    def current_rate(self) -> float:\n        \"\"\"Get the current emission rate.\"\"\"\n        with self._lock:\n            return self._current_rate\n    \n    def set_emission_rate(self, new_rate: float) -> None:\n        \"\"\"Set the emission rate dynamically.\n        \n        This method allows the backpressure controller to adjust the\n        data emission rate at runtime based on downstream capacity.\n        \n        Args:\n            new_rate: New emission rate in events per second.\n                     Will be clamped to [min_rate, max_rate].\n        \"\"\"\n        with self._lock:\n            old_rate = self._current_rate\n            # Clamp the rate to valid bounds\n            self._current_rate = max(self._min_rate, min(self._max_rate, new_rate))\n            \n            if old_rate != self._current_rate:\n                logger.info(\n                    f\"DataSourceOne [{self.source_id}] rate changed: \"\n                    f\"{old_rate:.2f} -> {self._current_rate:.2f} events/sec\"\n                )\n    \n    def get_emission_rate(self) -> float:\n        \"\"\"Get the current emission rate.\n        \n        Returns:\n            Current emission rate in events per second.\n        \"\"\"\n        return self.current_rate\n    \n    def _generate_event(self) -> DataEvent:\n        \"\"\"Generate a single data event.\"\"\"\n        with self._lock:\n            self._sequence_counter += 1\n            seq = self._sequence_counter\n        \n        return DataEvent(\n            event_id=str(uuid.uuid4()),\n            timestamp=time.time(),\n            payload={\n                \"data\": f\"event_data_{seq}\",\n                \"value\": random.random() * 100,\n                \"category\": random.choice([\"A\", \"B\", \"C\", \"D\"]),\n            },\n            source_id=self.source_id,\n            sequence_number=seq\n        )\n    \n    def _emission_loop(self) -> None:\n        \"\"\"Main emission loop running in a separate thread.\"\"\"\n        logger.info(f\"DataSourceOne [{self.source_id}] emission loop started\")\n        \n        while self._running:\n            try:\n                # Calculate sleep time based on current rate\n                with self._lock:\n                    rate = self._current_rate\n                \n                if rate <= 0:\n                    time.sleep(0.1)\n                    continue\n                \n                sleep_time = 1.0 / rate\n                \n                # Generate and emit event\n                event = self._generate_event()\n                \n                # Send to output queue if configured\n                if self._output_queue is not None:\n                    try:\n                        self._output_queue.put_nowait(event)\n                    except queue.Full:\n                        logger.warning(f\"Output queue full, dropping event {event.event_id}\")\n                \n                # Notify callbacks\n                for callback in self._callbacks:\n                    try:\n                        callback(event)\n                    except Exception as e:\n                        logger.error(f\"Callback error: {e}\")\n                \n                time.sleep(sleep_time)\n                \n            except Exception as e:\n                logger.error(f\"Error in emission loop: {e}\")\n                time.sleep(0.1)\n        \n        logger.info(f\"DataSourceOne [{self.source_id}] emission loop stopped\")\n    \n    def start(self, output_queue: Optional[queue.Queue] = None) -> None:\n        \"\"\"Start the data source emission.\n        \n        Args:\n            output_queue: Optional queue to send events to.\n        \"\"\"\n        if self._running:\n            logger.warning(f\"DataSourceOne [{self.source_id}] already running\")\n            return\n        \n        self._output_queue = output_queue\n        self._running = True\n        self._emission_thread = threading.Thread(\n            target=self._emission_loop,\n            name=f\"DataSource-{self.source_id}\",\n            daemon=True\n        )\n        self._emission_thread.start()\n        logger.info(f\"DataSourceOne [{self.source_id}] started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the data source emission.\"\"\"\n        self._running = False\n        if self._emission_thread is not None:\n            self._emission_thread.join(timeout=5.0)\n            self._emission_thread = None\n        logger.info(f\"DataSourceOne [{self.source_id}] stopped\")\n    \n    def register_callback(self, callback: Callable[[DataEvent], None]) -> None:\n        \"\"\"Register a callback for emitted events.\"\"\"\n        self._callbacks.append(callback)\n    \n    def unregister_callback(self, callback: Callable[[DataEvent], None]) -> None:\n        \"\"\"Unregister a callback.\"\"\"\n        if callback in self._callbacks:\n            self._callbacks.remove(callback)\n    \n    def generate_batch(self, count: int) -> Iterator[DataEvent]:\n        \"\"\"Generate a batch of events synchronously.\n        \n        Args:\n            count: Number of events to generate.\n            \n        Yields:\n            DataEvent objects.\n        \"\"\"\n        for _ in range(count):\n            yield self._generate_event()\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get source statistics.\"\"\"\n        with self._lock:\n            return {\n                \"source_id\": self.source_id,\n                \"current_rate\": self._current_rate,\n                \"initial_rate\": self.initial_rate,\n                \"sequence_counter\": self._sequence_counter,\n                \"running\": self._running,\n                \"min_rate\": self._min_rate,\n                \"max_rate\": self._max_rate,\n            }\n    \n    def is_running(self) -> bool:\n        \"\"\"Check if the source is running.\"\"\"\n        return self._running\n\n\n# Factory function for creating sources\ndef create_data_source(\n    source_id: str = \"source_1\",\n    initial_rate: float = 100.0,\n    **kwargs\n) -> DataSourceOne:\n    \"\"\"Factory function to create a DataSourceOne instance.\"\"\"\n    return DataSourceOne(source_id=source_id, initial_rate=initial_rate, **kwargs)\n",
            "src/module_2.py": "\"\"\"Secondary data source module for ChatterStream Nexus.\n\nThis module implements an alternative data source generator that produces\nevents for the stream processing pipeline with different characteristics.\n\"\"\"\n\nimport time\nimport threading\nimport queue\nfrom typing import Any, Dict, Optional, Callable, Iterator, List, Union\nfrom dataclasses import dataclass, field\nimport logging\nimport random\nimport uuid\nimport json\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass StreamEvent:\n    \"\"\"Represents a stream event from the secondary source.\"\"\"\n    event_id: str\n    timestamp: float\n    payload: Dict[str, Any]\n    source_id: str\n    sequence_number: int\n    event_type: str\n    priority: int = 0\n\n\nclass DataSourceTwo:\n    \"\"\"Secondary data source generator for the streaming platform.\n    \n    This class generates data events with different characteristics than\n    DataSourceOne, supporting multiple event types and priorities.\n    Supports dynamic rate adjustment for backpressure handling.\n    \n    Attributes:\n        source_id: Unique identifier for this source.\n        initial_rate: Starting emission rate in events per second.\n        current_rate: Current emission rate (can be adjusted dynamically).\n    \"\"\"\n    \n    EVENT_TYPES = [\"metric\", \"log\", \"trace\", \"alert\", \"heartbeat\"]\n    \n    def __init__(\n        self,\n        source_id: str = \"source_2\",\n        initial_rate: float = 50.0,\n        max_rate: float = 10000.0,\n        min_rate: float = 1.0,\n        event_types: Optional[List[str]] = None\n    ):\n        \"\"\"Initialize the secondary data source.\n        \n        Args:\n            source_id: Unique identifier for this source.\n            initial_rate: Initial emission rate in events/second.\n            max_rate: Maximum allowed emission rate.\n            min_rate: Minimum allowed emission rate.\n            event_types: List of event types to generate.\n        \"\"\"\n        self.source_id = source_id\n        self.initial_rate = initial_rate\n        self._current_rate = initial_rate\n        self._max_rate = max_rate\n        self._min_rate = min_rate\n        self._event_types = event_types or self.EVENT_TYPES\n        self._sequence_counter = 0\n        self._running = False\n        self._paused = False\n        self._lock = threading.RLock()\n        self._output_queue: Optional[queue.Queue] = None\n        self._emission_thread: Optional[threading.Thread] = None\n        self._callbacks: List[Callable[[StreamEvent], None]] = []\n        self._event_counts: Dict[str, int] = {et: 0 for et in self._event_types}\n        \n        logger.info(f\"DataSourceTwo initialized: {source_id}, rate={initial_rate}\")\n    \n    @property\n    def current_rate(self) -> float:\n        \"\"\"Get the current emission rate.\"\"\"\n        with self._lock:\n            return self._current_rate\n    \n    def set_emission_rate(self, new_rate: float) -> None:\n        \"\"\"Set the emission rate dynamically.\n        \n        This method allows the backpressure controller to adjust the\n        data emission rate at runtime based on downstream capacity.\n        \n        Args:\n            new_rate: New emission rate in events per second.\n                     Will be clamped to [min_rate, max_rate].\n        \"\"\"\n        with self._lock:\n            old_rate = self._current_rate\n            # Clamp the rate to valid bounds\n            self._current_rate = max(self._min_rate, min(self._max_rate, new_rate))\n            \n            if old_rate != self._current_rate:\n                logger.info(\n                    f\"DataSourceTwo [{self.source_id}] rate changed: \"\n                    f\"{old_rate:.2f} -> {self._current_rate:.2f} events/sec\"\n                )\n    \n    def get_emission_rate(self) -> float:\n        \"\"\"Get the current emission rate.\n        \n        Returns:\n            Current emission rate in events per second.\n        \"\"\"\n        return self.current_rate\n    \n    def _generate_event(self) -> StreamEvent:\n        \"\"\"Generate a single stream event.\"\"\"\n        with self._lock:\n            self._sequence_counter += 1\n            seq = self._sequence_counter\n        \n        event_type = random.choice(self._event_types)\n        priority = random.randint(0, 9)\n        \n        # Generate type-specific payload\n        if event_type == \"metric\":\n            payload = {\n                \"metric_name\": f\"metric_{random.randint(1, 100)}\",\n                \"value\": random.random() * 1000,\n                \"unit\": random.choice([\"ms\", \"bytes\", \"count\", \"percent\"]),\n            }\n        elif event_type == \"log\":\n            payload = {\n                \"level\": random.choice([\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\"]),\n                \"message\": f\"Log message {seq}\",\n                \"component\": f\"component_{random.randint(1, 10)}\",\n            }\n        elif event_type == \"trace\":\n            payload = {\n                \"trace_id\": str(uuid.uuid4()),\n                \"span_id\": str(uuid.uuid4())[:8],\n                \"duration_ms\": random.random() * 100,\n            }\n        elif event_type == \"alert\":\n            payload = {\n                \"severity\": random.choice([\"low\", \"medium\", \"high\", \"critical\"]),\n                \"title\": f\"Alert {seq}\",\n                \"resolved\": random.choice([True, False]),\n            }\n            priority = max(priority, 7)  # Alerts have higher priority\n        else:  # heartbeat\n            payload = {\n                \"status\": \"alive\",\n                \"uptime_seconds\": random.randint(0, 86400),\n            }\n        \n        with self._lock:\n            self._event_counts[event_type] += 1\n        \n        return StreamEvent(\n            event_id=str(uuid.uuid4()),\n            timestamp=time.time(),\n            payload=payload,\n            source_id=self.source_id,\n            sequence_number=seq,\n            event_type=event_type,\n            priority=priority\n        )\n    \n    def _emission_loop(self) -> None:\n        \"\"\"Main emission loop running in a separate thread.\"\"\"\n        logger.info(f\"DataSourceTwo [{self.source_id}] emission loop started\")\n        \n        while self._running:\n            try:\n                # Check if paused\n                if self._paused:\n                    time.sleep(0.1)\n                    continue\n                \n                # Calculate sleep time based on current rate\n                with self._lock:\n                    rate = self._current_rate\n                \n                if rate <= 0:\n                    time.sleep(0.1)\n                    continue\n                \n                sleep_time = 1.0 / rate\n                \n                # Generate and emit event\n                event = self._generate_event()\n                \n                # Send to output queue if configured\n                if self._output_queue is not None:\n                    try:\n                        self._output_queue.put_nowait(event)\n                    except queue.Full:\n                        logger.warning(\n                            f\"Output queue full, dropping event {event.event_id}\"\n                        )\n                \n                # Notify callbacks\n                for callback in self._callbacks:\n                    try:\n                        callback(event)\n                    except Exception as e:\n                        logger.error(f\"Callback error: {e}\")\n                \n                time.sleep(sleep_time)\n                \n            except Exception as e:\n                logger.error(f\"Error in emission loop: {e}\")\n                time.sleep(0.1)\n        \n        logger.info(f\"DataSourceTwo [{self.source_id}] emission loop stopped\")\n    \n    def start(self, output_queue: Optional[queue.Queue] = None) -> None:\n        \"\"\"Start the data source emission.\n        \n        Args:\n            output_queue: Optional queue to send events to.\n        \"\"\"\n        if self._running:\n            logger.warning(f\"DataSourceTwo [{self.source_id}] already running\")\n            return\n        \n        self._output_queue = output_queue\n        self._running = True\n        self._paused = False\n        self._emission_thread = threading.Thread(\n            target=self._emission_loop,\n            name=f\"DataSource-{self.source_id}\",\n            daemon=True\n        )\n        self._emission_thread.start()\n        logger.info(f\"DataSourceTwo [{self.source_id}] started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the data source emission.\"\"\"\n        self._running = False\n        if self._emission_thread is not None:\n            self._emission_thread.join(timeout=5.0)\n            self._emission_thread = None\n        logger.info(f\"DataSourceTwo [{self.source_id}] stopped\")\n    \n    def pause(self) -> None:\n        \"\"\"Pause event emission without stopping the thread.\"\"\"\n        self._paused = True\n        logger.info(f\"DataSourceTwo [{self.source_id}] paused\")\n    \n    def resume(self) -> None:\n        \"\"\"Resume event emission after pause.\"\"\"\n        self._paused = False\n        logger.info(f\"DataSourceTwo [{self.source_id}] resumed\")\n    \n    def register_callback(self, callback: Callable[[StreamEvent], None]) -> None:\n        \"\"\"Register a callback for emitted events.\"\"\"\n        self._callbacks.append(callback)\n    \n    def unregister_callback(self, callback: Callable[[StreamEvent], None]) -> None:\n        \"\"\"Unregister a callback.\"\"\"\n        if callback in self._callbacks:\n            self._callbacks.remove(callback)\n    \n    def generate_batch(self, count: int) -> Iterator[StreamEvent]:\n        \"\"\"Generate a batch of events synchronously.\n        \n        Args:\n            count: Number of events to generate.\n            \n        Yields:\n            StreamEvent objects.\n        \"\"\"\n        for _ in range(count):\n            yield self._generate_event()\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get source statistics.\"\"\"\n        with self._lock:\n            return {\n                \"source_id\": self.source_id,\n                \"current_rate\": self._current_rate,\n                \"initial_rate\": self.initial_rate,\n                \"sequence_counter\": self._sequence_counter,\n                \"running\": self._running,\n                \"paused\": self._paused,\n                \"min_rate\": self._min_rate,\n                \"max_rate\": self._max_rate,\n                \"event_counts\": dict(self._event_counts),\n                \"event_types\": list(self._event_types),\n            }\n    \n    def is_running(self) -> bool:\n        \"\"\"Check if the source is running.\"\"\"\n        return self._running and not self._paused\n    \n    def reset_counters(self) -> None:\n        \"\"\"Reset event counters.\"\"\"\n        with self._lock:\n            self._event_counts = {et: 0 for et in self._event_types}\n            logger.info(f\"DataSourceTwo [{self.source_id}] counters reset\")\n\n\n# Factory function for creating sources\ndef create_data_source(\n    source_id: str = \"source_2\",\n    initial_rate: float = 50.0,\n    **kwargs\n) -> DataSourceTwo:\n    \"\"\"Factory function to create a DataSourceTwo instance.\"\"\"\n    return DataSourceTwo(source_id=source_id, initial_rate=initial_rate, **kwargs)\n",
            "src/module_31.py": "\"\"\"Monitoring module for ChatterStream Nexus.\n\nThis module provides health monitoring, metrics collection, and\nperformance tracking for the streaming platform.\n\"\"\"\n\nimport time\nimport threading\nfrom typing import Any, Dict, Optional, List, Callable, TYPE_CHECKING\nfrom dataclasses import dataclass, field\nimport logging\nimport queue\n\nif TYPE_CHECKING:\n    from .module_20 import PipelineScheduler\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass HealthStatus:\n    \"\"\"Represents the health status of a component.\"\"\"\n    component_name: str\n    status: str  # \"healthy\", \"degraded\", \"unhealthy\"\n    last_check: float\n    details: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass QueueMetrics:\n    \"\"\"Metrics for a processing queue.\"\"\"\n    queue_name: str\n    current_size: int\n    max_size: int\n    fullness_percentage: float\n    \n    @classmethod\n    def from_queue_info(cls, name: str, current: int, maximum: int) -> 'QueueMetrics':\n        \"\"\"Create QueueMetrics from queue information.\"\"\"\n        fullness = (current / maximum) if maximum > 0 else 0.0\n        return cls(\n            queue_name=name,\n            current_size=current,\n            max_size=maximum,\n            fullness_percentage=fullness\n        )\n\n\n@dataclass\nclass MetricPoint:\n    \"\"\"A single metric data point.\"\"\"\n    name: str\n    value: float\n    timestamp: float\n    labels: Dict[str, str] = field(default_factory=dict)\n\n\nclass Monitor:\n    \"\"\"Central monitoring component for the streaming platform.\n    \n    Collects health and performance metrics from various components\n    including the pipeline scheduler's processing queues.\n    \"\"\"\n    \n    def __init__(self, check_interval: int = 10):\n        \"\"\"Initialize the monitor.\n        \n        Args:\n            check_interval: Interval in seconds between health checks.\n        \"\"\"\n        self.check_interval = check_interval\n        self._running = False\n        self._lock = threading.RLock()\n        self._health_statuses: Dict[str, HealthStatus] = {}\n        self._metrics: List[MetricPoint] = []\n        self._metrics_limit = 10000\n        self._check_thread: Optional[threading.Thread] = None\n        self._health_callbacks: List[Callable[[HealthStatus], None]] = []\n        self._scheduler_ref: Optional['PipelineScheduler'] = None\n        \n        logger.info(f\"Monitor initialized with check_interval={check_interval}s\")\n    \n    def set_scheduler(self, scheduler: 'PipelineScheduler') -> None:\n        \"\"\"Set reference to the pipeline scheduler for queue monitoring.\n        \n        Args:\n            scheduler: The PipelineScheduler instance to monitor.\n        \"\"\"\n        self._scheduler_ref = scheduler\n        logger.info(\"Monitor linked to PipelineScheduler\")\n    \n    def get_queue_fullness(self) -> float:\n        \"\"\"Get the fullness percentage of the most full queue.\n        \n        This method queries the pipeline scheduler for queue information\n        and returns the highest fullness percentage among all queues.\n        Used by the backpressure controller to determine throttling needs.\n        \n        Returns:\n            Float between 0.0 and 1.0 representing the fullest queue's\n            percentage (current_size / max_size). Returns 0.0 if no\n            scheduler is linked or no queues exist.\n        \"\"\"\n        if self._scheduler_ref is None:\n            logger.warning(\"No scheduler linked, returning 0.0 queue fullness\")\n            return 0.0\n        \n        try:\n            queue_info = self._scheduler_ref.get_queue_status()\n            if not queue_info:\n                return 0.0\n            \n            max_fullness = 0.0\n            for name, info in queue_info.items():\n                current = info.get('current_size', 0)\n                maximum = info.get('max_size', 1)\n                if maximum > 0:\n                    fullness = current / maximum\n                    max_fullness = max(max_fullness, fullness)\n            \n            return max_fullness\n            \n        except Exception as e:\n            logger.error(f\"Error getting queue fullness: {e}\")\n            return 0.0\n    \n    def get_all_queue_metrics(self) -> List[QueueMetrics]:\n        \"\"\"Get metrics for all monitored queues.\n        \n        Returns:\n            List of QueueMetrics for each queue in the scheduler.\n        \"\"\"\n        if self._scheduler_ref is None:\n            return []\n        \n        try:\n            queue_info = self._scheduler_ref.get_queue_status()\n            metrics = []\n            \n            for name, info in queue_info.items():\n                metrics.append(QueueMetrics.from_queue_info(\n                    name=name,\n                    current=info.get('current_size', 0),\n                    maximum=info.get('max_size', 1)\n                ))\n            \n            return metrics\n            \n        except Exception as e:\n            logger.error(f\"Error getting queue metrics: {e}\")\n            return []\n    \n    def record_metric(self, name: str, value: float, labels: Optional[Dict[str, str]] = None) -> None:\n        \"\"\"Record a metric data point.\n        \n        Args:\n            name: Metric name.\n            value: Metric value.\n            labels: Optional labels for the metric.\n        \"\"\"\n        with self._lock:\n            point = MetricPoint(\n                name=name,\n                value=value,\n                timestamp=time.time(),\n                labels=labels or {}\n            )\n            self._metrics.append(point)\n            \n            # Trim old metrics if limit exceeded\n            if len(self._metrics) > self._metrics_limit:\n                self._metrics = self._metrics[-self._metrics_limit:]\n    \n    def update_health(self, component: str, status: str, details: Optional[Dict[str, Any]] = None) -> None:\n        \"\"\"Update health status for a component.\n        \n        Args:\n            component: Component name.\n            status: Health status (\"healthy\", \"degraded\", \"unhealthy\").\n            details: Optional additional details.\n        \"\"\"\n        with self._lock:\n            health = HealthStatus(\n                component_name=component,\n                status=status,\n                last_check=time.time(),\n                details=details or {}\n            )\n            self._health_statuses[component] = health\n            \n            # Notify callbacks\n            for callback in self._health_callbacks:\n                try:\n                    callback(health)\n                except Exception as e:\n                    logger.error(f\"Health callback error: {e}\")\n    \n    def get_health(self, component: Optional[str] = None) -> Dict[str, HealthStatus]:\n        \"\"\"Get health status.\n        \n        Args:\n            component: Optional specific component to get. If None, returns all.\n            \n        Returns:\n            Dictionary of component name to HealthStatus.\n        \"\"\"\n        with self._lock:\n            if component:\n                if component in self._health_statuses:\n                    return {component: self._health_statuses[component]}\n                return {}\n            return dict(self._health_statuses)\n    \n    def get_metrics(self, name: Optional[str] = None, since: Optional[float] = None) -> List[MetricPoint]:\n        \"\"\"Get recorded metrics.\n        \n        Args:\n            name: Optional filter by metric name.\n            since: Optional filter by timestamp (return metrics after this time).\n            \n        Returns:\n            List of MetricPoint objects.\n        \"\"\"\n        with self._lock:\n            result = self._metrics\n            \n            if name:\n                result = [m for m in result if m.name == name]\n            \n            if since:\n                result = [m for m in result if m.timestamp >= since]\n            \n            return list(result)\n    \n    def register_health_callback(self, callback: Callable[[HealthStatus], None]) -> None:\n        \"\"\"Register a callback for health status changes.\"\"\"\n        self._health_callbacks.append(callback)\n    \n    def _health_check_loop(self) -> None:\n        \"\"\"Background health check loop.\"\"\"\n        logger.info(\"Monitor health check loop started\")\n        \n        while self._running:\n            try:\n                # Record queue metrics\n                queue_fullness = self.get_queue_fullness()\n                self.record_metric(\"queue_fullness_max\", queue_fullness)\n                \n                all_queue_metrics = self.get_all_queue_metrics()\n                for qm in all_queue_metrics:\n                    self.record_metric(\n                        \"queue_fullness\",\n                        qm.fullness_percentage,\n                        {\"queue_name\": qm.queue_name}\n                    )\n                \n                # Update overall health based on queue fullness\n                if queue_fullness > 0.9:\n                    self.update_health(\"queues\", \"unhealthy\", {\"fullness\": queue_fullness})\n                elif queue_fullness > 0.7:\n                    self.update_health(\"queues\", \"degraded\", {\"fullness\": queue_fullness})\n                else:\n                    self.update_health(\"queues\", \"healthy\", {\"fullness\": queue_fullness})\n                \n                time.sleep(self.check_interval)\n                \n            except Exception as e:\n                logger.error(f\"Error in health check loop: {e}\")\n                time.sleep(1)\n        \n        logger.info(\"Monitor health check loop stopped\")\n    \n    def start(self) -> None:\n        \"\"\"Start the monitoring background tasks.\"\"\"\n        if self._running:\n            logger.warning(\"Monitor already running\")\n            return\n        \n        self._running = True\n        self._check_thread = threading.Thread(\n            target=self._health_check_loop,\n            name=\"Monitor-HealthCheck\",\n            daemon=True\n        )\n        self._check_thread.start()\n        logger.info(\"Monitor started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the monitoring background tasks.\"\"\"\n        self._running = False\n        if self._check_thread is not None:\n            self._check_thread.join(timeout=5.0)\n            self._check_thread = None\n        logger.info(\"Monitor stopped\")\n    \n    def get_summary(self) -> Dict[str, Any]:\n        \"\"\"Get a summary of monitoring data.\"\"\"\n        with self._lock:\n            queue_metrics = self.get_all_queue_metrics()\n            return {\n                \"health_statuses\": {\n                    k: {\"status\": v.status, \"last_check\": v.last_check}\n                    for k, v in self._health_statuses.items()\n                },\n                \"metrics_count\": len(self._metrics),\n                \"queue_fullness_max\": self.get_queue_fullness(),\n                \"queues\": [\n                    {\n                        \"name\": qm.queue_name,\n                        \"fullness\": qm.fullness_percentage,\n                        \"current\": qm.current_size,\n                        \"max\": qm.max_size\n                    }\n                    for qm in queue_metrics\n                ],\n                \"running\": self._running,\n            }\n\n\n# Global monitor instance\n_monitor: Optional[Monitor] = None\n\n\ndef get_monitor() -> Monitor:\n    \"\"\"Get the global monitor instance.\"\"\"\n    global _monitor\n    if _monitor is None:\n        _monitor = Monitor()\n    return _monitor\n\n\ndef set_monitor(monitor: Monitor) -> None:\n    \"\"\"Set the global monitor instance.\"\"\"\n    global _monitor\n    _monitor = monitor\n",
            "src/module_20.py": "\"\"\"Pipeline scheduler module for ChatterStream Nexus.\n\nThis module handles pipeline scheduling, orchestration, and\nbackpressure control for the streaming platform.\n\"\"\"\n\nimport time\nimport threading\nimport queue\nfrom typing import Any, Dict, Optional, List, Callable, Union, TYPE_CHECKING\nfrom dataclasses import dataclass, field\nimport logging\nfrom enum import Enum\n\nif TYPE_CHECKING:\n    from .module_1 import DataSourceOne\n    from .module_2 import DataSourceTwo\n    from .module_31 import Monitor\n    from .config import Config\n\nlogger = logging.getLogger(__name__)\n\n\nclass StageState(Enum):\n    \"\"\"State of a processing stage.\"\"\"\n    IDLE = \"idle\"\n    RUNNING = \"running\"\n    PAUSED = \"paused\"\n    STOPPED = \"stopped\"\n    ERROR = \"error\"\n\n\n@dataclass\nclass ProcessingStage:\n    \"\"\"Represents a processing stage in the pipeline.\"\"\"\n    name: str\n    input_queue: queue.Queue\n    output_queue: Optional[queue.Queue]\n    processor: Callable[[Any], Any]\n    max_queue_size: int = 1000\n    state: StageState = StageState.IDLE\n    processed_count: int = 0\n    error_count: int = 0\n\n\nclass PipelineScheduler:\n    \"\"\"Scheduler for managing stream processing pipelines.\n    \n    Handles stage orchestration, queue management, and implements\n    dynamic backpressure control to prevent buffer overflow.\n    \"\"\"\n    \n    def __init__(self, config: Optional['Config'] = None):\n        \"\"\"Initialize the pipeline scheduler.\n        \n        Args:\n            config: Configuration object. If None, uses defaults.\n        \"\"\"\n        self._config = config\n        self._stages: Dict[str, ProcessingStage] = {}\n        self._stage_threads: Dict[str, threading.Thread] = {}\n        self._running = False\n        self._lock = threading.RLock()\n        \n        # Data sources for backpressure control\n        self._sources: List[Union['DataSourceOne', 'DataSourceTwo']] = []\n        \n        # Monitor reference for queue inspection\n        self._monitor: Optional['Monitor'] = None\n        \n        # Backpressure control state\n        self._backpressure_enabled = False\n        self._backpressure_thread: Optional[threading.Thread] = None\n        self._current_emission_rate: float = 100.0  # Default rate\n        self._last_backpressure_check: float = 0.0\n        \n        # Load backpressure config if available\n        if config is not None:\n            bp_config = config.backpressure\n            self._backpressure_enabled = bp_config.enabled\n            self._monitoring_interval = bp_config.monitoring_interval_seconds\n            self._high_watermark = bp_config.high_watermark_threshold\n            self._low_watermark = bp_config.low_watermark_threshold\n            self._throttle_factor = bp_config.throttle_factor\n            self._ramp_up_factor = bp_config.ramp_up_factor\n            self._min_rate = bp_config.min_emission_rate\n            self._max_rate = bp_config.max_emission_rate\n        else:\n            # Defaults\n            self._monitoring_interval = 5\n            self._high_watermark = 0.85\n            self._low_watermark = 0.25\n            self._throttle_factor = 0.9\n            self._ramp_up_factor = 1.1\n            self._min_rate = 1.0\n            self._max_rate = 10000.0\n        \n        logger.info(f\"PipelineScheduler initialized, backpressure={self._backpressure_enabled}\")\n    \n    def set_monitor(self, monitor: 'Monitor') -> None:\n        \"\"\"Set the monitor reference for queue inspection.\n        \n        Args:\n            monitor: The Monitor instance.\n        \"\"\"\n        self._monitor = monitor\n        # Also link scheduler to monitor for bidirectional access\n        monitor.set_scheduler(self)\n        logger.info(\"PipelineScheduler linked to Monitor\")\n    \n    def register_source(self, source: Union['DataSourceOne', 'DataSourceTwo']) -> None:\n        \"\"\"Register a data source for backpressure control.\n        \n        Args:\n            source: A data source instance with set_emission_rate method.\n        \"\"\"\n        self._sources.append(source)\n        # Initialize with current rate\n        if hasattr(source, 'get_emission_rate'):\n            rate = source.get_emission_rate()\n            if rate > 0:\n                self._current_emission_rate = rate\n        logger.info(f\"Registered source: {source.source_id}\")\n    \n    def unregister_source(self, source: Union['DataSourceOne', 'DataSourceTwo']) -> None:\n        \"\"\"Unregister a data source.\"\"\"\n        if source in self._sources:\n            self._sources.remove(source)\n            logger.info(f\"Unregistered source: {source.source_id}\")\n    \n    def add_stage(\n        self,\n        name: str,\n        processor: Callable[[Any], Any],\n        max_queue_size: int = 1000,\n        input_queue: Optional[queue.Queue] = None,\n        output_queue: Optional[queue.Queue] = None\n    ) -> queue.Queue:\n        \"\"\"Add a processing stage to the pipeline.\n        \n        Args:\n            name: Stage name.\n            processor: Processing function.\n            max_queue_size: Maximum input queue size.\n            input_queue: Optional existing input queue.\n            output_queue: Optional output queue for chaining.\n            \n        Returns:\n            The input queue for this stage.\n        \"\"\"\n        if input_queue is None:\n            input_queue = queue.Queue(maxsize=max_queue_size)\n        \n        stage = ProcessingStage(\n            name=name,\n            input_queue=input_queue,\n            output_queue=output_queue,\n            processor=processor,\n            max_queue_size=max_queue_size\n        )\n        \n        with self._lock:\n            self._stages[name] = stage\n        \n        logger.info(f\"Added stage: {name}, max_queue_size={max_queue_size}\")\n        return input_queue\n    \n    def remove_stage(self, name: str) -> None:\n        \"\"\"Remove a processing stage.\"\"\"\n        with self._lock:\n            if name in self._stages:\n                del self._stages[name]\n                logger.info(f\"Removed stage: {name}\")\n    \n    def get_queue_status(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Get status of all stage queues.\n        \n        Returns:\n            Dictionary mapping stage names to queue info including\n            current_size and max_size.\n        \"\"\"\n        with self._lock:\n            result = {}\n            for name, stage in self._stages.items():\n                result[name] = {\n                    'current_size': stage.input_queue.qsize(),\n                    'max_size': stage.max_queue_size,\n                    'state': stage.state.value,\n                    'processed_count': stage.processed_count,\n                    'error_count': stage.error_count,\n                }\n            return result\n    \n    def _process_stage(self, stage: ProcessingStage) -> None:\n        \"\"\"Processing loop for a single stage.\"\"\"\n        logger.info(f\"Stage {stage.name} processing loop started\")\n        stage.state = StageState.RUNNING\n        \n        while self._running:\n            try:\n                # Get item from input queue with timeout\n                try:\n                    item = stage.input_queue.get(timeout=1.0)\n                except queue.Empty:\n                    continue\n                \n                # Process the item\n                try:\n                    result = stage.processor(item)\n                    stage.processed_count += 1\n                    \n                    # Send to output queue if configured\n                    if stage.output_queue is not None and result is not None:\n                        try:\n                            stage.output_queue.put_nowait(result)\n                        except queue.Full:\n                            logger.warning(f\"Stage {stage.name} output queue full\")\n                    \n                except Exception as e:\n                    stage.error_count += 1\n                    logger.error(f\"Stage {stage.name} processing error: {e}\")\n                \n                stage.input_queue.task_done()\n                \n            except Exception as e:\n                logger.error(f\"Stage {stage.name} loop error: {e}\")\n                stage.state = StageState.ERROR\n                time.sleep(0.1)\n        \n        stage.state = StageState.STOPPED\n        logger.info(f\"Stage {stage.name} processing loop stopped\")\n    \n    def _apply_emission_rate(self, new_rate: float) -> None:\n        \"\"\"Apply new emission rate to all registered sources.\n        \n        Args:\n            new_rate: New emission rate in events/second.\n        \"\"\"\n        # Clamp to valid range\n        new_rate = max(self._min_rate, min(self._max_rate, new_rate))\n        \n        if abs(new_rate - self._current_emission_rate) < 0.01:\n            return  # No significant change\n        \n        old_rate = self._current_emission_rate\n        self._current_emission_rate = new_rate\n        \n        for source in self._sources:\n            try:\n                if hasattr(source, 'set_emission_rate'):\n                    source.set_emission_rate(new_rate)\n            except Exception as e:\n                logger.error(f\"Error setting emission rate on source: {e}\")\n        \n        logger.info(f\"Emission rate adjusted: {old_rate:.2f} -> {new_rate:.2f}\")\n    \n    def _backpressure_control_loop(self) -> None:\n        \"\"\"Background loop for backpressure control.\"\"\"\n        logger.info(\"Backpressure control loop started\")\n        \n        while self._running and self._backpressure_enabled:\n            try:\n                current_time = time.time()\n                \n                # Check if enough time has passed since last check\n                if current_time - self._last_backpressure_check < self._monitoring_interval:\n                    time.sleep(0.5)\n                    continue\n                \n                self._last_backpressure_check = current_time\n                \n                # Get queue fullness from monitor\n                queue_fullness = 0.0\n                if self._monitor is not None:\n                    queue_fullness = self._monitor.get_queue_fullness()\n                else:\n                    # Fall back to direct queue inspection\n                    queue_status = self.get_queue_status()\n                    if queue_status:\n                        max_fullness = 0.0\n                        for info in queue_status.values():\n                            current = info.get('current_size', 0)\n                            maximum = info.get('max_size', 1)\n                            if maximum > 0:\n                                fullness = current / maximum\n                                max_fullness = max(max_fullness, fullness)\n                        queue_fullness = max_fullness\n                \n                # Apply backpressure logic\n                if queue_fullness >= self._high_watermark:\n                    # Throttle down\n                    new_rate = self._current_emission_rate * self._throttle_factor\n                    logger.info(\n                        f\"Backpressure: Queue fullness {queue_fullness:.2%} >= \"\n                        f\"high watermark {self._high_watermark:.2%}, throttling down\"\n                    )\n                    self._apply_emission_rate(new_rate)\n                    \n                elif queue_fullness <= self._low_watermark:\n                    # Ramp up\n                    new_rate = self._current_emission_rate * self._ramp_up_factor\n                    logger.debug(\n                        f\"Backpressure: Queue fullness {queue_fullness:.2%} <= \"\n                        f\"low watermark {self._low_watermark:.2%}, ramping up\"\n                    )\n                    self._apply_emission_rate(new_rate)\n                \n                # Record metrics if monitor is available\n                if self._monitor is not None:\n                    self._monitor.record_metric(\n                        \"backpressure_emission_rate\",\n                        self._current_emission_rate\n                    )\n                    self._monitor.record_metric(\n                        \"backpressure_queue_fullness\",\n                        queue_fullness\n                    )\n                \n            except Exception as e:\n                logger.error(f\"Error in backpressure control loop: {e}\")\n                time.sleep(1)\n        \n        logger.info(\"Backpressure control loop stopped\")\n    \n    def start(self) -> None:\n        \"\"\"Start the pipeline scheduler and all stages.\"\"\"\n        if self._running:\n            logger.warning(\"PipelineScheduler already running\")\n            return\n        \n        self._running = True\n        \n        # Start processing threads for each stage\n        with self._lock:\n            for name, stage in self._stages.items():\n                thread = threading.Thread(\n                    target=self._process_stage,\n                    args=(stage,),\n                    name=f\"Stage-{name}\",\n                    daemon=True\n                )\n                self._stage_threads[name] = thread\n                thread.start()\n        \n        # Start backpressure control if enabled\n        if self._backpressure_enabled:\n            self._backpressure_thread = threading.Thread(\n                target=self._backpressure_control_loop,\n                name=\"BackpressureControl\",\n                daemon=True\n            )\n            self._backpressure_thread.start()\n            logger.info(\"Backpressure control enabled\")\n        \n        logger.info(\"PipelineScheduler started\")\n    \n    def stop(self) -> None:\n        \"\"\"Stop the pipeline scheduler and all stages.\"\"\"\n        self._running = False\n        \n        # Wait for stage threads\n        for name, thread in self._stage_threads.items():\n            thread.join(timeout=5.0)\n        self._stage_threads.clear()\n        \n        # Wait for backpressure thread\n        if self._backpressure_thread is not None:\n            self._backpressure_thread.join(timeout=5.0)\n            self._backpressure_thread = None\n        \n        logger.info(\"PipelineScheduler stopped\")\n    \n    def enable_backpressure(self) -> None:\n        \"\"\"Enable backpressure control at runtime.\"\"\"\n        if self._backpressure_enabled:\n            return\n        \n        self._backpressure_enabled = True\n        \n        if self._running and self._backpressure_thread is None:\n            self._backpressure_thread = threading.Thread(\n                target=self._backpressure_control_loop,\n                name=\"BackpressureControl\",\n                daemon=True\n            )\n            self._backpressure_thread.start()\n        \n        logger.info(\"Backpressure control enabled\")\n    \n    def disable_backpressure(self) -> None:\n        \"\"\"Disable backpressure control at runtime.\"\"\"\n        self._backpressure_enabled = False\n        logger.info(\"Backpressure control disabled\")\n    \n    def get_backpressure_status(self) -> Dict[str, Any]:\n        \"\"\"Get current backpressure status.\"\"\"\n        return {\n            \"enabled\": self._backpressure_enabled,\n            \"current_emission_rate\": self._current_emission_rate,\n            \"min_rate\": self._min_rate,\n            \"max_rate\": self._max_rate,\n            \"high_watermark\": self._high_watermark,\n            \"low_watermark\": self._low_watermark,\n            \"throttle_factor\": self._throttle_factor,\n            \"ramp_up_factor\": self._ramp_up_factor,\n            \"monitoring_interval\": self._monitoring_interval,\n            \"registered_sources\": len(self._sources),\n            \"last_check\": self._last_backpressure_check,\n        }\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get scheduler statistics.\"\"\"\n        with self._lock:\n            return {\n                \"running\": self._running,\n                \"stages\": list(self._stages.keys()),\n                \"stage_count\": len(self._stages),\n                \"queue_status\": self.get_queue_status(),\n                \"backpressure\": self.get_backpressure_status(),\n                \"source_count\": len(self._sources),\n            }\n\n\n# Global scheduler instance\n_scheduler: Optional[PipelineScheduler] = None\n\n\ndef get_scheduler(config: Optional['Config'] = None) -> PipelineScheduler:\n    \"\"\"Get the global scheduler instance.\"\"\"\n    global _scheduler\n    if _scheduler is None:\n        _scheduler = PipelineScheduler(config)\n    return _scheduler\n\n\ndef set_scheduler(scheduler: PipelineScheduler) -> None:\n    \"\"\"Set the global scheduler instance.\"\"\"\n    global _scheduler\n    _scheduler = scheduler\n",
            "docs/api.md": "# ChatterStream Nexus API Documentation\n\nThis document provides comprehensive API documentation for the ChatterStream Nexus streaming platform.\n\n## Overview\n\nChatterStream Nexus is a high-throughput, parallel data streaming platform designed for real-time data processing at scale.\n\n## Core Components\n\n### Data Sources\n\nThe platform supports multiple data source types:\n\n- **DataSourceOne** (`src/module_1.py`): Primary event generator\n- **DataSourceTwo** (`src/module_2.py`): Secondary event generator with multiple event types\n\n### Pipeline Scheduler\n\nThe `PipelineScheduler` (`src/module_20.py`) orchestrates data flow through processing stages.\n\n### Monitoring\n\nThe `Monitor` (`src/module_31.py`) provides health checks and metrics collection.\n\n---\n\n## Dynamic Backpressure\n\nDynamic backpressure is a flow control mechanism that automatically regulates data ingestion rates based on the real-time processing capacity of pipeline stages. This prevents buffer overflow, data loss, and system instability when downstream components become bottlenecks.\n\n### How It Works\n\n1. The scheduler periodically monitors the fullness of processing stage queues\n2. When queue fullness exceeds the high watermark threshold, the system throttles data sources\n3. When queue fullness drops below the low watermark threshold, the system ramps up the rate\n4. Rate adjustments are applied gradually using configurable factors\n\n### Configuration\n\nBackpressure is configured in `src/config.py` under the `backpressure` section:\n\n```python\n@dataclass\nclass BackpressureConfig:\n    enabled: bool = True\n    monitoring_interval_seconds: int = 5\n    high_watermark_threshold: float = 0.85\n    low_watermark_threshold: float = 0.25\n    throttle_factor: float = 0.9\n    ramp_up_factor: float = 1.1\n    min_emission_rate: float = 1.0\n    max_emission_rate: float = 10000.0\n```\n\n#### Configuration Parameters\n\n| Parameter | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `enabled` | bool | `True` | Enables or disables the backpressure mechanism |\n| `monitoring_interval_seconds` | int | `5` | How often (in seconds) to check queue sizes |\n| `high_watermark_threshold` | float | `0.85` | Queue fullness percentage (0.0-1.0) that triggers throttling. When the fullest queue exceeds this threshold, source rates are reduced |\n| `low_watermark_threshold` | float | `0.25` | Queue fullness percentage (0.0-1.0) below which the system ramps up rates. When all queues are below this threshold, source rates are increased |\n| `throttle_factor` | float | `0.9` | Multiplier applied to current rate when throttling down. A value of 0.9 reduces the rate by 10% |\n| `ramp_up_factor` | float | `1.1` | Multiplier applied to current rate when ramping up. A value of 1.1 increases the rate by 10% |\n| `min_emission_rate` | float | `1.0` | Minimum allowed emission rate in events/second. The rate will never go below this value |\n| `max_emission_rate` | float | `10000.0` | Maximum allowed emission rate in events/second. The rate will never exceed this value |\n\n### Environment Variables\n\nBackpressure can also be configured via environment variables:\n\n- `BACKPRESSURE_ENABLED`: Set to `true` or `false`\n- `BACKPRESSURE_MONITORING_INTERVAL`: Integer seconds\n- `BACKPRESSURE_HIGH_WATERMARK`: Float threshold (e.g., `0.85`)\n- `BACKPRESSURE_LOW_WATERMARK`: Float threshold (e.g., `0.25`)\n- `BACKPRESSURE_THROTTLE_FACTOR`: Float factor (e.g., `0.9`)\n- `BACKPRESSURE_RAMP_UP_FACTOR`: Float factor (e.g., `1.1`)\n\n### API Methods\n\n#### PipelineScheduler\n\n```python\n# Enable backpressure at runtime\nscheduler.enable_backpressure()\n\n# Disable backpressure at runtime\nscheduler.disable_backpressure()\n\n# Get backpressure status\nstatus = scheduler.get_backpressure_status()\n# Returns: {\n#     \"enabled\": True,\n#     \"current_emission_rate\": 100.0,\n#     \"min_rate\": 1.0,\n#     \"max_rate\": 10000.0,\n#     \"high_watermark\": 0.85,\n#     \"low_watermark\": 0.25,\n#     ...\n# }\n\n# Register a data source for rate control\nscheduler.register_source(data_source)\n\n# Get queue status\nqueue_status = scheduler.get_queue_status()\n```\n\n#### Data Sources\n\nBoth `DataSourceOne` and `DataSourceTwo` support dynamic rate adjustment:\n\n```python\n# Set emission rate dynamically\nsource.set_emission_rate(50.0)  # 50 events/second\n\n# Get current emission rate\nrate = source.get_emission_rate()\n```\n\n#### Monitor\n\n```python\n# Get the fullness of the most full queue\nfullness = monitor.get_queue_fullness()  # Returns 0.0 to 1.0\n\n# Get detailed metrics for all queues\nmetrics = monitor.get_all_queue_metrics()\n```\n\n### Usage Example\n\n```python\nfrom src.config import Config, get_config\nfrom src.module_1 import DataSourceOne\nfrom src.module_20 import PipelineScheduler\nfrom src.module_31 import Monitor\n\n# Create configuration with backpressure enabled\nconfig = Config()\nconfig.backpressure.enabled = True\nconfig.backpressure.high_watermark_threshold = 0.80\nconfig.backpressure.low_watermark_threshold = 0.20\n\n# Create components\nscheduler = PipelineScheduler(config)\nmonitor = Monitor()\nsource = DataSourceOne(initial_rate=100.0)\n\n# Link components\nscheduler.set_monitor(monitor)\nscheduler.register_source(source)\n\n# Add processing stages\ninput_queue = scheduler.add_stage(\n    name=\"processor\",\n    processor=lambda x: x,\n    max_queue_size=1000\n)\n\n# Start everything\nmonitor.start()\nscheduler.start()\nsource.start(output_queue=input_queue)\n\n# The system will now automatically adjust source rates\n# based on queue fullness\n```\n\n### Best Practices\n\n1. **Set appropriate watermarks**: The gap between high and low watermarks should be large enough to prevent oscillation but small enough to respond quickly to load changes.\n\n2. **Tune throttle/ramp-up factors**: Smaller factors (closer to 1.0) provide smoother adjustments but slower response. Larger factors respond faster but may cause oscillation.\n\n3. **Monitor metrics**: Use the monitoring system to track `backpressure_emission_rate` and `backpressure_queue_fullness` metrics to understand system behavior.\n\n4. **Set realistic rate bounds**: Configure `min_emission_rate` and `max_emission_rate` based on your system's actual capabilities.\n\n---\n\n## Additional API Reference\n\n### Configuration API\n\n```python\nfrom src.config import get_config, set_config, Config\n\n# Get global config\nconfig = get_config()\n\n# Create from environment\nconfig = Config.from_env()\n\n# Create from dictionary\nconfig = Config.from_dict({\n    'backpressure': {\n        'enabled': True,\n        'high_watermark_threshold': 0.90\n    }\n})\n```\n\n### Health Monitoring\n\n```python\nfrom src.module_31 import get_monitor\n\nmonitor = get_monitor()\nmonitor.start()\n\n# Record custom metrics\nmonitor.record_metric(\"custom_metric\", 42.0, {\"label\": \"value\"})\n\n# Update health status\nmonitor.update_health(\"my_component\", \"healthy\", {\"uptime\": 3600})\n\n# Get summary\nsummary = monitor.get_summary()\n```\n"
          },
          "generated_files": [
            "src/config.py",
            "src/module_1.py",
            "src/module_2.py",
            "src/module_31.py",
            "src/module_20.py",
            "docs/api.md"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8779170293008414,
                "dependency_traversal_accuracy": 0.8153613411343674,
                "cross_file_reasoning_depth": 0.4643055555555556,
                "system_thinking_score": 0.5368303354578726,
                "robustness_score": 0.0014714537963507945,
                "comprehensiveness_score": 0.5716539140670982,
                "innovation_score": 0.25664361389052387,
                "solution_elegance_score": 0.5620941531152018
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.10973962866260517,
                "dependency_traversal_weighted": 0.10192016764179593,
                "cross_file_reasoning_weighted": 0.05803819444444445,
                "system_thinking_weighted": 0.06710379193223408,
                "robustness_weighted": 0.0001839317245438493,
                "comprehensiveness_weighted": 0.07145673925838728,
                "innovation_weighted": 0.032080451736315484,
                "solution_elegance_weighted": 0.07026176913940023
              },
              "total_software_engineering_score": 0.5107846745397264
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.42161107063293457,
                "errors": [
                  "  File \"docs/api.py\", line 179",
                  "    4. **Set realistic rate bounds**: Configure `min_emission_rate` and `max_emission_rate` based on your system's actual capabilities.",
                  "                                                                                                                ^",
                  "SyntaxError: unterminated string literal (detected at line 179)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "src/config.py",
                  "src/module_1.py",
                  "src/module_2.py",
                  "src/module_31.py",
                  "src/module_20.py",
                  "docs/api.md"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 6,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 6 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.41885874877810364,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.41885874877810364,
                "idc_weight": 0.2,
                "total_functional_score": 0.4237717497556207
              }
            },
            "code_quality_details": {
              "files_analyzed": 6,
              "quality_checks": {
                "src/config.py": {
                  "line_count": 149,
                  "non_empty_lines": 122,
                  "comment_lines": 2,
                  "comment_ratio": 0.01639344262295082,
                  "function_count": 6,
                  "class_count": 4,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "src/module_1.py": {
                  "line_count": 239,
                  "non_empty_lines": 194,
                  "comment_lines": 6,
                  "comment_ratio": 0.030927835051546393,
                  "function_count": 14,
                  "class_count": 3,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "src/module_2.py": {
                  "line_count": 313,
                  "non_empty_lines": 260,
                  "comment_lines": 8,
                  "comment_ratio": 0.03076923076923077,
                  "function_count": 17,
                  "class_count": 8,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "src/module_31.py": {
                  "line_count": 336,
                  "non_empty_lines": 270,
                  "comment_lines": 5,
                  "comment_ratio": 0.018518518518518517,
                  "function_count": 16,
                  "class_count": 4,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "src/module_20.py": {
                  "line_count": 440,
                  "non_empty_lines": 361,
                  "comment_lines": 23,
                  "comment_ratio": 0.06371191135734072,
                  "function_count": 18,
                  "class_count": 3,
                  "import_count": 20,
                  "quality_score": 0.7999999999999999
                },
                "docs/api.md": {
                  "line_count": 222,
                  "non_empty_lines": 157,
                  "comment_lines": 51,
                  "comment_ratio": 0.3248407643312102,
                  "function_count": 0,
                  "class_count": 1,
                  "import_count": 14,
                  "quality_score": 0.8999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.8116666666666665,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.661395534290271,
                "multi_session_memory_retention": 0.6023214602161968
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.3306977671451355,
                "multi_session_memory_retention_weighted": 0.3011607301080984
              },
              "total_longcontext_utilization_score": 0.631858497253234
            }
          },
          "timestamp": "2026-01-14T21:07:05.596762"
        }
      }
    },
    "python_ml_nlp_easy_017_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_ml_nlp_easy_017_feature_implementation_expert_01",
          "scenario_title": "Implement Shadow Deployment (A/B Testing) for Model Evaluation",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5339060076556738,
          "functional_correctness_score": 0.6278900169204737,
          "code_quality_score": 0.8233333333333331,
          "longcontext_utilization_score": 0.6386111111111111,
          "total_score": 3.152285929580947,
          "generation_time": 64.2057044506073,
          "code_files_generated": 3,
          "total_lines_generated": 510,
          "parsing_success": true,
          "solution_code": {
            "edu_vocab_coach/config.py": "import os\nfrom pathlib import Path\n\n# Base directory configuration\nBASE_DIR = Path(__file__).parent\nDATA_DIR = BASE_DIR / \"data\"\nMODEL_DIR = BASE_DIR / \"models\"\n\n# Ensure directories exist\nDATA_DIR.mkdir(exist_ok=True)\nMODEL_DIR.mkdir(exist_ok=True)\n\n# Database configuration\nDATABASE_PATH = DATA_DIR / \"vocabulary.db\"\n\n# Model configuration\nMODEL_PATH = MODEL_DIR / \"difficulty_model.pkl\"\n\n# Shadow Deployment / A/B Testing Configuration\nSHADOW_DEPLOYMENT_ENABLED = os.environ.get(\"SHADOW_DEPLOYMENT_ENABLED\", \"false\").lower() == \"true\"\n\n# Champion model is the current production model\nCHAMPION_MODEL_PATH = MODEL_DIR / \"difficulty_model.pkl\"\n\n# Challenger model is the newly trained model awaiting evaluation\nCHALLENGER_MODEL_PATH = MODEL_DIR / \"difficulty_model_challenger.pkl\"\n\n# Percentage of traffic to route to the challenger model (0-100)\n# Default is 10% to challenger, 90% to champion\nCHALLENGER_TRAFFIC_PERCENTAGE = int(os.environ.get(\"CHALLENGER_TRAFFIC_PERCENTAGE\", \"10\"))\n\n# Validate traffic percentage\nif CHALLENGER_TRAFFIC_PERCENTAGE < 0:\n    CHALLENGER_TRAFFIC_PERCENTAGE = 0\nelif CHALLENGER_TRAFFIC_PERCENTAGE > 100:\n    CHALLENGER_TRAFFIC_PERCENTAGE = 100\n\n# NLP Pipeline configuration\nNLP_MODEL_NAME = \"en_core_web_sm\"\n\n# API configuration\nAPI_HOST = os.environ.get(\"API_HOST\", \"0.0.0.0\")\nAPI_PORT = int(os.environ.get(\"API_PORT\", \"5000\"))\nDEBUG_MODE = os.environ.get(\"DEBUG_MODE\", \"false\").lower() == \"true\"\n\n# Retraining configuration\nRETRAIN_MIN_SAMPLES = int(os.environ.get(\"RETRAIN_MIN_SAMPLES\", \"100\"))\nRETRAIN_INTERVAL_HOURS = int(os.environ.get(\"RETRAIN_INTERVAL_HOURS\", \"24\"))\n\n# Logging configuration\nLOG_LEVEL = os.environ.get(\"LOG_LEVEL\", \"INFO\")\nLOG_FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
            "edu_vocab_coach/app.py": "import random\nimport logging\nfrom flask import Flask, request, jsonify, render_template\nfrom pathlib import Path\n\nimport config\nfrom src.eduvocab_coach.nlp_pipeline import NLPPipeline\n\n# Configure logging\nlogging.basicConfig(level=config.LOG_LEVEL, format=config.LOG_FORMAT)\nlogger = logging.getLogger(__name__)\n\napp = Flask(__name__)\n\n# Global model instances\nchampion_pipeline = None\nchallenger_pipeline = None\nchallenger_available = False\n\n\ndef load_models():\n    \"\"\"Load champion and optionally challenger models at startup.\"\"\"\n    global champion_pipeline, challenger_pipeline, challenger_available\n    \n    # Always load the champion model\n    champion_path = config.CHAMPION_MODEL_PATH\n    if champion_path.exists():\n        try:\n            champion_pipeline = NLPPipeline(model_path=str(champion_path))\n            logger.info(f\"Champion model loaded from {champion_path}\")\n        except Exception as e:\n            logger.error(f\"Failed to load champion model: {e}\")\n            champion_pipeline = NLPPipeline()  # Fallback to default/new pipeline\n            logger.info(\"Using default NLP pipeline as champion\")\n    else:\n        champion_pipeline = NLPPipeline()\n        logger.info(\"No champion model found, using default NLP pipeline\")\n    \n    # Load challenger model if shadow deployment is enabled\n    if config.SHADOW_DEPLOYMENT_ENABLED:\n        challenger_path = config.CHALLENGER_MODEL_PATH\n        if challenger_path.exists():\n            try:\n                challenger_pipeline = NLPPipeline(model_path=str(challenger_path))\n                challenger_available = True\n                logger.info(f\"Challenger model loaded from {challenger_path}\")\n                logger.info(f\"Shadow deployment enabled: {config.CHALLENGER_TRAFFIC_PERCENTAGE}% traffic to challenger\")\n            except Exception as e:\n                logger.warning(f\"Failed to load challenger model: {e}\")\n                challenger_available = False\n                logger.info(\"Shadow deployment enabled but challenger model not available\")\n        else:\n            challenger_available = False\n            logger.info(f\"Shadow deployment enabled but challenger model not found at {challenger_path}\")\n    else:\n        logger.info(\"Shadow deployment is disabled\")\n\n\ndef select_model():\n    \"\"\"Select which model to use for prediction based on traffic routing.\n    \n    Returns:\n        tuple: (pipeline, model_name) - the selected pipeline and its identifier\n    \"\"\"\n    global champion_pipeline, challenger_pipeline, challenger_available\n    \n    # If shadow deployment is disabled or challenger not available, use champion\n    if not config.SHADOW_DEPLOYMENT_ENABLED or not challenger_available:\n        return champion_pipeline, \"champion\"\n    \n    # Route traffic based on percentage\n    random_value = random.randint(1, 100)\n    if random_value <= config.CHALLENGER_TRAFFIC_PERCENTAGE:\n        return challenger_pipeline, \"challenger\"\n    else:\n        return champion_pipeline, \"champion\"\n\n\ndef reload_challenger_model():\n    \"\"\"Reload the challenger model if it exists. Called when a new model is trained.\"\"\"\n    global challenger_pipeline, challenger_available\n    \n    if not config.SHADOW_DEPLOYMENT_ENABLED:\n        return False\n    \n    challenger_path = config.CHALLENGER_MODEL_PATH\n    if challenger_path.exists():\n        try:\n            challenger_pipeline = NLPPipeline(model_path=str(challenger_path))\n            challenger_available = True\n            logger.info(f\"Challenger model reloaded from {challenger_path}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to reload challenger model: {e}\")\n            return False\n    return False\n\n\n@app.route(\"/\")\ndef index():\n    \"\"\"Render the main page.\"\"\"\n    return render_template(\"index.html\")\n\n\n@app.route(\"/api/predict\", methods=[\"POST\"])\ndef predict():\n    \"\"\"Predict difficulty for a given word or text.\n    \n    Expects JSON with 'text' field.\n    Returns prediction with model identifier for tracking.\n    \"\"\"\n    try:\n        data = request.get_json()\n        if not data or \"text\" not in data:\n            return jsonify({\"error\": \"Missing 'text' field in request\"}), 400\n        \n        text = data[\"text\"]\n        if not text or not text.strip():\n            return jsonify({\"error\": \"Empty text provided\"}), 400\n        \n        # Select model based on traffic routing\n        pipeline, model_name = select_model()\n        \n        # Make prediction\n        result = pipeline.predict_difficulty(text)\n        \n        # Add model identifier to response for tracking/monitoring\n        response = {\n            \"text\": text,\n            \"difficulty\": result.get(\"difficulty\"),\n            \"confidence\": result.get(\"confidence\"),\n            \"model_used\": model_name\n        }\n        \n        logger.debug(f\"Prediction made using {model_name} model for text: {text[:50]}...\")\n        \n        return jsonify(response)\n    \n    except Exception as e:\n        logger.error(f\"Prediction error: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route(\"/api/analyze\", methods=[\"POST\"])\ndef analyze():\n    \"\"\"Analyze text and return detailed NLP features.\n    \n    Expects JSON with 'text' field.\n    \"\"\"\n    try:\n        data = request.get_json()\n        if not data or \"text\" not in data:\n            return jsonify({\"error\": \"Missing 'text' field in request\"}), 400\n        \n        text = data[\"text\"]\n        if not text or not text.strip():\n            return jsonify({\"error\": \"Empty text provided\"}), 400\n        \n        # Select model based on traffic routing\n        pipeline, model_name = select_model()\n        \n        # Analyze text\n        result = pipeline.analyze_text(text)\n        result[\"model_used\"] = model_name\n        \n        return jsonify(result)\n    \n    except Exception as e:\n        logger.error(f\"Analysis error: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n\n\n@app.route(\"/api/health\", methods=[\"GET\"])\ndef health():\n    \"\"\"Health check endpoint.\"\"\"\n    status = {\n        \"status\": \"healthy\",\n        \"champion_model_loaded\": champion_pipeline is not None,\n        \"shadow_deployment_enabled\": config.SHADOW_DEPLOYMENT_ENABLED,\n        \"challenger_model_loaded\": challenger_available,\n        \"challenger_traffic_percentage\": config.CHALLENGER_TRAFFIC_PERCENTAGE if config.SHADOW_DEPLOYMENT_ENABLED else 0\n    }\n    return jsonify(status)\n\n\n@app.route(\"/api/model/status\", methods=[\"GET\"])\ndef model_status():\n    \"\"\"Get current model deployment status.\"\"\"\n    return jsonify({\n        \"shadow_deployment_enabled\": config.SHADOW_DEPLOYMENT_ENABLED,\n        \"champion_model_path\": str(config.CHAMPION_MODEL_PATH),\n        \"champion_model_exists\": config.CHAMPION_MODEL_PATH.exists(),\n        \"challenger_model_path\": str(config.CHALLENGER_MODEL_PATH),\n        \"challenger_model_exists\": config.CHALLENGER_MODEL_PATH.exists(),\n        \"challenger_available\": challenger_available,\n        \"challenger_traffic_percentage\": config.CHALLENGER_TRAFFIC_PERCENTAGE\n    })\n\n\n@app.route(\"/api/model/reload-challenger\", methods=[\"POST\"])\ndef reload_challenger():\n    \"\"\"Manually trigger a reload of the challenger model.\"\"\"\n    success = reload_challenger_model()\n    if success:\n        return jsonify({\"message\": \"Challenger model reloaded successfully\"})\n    else:\n        return jsonify({\"error\": \"Failed to reload challenger model\"}), 500\n\n\n# Load models when the module is imported\nload_models()\n\n\nif __name__ == \"__main__\":\n    app.run(\n        host=config.API_HOST,\n        port=config.API_PORT,\n        debug=config.DEBUG_MODE\n    )\n",
            "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py": "import logging\nimport pickle\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any, List, Tuple\n\nimport config\n\nlogger = logging.getLogger(__name__)\n\n\nclass Retrainer:\n    \"\"\"Handles model retraining and saving for the EduVocab Coach.\n    \n    When shadow deployment is enabled, newly trained models are saved\n    as challenger models rather than overwriting the production champion model.\n    \"\"\"\n    \n    def __init__(self, model_class=None):\n        \"\"\"Initialize the Retrainer.\n        \n        Args:\n            model_class: The model class to use for training. If None,\n                        a default model will be used.\n        \"\"\"\n        self.model_class = model_class\n        self.last_training_time: Optional[datetime] = None\n        self.training_history: List[Dict[str, Any]] = []\n        \n    def _get_save_path(self) -> Path:\n        \"\"\"Determine the appropriate path to save the trained model.\n        \n        If shadow deployment is enabled, saves to challenger path.\n        Otherwise, saves to the main model path (champion).\n        \n        Returns:\n            Path: The path where the model should be saved.\n        \"\"\"\n        if config.SHADOW_DEPLOYMENT_ENABLED:\n            return config.CHALLENGER_MODEL_PATH\n        else:\n            return config.CHAMPION_MODEL_PATH\n    \n    def prepare_training_data(self, raw_data: List[Dict[str, Any]]) -> Tuple[List, List]:\n        \"\"\"Prepare raw data for training.\n        \n        Args:\n            raw_data: List of dictionaries containing training samples.\n            \n        Returns:\n            Tuple of (features, labels) for training.\n        \"\"\"\n        features = []\n        labels = []\n        \n        for sample in raw_data:\n            if \"text\" in sample and \"difficulty\" in sample:\n                features.append(sample[\"text\"])\n                labels.append(sample[\"difficulty\"])\n        \n        return features, labels\n    \n    def train_model(self, features: List, labels: List) -> Any:\n        \"\"\"Train a new model on the provided data.\n        \n        Args:\n            features: List of feature data (texts).\n            labels: List of corresponding labels (difficulty scores).\n            \n        Returns:\n            The trained model object.\n        \"\"\"\n        if self.model_class is None:\n            # Use a simple default model for demonstration\n            from sklearn.feature_extraction.text import TfidfVectorizer\n            from sklearn.linear_model import LogisticRegression\n            from sklearn.pipeline import Pipeline\n            \n            model = Pipeline([\n                ('tfidf', TfidfVectorizer(max_features=5000)),\n                ('clf', LogisticRegression(max_iter=1000))\n            ])\n        else:\n            model = self.model_class()\n        \n        model.fit(features, labels)\n        return model\n    \n    def save_model(self, model: Any, path: Path) -> bool:\n        \"\"\"Save the trained model to disk.\n        \n        Args:\n            model: The trained model to save.\n            path: The path where the model should be saved.\n            \n        Returns:\n            bool: True if save was successful, False otherwise.\n        \"\"\"\n        try:\n            # Ensure parent directory exists\n            path.parent.mkdir(parents=True, exist_ok=True)\n            \n            with open(path, 'wb') as f:\n                pickle.dump(model, f)\n            \n            logger.info(f\"Model saved successfully to {path}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to save model to {path}: {e}\")\n            return False\n    \n    def train_and_save_model(self, training_data: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Train a new model and save it to the appropriate location.\n        \n        When shadow deployment is enabled, the model is saved as the challenger\n        model, allowing for A/B testing against the current champion.\n        \n        Args:\n            training_data: List of training samples with 'text' and 'difficulty' fields.\n            \n        Returns:\n            Dict containing training results and metadata.\n        \"\"\"\n        result = {\n            \"success\": False,\n            \"timestamp\": datetime.now().isoformat(),\n            \"samples_used\": 0,\n            \"model_path\": None,\n            \"is_challenger\": config.SHADOW_DEPLOYMENT_ENABLED,\n            \"error\": None\n        }\n        \n        try:\n            # Check minimum samples requirement\n            if len(training_data) < config.RETRAIN_MIN_SAMPLES:\n                result[\"error\"] = f\"Insufficient training data. Need at least {config.RETRAIN_MIN_SAMPLES} samples, got {len(training_data)}\"\n                logger.warning(result[\"error\"])\n                return result\n            \n            # Prepare data\n            features, labels = self.prepare_training_data(training_data)\n            result[\"samples_used\"] = len(features)\n            \n            if len(features) == 0:\n                result[\"error\"] = \"No valid training samples found in data\"\n                logger.warning(result[\"error\"])\n                return result\n            \n            # Train model\n            logger.info(f\"Training model with {len(features)} samples...\")\n            model = self.train_model(features, labels)\n            \n            # Determine save path based on shadow deployment setting\n            save_path = self._get_save_path()\n            result[\"model_path\"] = str(save_path)\n            \n            if config.SHADOW_DEPLOYMENT_ENABLED:\n                logger.info(f\"Shadow deployment enabled - saving as challenger model to {save_path}\")\n            else:\n                logger.info(f\"Shadow deployment disabled - saving as main model to {save_path}\")\n            \n            # Save model\n            if self.save_model(model, save_path):\n                result[\"success\"] = True\n                self.last_training_time = datetime.now()\n                \n                # Record in training history\n                self.training_history.append({\n                    \"timestamp\": result[\"timestamp\"],\n                    \"samples\": result[\"samples_used\"],\n                    \"path\": result[\"model_path\"],\n                    \"is_challenger\": result[\"is_challenger\"]\n                })\n                \n                logger.info(f\"Model training completed successfully. Saved to {save_path}\")\n            else:\n                result[\"error\"] = \"Failed to save model to disk\"\n                \n        except Exception as e:\n            result[\"error\"] = str(e)\n            logger.error(f\"Model training failed: {e}\")\n        \n        return result\n    \n    def promote_challenger_to_champion(self) -> bool:\n        \"\"\"Promote the current challenger model to champion.\n        \n        This copies the challenger model to the champion path,\n        effectively making it the new production model.\n        \n        Returns:\n            bool: True if promotion was successful, False otherwise.\n        \"\"\"\n        try:\n            challenger_path = config.CHALLENGER_MODEL_PATH\n            champion_path = config.CHAMPION_MODEL_PATH\n            \n            if not challenger_path.exists():\n                logger.error(\"No challenger model exists to promote\")\n                return False\n            \n            # Load challenger model\n            with open(challenger_path, 'rb') as f:\n                model = pickle.load(f)\n            \n            # Save as champion\n            with open(champion_path, 'wb') as f:\n                pickle.dump(model, f)\n            \n            logger.info(f\"Challenger model promoted to champion: {champion_path}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to promote challenger to champion: {e}\")\n            return False\n    \n    def get_training_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get the history of training runs.\n        \n        Returns:\n            List of training history records.\n        \"\"\"\n        return self.training_history.copy()\n    \n    def should_retrain(self) -> bool:\n        \"\"\"Check if enough time has passed since last training.\n        \n        Returns:\n            bool: True if retraining should occur, False otherwise.\n        \"\"\"\n        if self.last_training_time is None:\n            return True\n        \n        from datetime import timedelta\n        time_since_training = datetime.now() - self.last_training_time\n        return time_since_training >= timedelta(hours=config.RETRAIN_INTERVAL_HOURS)\n"
          },
          "generated_files": [
            "edu_vocab_coach/config.py",
            "edu_vocab_coach/app.py",
            "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7385113268608415,
                "dependency_traversal_accuracy": 0.7517091822176568,
                "cross_file_reasoning_depth": 0.2877777777777778,
                "system_thinking_score": 0.5518790849673203,
                "robustness_score": 0.4446078431372549,
                "comprehensiveness_score": 0.5223202614379084,
                "innovation_score": 0.1875,
                "solution_elegance_score": 0.7869425848466307
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09231391585760519,
                "dependency_traversal_weighted": 0.0939636477772071,
                "cross_file_reasoning_weighted": 0.035972222222222225,
                "system_thinking_weighted": 0.06898488562091504,
                "robustness_weighted": 0.05557598039215686,
                "comprehensiveness_weighted": 0.06529003267973855,
                "innovation_weighted": 0.0234375,
                "solution_elegance_weighted": 0.09836782310582884
              },
              "total_software_engineering_score": 0.5339060076556738
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.19878721237182617,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "edu_vocab_coach/config.py",
                  "edu_vocab_coach/app.py",
                  "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 3,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 3 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.23945008460236888,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.23945008460236888,
                "idc_weight": 0.2,
                "total_functional_score": 0.6278900169204737
              }
            },
            "code_quality_details": {
              "files_analyzed": 3,
              "quality_checks": {
                "edu_vocab_coach/config.py": {
                  "line_count": 53,
                  "non_empty_lines": 39,
                  "comment_lines": 14,
                  "comment_ratio": 0.358974358974359,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 3,
                  "quality_score": 0.8999999999999999
                },
                "edu_vocab_coach/app.py": {
                  "line_count": 220,
                  "non_empty_lines": 172,
                  "comment_lines": 12,
                  "comment_ratio": 0.06976744186046512,
                  "function_count": 9,
                  "class_count": 0,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "edu_vocab_coach/src/eduvocab_coach/ml_ops/retrainer.py": {
                  "line_count": 237,
                  "non_empty_lines": 183,
                  "comment_lines": 10,
                  "comment_ratio": 0.0546448087431694,
                  "function_count": 9,
                  "class_count": 4,
                  "import_count": 17,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.8233333333333331,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.64,
                "multi_session_memory_retention": 0.6372222222222222
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.32,
                "multi_session_memory_retention_weighted": 0.3186111111111111
              },
              "total_longcontext_utilization_score": 0.6386111111111111
            }
          },
          "timestamp": "2026-01-14T21:51:11.177797"
        }
      }
    },
    "python_system_automation_hard_062_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_system_automation_hard_062_feature_implementation_expert_01",
          "scenario_title": "Implement Proactive Remediation Engine for S3 Security Findings",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5360174270613095,
          "functional_correctness_score": 0.4866102635228849,
          "code_quality_score": 0.8199999999999998,
          "longcontext_utilization_score": 0.5122646280734516,
          "total_score": 2.878082563443672,
          "generation_time": 136.45841193199158,
          "code_files_generated": 7,
          "total_lines_generated": 1338,
          "parsing_success": true,
          "solution_code": {
            "src/remediation_engine.py": "\"\"\"Proactive Remediation Engine for NimbusCustodian.\n\nThis module provides automated remediation capabilities for security findings,\nstarting with S3 bucket public read ACL remediation.\n\"\"\"\n\nimport logging\nfrom typing import Optional, Any, Dict\n\nlogger = logging.getLogger(__name__)\n\n\nclass RemediationError(Exception):\n    \"\"\"Exception raised when remediation fails.\"\"\"\n    pass\n\n\nclass RemediationEngine:\n    \"\"\"Engine for automated remediation of security findings.\"\"\"\n    \n    def __init__(self, aws_client_factory=None):\n        \"\"\"Initialize the remediation engine.\n        \n        Args:\n            aws_client_factory: Optional callable that returns AWS clients.\n                               If None, will use utils.get_aws_client.\n        \"\"\"\n        self._aws_client_factory = aws_client_factory\n    \n    def _get_s3_client(self):\n        \"\"\"Get an S3 client using the configured factory.\"\"\"\n        if self._aws_client_factory:\n            return self._aws_client_factory('s3')\n        else:\n            from src.utils import get_aws_client\n            return get_aws_client('s3')\n    \n    def remediate_s3_public_read_acl(self, bucket_name: str) -> bool:\n        \"\"\"Remediate an S3 bucket with public read ACL by setting it to private.\n        \n        Args:\n            bucket_name: The name of the S3 bucket to remediate.\n            \n        Returns:\n            bool: True if remediation was successful, False otherwise.\n            \n        Raises:\n            RemediationError: If remediation fails due to an error.\n        \"\"\"\n        if not bucket_name:\n            raise RemediationError(\"Bucket name cannot be empty\")\n        \n        try:\n            s3_client = self._get_s3_client()\n            s3_client.put_bucket_acl(\n                Bucket=bucket_name,\n                ACL='private'\n            )\n            logger.info(f\"Successfully remediated S3 bucket {bucket_name} by setting ACL to private.\")\n            return True\n        except Exception as e:\n            error_msg = f\"Failed to remediate S3 bucket {bucket_name}: {str(e)}\"\n            logger.error(error_msg)\n            raise RemediationError(error_msg) from e\n    \n    def remediate_finding(self, finding: Any) -> bool:\n        \"\"\"Remediate a security finding based on its type.\n        \n        Args:\n            finding: The finding object to remediate.\n            \n        Returns:\n            bool: True if remediation was successful, False otherwise.\n        \"\"\"\n        finding_type = getattr(finding, 'type', None) or finding.get('type') if isinstance(finding, dict) else None\n        \n        if finding_type == 'S3_PUBLIC_READ_ACL':\n            # Extract bucket name from finding\n            if isinstance(finding, dict):\n                bucket_name = finding.get('resource', {}).get('bucket_name') or finding.get('bucket_name')\n            else:\n                resource = getattr(finding, 'resource', {})\n                bucket_name = resource.get('bucket_name') if isinstance(resource, dict) else getattr(finding, 'bucket_name', None)\n            \n            if not bucket_name:\n                logger.error(\"Cannot remediate: bucket_name not found in finding\")\n                return False\n            \n            try:\n                success = self.remediate_s3_public_read_acl(bucket_name)\n                if success and hasattr(finding, 'update_status'):\n                    finding.update_status('REMEDIATED')\n                return success\n            except RemediationError:\n                return False\n        else:\n            logger.warning(f\"No remediation handler for finding type: {finding_type}\")\n            return False\n\n\n# Module-level convenience functions\n_default_engine = None\n\n\ndef get_remediation_engine(aws_client_factory=None) -> RemediationEngine:\n    \"\"\"Get or create a remediation engine instance.\n    \n    Args:\n        aws_client_factory: Optional callable for creating AWS clients.\n        \n    Returns:\n        RemediationEngine: The remediation engine instance.\n    \"\"\"\n    global _default_engine\n    if aws_client_factory:\n        return RemediationEngine(aws_client_factory)\n    if _default_engine is None:\n        _default_engine = RemediationEngine()\n    return _default_engine\n\n\ndef remediate_s3_public_read_acl(bucket_name: str) -> bool:\n    \"\"\"Convenience function to remediate S3 public read ACL.\n    \n    Args:\n        bucket_name: The name of the S3 bucket to remediate.\n        \n    Returns:\n        bool: True if remediation was successful.\n    \"\"\"\n    engine = get_remediation_engine()\n    return engine.remediate_s3_public_read_acl(bucket_name)\n\n\ndef remediate_finding(finding: Any) -> bool:\n    \"\"\"Convenience function to remediate a security finding.\n    \n    Args:\n        finding: The finding object to remediate.\n        \n    Returns:\n        bool: True if remediation was successful.\n    \"\"\"\n    engine = get_remediation_engine()\n    return engine.remediate_finding(finding)\n",
            "src/module_7.py": "\"\"\"Central Event Handler Module for NimbusCustodian.\n\nThis module handles events from various sources including security findings\nand triggers appropriate actions including remediation when enabled.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional, Callable, List\n\nlogger = logging.getLogger(__name__)\n\n# Global configuration object - assumed to be loaded elsewhere\nconfig = {\n    'remediation': {\n        'enabled': False\n    }\n}\n\n\nclass EventHandler:\n    \"\"\"Central event handler for processing system events.\"\"\"\n    \n    def __init__(self, config_provider: Optional[Callable] = None):\n        \"\"\"Initialize the event handler.\n        \n        Args:\n            config_provider: Optional callable that returns configuration.\n        \"\"\"\n        self._config_provider = config_provider\n        self._handlers: Dict[str, List[Callable]] = {}\n        self._remediation_engine = None\n    \n    def _get_config(self) -> Dict:\n        \"\"\"Get the current configuration.\"\"\"\n        if self._config_provider:\n            return self._config_provider()\n        return config\n    \n    def _is_remediation_enabled(self) -> bool:\n        \"\"\"Check if remediation is enabled in configuration.\"\"\"\n        cfg = self._get_config()\n        remediation_config = cfg.get('remediation', {})\n        return remediation_config.get('enabled', False)\n    \n    def _get_remediation_engine(self):\n        \"\"\"Lazily load and return the remediation engine.\"\"\"\n        if self._remediation_engine is None:\n            from src.remediation_engine import get_remediation_engine\n            self._remediation_engine = get_remediation_engine()\n        return self._remediation_engine\n    \n    def register_handler(self, event_type: str, handler: Callable) -> None:\n        \"\"\"Register a handler for a specific event type.\n        \n        Args:\n            event_type: The type of event to handle.\n            handler: The handler function to call.\n        \"\"\"\n        if event_type not in self._handlers:\n            self._handlers[event_type] = []\n        self._handlers[event_type].append(handler)\n        logger.debug(f\"Registered handler for event type: {event_type}\")\n    \n    def process_event(self, event: Dict[str, Any]) -> bool:\n        \"\"\"Process an incoming event.\n        \n        Args:\n            event: The event data to process.\n            \n        Returns:\n            bool: True if event was processed successfully.\n        \"\"\"\n        event_type = event.get('type', 'UNKNOWN')\n        logger.info(f\"Processing event of type: {event_type}\")\n        \n        # Call registered handlers\n        handlers = self._handlers.get(event_type, [])\n        for handler in handlers:\n            try:\n                handler(event)\n            except Exception as e:\n                logger.error(f\"Handler error for {event_type}: {e}\")\n        \n        return True\n    \n    def process_security_finding(self, finding: Any) -> bool:\n        \"\"\"Process a security finding and trigger remediation if appropriate.\n        \n        Args:\n            finding: The security finding to process.\n            \n        Returns:\n            bool: True if finding was processed successfully.\n        \"\"\"\n        # Extract finding attributes\n        if isinstance(finding, dict):\n            finding_type = finding.get('type')\n            severity = finding.get('severity')\n        else:\n            finding_type = getattr(finding, 'type', None)\n            severity = getattr(finding, 'severity', None)\n        \n        logger.info(f\"Processing security finding: type={finding_type}, severity={severity}\")\n        \n        # Check if this is a critical S3 public read ACL finding\n        if finding_type == 'S3_PUBLIC_READ_ACL' and severity == 'CRITICAL':\n            logger.warning(f\"Critical S3 public read ACL finding detected\")\n            \n            # Check if remediation is enabled\n            if self._is_remediation_enabled():\n                logger.info(\"Remediation is enabled, attempting automatic remediation\")\n                try:\n                    engine = self._get_remediation_engine()\n                    success = engine.remediate_finding(finding)\n                    if success:\n                        logger.info(\"Remediation completed successfully\")\n                        return True\n                    else:\n                        logger.warning(\"Remediation was not successful\")\n                except Exception as e:\n                    logger.error(f\"Remediation failed with error: {e}\")\n            else:\n                logger.info(\"Remediation is disabled, skipping automatic remediation\")\n        \n        return True\n\n\n# Module-level event handler instance\n_event_handler = None\n\n\ndef get_event_handler(config_provider: Optional[Callable] = None) -> EventHandler:\n    \"\"\"Get or create the event handler instance.\n    \n    Args:\n        config_provider: Optional configuration provider callable.\n        \n    Returns:\n        EventHandler: The event handler instance.\n    \"\"\"\n    global _event_handler\n    if config_provider:\n        return EventHandler(config_provider)\n    if _event_handler is None:\n        _event_handler = EventHandler()\n    return _event_handler\n\n\ndef process_security_finding(finding: Any) -> bool:\n    \"\"\"Convenience function to process a security finding.\n    \n    Args:\n        finding: The security finding to process.\n        \n    Returns:\n        bool: True if finding was processed successfully.\n    \"\"\"\n    handler = get_event_handler()\n    return handler.process_security_finding(finding)\n\n\ndef handle_event(event: Dict[str, Any]) -> bool:\n    \"\"\"Convenience function to handle an event.\n    \n    Args:\n        event: The event to handle.\n        \n    Returns:\n        bool: True if event was handled successfully.\n    \"\"\"\n    handler = get_event_handler()\n    return handler.process_event(event)\n",
            "src/module_20.py": "\"\"\"Security Scanning Module for NimbusCustodian.\n\nThis module provides security scanning capabilities including\nS3 bucket ACL analysis and finding generation.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, List, Optional, Callable\nfrom dataclasses import dataclass, field\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\n\nclass FindingSeverity(Enum):\n    \"\"\"Severity levels for security findings.\"\"\"\n    LOW = 'LOW'\n    MEDIUM = 'MEDIUM'\n    HIGH = 'HIGH'\n    CRITICAL = 'CRITICAL'\n\n\nclass FindingStatus(Enum):\n    \"\"\"Status values for security findings.\"\"\"\n    OPEN = 'OPEN'\n    ACKNOWLEDGED = 'ACKNOWLEDGED'\n    REMEDIATED = 'REMEDIATED'\n    SUPPRESSED = 'SUPPRESSED'\n\n\n@dataclass\nclass Finding:\n    \"\"\"Represents a security finding.\"\"\"\n    type: str\n    severity: str\n    resource: Dict[str, Any]\n    description: str\n    status: str = 'OPEN'\n    id: Optional[str] = None\n    \n    def update_status(self, new_status: str) -> None:\n        \"\"\"Update the status of this finding.\n        \n        Args:\n            new_status: The new status value.\n        \"\"\"\n        old_status = self.status\n        self.status = new_status\n        logger.info(f\"Finding {self.id or self.type} status updated from {old_status} to {new_status}\")\n    \n    @property\n    def bucket_name(self) -> Optional[str]:\n        \"\"\"Get the bucket name from the resource if available.\"\"\"\n        return self.resource.get('bucket_name')\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert finding to dictionary.\"\"\"\n        return {\n            'id': self.id,\n            'type': self.type,\n            'severity': self.severity,\n            'resource': self.resource,\n            'description': self.description,\n            'status': self.status\n        }\n\n\nclass SecurityScanner:\n    \"\"\"Scanner for security issues in cloud resources.\"\"\"\n    \n    def __init__(self, aws_client_factory: Optional[Callable] = None):\n        \"\"\"Initialize the security scanner.\n        \n        Args:\n            aws_client_factory: Optional callable for creating AWS clients.\n        \"\"\"\n        self._aws_client_factory = aws_client_factory\n        self._findings: List[Finding] = []\n        self._finding_handlers: List[Callable] = []\n    \n    def _get_s3_client(self):\n        \"\"\"Get an S3 client.\"\"\"\n        if self._aws_client_factory:\n            return self._aws_client_factory('s3')\n        else:\n            from src.utils import get_aws_client\n            return get_aws_client('s3')\n    \n    def register_finding_handler(self, handler: Callable) -> None:\n        \"\"\"Register a handler to be called when findings are generated.\n        \n        Args:\n            handler: Callable that takes a Finding object.\n        \"\"\"\n        self._finding_handlers.append(handler)\n    \n    def _emit_finding(self, finding: Finding) -> None:\n        \"\"\"Emit a finding to all registered handlers.\n        \n        Args:\n            finding: The finding to emit.\n        \"\"\"\n        self._findings.append(finding)\n        for handler in self._finding_handlers:\n            try:\n                handler(finding)\n            except Exception as e:\n                logger.error(f\"Finding handler error: {e}\")\n    \n    def scan_s3_bucket_acls(self) -> List[Finding]:\n        \"\"\"Scan S3 buckets for public ACL configurations.\n        \n        Returns:\n            List of findings for buckets with public ACLs.\n        \"\"\"\n        findings = []\n        try:\n            s3_client = self._get_s3_client()\n            response = s3_client.list_buckets()\n            buckets = response.get('Buckets', [])\n            \n            for bucket in buckets:\n                bucket_name = bucket.get('Name')\n                if not bucket_name:\n                    continue\n                \n                try:\n                    acl_response = s3_client.get_bucket_acl(Bucket=bucket_name)\n                    grants = acl_response.get('Grants', [])\n                    \n                    for grant in grants:\n                        grantee = grant.get('Grantee', {})\n                        permission = grant.get('Permission', '')\n                        uri = grantee.get('URI', '')\n                        \n                        # Check for public read access\n                        if 'AllUsers' in uri and permission in ['READ', 'FULL_CONTROL']:\n                            finding = Finding(\n                                type='S3_PUBLIC_READ_ACL',\n                                severity='CRITICAL',\n                                resource={'bucket_name': bucket_name},\n                                description=f\"S3 bucket {bucket_name} has public read access via ACL\",\n                                id=f\"s3-public-acl-{bucket_name}\"\n                            )\n                            findings.append(finding)\n                            self._emit_finding(finding)\n                            logger.warning(f\"Found public read ACL on bucket: {bucket_name}\")\n                            break\n                \n                except Exception as e:\n                    logger.error(f\"Error checking ACL for bucket {bucket_name}: {e}\")\n        \n        except Exception as e:\n            logger.error(f\"Error scanning S3 buckets: {e}\")\n        \n        return findings\n    \n    def get_findings(self) -> List[Finding]:\n        \"\"\"Get all findings from the scanner.\n        \n        Returns:\n            List of all findings.\n        \"\"\"\n        return self._findings.copy()\n    \n    def clear_findings(self) -> None:\n        \"\"\"Clear all stored findings.\"\"\"\n        self._findings.clear()\n\n\n# Module-level scanner instance\n_scanner = None\n\n\ndef get_security_scanner(aws_client_factory: Optional[Callable] = None) -> SecurityScanner:\n    \"\"\"Get or create the security scanner instance.\n    \n    Args:\n        aws_client_factory: Optional callable for creating AWS clients.\n        \n    Returns:\n        SecurityScanner: The scanner instance.\n    \"\"\"\n    global _scanner\n    if aws_client_factory:\n        return SecurityScanner(aws_client_factory)\n    if _scanner is None:\n        _scanner = SecurityScanner()\n    return _scanner\n\n\ndef scan_s3_buckets() -> List[Finding]:\n    \"\"\"Convenience function to scan S3 buckets.\n    \n    Returns:\n        List of findings.\n    \"\"\"\n    scanner = get_security_scanner()\n    return scanner.scan_s3_bucket_acls()\n\n\ndef create_finding(finding_type: str, severity: str, resource: Dict[str, Any], \n                   description: str) -> Finding:\n    \"\"\"Create a new finding.\n    \n    Args:\n        finding_type: Type of the finding.\n        severity: Severity level.\n        resource: Resource information.\n        description: Finding description.\n        \n    Returns:\n        Finding: The created finding.\n    \"\"\"\n    return Finding(\n        type=finding_type,\n        severity=severity,\n        resource=resource,\n        description=description\n    )\n",
            "src/utils.py": "\"\"\"Utility functions for NimbusCustodian.\n\nProvides common utilities including AWS client management.\n\"\"\"\n\nimport logging\nfrom typing import Any, Optional, Dict\n\nlogger = logging.getLogger(__name__)\n\n# Cache for AWS clients\n_aws_clients: Dict[str, Any] = {}\n\n\ndef get_aws_client(service_name: str, region: Optional[str] = None) -> Any:\n    \"\"\"Get an AWS client for the specified service.\n    \n    Args:\n        service_name: The AWS service name (e.g., 's3', 'ec2').\n        region: Optional AWS region name.\n        \n    Returns:\n        A boto3 client for the specified service.\n    \"\"\"\n    cache_key = f\"{service_name}:{region or 'default'}\"\n    \n    if cache_key not in _aws_clients:\n        try:\n            import boto3\n            if region:\n                client = boto3.client(service_name, region_name=region)\n            else:\n                client = boto3.client(service_name)\n            _aws_clients[cache_key] = client\n            logger.debug(f\"Created AWS client for {service_name}\")\n        except Exception as e:\n            logger.error(f\"Failed to create AWS client for {service_name}: {e}\")\n            raise\n    \n    return _aws_clients[cache_key]\n\n\ndef clear_aws_client_cache() -> None:\n    \"\"\"Clear the AWS client cache.\"\"\"\n    global _aws_clients\n    _aws_clients.clear()\n    logger.debug(\"Cleared AWS client cache\")\n\n\ndef format_resource_arn(service: str, resource_type: str, resource_id: str,\n                        region: str = '', account_id: str = '') -> str:\n    \"\"\"Format an AWS resource ARN.\n    \n    Args:\n        service: AWS service name.\n        resource_type: Type of resource.\n        resource_id: Resource identifier.\n        region: AWS region (optional for global resources).\n        account_id: AWS account ID (optional for some resources).\n        \n    Returns:\n        Formatted ARN string.\n    \"\"\"\n    return f\"arn:aws:{service}:{region}:{account_id}:{resource_type}/{resource_id}\"\n\n\ndef parse_s3_uri(uri: str) -> Dict[str, str]:\n    \"\"\"Parse an S3 URI into bucket and key components.\n    \n    Args:\n        uri: S3 URI in format s3://bucket/key.\n        \n    Returns:\n        Dictionary with 'bucket' and 'key' keys.\n    \"\"\"\n    if not uri.startswith('s3://'):\n        raise ValueError(f\"Invalid S3 URI: {uri}\")\n    \n    path = uri[5:]  # Remove 's3://'\n    parts = path.split('/', 1)\n    \n    return {\n        'bucket': parts[0],\n        'key': parts[1] if len(parts) > 1 else ''\n    }\n\n\ndef safe_get(obj: Any, *keys: str, default: Any = None) -> Any:\n    \"\"\"Safely get a nested value from a dictionary or object.\n    \n    Args:\n        obj: The object to get values from.\n        *keys: Keys to traverse.\n        default: Default value if key not found.\n        \n    Returns:\n        The value at the specified path or default.\n    \"\"\"\n    current = obj\n    for key in keys:\n        if isinstance(current, dict):\n            current = current.get(key)\n        elif hasattr(current, key):\n            current = getattr(current, key)\n        else:\n            return default\n        if current is None:\n            return default\n    return current\n",
            "tests/test_remediation_engine.py": "\"\"\"Unit tests for the Remediation Engine module.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch\nimport logging\n\nfrom src.remediation_engine import (\n    RemediationEngine,\n    RemediationError,\n    get_remediation_engine,\n    remediate_s3_public_read_acl,\n    remediate_finding\n)\nfrom src.module_20 import Finding\n\n\nclass TestRemediationEngine:\n    \"\"\"Tests for the RemediationEngine class.\"\"\"\n    \n    def test_init_with_custom_client_factory(self):\n        \"\"\"Test initialization with custom AWS client factory.\"\"\"\n        mock_factory = Mock()\n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        assert engine._aws_client_factory == mock_factory\n    \n    def test_init_without_client_factory(self):\n        \"\"\"Test initialization without AWS client factory.\"\"\"\n        engine = RemediationEngine()\n        assert engine._aws_client_factory is None\n    \n    def test_remediate_s3_public_read_acl_success(self):\n        \"\"\"Test successful S3 bucket ACL remediation.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_s3_public_read_acl('test-bucket')\n        \n        assert result is True\n        mock_factory.assert_called_once_with('s3')\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='test-bucket',\n            ACL='private'\n        )\n    \n    def test_remediate_s3_public_read_acl_empty_bucket_name(self):\n        \"\"\"Test remediation with empty bucket name raises error.\"\"\"\n        engine = RemediationEngine()\n        \n        with pytest.raises(RemediationError) as exc_info:\n            engine.remediate_s3_public_read_acl('')\n        \n        assert \"Bucket name cannot be empty\" in str(exc_info.value)\n    \n    def test_remediate_s3_public_read_acl_aws_error(self):\n        \"\"\"Test remediation handles AWS errors properly.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"Access Denied\")\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        \n        with pytest.raises(RemediationError) as exc_info:\n            engine.remediate_s3_public_read_acl('test-bucket')\n        \n        assert \"Failed to remediate S3 bucket test-bucket\" in str(exc_info.value)\n    \n    def test_remediate_finding_s3_public_read_acl_with_finding_object(self):\n        \"\"\"Test remediation with Finding object.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'my-bucket'},\n            description='Test finding'\n        )\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_finding(finding)\n        \n        assert result is True\n        assert finding.status == 'REMEDIATED'\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='my-bucket',\n            ACL='private'\n        )\n    \n    def test_remediate_finding_s3_public_read_acl_with_dict(self):\n        \"\"\"Test remediation with dictionary finding.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        finding = {\n            'type': 'S3_PUBLIC_READ_ACL',\n            'severity': 'CRITICAL',\n            'resource': {'bucket_name': 'dict-bucket'},\n            'description': 'Test finding'\n        }\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_finding(finding)\n        \n        assert result is True\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='dict-bucket',\n            ACL='private'\n        )\n    \n    def test_remediate_finding_unknown_type(self):\n        \"\"\"Test remediation with unknown finding type.\"\"\"\n        engine = RemediationEngine()\n        \n        finding = {\n            'type': 'UNKNOWN_FINDING_TYPE',\n            'severity': 'HIGH',\n            'resource': {},\n            'description': 'Unknown finding'\n        }\n        \n        result = engine.remediate_finding(finding)\n        assert result is False\n    \n    def test_remediate_finding_missing_bucket_name(self):\n        \"\"\"Test remediation when bucket name is missing.\"\"\"\n        engine = RemediationEngine()\n        \n        finding = {\n            'type': 'S3_PUBLIC_READ_ACL',\n            'severity': 'CRITICAL',\n            'resource': {},\n            'description': 'Missing bucket'\n        }\n        \n        result = engine.remediate_finding(finding)\n        assert result is False\n    \n    def test_remediate_finding_handles_remediation_error(self):\n        \"\"\"Test that remediation errors are handled gracefully.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"AWS Error\")\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'error-bucket'},\n            description='Test finding'\n        )\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        result = engine.remediate_finding(finding)\n        \n        assert result is False\n        # Status should not be updated on failure\n        assert finding.status == 'OPEN'\n\n\nclass TestModuleFunctions:\n    \"\"\"Tests for module-level convenience functions.\"\"\"\n    \n    def test_get_remediation_engine_returns_instance(self):\n        \"\"\"Test that get_remediation_engine returns an engine instance.\"\"\"\n        mock_factory = Mock()\n        engine = get_remediation_engine(aws_client_factory=mock_factory)\n        assert isinstance(engine, RemediationEngine)\n    \n    def test_remediate_s3_public_read_acl_function(self):\n        \"\"\"Test the module-level remediate function.\"\"\"\n        mock_s3_client = Mock()\n        \n        with patch('src.remediation_engine._default_engine') as mock_engine:\n            mock_engine.remediate_s3_public_read_acl.return_value = True\n            # Need to reset the default engine for this test\n            import src.remediation_engine as rem_module\n            rem_module._default_engine = None\n            \n            mock_factory = Mock(return_value=mock_s3_client)\n            engine = RemediationEngine(aws_client_factory=mock_factory)\n            result = engine.remediate_s3_public_read_acl('test-bucket')\n            \n            assert result is True\n\n\nclass TestLogging:\n    \"\"\"Tests for logging behavior.\"\"\"\n    \n    def test_successful_remediation_logs_message(self, caplog):\n        \"\"\"Test that successful remediation logs the correct message.\"\"\"\n        mock_s3_client = Mock()\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        \n        with caplog.at_level(logging.INFO):\n            engine.remediate_s3_public_read_acl('logged-bucket')\n        \n        assert \"Successfully remediated S3 bucket logged-bucket by setting ACL to private.\" in caplog.text\n    \n    def test_failed_remediation_logs_error(self, caplog):\n        \"\"\"Test that failed remediation logs an error.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"Test error\")\n        mock_factory = Mock(return_value=mock_s3_client)\n        \n        engine = RemediationEngine(aws_client_factory=mock_factory)\n        \n        with caplog.at_level(logging.ERROR):\n            with pytest.raises(RemediationError):\n                engine.remediate_s3_public_read_acl('error-bucket')\n        \n        assert \"Failed to remediate S3 bucket error-bucket\" in caplog.text\n",
            "tests/test_main.py": "\"\"\"Main test file for NimbusCustodian including integration tests.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch\nimport logging\n\nfrom src.module_7 import EventHandler, get_event_handler, process_security_finding\nfrom src.module_20 import Finding, SecurityScanner\nfrom src.remediation_engine import RemediationEngine\n\n\nclass TestEventHandler:\n    \"\"\"Tests for the EventHandler class.\"\"\"\n    \n    def test_process_event_basic(self):\n        \"\"\"Test basic event processing.\"\"\"\n        handler = EventHandler()\n        event = {'type': 'TEST_EVENT', 'data': 'test'}\n        result = handler.process_event(event)\n        assert result is True\n    \n    def test_register_and_call_handler(self):\n        \"\"\"Test registering and calling event handlers.\"\"\"\n        handler = EventHandler()\n        mock_callback = Mock()\n        \n        handler.register_handler('TEST_EVENT', mock_callback)\n        handler.process_event({'type': 'TEST_EVENT'})\n        \n        mock_callback.assert_called_once()\n\n\nclass TestSecurityFindingIntegration:\n    \"\"\"Integration tests for security finding processing and remediation.\"\"\"\n    \n    def test_critical_s3_finding_triggers_remediation_when_enabled(self):\n        \"\"\"Test that critical S3 findings trigger remediation when enabled.\"\"\"\n        # Setup mock S3 client\n        mock_s3_client = Mock()\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create event handler with config\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine\n        mock_remediation_engine = Mock()\n        mock_remediation_engine.remediate_finding.return_value = True\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'vulnerable-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_called_once_with(finding)\n    \n    def test_critical_s3_finding_does_not_trigger_remediation_when_disabled(self):\n        \"\"\"Test that critical S3 findings do not trigger remediation when disabled.\"\"\"\n        # Setup config with remediation disabled\n        config = {'remediation': {'enabled': False}}\n        config_provider = lambda: config\n        \n        # Create event handler with config\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine (should not be called)\n        mock_remediation_engine = Mock()\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'vulnerable-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was NOT triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_not_called()\n    \n    def test_non_critical_s3_finding_does_not_trigger_remediation(self):\n        \"\"\"Test that non-critical S3 findings do not trigger remediation.\"\"\"\n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine\n        mock_remediation_engine = Mock()\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create HIGH severity (not CRITICAL) S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='HIGH',  # Not CRITICAL\n            resource={'bucket_name': 'some-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was NOT triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_not_called()\n    \n    def test_different_finding_type_does_not_trigger_s3_remediation(self):\n        \"\"\"Test that different finding types do not trigger S3 remediation.\"\"\"\n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        \n        # Inject mock remediation engine\n        mock_remediation_engine = Mock()\n        event_handler._remediation_engine = mock_remediation_engine\n        \n        # Create different type of finding\n        finding = Finding(\n            type='EC2_SECURITY_GROUP_OPEN',\n            severity='CRITICAL',\n            resource={'instance_id': 'i-12345'},\n            description='Security group is open'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify remediation was NOT triggered\n        assert result is True\n        mock_remediation_engine.remediate_finding.assert_not_called()\n    \n    def test_end_to_end_remediation_flow(self):\n        \"\"\"Test the complete flow from finding to remediation.\"\"\"\n        # Setup mock S3 client\n        mock_s3_client = Mock()\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create real remediation engine with mock AWS client\n        remediation_engine = RemediationEngine(aws_client_factory=mock_aws_factory)\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        event_handler._remediation_engine = remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'public-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding\n        result = event_handler.process_security_finding(finding)\n        \n        # Verify the complete flow\n        assert result is True\n        mock_s3_client.put_bucket_acl.assert_called_once_with(\n            Bucket='public-bucket',\n            ACL='private'\n        )\n        assert finding.status == 'REMEDIATED'\n    \n    def test_remediation_failure_handling(self):\n        \"\"\"Test handling of remediation failures.\"\"\"\n        # Setup mock S3 client that fails\n        mock_s3_client = Mock()\n        mock_s3_client.put_bucket_acl.side_effect = Exception(\"Access Denied\")\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        # Setup config with remediation enabled\n        config = {'remediation': {'enabled': True}}\n        config_provider = lambda: config\n        \n        # Create real remediation engine with mock AWS client\n        remediation_engine = RemediationEngine(aws_client_factory=mock_aws_factory)\n        \n        # Create event handler\n        event_handler = EventHandler(config_provider=config_provider)\n        event_handler._remediation_engine = remediation_engine\n        \n        # Create critical S3 finding\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'protected-bucket'},\n            description='Public read ACL detected'\n        )\n        \n        # Process the finding - should not raise exception\n        result = event_handler.process_security_finding(finding)\n        \n        # Finding status should remain OPEN since remediation failed\n        assert finding.status == 'OPEN'\n\n\nclass TestSecurityScanner:\n    \"\"\"Tests for the SecurityScanner class.\"\"\"\n    \n    def test_scan_s3_bucket_acls_finds_public_buckets(self):\n        \"\"\"Test that scanner correctly identifies public buckets.\"\"\"\n        # Setup mock S3 client\n        mock_s3_client = Mock()\n        mock_s3_client.list_buckets.return_value = {\n            'Buckets': [{'Name': 'public-bucket'}, {'Name': 'private-bucket'}]\n        }\n        mock_s3_client.get_bucket_acl.side_effect = [\n            # Public bucket\n            {\n                'Grants': [{\n                    'Grantee': {'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n                    'Permission': 'READ'\n                }]\n            },\n            # Private bucket\n            {\n                'Grants': [{\n                    'Grantee': {'Type': 'CanonicalUser'},\n                    'Permission': 'FULL_CONTROL'\n                }]\n            }\n        ]\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        scanner = SecurityScanner(aws_client_factory=mock_aws_factory)\n        findings = scanner.scan_s3_bucket_acls()\n        \n        assert len(findings) == 1\n        assert findings[0].type == 'S3_PUBLIC_READ_ACL'\n        assert findings[0].severity == 'CRITICAL'\n        assert findings[0].resource['bucket_name'] == 'public-bucket'\n    \n    def test_scanner_emits_findings_to_handlers(self):\n        \"\"\"Test that scanner emits findings to registered handlers.\"\"\"\n        mock_s3_client = Mock()\n        mock_s3_client.list_buckets.return_value = {\n            'Buckets': [{'Name': 'public-bucket'}]\n        }\n        mock_s3_client.get_bucket_acl.return_value = {\n            'Grants': [{\n                'Grantee': {'URI': 'http://acs.amazonaws.com/groups/global/AllUsers'},\n                'Permission': 'READ'\n            }]\n        }\n        mock_aws_factory = Mock(return_value=mock_s3_client)\n        \n        scanner = SecurityScanner(aws_client_factory=mock_aws_factory)\n        \n        # Register a mock handler\n        mock_handler = Mock()\n        scanner.register_finding_handler(mock_handler)\n        \n        # Run scan\n        scanner.scan_s3_bucket_acls()\n        \n        # Verify handler was called\n        mock_handler.assert_called_once()\n        called_finding = mock_handler.call_args[0][0]\n        assert called_finding.type == 'S3_PUBLIC_READ_ACL'\n\n\nclass TestFinding:\n    \"\"\"Tests for the Finding class.\"\"\"\n    \n    def test_finding_update_status(self):\n        \"\"\"Test updating finding status.\"\"\"\n        finding = Finding(\n            type='TEST',\n            severity='HIGH',\n            resource={},\n            description='Test'\n        )\n        \n        assert finding.status == 'OPEN'\n        finding.update_status('REMEDIATED')\n        assert finding.status == 'REMEDIATED'\n    \n    def test_finding_bucket_name_property(self):\n        \"\"\"Test bucket_name property.\"\"\"\n        finding = Finding(\n            type='S3_PUBLIC_READ_ACL',\n            severity='CRITICAL',\n            resource={'bucket_name': 'my-bucket'},\n            description='Test'\n        )\n        \n        assert finding.bucket_name == 'my-bucket'\n    \n    def test_finding_to_dict(self):\n        \"\"\"Test converting finding to dictionary.\"\"\"\n        finding = Finding(\n            type='TEST',\n            severity='HIGH',\n            resource={'key': 'value'},\n            description='Test finding',\n            id='test-123'\n        )\n        \n        result = finding.to_dict()\n        \n        assert result['type'] == 'TEST'\n        assert result['severity'] == 'HIGH'\n        assert result['resource'] == {'key': 'value'}\n        assert result['description'] == 'Test finding'\n        assert result['id'] == 'test-123'\n        assert result['status'] == 'OPEN'\n",
            "tests/test_utils.py": "\"\"\"Tests for utility functions.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, patch\n\nfrom src.utils import (\n    get_aws_client,\n    clear_aws_client_cache,\n    format_resource_arn,\n    parse_s3_uri,\n    safe_get\n)\n\n\nclass TestGetAwsClient:\n    \"\"\"Tests for get_aws_client function.\"\"\"\n    \n    @patch('src.utils.boto3')\n    def test_get_aws_client_creates_client(self, mock_boto3):\n        \"\"\"Test that get_aws_client creates a boto3 client.\"\"\"\n        clear_aws_client_cache()\n        mock_client = Mock()\n        mock_boto3.client.return_value = mock_client\n        \n        result = get_aws_client('s3')\n        \n        mock_boto3.client.assert_called_once_with('s3')\n        assert result == mock_client\n    \n    @patch('src.utils.boto3')\n    def test_get_aws_client_with_region(self, mock_boto3):\n        \"\"\"Test that get_aws_client passes region parameter.\"\"\"\n        clear_aws_client_cache()\n        mock_client = Mock()\n        mock_boto3.client.return_value = mock_client\n        \n        result = get_aws_client('s3', region='us-west-2')\n        \n        mock_boto3.client.assert_called_once_with('s3', region_name='us-west-2')\n    \n    @patch('src.utils.boto3')\n    def test_get_aws_client_caches_client(self, mock_boto3):\n        \"\"\"Test that get_aws_client caches clients.\"\"\"\n        clear_aws_client_cache()\n        mock_client = Mock()\n        mock_boto3.client.return_value = mock_client\n        \n        result1 = get_aws_client('s3')\n        result2 = get_aws_client('s3')\n        \n        # Should only create client once\n        assert mock_boto3.client.call_count == 1\n        assert result1 == result2\n\n\nclass TestFormatResourceArn:\n    \"\"\"Tests for format_resource_arn function.\"\"\"\n    \n    def test_format_full_arn(self):\n        \"\"\"Test formatting a complete ARN.\"\"\"\n        arn = format_resource_arn(\n            service='s3',\n            resource_type='bucket',\n            resource_id='my-bucket',\n            region='us-east-1',\n            account_id='123456789012'\n        )\n        \n        assert arn == 'arn:aws:s3:us-east-1:123456789012:bucket/my-bucket'\n    \n    def test_format_global_resource_arn(self):\n        \"\"\"Test formatting ARN for global resource.\"\"\"\n        arn = format_resource_arn(\n            service='s3',\n            resource_type='bucket',\n            resource_id='my-bucket'\n        )\n        \n        assert arn == 'arn:aws:s3:::bucket/my-bucket'\n\n\nclass TestParseS3Uri:\n    \"\"\"Tests for parse_s3_uri function.\"\"\"\n    \n    def test_parse_full_uri(self):\n        \"\"\"Test parsing S3 URI with key.\"\"\"\n        result = parse_s3_uri('s3://my-bucket/path/to/object.txt')\n        \n        assert result['bucket'] == 'my-bucket'\n        assert result['key'] == 'path/to/object.txt'\n    \n    def test_parse_bucket_only_uri(self):\n        \"\"\"Test parsing S3 URI with only bucket.\"\"\"\n        result = parse_s3_uri('s3://my-bucket')\n        \n        assert result['bucket'] == 'my-bucket'\n        assert result['key'] == ''\n    \n    def test_parse_invalid_uri_raises_error(self):\n        \"\"\"Test that invalid URI raises ValueError.\"\"\"\n        with pytest.raises(ValueError) as exc_info:\n            parse_s3_uri('http://example.com')\n        \n        assert 'Invalid S3 URI' in str(exc_info.value)\n\n\nclass TestSafeGet:\n    \"\"\"Tests for safe_get function.\"\"\"\n    \n    def test_safe_get_dict_single_key(self):\n        \"\"\"Test getting value from dict with single key.\"\"\"\n        obj = {'key': 'value'}\n        result = safe_get(obj, 'key')\n        assert result == 'value'\n    \n    def test_safe_get_dict_nested_keys(self):\n        \"\"\"Test getting nested value from dict.\"\"\"\n        obj = {'level1': {'level2': {'level3': 'deep_value'}}}\n        result = safe_get(obj, 'level1', 'level2', 'level3')\n        assert result == 'deep_value'\n    \n    def test_safe_get_missing_key_returns_default(self):\n        \"\"\"Test that missing key returns default value.\"\"\"\n        obj = {'key': 'value'}\n        result = safe_get(obj, 'missing', default='default_value')\n        assert result == 'default_value'\n    \n    def test_safe_get_none_value_returns_default(self):\n        \"\"\"Test that None value returns default.\"\"\"\n        obj = {'key': None}\n        result = safe_get(obj, 'key', default='default_value')\n        assert result == 'default_value'\n    \n    def test_safe_get_object_attribute(self):\n        \"\"\"Test getting attribute from object.\"\"\"\n        class TestObj:\n            attr = 'attr_value'\n        \n        obj = TestObj()\n        result = safe_get(obj, 'attr')\n        assert result == 'attr_value'\n"
          },
          "generated_files": [
            "src/remediation_engine.py",
            "src/module_7.py",
            "src/module_20.py",
            "src/utils.py",
            "tests/test_remediation_engine.py",
            "tests/test_main.py",
            "tests/test_utils.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7962346702021875,
                "dependency_traversal_accuracy": 0.8116628899323408,
                "cross_file_reasoning_depth": 0.20952380952380953,
                "system_thinking_score": 0.5658790849673203,
                "robustness_score": 0.1587742899850523,
                "comprehensiveness_score": 0.706509715994021,
                "innovation_score": 0.18125000000000002,
                "solution_elegance_score": 0.8583049558857447
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09952933377527344,
                "dependency_traversal_weighted": 0.1014578612415426,
                "cross_file_reasoning_weighted": 0.02619047619047619,
                "system_thinking_weighted": 0.07073488562091504,
                "robustness_weighted": 0.019846786248131538,
                "comprehensiveness_weighted": 0.08831371449925263,
                "innovation_weighted": 0.022656250000000003,
                "solution_elegance_weighted": 0.10728811948571809
              },
              "total_software_engineering_score": 0.5360174270613095
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.4560565948486328,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "src/remediation_engine.py",
                  "src/module_7.py",
                  "src/module_20.py",
                  "src/utils.py",
                  "tests/test_remediation_engine.py",
                  "tests/test_main.py",
                  "tests/test_utils.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.0,
                "tests_run": 4,
                "tests_passed": 0,
                "tests_failed": 4,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": false,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": false,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 7,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 7 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.2830513176144244,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.0,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.2830513176144244,
                "idc_weight": 0.2,
                "total_functional_score": 0.4866102635228849
              }
            },
            "code_quality_details": {
              "files_analyzed": 7,
              "quality_checks": {
                "src/remediation_engine.py": {
                  "line_count": 146,
                  "non_empty_lines": 110,
                  "comment_lines": 2,
                  "comment_ratio": 0.01818181818181818,
                  "function_count": 7,
                  "class_count": 4,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "src/module_7.py": {
                  "line_count": 173,
                  "non_empty_lines": 133,
                  "comment_lines": 6,
                  "comment_ratio": 0.045112781954887216,
                  "function_count": 10,
                  "class_count": 7,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "src/module_20.py": {
                  "line_count": 221,
                  "non_empty_lines": 173,
                  "comment_lines": 2,
                  "comment_ratio": 0.011560693641618497,
                  "function_count": 13,
                  "class_count": 4,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "src/utils.py": {
                  "line_count": 110,
                  "non_empty_lines": 83,
                  "comment_lines": 1,
                  "comment_ratio": 0.012048192771084338,
                  "function_count": 5,
                  "class_count": 0,
                  "import_count": 5,
                  "quality_score": 0.7999999999999999
                },
                "tests/test_remediation_engine.py": {
                  "line_count": 214,
                  "non_empty_lines": 162,
                  "comment_lines": 2,
                  "comment_ratio": 0.012345679012345678,
                  "function_count": 14,
                  "class_count": 3,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "tests/test_main.py": {
                  "line_count": 332,
                  "non_empty_lines": 263,
                  "comment_lines": 45,
                  "comment_ratio": 0.17110266159695817,
                  "function_count": 13,
                  "class_count": 7,
                  "import_count": 11,
                  "quality_score": 0.9999999999999999
                },
                "tests/test_utils.py": {
                  "line_count": 142,
                  "non_empty_lines": 106,
                  "comment_lines": 1,
                  "comment_ratio": 0.009433962264150943,
                  "function_count": 13,
                  "class_count": 5,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.8199999999999998,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.48981092436974794,
                "multi_session_memory_retention": 0.5347183317771553
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.24490546218487397,
                "multi_session_memory_retention_weighted": 0.26735916588857767
              },
              "total_longcontext_utilization_score": 0.5122646280734516
            }
          },
          "timestamp": "2026-01-14T21:44:43.650491"
        }
      }
    },
    "python_fintech_payment_expert_029_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_fintech_payment_expert_029_feature_implementation_expert_01",
          "scenario_title": "Implement Dynamic, Risk-Based Transaction Fees",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5781345341314588,
          "functional_correctness_score": 0.6489113739232005,
          "code_quality_score": 0.7999999999999999,
          "longcontext_utilization_score": 0.8579365079365079,
          "total_score": 3.3586043831159724,
          "generation_time": 222.36056971549988,
          "code_files_generated": 9,
          "total_lines_generated": 1896,
          "parsing_success": true,
          "solution_code": {
            "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py": "\"\"\"Fee calculation API endpoint for risk-based transaction fees.\"\"\"\nfrom fastapi import APIRouter, HTTPException\nfrom pydantic import BaseModel, Field\nfrom decimal import Decimal, ROUND_HALF_UP\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(prefix=\"/v1/fees\", tags=[\"fees\"])\n\n# Constants for fee calculation\nBASE_RATE = Decimal(\"0.005\")  # 0.5%\nRISK_PREMIUM = Decimal(\"0.02\")  # 2%\n\n\nclass FeeCalculationRequest(BaseModel):\n    \"\"\"Request model for fee calculation.\"\"\"\n    amount: Decimal = Field(..., gt=0, description=\"Transaction amount\")\n    currency: str = Field(..., min_length=3, max_length=3, description=\"Currency code\")\n    source_user_id: str = Field(..., description=\"Source user ID\")\n    destination_pod_id: str = Field(..., description=\"Destination pod ID\")\n\n\nclass FeeCalculationResponse(BaseModel):\n    \"\"\"Response model for fee calculation.\"\"\"\n    fee: Decimal = Field(..., description=\"Calculated transaction fee\")\n    total_debit_amount: Decimal = Field(..., description=\"Total amount to debit (amount + fee)\")\n    base_rate: Decimal = Field(..., description=\"Base rate used\")\n    risk_premium: Decimal = Field(..., description=\"Risk premium used\")\n    user_reputation_score: Decimal = Field(..., description=\"User reputation score used\")\n    currency: str = Field(..., description=\"Currency code\")\n\n\ndef get_user_reputation_score(user_id: str) -> Decimal:\n    \"\"\"Fetch user reputation score.\n    \n    In a real implementation, this would call the user service or a cache.\n    For this implementation, we use a deterministic mock based on user_id.\n    \n    Args:\n        user_id: The user's unique identifier\n        \n    Returns:\n        A reputation score between 0.0 and 1.0\n    \"\"\"\n    # Mock implementation: hash the user_id to get a deterministic score\n    # In production, this would call the user_service reputation endpoint\n    hash_value = hash(user_id)\n    # Normalize to 0.0-1.0 range\n    score = abs(hash_value % 100) / 100.0\n    return Decimal(str(score)).quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\n\n\ndef calculate_transaction_fee(\n    amount: Decimal,\n    user_reputation_score: Decimal,\n    base_rate: Decimal = BASE_RATE,\n    risk_premium: Decimal = RISK_PREMIUM\n) -> Decimal:\n    \"\"\"Calculate the transaction fee based on amount and user reputation.\n    \n    Formula: fee = (base_rate * amount) + (risk_premium * amount * user_reputation_score)\n    \n    Higher reputation scores result in higher fees (risk-based pricing).\n    This incentivizes maintaining good standing while covering platform risk.\n    \n    Args:\n        amount: Transaction amount\n        user_reputation_score: User's reputation score (0.0 to 1.0)\n        base_rate: Base fee rate (default 0.5%)\n        risk_premium: Risk premium rate (default 2%)\n        \n    Returns:\n        Calculated fee amount\n    \"\"\"\n    base_fee = base_rate * amount\n    risk_fee = risk_premium * amount * user_reputation_score\n    total_fee = base_fee + risk_fee\n    # Round to 2 decimal places\n    return total_fee.quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP)\n\n\n@router.post(\"/calculate\", response_model=FeeCalculationResponse)\nasync def calculate_fees(request: FeeCalculationRequest) -> FeeCalculationResponse:\n    \"\"\"Calculate transaction fees based on risk assessment.\n    \n    This endpoint calculates dynamic fees based on:\n    - Transaction amount\n    - Source user's reputation score\n    - Base rate and risk premium\n    \n    Args:\n        request: Fee calculation request with transaction details\n        \n    Returns:\n        Calculated fee and total debit amount\n    \"\"\"\n    try:\n        logger.info(\n            f\"Calculating fees for user {request.source_user_id}, \"\n            f\"amount {request.amount} {request.currency}\"\n        )\n        \n        # Get user reputation score\n        user_reputation_score = get_user_reputation_score(request.source_user_id)\n        \n        # Calculate fee\n        fee = calculate_transaction_fee(\n            amount=request.amount,\n            user_reputation_score=user_reputation_score\n        )\n        \n        # Calculate total debit amount\n        total_debit_amount = request.amount + fee\n        \n        logger.info(\n            f\"Fee calculated: {fee} {request.currency}, \"\n            f\"total debit: {total_debit_amount} {request.currency}, \"\n            f\"reputation score: {user_reputation_score}\"\n        )\n        \n        return FeeCalculationResponse(\n            fee=fee,\n            total_debit_amount=total_debit_amount,\n            base_rate=BASE_RATE,\n            risk_premium=RISK_PREMIUM,\n            user_reputation_score=user_reputation_score,\n            currency=request.currency\n        )\n        \n    except Exception as e:\n        logger.error(f\"Error calculating fees: {str(e)}\")\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to calculate transaction fees: {str(e)}\"\n        )\n",
            "crowdpay_connect/services/risk_compliance_service/app/main.py": "\"\"\"Main application entry point for the Risk Compliance Service.\"\"\"\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nimport logging\n\nfrom app.api.v1 import assessment\nfrom app.api.v1 import fees\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(\n    title=\"Risk Compliance Service\",\n    description=\"Service for risk assessment, compliance checking, and fee calculation\",\n    version=\"1.0.0\"\n)\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(assessment.router)\napp.include_router(fees.router)\n\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"service\": \"risk_compliance_service\"}\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Handle application startup.\"\"\"\n    logger.info(\"Risk Compliance Service starting up...\")\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    \"\"\"Handle application shutdown.\"\"\"\n    logger.info(\"Risk Compliance Service shutting down...\")\n",
            "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py": "\"\"\"Unit tests for fee calculation logic.\"\"\"\nimport pytest\nfrom decimal import Decimal\nfrom unittest.mock import patch, AsyncMock\nfrom fastapi.testclient import TestClient\n\nfrom app.main import app\nfrom app.api.v1.fees import (\n    calculate_transaction_fee,\n    get_user_reputation_score,\n    BASE_RATE,\n    RISK_PREMIUM,\n    FeeCalculationRequest,\n    FeeCalculationResponse\n)\n\nclient = TestClient(app)\n\n\nclass TestFeeCalculationLogic:\n    \"\"\"Test cases for fee calculation logic.\"\"\"\n    \n    def test_calculate_fee_with_zero_reputation(self):\n        \"\"\"Test fee calculation with zero reputation score.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"0.0\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # With 0 reputation, only base fee applies: 0.005 * 100 = 0.50\n        expected_fee = Decimal(\"0.50\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_with_full_reputation(self):\n        \"\"\"Test fee calculation with maximum reputation score.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"1.0\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 100 = 0.50\n        # Risk fee: 0.02 * 100 * 1.0 = 2.00\n        # Total: 2.50\n        expected_fee = Decimal(\"2.50\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_with_partial_reputation(self):\n        \"\"\"Test fee calculation with 50% reputation score.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"0.5\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 100 = 0.50\n        # Risk fee: 0.02 * 100 * 0.5 = 1.00\n        # Total: 1.50\n        expected_fee = Decimal(\"1.50\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_large_amount(self):\n        \"\"\"Test fee calculation with large transaction amount.\"\"\"\n        amount = Decimal(\"10000.00\")\n        reputation_score = Decimal(\"0.75\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 10000 = 50.00\n        # Risk fee: 0.02 * 10000 * 0.75 = 150.00\n        # Total: 200.00\n        expected_fee = Decimal(\"200.00\")\n        assert fee == expected_fee\n    \n    def test_calculate_fee_small_amount(self):\n        \"\"\"Test fee calculation with small transaction amount.\"\"\"\n        amount = Decimal(\"1.00\")\n        reputation_score = Decimal(\"0.5\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Base fee: 0.005 * 1 = 0.005 -> rounds to 0.01 or 0.02\n        # Risk fee: 0.02 * 1 * 0.5 = 0.01\n        # Total: ~0.02\n        assert fee >= Decimal(\"0.01\")\n        assert fee <= Decimal(\"0.03\")\n    \n    def test_calculate_fee_custom_rates(self):\n        \"\"\"Test fee calculation with custom base rate and risk premium.\"\"\"\n        amount = Decimal(\"100.00\")\n        reputation_score = Decimal(\"0.5\")\n        custom_base_rate = Decimal(\"0.01\")  # 1%\n        custom_risk_premium = Decimal(\"0.05\")  # 5%\n        \n        fee = calculate_transaction_fee(\n            amount,\n            reputation_score,\n            base_rate=custom_base_rate,\n            risk_premium=custom_risk_premium\n        )\n        \n        # Base fee: 0.01 * 100 = 1.00\n        # Risk fee: 0.05 * 100 * 0.5 = 2.50\n        # Total: 3.50\n        expected_fee = Decimal(\"3.50\")\n        assert fee == expected_fee\n    \n    def test_fee_rounding(self):\n        \"\"\"Test that fees are properly rounded to 2 decimal places.\"\"\"\n        amount = Decimal(\"33.33\")\n        reputation_score = Decimal(\"0.33\")\n        \n        fee = calculate_transaction_fee(amount, reputation_score)\n        \n        # Ensure fee has exactly 2 decimal places\n        assert fee == fee.quantize(Decimal(\"0.01\"))\n\n\nclass TestUserReputationScore:\n    \"\"\"Test cases for user reputation score retrieval.\"\"\"\n    \n    def test_reputation_score_range(self):\n        \"\"\"Test that reputation score is within valid range.\"\"\"\n        for user_id in [\"user1\", \"user2\", \"user123\", \"test-user\"]:\n            score = get_user_reputation_score(user_id)\n            assert Decimal(\"0.0\") <= score <= Decimal(\"1.0\")\n    \n    def test_reputation_score_deterministic(self):\n        \"\"\"Test that same user_id always returns same score.\"\"\"\n        user_id = \"consistent-user-123\"\n        score1 = get_user_reputation_score(user_id)\n        score2 = get_user_reputation_score(user_id)\n        assert score1 == score2\n    \n    def test_different_users_can_have_different_scores(self):\n        \"\"\"Test that different users can have different scores.\"\"\"\n        # With enough users, we should see variation\n        scores = set()\n        for i in range(100):\n            score = get_user_reputation_score(f\"user-{i}\")\n            scores.add(score)\n        \n        # Should have multiple unique scores\n        assert len(scores) > 1\n\n\nclass TestFeeCalculationEndpoint:\n    \"\"\"Test cases for the /v1/fees/calculate endpoint.\"\"\"\n    \n    def test_calculate_fees_success(self):\n        \"\"\"Test successful fee calculation via API.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 200\n        data = response.json()\n        \n        assert \"fee\" in data\n        assert \"total_debit_amount\" in data\n        assert \"base_rate\" in data\n        assert \"risk_premium\" in data\n        assert \"user_reputation_score\" in data\n        assert \"currency\" in data\n        \n        # Verify total = amount + fee\n        fee = Decimal(data[\"fee\"])\n        total = Decimal(data[\"total_debit_amount\"])\n        assert total == Decimal(\"100.00\") + fee\n    \n    def test_calculate_fees_invalid_amount(self):\n        \"\"\"Test fee calculation with invalid amount.\"\"\"\n        request_data = {\n            \"amount\": \"-100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 422  # Validation error\n    \n    def test_calculate_fees_invalid_currency(self):\n        \"\"\"Test fee calculation with invalid currency code.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\",\n            \"currency\": \"INVALID\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 422  # Validation error\n    \n    def test_calculate_fees_missing_fields(self):\n        \"\"\"Test fee calculation with missing required fields.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\"\n            # Missing other required fields\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 422  # Validation error\n    \n    def test_calculate_fees_returns_correct_rates(self):\n        \"\"\"Test that endpoint returns correct base rate and risk premium.\"\"\"\n        request_data = {\n            \"amount\": \"100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"user-123\",\n            \"destination_pod_id\": \"pod-456\"\n        }\n        \n        response = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response.status_code == 200\n        data = response.json()\n        \n        assert Decimal(data[\"base_rate\"]) == BASE_RATE\n        assert Decimal(data[\"risk_premium\"]) == RISK_PREMIUM\n    \n    def test_calculate_fees_different_currencies(self):\n        \"\"\"Test fee calculation with different currencies.\"\"\"\n        currencies = [\"USD\", \"EUR\", \"GBP\"]\n        \n        for currency in currencies:\n            request_data = {\n                \"amount\": \"100.00\",\n                \"currency\": currency,\n                \"source_user_id\": \"user-123\",\n                \"destination_pod_id\": \"pod-456\"\n            }\n            \n            response = client.post(\"/v1/fees/calculate\", json=request_data)\n            \n            assert response.status_code == 200\n            assert response.json()[\"currency\"] == currency\n\n\nclass TestFeeCalculationIntegration:\n    \"\"\"Integration tests for fee calculation.\"\"\"\n    \n    def test_fee_calculation_consistency(self):\n        \"\"\"Test that fee calculation is consistent for same inputs.\"\"\"\n        request_data = {\n            \"amount\": \"500.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": \"consistent-user\",\n            \"destination_pod_id\": \"pod-789\"\n        }\n        \n        response1 = client.post(\"/v1/fees/calculate\", json=request_data)\n        response2 = client.post(\"/v1/fees/calculate\", json=request_data)\n        \n        assert response1.json() == response2.json()\n    \n    def test_fee_scales_with_amount(self):\n        \"\"\"Test that fee scales proportionally with amount.\"\"\"\n        user_id = \"scaling-test-user\"\n        \n        response1 = client.post(\"/v1/fees/calculate\", json={\n            \"amount\": \"100.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": user_id,\n            \"destination_pod_id\": \"pod-123\"\n        })\n        \n        response2 = client.post(\"/v1/fees/calculate\", json={\n            \"amount\": \"200.00\",\n            \"currency\": \"USD\",\n            \"source_user_id\": user_id,\n            \"destination_pod_id\": \"pod-123\"\n        })\n        \n        fee1 = Decimal(response1.json()[\"fee\"])\n        fee2 = Decimal(response2.json()[\"fee\"])\n        \n        # Fee should roughly double when amount doubles\n        assert Decimal(\"1.9\") <= fee2 / fee1 <= Decimal(\"2.1\")\n",
            "crowdpay_connect/services/transaction_service/app/models/saga_state.py": "\"\"\"Saga state model for tracking payment saga progress.\"\"\"\nfrom sqlalchemy import Column, String, Enum, DateTime, JSON, Numeric\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom datetime import datetime\nimport enum\nimport uuid\n\nfrom app.db.base import Base\n\n\nclass SagaStatus(enum.Enum):\n    \"\"\"Enumeration of possible saga statuses.\"\"\"\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    COMPENSATING = \"compensating\"\n    FAILED = \"failed\"\n    ROLLED_BACK = \"rolled_back\"\n\n\nclass SagaStepStatus(enum.Enum):\n    \"\"\"Enumeration of possible saga step statuses.\"\"\"\n    PENDING = \"pending\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    COMPENSATED = \"compensated\"\n\n\nclass SagaState(Base):\n    \"\"\"Model representing the state of a payment saga.\"\"\"\n    \n    __tablename__ = \"saga_states\"\n    \n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    transaction_id = Column(UUID(as_uuid=True), unique=True, nullable=False, index=True)\n    \n    # Saga status tracking\n    status = Column(Enum(SagaStatus), default=SagaStatus.PENDING, nullable=False)\n    current_step = Column(String(100), nullable=True)\n    current_step_status = Column(Enum(SagaStepStatus), default=SagaStepStatus.PENDING)\n    \n    # Transaction details\n    source_wallet_id = Column(UUID(as_uuid=True), nullable=False)\n    destination_pod_id = Column(UUID(as_uuid=True), nullable=False)\n    source_user_id = Column(String(100), nullable=False)\n    amount = Column(Numeric(precision=18, scale=2), nullable=False)\n    currency = Column(String(3), nullable=False)\n    \n    # Fee information (new fields for dynamic fees)\n    transaction_fee = Column(Numeric(precision=18, scale=2), nullable=True)\n    total_debit_amount = Column(Numeric(precision=18, scale=2), nullable=True)\n    fee_calculation_details = Column(JSON, nullable=True)  # Stores full fee response\n    \n    # Step completion tracking\n    completed_steps = Column(JSON, default=list)\n    step_results = Column(JSON, default=dict)\n    \n    # Error tracking\n    error_message = Column(String(500), nullable=True)\n    failed_step = Column(String(100), nullable=True)\n    \n    # Timestamps\n    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)\n    completed_at = Column(DateTime, nullable=True)\n    \n    def __repr__(self):\n        return f\"<SagaState(id={self.id}, transaction_id={self.transaction_id}, status={self.status})>\"\n    \n    def to_dict(self):\n        \"\"\"Convert saga state to dictionary.\"\"\"\n        return {\n            \"id\": str(self.id),\n            \"transaction_id\": str(self.transaction_id),\n            \"status\": self.status.value,\n            \"current_step\": self.current_step,\n            \"current_step_status\": self.current_step_status.value if self.current_step_status else None,\n            \"source_wallet_id\": str(self.source_wallet_id),\n            \"destination_pod_id\": str(self.destination_pod_id),\n            \"source_user_id\": self.source_user_id,\n            \"amount\": str(self.amount),\n            \"currency\": self.currency,\n            \"transaction_fee\": str(self.transaction_fee) if self.transaction_fee else None,\n            \"total_debit_amount\": str(self.total_debit_amount) if self.total_debit_amount else None,\n            \"fee_calculation_details\": self.fee_calculation_details,\n            \"completed_steps\": self.completed_steps,\n            \"step_results\": self.step_results,\n            \"error_message\": self.error_message,\n            \"failed_step\": self.failed_step,\n            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n            \"updated_at\": self.updated_at.isoformat() if self.updated_at else None,\n            \"completed_at\": self.completed_at.isoformat() if self.completed_at else None\n        }\n    \n    def mark_step_completed(self, step_name: str, result: dict = None):\n        \"\"\"Mark a step as completed and store its result.\"\"\"\n        if self.completed_steps is None:\n            self.completed_steps = []\n        if step_name not in self.completed_steps:\n            self.completed_steps = self.completed_steps + [step_name]\n        \n        if result:\n            if self.step_results is None:\n                self.step_results = {}\n            self.step_results = {**self.step_results, step_name: result}\n    \n    def set_fee_details(self, fee: float, total_debit: float, details: dict = None):\n        \"\"\"Set fee calculation details.\"\"\"\n        from decimal import Decimal\n        self.transaction_fee = Decimal(str(fee))\n        self.total_debit_amount = Decimal(str(total_debit))\n        self.fee_calculation_details = details\n",
            "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py": "\"\"\"Payment Saga implementation for orchestrating payment transactions.\"\"\"\nimport logging\nimport httpx\nfrom decimal import Decimal\nfrom typing import Optional, Dict, Any\nfrom datetime import datetime\nimport json\n\nfrom app.models.saga_state import SagaState, SagaStatus, SagaStepStatus\nfrom app.events.saga_coordinator import SagaCoordinator\nfrom libs.shared_events.schemas import DebitWallet, CreditPod, PaymentCompleted, PaymentFailed\n\nlogger = logging.getLogger(__name__)\n\n# Configuration for risk service\nRISK_SERVICE_URL = \"http://risk-compliance-service:8000\"\nFEE_CALCULATION_ENDPOINT = \"/v1/fees/calculate\"\nFEE_CALCULATION_TIMEOUT = 10.0  # seconds\n\n\nclass PaymentSagaError(Exception):\n    \"\"\"Custom exception for payment saga errors.\"\"\"\n    pass\n\n\nclass PaymentSaga:\n    \"\"\"Orchestrates the payment transaction saga.\n    \n    Steps:\n    1. Validate transaction\n    2. Calculate fees (NEW)\n    3. Debit source wallet\n    4. Credit destination pod\n    5. Complete transaction\n    \n    Each step has a corresponding compensation action for rollback.\n    \"\"\"\n    \n    STEPS = [\n        \"validate_transaction\",\n        \"calculate_fees\",\n        \"debit_source_wallet\",\n        \"credit_destination_pod\",\n        \"complete_transaction\"\n    ]\n    \n    def __init__(self, saga_state: SagaState, coordinator: SagaCoordinator):\n        \"\"\"Initialize the payment saga.\n        \n        Args:\n            saga_state: The saga state model instance\n            coordinator: The saga coordinator for event publishing\n        \"\"\"\n        self.saga_state = saga_state\n        self.coordinator = coordinator\n        self._http_client: Optional[httpx.AsyncClient] = None\n    \n    async def execute(self) -> bool:\n        \"\"\"Execute the payment saga.\n        \n        Returns:\n            True if saga completed successfully, False otherwise\n        \"\"\"\n        logger.info(f\"Starting payment saga for transaction {self.saga_state.transaction_id}\")\n        \n        self.saga_state.status = SagaStatus.IN_PROGRESS\n        await self.coordinator.update_saga_state(self.saga_state)\n        \n        try:\n            for step in self.STEPS:\n                if step in (self.saga_state.completed_steps or []):\n                    logger.info(f\"Skipping already completed step: {step}\")\n                    continue\n                \n                self.saga_state.current_step = step\n                self.saga_state.current_step_status = SagaStepStatus.EXECUTING\n                await self.coordinator.update_saga_state(self.saga_state)\n                \n                step_method = getattr(self, f\"_step_{step}\")\n                result = await step_method()\n                \n                self.saga_state.mark_step_completed(step, result)\n                self.saga_state.current_step_status = SagaStepStatus.COMPLETED\n                await self.coordinator.update_saga_state(self.saga_state)\n                \n                logger.info(f\"Completed step: {step}\")\n            \n            self.saga_state.status = SagaStatus.COMPLETED\n            self.saga_state.completed_at = datetime.utcnow()\n            await self.coordinator.update_saga_state(self.saga_state)\n            \n            logger.info(f\"Payment saga completed successfully for transaction {self.saga_state.transaction_id}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Payment saga failed at step {self.saga_state.current_step}: {str(e)}\")\n            self.saga_state.error_message = str(e)\n            self.saga_state.failed_step = self.saga_state.current_step\n            self.saga_state.current_step_status = SagaStepStatus.FAILED\n            await self.coordinator.update_saga_state(self.saga_state)\n            \n            await self.compensate()\n            return False\n        finally:\n            if self._http_client:\n                await self._http_client.aclose()\n    \n    async def compensate(self):\n        \"\"\"Execute compensation for all completed steps in reverse order.\"\"\"\n        logger.info(f\"Starting compensation for transaction {self.saga_state.transaction_id}\")\n        \n        self.saga_state.status = SagaStatus.COMPENSATING\n        await self.coordinator.update_saga_state(self.saga_state)\n        \n        completed_steps = list(reversed(self.saga_state.completed_steps or []))\n        \n        for step in completed_steps:\n            try:\n                compensate_method = getattr(self, f\"_compensate_{step}\", None)\n                if compensate_method:\n                    logger.info(f\"Compensating step: {step}\")\n                    await compensate_method()\n            except Exception as e:\n                logger.error(f\"Compensation failed for step {step}: {str(e)}\")\n        \n        self.saga_state.status = SagaStatus.ROLLED_BACK\n        await self.coordinator.update_saga_state(self.saga_state)\n        \n        # Publish payment failed event\n        await self.coordinator.publish_event(PaymentFailed(\n            transaction_id=str(self.saga_state.transaction_id),\n            source_wallet_id=str(self.saga_state.source_wallet_id),\n            destination_pod_id=str(self.saga_state.destination_pod_id),\n            amount=str(self.saga_state.amount),\n            currency=self.saga_state.currency,\n            error_message=self.saga_state.error_message,\n            failed_step=self.saga_state.failed_step\n        ))\n        \n        logger.info(f\"Compensation completed for transaction {self.saga_state.transaction_id}\")\n    \n    # Step implementations\n    \n    async def _step_validate_transaction(self) -> Dict[str, Any]:\n        \"\"\"Validate the transaction details.\"\"\"\n        logger.info(f\"Validating transaction {self.saga_state.transaction_id}\")\n        \n        # Validate amount is positive\n        if self.saga_state.amount <= 0:\n            raise PaymentSagaError(\"Transaction amount must be positive\")\n        \n        # Validate currency\n        valid_currencies = [\"USD\", \"EUR\", \"GBP\", \"CAD\", \"AUD\"]\n        if self.saga_state.currency not in valid_currencies:\n            raise PaymentSagaError(f\"Invalid currency: {self.saga_state.currency}\")\n        \n        return {\"validated\": True, \"timestamp\": datetime.utcnow().isoformat()}\n    \n    async def _compensate_validate_transaction(self):\n        \"\"\"Compensation for validate step - nothing to undo.\"\"\"\n        logger.info(f\"Compensating validate_transaction - no action needed\")\n    \n    async def _step_calculate_fees(self) -> Dict[str, Any]:\n        \"\"\"Calculate transaction fees via risk compliance service.\"\"\"\n        logger.info(f\"Calculating fees for transaction {self.saga_state.transaction_id}\")\n        \n        if not self._http_client:\n            self._http_client = httpx.AsyncClient(timeout=FEE_CALCULATION_TIMEOUT)\n        \n        request_payload = {\n            \"amount\": str(self.saga_state.amount),\n            \"currency\": self.saga_state.currency,\n            \"source_user_id\": self.saga_state.source_user_id,\n            \"destination_pod_id\": str(self.saga_state.destination_pod_id)\n        }\n        \n        try:\n            response = await self._http_client.post(\n                f\"{RISK_SERVICE_URL}{FEE_CALCULATION_ENDPOINT}\",\n                json=request_payload\n            )\n            response.raise_for_status()\n            \n            fee_data = response.json()\n            \n            # Update saga state with fee information\n            self.saga_state.set_fee_details(\n                fee=float(fee_data[\"fee\"]),\n                total_debit=float(fee_data[\"total_debit_amount\"]),\n                details=fee_data\n            )\n            \n            logger.info(\n                f\"Fee calculated: {fee_data['fee']} {self.saga_state.currency}, \"\n                f\"total debit: {fee_data['total_debit_amount']}\"\n            )\n            \n            return {\n                \"fee\": fee_data[\"fee\"],\n                \"total_debit_amount\": fee_data[\"total_debit_amount\"],\n                \"user_reputation_score\": fee_data[\"user_reputation_score\"],\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n            \n        except httpx.HTTPStatusError as e:\n            logger.error(f\"Fee calculation API error: {e.response.status_code} - {e.response.text}\")\n            raise PaymentSagaError(f\"Fee calculation failed: {e.response.text}\")\n        except httpx.RequestError as e:\n            logger.error(f\"Fee calculation request error: {str(e)}\")\n            raise PaymentSagaError(f\"Fee calculation service unavailable: {str(e)}\")\n    \n    async def _compensate_calculate_fees(self):\n        \"\"\"Compensation for calculate_fees step.\n        \n        While there's nothing to undo (fees are just calculated, not charged),\n        we log the compensation for audit purposes and pattern integrity.\n        \"\"\"\n        logger.info(\n            f\"Compensating calculate_fees for transaction {self.saga_state.transaction_id} - \"\n            f\"Fee calculation reversed (no action needed, fee was: {self.saga_state.transaction_fee})\"\n        )\n        # Clear fee data from saga state for clarity\n        self.saga_state.fee_calculation_details = {\n            **(self.saga_state.fee_calculation_details or {}),\n            \"compensated\": True,\n            \"compensation_timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _step_debit_source_wallet(self) -> Dict[str, Any]:\n        \"\"\"Debit the source wallet with total amount (including fee).\"\"\"\n        logger.info(f\"Debiting source wallet for transaction {self.saga_state.transaction_id}\")\n        \n        # Use total_debit_amount which includes the fee\n        debit_amount = self.saga_state.total_debit_amount or self.saga_state.amount\n        fee_amount = self.saga_state.transaction_fee or Decimal(\"0.00\")\n        \n        # Publish DebitWallet event with separate amount and fee fields\n        await self.coordinator.publish_event(DebitWallet(\n            transaction_id=str(self.saga_state.transaction_id),\n            wallet_id=str(self.saga_state.source_wallet_id),\n            amount=str(self.saga_state.amount),\n            fee=str(fee_amount),\n            total_debit_amount=str(debit_amount),\n            currency=self.saga_state.currency,\n            source_user_id=self.saga_state.source_user_id,\n            destination_pod_id=str(self.saga_state.destination_pod_id)\n        ))\n        \n        logger.info(\n            f\"DebitWallet event published: amount={self.saga_state.amount}, \"\n            f\"fee={fee_amount}, total={debit_amount}\"\n        )\n        \n        return {\n            \"debited\": True,\n            \"amount\": str(self.saga_state.amount),\n            \"fee\": str(fee_amount),\n            \"total_debit_amount\": str(debit_amount),\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _compensate_debit_source_wallet(self):\n        \"\"\"Compensation for debit step - credit back the debited amount.\"\"\"\n        logger.info(f\"Compensating debit_source_wallet for transaction {self.saga_state.transaction_id}\")\n        \n        # Credit back the full debited amount (including fee)\n        refund_amount = self.saga_state.total_debit_amount or self.saga_state.amount\n        \n        await self.coordinator.publish_event({\n            \"event_type\": \"CreditWallet\",\n            \"transaction_id\": str(self.saga_state.transaction_id),\n            \"wallet_id\": str(self.saga_state.source_wallet_id),\n            \"amount\": str(refund_amount),\n            \"currency\": self.saga_state.currency,\n            \"reason\": \"saga_compensation\"\n        })\n    \n    async def _step_credit_destination_pod(self) -> Dict[str, Any]:\n        \"\"\"Credit the destination pod with the principal amount.\"\"\"\n        logger.info(f\"Crediting destination pod for transaction {self.saga_state.transaction_id}\")\n        \n        # Credit only the principal amount (not the fee)\n        await self.coordinator.publish_event(CreditPod(\n            transaction_id=str(self.saga_state.transaction_id),\n            pod_id=str(self.saga_state.destination_pod_id),\n            amount=str(self.saga_state.amount),\n            currency=self.saga_state.currency,\n            source_wallet_id=str(self.saga_state.source_wallet_id)\n        ))\n        \n        return {\n            \"credited\": True,\n            \"amount\": str(self.saga_state.amount),\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _compensate_credit_destination_pod(self):\n        \"\"\"Compensation for credit step - debit back from pod.\"\"\"\n        logger.info(f\"Compensating credit_destination_pod for transaction {self.saga_state.transaction_id}\")\n        \n        await self.coordinator.publish_event({\n            \"event_type\": \"DebitPod\",\n            \"transaction_id\": str(self.saga_state.transaction_id),\n            \"pod_id\": str(self.saga_state.destination_pod_id),\n            \"amount\": str(self.saga_state.amount),\n            \"currency\": self.saga_state.currency,\n            \"reason\": \"saga_compensation\"\n        })\n    \n    async def _step_complete_transaction(self) -> Dict[str, Any]:\n        \"\"\"Complete the transaction and publish success event.\"\"\"\n        logger.info(f\"Completing transaction {self.saga_state.transaction_id}\")\n        \n        await self.coordinator.publish_event(PaymentCompleted(\n            transaction_id=str(self.saga_state.transaction_id),\n            source_wallet_id=str(self.saga_state.source_wallet_id),\n            destination_pod_id=str(self.saga_state.destination_pod_id),\n            amount=str(self.saga_state.amount),\n            fee=str(self.saga_state.transaction_fee or Decimal(\"0.00\")),\n            total_amount=str(self.saga_state.total_debit_amount or self.saga_state.amount),\n            currency=self.saga_state.currency\n        ))\n        \n        return {\n            \"completed\": True,\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n    \n    async def _compensate_complete_transaction(self):\n        \"\"\"Compensation for complete step - nothing to undo.\"\"\"\n        logger.info(f\"Compensating complete_transaction - no action needed\")\n",
            "crowdpay_connect/libs/shared_events/schemas.py": "\"\"\"Shared event schemas for inter-service communication.\"\"\"\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\nfrom datetime import datetime\nfrom enum import Enum\n\n\nclass EventType(str, Enum):\n    \"\"\"Enumeration of event types.\"\"\"\n    DEBIT_WALLET = \"DebitWallet\"\n    CREDIT_WALLET = \"CreditWallet\"\n    CREDIT_POD = \"CreditPod\"\n    DEBIT_POD = \"DebitPod\"\n    PAYMENT_COMPLETED = \"PaymentCompleted\"\n    PAYMENT_FAILED = \"PaymentFailed\"\n    USER_CREATED = \"UserCreated\"\n    USER_UPDATED = \"UserUpdated\"\n    POD_CREATED = \"PodCreated\"\n    POD_UPDATED = \"PodUpdated\"\n    KYC_COMPLETED = \"KycCompleted\"\n    RISK_ASSESSMENT_COMPLETED = \"RiskAssessmentCompleted\"\n\n\nclass BaseEvent(BaseModel):\n    \"\"\"Base class for all events.\"\"\"\n    event_type: str\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n    correlation_id: Optional[str] = None\n    \n    class Config:\n        json_encoders = {\n            datetime: lambda v: v.isoformat()\n        }\n\n\nclass DebitWallet(BaseEvent):\n    \"\"\"Event for debiting a wallet.\n    \n    This event now includes separate amount and fee fields for better\n    transparency and audit capabilities.\n    \"\"\"\n    event_type: str = EventType.DEBIT_WALLET.value\n    transaction_id: str\n    wallet_id: str\n    amount: str  # Principal amount\n    fee: str = \"0.00\"  # Transaction fee (NEW)\n    total_debit_amount: str  # Total to debit (amount + fee) (NEW)\n    currency: str\n    source_user_id: Optional[str] = None\n    destination_pod_id: Optional[str] = None\n    reason: Optional[str] = None\n\n\nclass CreditWallet(BaseEvent):\n    \"\"\"Event for crediting a wallet.\"\"\"\n    event_type: str = EventType.CREDIT_WALLET.value\n    transaction_id: str\n    wallet_id: str\n    amount: str\n    currency: str\n    source_pod_id: Optional[str] = None\n    reason: Optional[str] = None\n\n\nclass CreditPod(BaseEvent):\n    \"\"\"Event for crediting a pod.\"\"\"\n    event_type: str = EventType.CREDIT_POD.value\n    transaction_id: str\n    pod_id: str\n    amount: str\n    currency: str\n    source_wallet_id: Optional[str] = None\n\n\nclass DebitPod(BaseEvent):\n    \"\"\"Event for debiting a pod.\"\"\"\n    event_type: str = EventType.DEBIT_POD.value\n    transaction_id: str\n    pod_id: str\n    amount: str\n    currency: str\n    destination_wallet_id: Optional[str] = None\n    reason: Optional[str] = None\n\n\nclass PaymentCompleted(BaseEvent):\n    \"\"\"Event indicating a payment has been completed successfully.\"\"\"\n    event_type: str = EventType.PAYMENT_COMPLETED.value\n    transaction_id: str\n    source_wallet_id: str\n    destination_pod_id: str\n    amount: str  # Principal amount\n    fee: str = \"0.00\"  # Transaction fee (NEW)\n    total_amount: str  # Total debited (amount + fee) (NEW)\n    currency: str\n\n\nclass PaymentFailed(BaseEvent):\n    \"\"\"Event indicating a payment has failed.\"\"\"\n    event_type: str = EventType.PAYMENT_FAILED.value\n    transaction_id: str\n    source_wallet_id: str\n    destination_pod_id: str\n    amount: str\n    currency: str\n    error_message: Optional[str] = None\n    failed_step: Optional[str] = None\n\n\nclass UserCreated(BaseEvent):\n    \"\"\"Event indicating a new user has been created.\"\"\"\n    event_type: str = EventType.USER_CREATED.value\n    user_id: str\n    email: str\n    username: str\n\n\nclass UserUpdated(BaseEvent):\n    \"\"\"Event indicating a user has been updated.\"\"\"\n    event_type: str = EventType.USER_UPDATED.value\n    user_id: str\n    updated_fields: dict\n\n\nclass PodCreated(BaseEvent):\n    \"\"\"Event indicating a new pod has been created.\"\"\"\n    event_type: str = EventType.POD_CREATED.value\n    pod_id: str\n    name: str\n    owner_id: str\n    target_amount: Optional[str] = None\n    currency: str\n\n\nclass PodUpdated(BaseEvent):\n    \"\"\"Event indicating a pod has been updated.\"\"\"\n    event_type: str = EventType.POD_UPDATED.value\n    pod_id: str\n    updated_fields: dict\n\n\nclass KycCompleted(BaseEvent):\n    \"\"\"Event indicating KYC verification has been completed.\"\"\"\n    event_type: str = EventType.KYC_COMPLETED.value\n    user_id: str\n    verification_id: str\n    status: str  # approved, rejected, pending_review\n    verification_level: Optional[str] = None\n\n\nclass RiskAssessmentCompleted(BaseEvent):\n    \"\"\"Event indicating a risk assessment has been completed.\"\"\"\n    event_type: str = EventType.RISK_ASSESSMENT_COMPLETED.value\n    assessment_id: str\n    entity_type: str  # user, transaction, pod\n    entity_id: str\n    risk_score: float\n    risk_level: str  # low, medium, high, critical\n    factors: Optional[dict] = None\n\n\n# Event factory for deserializing events\nEVENT_TYPE_MAP = {\n    EventType.DEBIT_WALLET.value: DebitWallet,\n    EventType.CREDIT_WALLET.value: CreditWallet,\n    EventType.CREDIT_POD.value: CreditPod,\n    EventType.DEBIT_POD.value: DebitPod,\n    EventType.PAYMENT_COMPLETED.value: PaymentCompleted,\n    EventType.PAYMENT_FAILED.value: PaymentFailed,\n    EventType.USER_CREATED.value: UserCreated,\n    EventType.USER_UPDATED.value: UserUpdated,\n    EventType.POD_CREATED.value: PodCreated,\n    EventType.POD_UPDATED.value: PodUpdated,\n    EventType.KYC_COMPLETED.value: KycCompleted,\n    EventType.RISK_ASSESSMENT_COMPLETED.value: RiskAssessmentCompleted,\n}\n\n\ndef deserialize_event(event_data: dict) -> BaseEvent:\n    \"\"\"Deserialize event data into the appropriate event class.\n    \n    Args:\n        event_data: Dictionary containing event data\n        \n    Returns:\n        Deserialized event instance\n        \n    Raises:\n        ValueError: If event type is unknown\n    \"\"\"\n    event_type = event_data.get(\"event_type\")\n    if event_type not in EVENT_TYPE_MAP:\n        raise ValueError(f\"Unknown event type: {event_type}\")\n    \n    event_class = EVENT_TYPE_MAP[event_type]\n    return event_class(**event_data)\n",
            "crowdpay_connect/services/wallet_service/app/models/transaction_log.py": "\"\"\"Transaction log model for recording all wallet transactions.\"\"\"\nfrom sqlalchemy import Column, String, Enum, DateTime, Numeric, Text, Index\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom datetime import datetime\nimport enum\nimport uuid\n\nfrom app.db.base import Base\n\n\nclass TransactionType(enum.Enum):\n    \"\"\"Enumeration of transaction types.\"\"\"\n    DEBIT = \"debit\"\n    CREDIT = \"credit\"\n    TRANSFER = \"transfer\"\n    FEE = \"fee\"\n    REFUND = \"refund\"\n    ADJUSTMENT = \"adjustment\"\n\n\nclass TransactionStatus(enum.Enum):\n    \"\"\"Enumeration of transaction statuses.\"\"\"\n    PENDING = \"pending\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    REVERSED = \"reversed\"\n\n\nclass TransactionLog(Base):\n    \"\"\"Model for logging all wallet transactions.\n    \n    This provides an immutable audit trail of all financial movements.\n    \"\"\"\n    \n    __tablename__ = \"transaction_logs\"\n    \n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    transaction_id = Column(UUID(as_uuid=True), nullable=False, index=True)\n    \n    # Wallet information\n    wallet_id = Column(UUID(as_uuid=True), nullable=False, index=True)\n    user_id = Column(String(100), nullable=True, index=True)\n    \n    # Transaction details\n    transaction_type = Column(Enum(TransactionType), nullable=False)\n    status = Column(Enum(TransactionStatus), default=TransactionStatus.PENDING, nullable=False)\n    \n    # Amount fields - now with separate fee tracking\n    amount = Column(Numeric(precision=18, scale=2), nullable=False)  # Principal amount\n    fee = Column(Numeric(precision=18, scale=2), nullable=True, default=0)  # Transaction fee (NEW)\n    total_amount = Column(Numeric(precision=18, scale=2), nullable=True)  # Total (amount + fee) (NEW)\n    currency = Column(String(3), nullable=False)\n    \n    # Balance tracking\n    balance_before = Column(Numeric(precision=18, scale=2), nullable=True)\n    balance_after = Column(Numeric(precision=18, scale=2), nullable=True)\n    \n    # Reference information\n    reference_type = Column(String(50), nullable=True)  # pod, wallet, external\n    reference_id = Column(UUID(as_uuid=True), nullable=True)  # pod_id, wallet_id, etc.\n    \n    # Additional metadata\n    description = Column(Text, nullable=True)\n    metadata = Column(Text, nullable=True)  # JSON string for additional data\n    \n    # Timestamps\n    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)\n    completed_at = Column(DateTime, nullable=True)\n    \n    # Indexes for common queries\n    __table_args__ = (\n        Index('idx_transaction_log_wallet_created', 'wallet_id', 'created_at'),\n        Index('idx_transaction_log_user_created', 'user_id', 'created_at'),\n        Index('idx_transaction_log_type_status', 'transaction_type', 'status'),\n    )\n    \n    def __repr__(self):\n        return (\n            f\"<TransactionLog(id={self.id}, transaction_id={self.transaction_id}, \"\n            f\"type={self.transaction_type}, amount={self.amount}, fee={self.fee})>\"\n        )\n    \n    def to_dict(self):\n        \"\"\"Convert transaction log to dictionary.\"\"\"\n        return {\n            \"id\": str(self.id),\n            \"transaction_id\": str(self.transaction_id),\n            \"wallet_id\": str(self.wallet_id),\n            \"user_id\": self.user_id,\n            \"transaction_type\": self.transaction_type.value,\n            \"status\": self.status.value,\n            \"amount\": str(self.amount),\n            \"fee\": str(self.fee) if self.fee else \"0.00\",\n            \"total_amount\": str(self.total_amount) if self.total_amount else str(self.amount),\n            \"currency\": self.currency,\n            \"balance_before\": str(self.balance_before) if self.balance_before else None,\n            \"balance_after\": str(self.balance_after) if self.balance_after else None,\n            \"reference_type\": self.reference_type,\n            \"reference_id\": str(self.reference_id) if self.reference_id else None,\n            \"description\": self.description,\n            \"metadata\": self.metadata,\n            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n            \"updated_at\": self.updated_at.isoformat() if self.updated_at else None,\n            \"completed_at\": self.completed_at.isoformat() if self.completed_at else None\n        }\n    \n    @classmethod\n    def create_debit_log(\n        cls,\n        transaction_id: uuid.UUID,\n        wallet_id: uuid.UUID,\n        amount: float,\n        currency: str,\n        fee: float = 0.0,\n        user_id: str = None,\n        reference_type: str = None,\n        reference_id: uuid.UUID = None,\n        description: str = None,\n        balance_before: float = None,\n        balance_after: float = None\n    ) -> \"TransactionLog\":\n        \"\"\"Factory method to create a debit transaction log.\"\"\"\n        from decimal import Decimal\n        \n        amount_decimal = Decimal(str(amount))\n        fee_decimal = Decimal(str(fee))\n        total = amount_decimal + fee_decimal\n        \n        return cls(\n            transaction_id=transaction_id,\n            wallet_id=wallet_id,\n            user_id=user_id,\n            transaction_type=TransactionType.DEBIT,\n            status=TransactionStatus.PENDING,\n            amount=amount_decimal,\n            fee=fee_decimal,\n            total_amount=total,\n            currency=currency,\n            reference_type=reference_type,\n            reference_id=reference_id,\n            description=description,\n            balance_before=Decimal(str(balance_before)) if balance_before is not None else None,\n            balance_after=Decimal(str(balance_after)) if balance_after is not None else None\n        )\n    \n    @classmethod\n    def create_credit_log(\n        cls,\n        transaction_id: uuid.UUID,\n        wallet_id: uuid.UUID,\n        amount: float,\n        currency: str,\n        user_id: str = None,\n        reference_type: str = None,\n        reference_id: uuid.UUID = None,\n        description: str = None,\n        balance_before: float = None,\n        balance_after: float = None\n    ) -> \"TransactionLog\":\n        \"\"\"Factory method to create a credit transaction log.\"\"\"\n        from decimal import Decimal\n        \n        amount_decimal = Decimal(str(amount))\n        \n        return cls(\n            transaction_id=transaction_id,\n            wallet_id=wallet_id,\n            user_id=user_id,\n            transaction_type=TransactionType.CREDIT,\n            status=TransactionStatus.PENDING,\n            amount=amount_decimal,\n            fee=Decimal(\"0.00\"),\n            total_amount=amount_decimal,\n            currency=currency,\n            reference_type=reference_type,\n            reference_id=reference_id,\n            description=description,\n            balance_before=Decimal(str(balance_before)) if balance_before is not None else None,\n            balance_after=Decimal(str(balance_after)) if balance_after is not None else None\n        )\n",
            "crowdpay_connect/services/wallet_service/app/events/consumer.py": "\"\"\"Event consumer for wallet service.\"\"\"\nimport json\nimport logging\nfrom decimal import Decimal\nfrom typing import Optional\nfrom datetime import datetime\nimport uuid\n\nfrom kafka import KafkaConsumer\nfrom sqlalchemy.orm import Session\n\nfrom app.db.session import get_db_session\nfrom app.models.wallet import Wallet\nfrom app.models.transaction_log import TransactionLog, TransactionType, TransactionStatus\nfrom app.core.ledger import Ledger\nfrom libs.shared_events.schemas import DebitWallet, CreditWallet, deserialize_event\n\nlogger = logging.getLogger(__name__)\n\n# Kafka configuration\nKAFKA_BOOTSTRAP_SERVERS = \"kafka:9092\"\nWALLET_EVENTS_TOPIC = \"wallet-events\"\nCONSUMER_GROUP = \"wallet-service-consumer\"\n\n\nclass WalletEventConsumer:\n    \"\"\"Consumer for wallet-related events.\"\"\"\n    \n    def __init__(self, bootstrap_servers: str = KAFKA_BOOTSTRAP_SERVERS):\n        \"\"\"Initialize the wallet event consumer.\n        \n        Args:\n            bootstrap_servers: Kafka bootstrap servers\n        \"\"\"\n        self.bootstrap_servers = bootstrap_servers\n        self.consumer: Optional[KafkaConsumer] = None\n        self.ledger = Ledger()\n    \n    def start(self):\n        \"\"\"Start consuming events.\"\"\"\n        logger.info(\"Starting wallet event consumer...\")\n        \n        self.consumer = KafkaConsumer(\n            WALLET_EVENTS_TOPIC,\n            bootstrap_servers=self.bootstrap_servers,\n            group_id=CONSUMER_GROUP,\n            auto_offset_reset='earliest',\n            enable_auto_commit=True,\n            value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n        )\n        \n        logger.info(f\"Subscribed to topic: {WALLET_EVENTS_TOPIC}\")\n        \n        for message in self.consumer:\n            try:\n                self._process_message(message.value)\n            except Exception as e:\n                logger.error(f\"Error processing message: {str(e)}\")\n    \n    def stop(self):\n        \"\"\"Stop consuming events.\"\"\"\n        if self.consumer:\n            self.consumer.close()\n            logger.info(\"Wallet event consumer stopped\")\n    \n    def _process_message(self, message: dict):\n        \"\"\"Process an incoming message.\n        \n        Args:\n            message: The message payload\n        \"\"\"\n        event_type = message.get(\"event_type\")\n        logger.info(f\"Processing event: {event_type}\")\n        \n        if event_type == \"DebitWallet\":\n            self._handle_debit_wallet(message)\n        elif event_type == \"CreditWallet\":\n            self._handle_credit_wallet(message)\n        else:\n            logger.warning(f\"Unknown event type: {event_type}\")\n    \n    def _handle_debit_wallet(self, event_data: dict):\n        \"\"\"Handle DebitWallet event.\n        \n        This now processes the updated event schema with separate amount and fee fields.\n        \n        Args:\n            event_data: The event payload\n        \"\"\"\n        logger.info(f\"Handling DebitWallet event: {event_data.get('transaction_id')}\")\n        \n        try:\n            # Parse event data\n            transaction_id = uuid.UUID(event_data[\"transaction_id\"])\n            wallet_id = uuid.UUID(event_data[\"wallet_id\"])\n            amount = Decimal(event_data[\"amount\"])  # Principal amount\n            fee = Decimal(event_data.get(\"fee\", \"0.00\"))  # Transaction fee\n            total_debit = Decimal(event_data.get(\"total_debit_amount\", str(amount + fee)))\n            currency = event_data[\"currency\"]\n            source_user_id = event_data.get(\"source_user_id\")\n            destination_pod_id = event_data.get(\"destination_pod_id\")\n            \n            with get_db_session() as db:\n                # Get wallet\n                wallet = db.query(Wallet).filter(Wallet.id == wallet_id).first()\n                if not wallet:\n                    logger.error(f\"Wallet not found: {wallet_id}\")\n                    return\n                \n                balance_before = wallet.balance\n                \n                # Validate sufficient balance\n                if wallet.balance < total_debit:\n                    logger.error(\n                        f\"Insufficient balance for wallet {wallet_id}: \"\n                        f\"balance={wallet.balance}, required={total_debit}\"\n                    )\n                    self._create_failed_transaction_log(\n                        db, transaction_id, wallet_id, amount, fee, currency,\n                        source_user_id, destination_pod_id, \"Insufficient balance\"\n                    )\n                    return\n                \n                # Perform debit using ledger\n                self.ledger.debit(\n                    wallet=wallet,\n                    amount=total_debit,\n                    currency=currency\n                )\n                \n                balance_after = wallet.balance\n                \n                # Create transaction log with fee information\n                transaction_log = TransactionLog.create_debit_log(\n                    transaction_id=transaction_id,\n                    wallet_id=wallet_id,\n                    amount=float(amount),\n                    currency=currency,\n                    fee=float(fee),\n                    user_id=source_user_id,\n                    reference_type=\"pod\" if destination_pod_id else None,\n                    reference_id=uuid.UUID(destination_pod_id) if destination_pod_id else None,\n                    description=f\"Payment to pod {destination_pod_id}\" if destination_pod_id else \"Debit\",\n                    balance_before=float(balance_before),\n                    balance_after=float(balance_after)\n                )\n                transaction_log.status = TransactionStatus.COMPLETED\n                transaction_log.completed_at = datetime.utcnow()\n                \n                db.add(transaction_log)\n                db.commit()\n                \n                logger.info(\n                    f\"DebitWallet completed: transaction={transaction_id}, \"\n                    f\"amount={amount}, fee={fee}, total={total_debit}, \"\n                    f\"balance: {balance_before} -> {balance_after}\"\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error handling DebitWallet event: {str(e)}\")\n            raise\n    \n    def _handle_credit_wallet(self, event_data: dict):\n        \"\"\"Handle CreditWallet event.\n        \n        Args:\n            event_data: The event payload\n        \"\"\"\n        logger.info(f\"Handling CreditWallet event: {event_data.get('transaction_id')}\")\n        \n        try:\n            transaction_id = uuid.UUID(event_data[\"transaction_id\"])\n            wallet_id = uuid.UUID(event_data[\"wallet_id\"])\n            amount = Decimal(event_data[\"amount\"])\n            currency = event_data[\"currency\"]\n            source_pod_id = event_data.get(\"source_pod_id\")\n            reason = event_data.get(\"reason\")\n            \n            with get_db_session() as db:\n                # Get wallet\n                wallet = db.query(Wallet).filter(Wallet.id == wallet_id).first()\n                if not wallet:\n                    logger.error(f\"Wallet not found: {wallet_id}\")\n                    return\n                \n                balance_before = wallet.balance\n                \n                # Perform credit using ledger\n                self.ledger.credit(\n                    wallet=wallet,\n                    amount=amount,\n                    currency=currency\n                )\n                \n                balance_after = wallet.balance\n                \n                # Create transaction log\n                transaction_log = TransactionLog.create_credit_log(\n                    transaction_id=transaction_id,\n                    wallet_id=wallet_id,\n                    amount=float(amount),\n                    currency=currency,\n                    user_id=str(wallet.user_id) if wallet.user_id else None,\n                    reference_type=\"pod\" if source_pod_id else None,\n                    reference_id=uuid.UUID(source_pod_id) if source_pod_id else None,\n                    description=reason or f\"Credit from pod {source_pod_id}\" if source_pod_id else \"Credit\",\n                    balance_before=float(balance_before),\n                    balance_after=float(balance_after)\n                )\n                transaction_log.status = TransactionStatus.COMPLETED\n                transaction_log.completed_at = datetime.utcnow()\n                \n                db.add(transaction_log)\n                db.commit()\n                \n                logger.info(\n                    f\"CreditWallet completed: transaction={transaction_id}, \"\n                    f\"amount={amount}, balance: {balance_before} -> {balance_after}\"\n                )\n                \n        except Exception as e:\n            logger.error(f\"Error handling CreditWallet event: {str(e)}\")\n            raise\n    \n    def _create_failed_transaction_log(\n        self,\n        db: Session,\n        transaction_id: uuid.UUID,\n        wallet_id: uuid.UUID,\n        amount: Decimal,\n        fee: Decimal,\n        currency: str,\n        user_id: str,\n        destination_pod_id: str,\n        error_message: str\n    ):\n        \"\"\"Create a failed transaction log entry.\"\"\"\n        transaction_log = TransactionLog(\n            transaction_id=transaction_id,\n            wallet_id=wallet_id,\n            user_id=user_id,\n            transaction_type=TransactionType.DEBIT,\n            status=TransactionStatus.FAILED,\n            amount=amount,\n            fee=fee,\n            total_amount=amount + fee,\n            currency=currency,\n            reference_type=\"pod\" if destination_pod_id else None,\n            reference_id=uuid.UUID(destination_pod_id) if destination_pod_id else None,\n            description=f\"Failed: {error_message}\"\n        )\n        db.add(transaction_log)\n        db.commit()\n\n\ndef start_consumer():\n    \"\"\"Start the wallet event consumer.\"\"\"\n    consumer = WalletEventConsumer()\n    try:\n        consumer.start()\n    except KeyboardInterrupt:\n        consumer.stop()\n\n\nif __name__ == \"__main__\":\n    start_consumer()\n",
            "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py": "\"\"\"Integration tests for payment saga with fee calculation.\"\"\"\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\nfrom decimal import Decimal\nfrom datetime import datetime\nimport uuid\nimport httpx\n\nfrom app.sagas.payment_saga import PaymentSaga, PaymentSagaError, RISK_SERVICE_URL, FEE_CALCULATION_ENDPOINT\nfrom app.models.saga_state import SagaState, SagaStatus, SagaStepStatus\nfrom app.events.saga_coordinator import SagaCoordinator\n\n\nclass TestPaymentSagaFeeCalculation:\n    \"\"\"Test cases for fee calculation step in payment saga.\"\"\"\n    \n    @pytest.fixture\n    def mock_coordinator(self):\n        \"\"\"Create a mock saga coordinator.\"\"\"\n        coordinator = MagicMock(spec=SagaCoordinator)\n        coordinator.update_saga_state = AsyncMock()\n        coordinator.publish_event = AsyncMock()\n        return coordinator\n    \n    @pytest.fixture\n    def saga_state(self):\n        \"\"\"Create a test saga state.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"test-user-123\",\n            amount=Decimal(\"100.00\"),\n            currency=\"USD\",\n            status=SagaStatus.PENDING,\n            completed_steps=[]\n        )\n        return state\n    \n    @pytest.fixture\n    def fee_response(self):\n        \"\"\"Create a mock fee calculation response.\"\"\"\n        return {\n            \"fee\": \"1.50\",\n            \"total_debit_amount\": \"101.50\",\n            \"base_rate\": \"0.005\",\n            \"risk_premium\": \"0.02\",\n            \"user_reputation_score\": \"0.50\",\n            \"currency\": \"USD\"\n        }\n    \n    @pytest.mark.asyncio\n    async def test_fee_calculation_step_success(self, saga_state, mock_coordinator, fee_response):\n        \"\"\"Test successful fee calculation step.\"\"\"\n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        # Mock HTTP client response\n        mock_response = MagicMock()\n        mock_response.json.return_value = fee_response\n        mock_response.raise_for_status = MagicMock()\n        \n        with patch.object(httpx.AsyncClient, 'post', new_callable=AsyncMock) as mock_post:\n            mock_post.return_value = mock_response\n            \n            # Create HTTP client manually for the test\n            saga._http_client = httpx.AsyncClient()\n            saga._http_client.post = mock_post\n            \n            result = await saga._step_calculate_fees()\n            \n            # Verify API was called with correct payload\n            mock_post.assert_called_once()\n            call_args = mock_post.call_args\n            assert call_args[0][0] == f\"{RISK_SERVICE_URL}{FEE_CALCULATION_ENDPOINT}\"\n            \n            request_payload = call_args[1][\"json\"]\n            assert request_payload[\"amount\"] == \"100.00\"\n            assert request_payload[\"currency\"] == \"USD\"\n            assert request_payload[\"source_user_id\"] == \"test-user-123\"\n            \n            # Verify saga state was updated\n            assert saga_state.transaction_fee == Decimal(\"1.50\")\n            assert saga_state.total_debit_amount == Decimal(\"101.50\")\n            assert saga_state.fee_calculation_details == fee_response\n            \n            # Verify result\n            assert result[\"fee\"] == \"1.50\"\n            assert result[\"total_debit_amount\"] == \"101.50\"\n            assert result[\"user_reputation_score\"] == \"0.50\"\n    \n    @pytest.mark.asyncio\n    async def test_fee_calculation_step_api_error(self, saga_state, mock_coordinator):\n        \"\"\"Test fee calculation step with API error.\"\"\"\n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        # Mock HTTP client to raise error\n        mock_response = MagicMock()\n        mock_response.status_code = 500\n        mock_response.text = \"Internal Server Error\"\n        mock_response.raise_for_status.side_effect = httpx.HTTPStatusError(\n            \"Server Error\",\n            request=MagicMock(),\n            response=mock_response\n        )\n        \n        with patch.object(httpx.AsyncClient, 'post', new_callable=AsyncMock) as mock_post:\n            mock_post.return_value = mock_response\n            \n            saga._http_client = httpx.AsyncClient()\n            saga._http_client.post = mock_post\n            \n            with pytest.raises(PaymentSagaError) as exc_info:\n                await saga._step_calculate_fees()\n            \n            assert \"Fee calculation failed\" in str(exc_info.value)\n    \n    @pytest.mark.asyncio\n    async def test_fee_calculation_step_connection_error(self, saga_state, mock_coordinator):\n        \"\"\"Test fee calculation step with connection error.\"\"\"\n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        with patch.object(httpx.AsyncClient, 'post', new_callable=AsyncMock) as mock_post:\n            mock_post.side_effect = httpx.RequestError(\"Connection refused\")\n            \n            saga._http_client = httpx.AsyncClient()\n            saga._http_client.post = mock_post\n            \n            with pytest.raises(PaymentSagaError) as exc_info:\n                await saga._step_calculate_fees()\n            \n            assert \"Fee calculation service unavailable\" in str(exc_info.value)\n    \n    @pytest.mark.asyncio\n    async def test_compensate_fee_calculation(self, saga_state, mock_coordinator):\n        \"\"\"Test fee calculation compensation.\"\"\"\n        saga_state.transaction_fee = Decimal(\"1.50\")\n        saga_state.fee_calculation_details = {\"fee\": \"1.50\"}\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        await saga._compensate_calculate_fees()\n        \n        # Verify compensation was logged\n        assert saga_state.fee_calculation_details.get(\"compensated\") is True\n        assert \"compensation_timestamp\" in saga_state.fee_calculation_details\n    \n    @pytest.mark.asyncio\n    async def test_debit_wallet_uses_total_amount(self, saga_state, mock_coordinator, fee_response):\n        \"\"\"Test that debit wallet step uses total_debit_amount.\"\"\"\n        # Set up saga state with fee information\n        saga_state.transaction_fee = Decimal(\"1.50\")\n        saga_state.total_debit_amount = Decimal(\"101.50\")\n        saga_state.fee_calculation_details = fee_response\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        result = await saga._step_debit_source_wallet()\n        \n        # Verify event was published with correct amounts\n        mock_coordinator.publish_event.assert_called_once()\n        event = mock_coordinator.publish_event.call_args[0][0]\n        \n        assert event.amount == \"100.00\"  # Principal amount\n        assert event.fee == \"1.50\"  # Fee\n        assert event.total_debit_amount == \"101.50\"  # Total\n        \n        # Verify result\n        assert result[\"amount\"] == \"100.00\"\n        assert result[\"fee\"] == \"1.50\"\n        assert result[\"total_debit_amount\"] == \"101.50\"\n    \n    @pytest.mark.asyncio\n    async def test_debit_wallet_without_fee(self, saga_state, mock_coordinator):\n        \"\"\"Test debit wallet step when no fee is calculated (fallback).\"\"\"\n        # No fee information set\n        saga_state.transaction_fee = None\n        saga_state.total_debit_amount = None\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        result = await saga._step_debit_source_wallet()\n        \n        # Verify event was published with original amount\n        mock_coordinator.publish_event.assert_called_once()\n        event = mock_coordinator.publish_event.call_args[0][0]\n        \n        assert event.amount == \"100.00\"\n        assert event.fee == \"0.00\"  # Default fee\n        assert event.total_debit_amount == \"100.00\"  # Same as amount\n\n\nclass TestPaymentSagaFullFlow:\n    \"\"\"Integration tests for complete payment saga flow with fees.\"\"\"\n    \n    @pytest.fixture\n    def mock_coordinator(self):\n        \"\"\"Create a mock saga coordinator.\"\"\"\n        coordinator = MagicMock(spec=SagaCoordinator)\n        coordinator.update_saga_state = AsyncMock()\n        coordinator.publish_event = AsyncMock()\n        return coordinator\n    \n    @pytest.fixture\n    def saga_state(self):\n        \"\"\"Create a test saga state.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"test-user-456\",\n            amount=Decimal(\"500.00\"),\n            currency=\"USD\",\n            status=SagaStatus.PENDING,\n            completed_steps=[]\n        )\n        return state\n    \n    @pytest.mark.asyncio\n    async def test_saga_steps_order(self):\n        \"\"\"Test that saga steps are in correct order.\"\"\"\n        expected_steps = [\n            \"validate_transaction\",\n            \"calculate_fees\",\n            \"debit_source_wallet\",\n            \"credit_destination_pod\",\n            \"complete_transaction\"\n        ]\n        assert PaymentSaga.STEPS == expected_steps\n    \n    @pytest.mark.asyncio\n    async def test_saga_rollback_after_fee_calculation(self, saga_state, mock_coordinator):\n        \"\"\"Test saga rollback when failure occurs after fee calculation.\"\"\"\n        saga_state.completed_steps = [\"validate_transaction\", \"calculate_fees\"]\n        saga_state.transaction_fee = Decimal(\"5.00\")\n        saga_state.total_debit_amount = Decimal(\"505.00\")\n        saga_state.fee_calculation_details = {\"fee\": \"5.00\"}\n        saga_state.error_message = \"Debit failed\"\n        saga_state.failed_step = \"debit_source_wallet\"\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        await saga.compensate()\n        \n        # Verify compensation was called for completed steps in reverse order\n        assert saga_state.status == SagaStatus.ROLLED_BACK\n        assert saga_state.fee_calculation_details.get(\"compensated\") is True\n        \n        # Verify PaymentFailed event was published\n        payment_failed_call = None\n        for call in mock_coordinator.publish_event.call_args_list:\n            event = call[0][0]\n            if hasattr(event, 'event_type') and event.event_type == \"PaymentFailed\":\n                payment_failed_call = event\n                break\n        \n        assert payment_failed_call is not None\n        assert payment_failed_call.error_message == \"Debit failed\"\n    \n    @pytest.mark.asyncio\n    async def test_payment_completed_includes_fee(self, saga_state, mock_coordinator):\n        \"\"\"Test that PaymentCompleted event includes fee information.\"\"\"\n        saga_state.transaction_fee = Decimal(\"5.00\")\n        saga_state.total_debit_amount = Decimal(\"505.00\")\n        \n        saga = PaymentSaga(saga_state, mock_coordinator)\n        \n        result = await saga._step_complete_transaction()\n        \n        # Verify PaymentCompleted event\n        mock_coordinator.publish_event.assert_called_once()\n        event = mock_coordinator.publish_event.call_args[0][0]\n        \n        assert event.event_type == \"PaymentCompleted\"\n        assert event.amount == \"500.00\"\n        assert event.fee == \"5.00\"\n        assert event.total_amount == \"505.00\"\n\n\nclass TestSagaStateModel:\n    \"\"\"Tests for SagaState model fee-related fields.\"\"\"\n    \n    def test_saga_state_set_fee_details(self):\n        \"\"\"Test setting fee details on saga state.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"user-123\",\n            amount=Decimal(\"100.00\"),\n            currency=\"USD\"\n        )\n        \n        details = {\n            \"base_rate\": \"0.005\",\n            \"risk_premium\": \"0.02\",\n            \"user_reputation_score\": \"0.75\"\n        }\n        \n        state.set_fee_details(fee=2.25, total_debit=102.25, details=details)\n        \n        assert state.transaction_fee == Decimal(\"2.25\")\n        assert state.total_debit_amount == Decimal(\"102.25\")\n        assert state.fee_calculation_details == details\n    \n    def test_saga_state_to_dict_includes_fees(self):\n        \"\"\"Test that to_dict includes fee fields.\"\"\"\n        state = SagaState(\n            id=uuid.uuid4(),\n            transaction_id=uuid.uuid4(),\n            source_wallet_id=uuid.uuid4(),\n            destination_pod_id=uuid.uuid4(),\n            source_user_id=\"user-123\",\n            amount=Decimal(\"100.00\"),\n            currency=\"USD\",\n            transaction_fee=Decimal(\"1.50\"),\n            total_debit_amount=Decimal(\"101.50\"),\n            fee_calculation_details={\"test\": \"data\"}\n        )\n        \n        result = state.to_dict()\n        \n        assert result[\"transaction_fee\"] == \"1.50\"\n        assert result[\"total_debit_amount\"] == \"101.50\"\n        assert result[\"fee_calculation_details\"] == {\"test\": \"data\"}\n"
          },
          "generated_files": [
            "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py",
            "crowdpay_connect/services/risk_compliance_service/app/main.py",
            "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py",
            "crowdpay_connect/services/transaction_service/app/models/saga_state.py",
            "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py",
            "crowdpay_connect/libs/shared_events/schemas.py",
            "crowdpay_connect/services/wallet_service/app/models/transaction_log.py",
            "crowdpay_connect/services/wallet_service/app/events/consumer.py",
            "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8000565981531128,
                "dependency_traversal_accuracy": 0.7767769167267604,
                "cross_file_reasoning_depth": 0.34990740740740744,
                "system_thinking_score": 0.5215795896417639,
                "robustness_score": 0.3716772151898734,
                "comprehensiveness_score": 0.6759215893108299,
                "innovation_score": 0.39699367088607596,
                "solution_elegance_score": 0.7321632857358469
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.1000070747691391,
                "dependency_traversal_weighted": 0.09709711459084505,
                "cross_file_reasoning_weighted": 0.04373842592592593,
                "system_thinking_weighted": 0.06519744870522048,
                "robustness_weighted": 0.046459651898734175,
                "comprehensiveness_weighted": 0.08449019866385374,
                "innovation_weighted": 0.049624208860759494,
                "solution_elegance_weighted": 0.09152041071698086
              },
              "total_software_engineering_score": 0.5781345341314588
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.5676507949829102,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py",
                  "crowdpay_connect/services/risk_compliance_service/app/main.py",
                  "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py",
                  "crowdpay_connect/services/transaction_service/app/models/saga_state.py",
                  "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py",
                  "crowdpay_connect/libs/shared_events/schemas.py",
                  "crowdpay_connect/services/wallet_service/app/models/transaction_log.py",
                  "crowdpay_connect/services/wallet_service/app/events/consumer.py",
                  "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 9,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 9 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.34455686961600235,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.34455686961600235,
                "idc_weight": 0.2,
                "total_functional_score": 0.6489113739232005
              }
            },
            "code_quality_details": {
              "files_analyzed": 9,
              "quality_checks": {
                "crowdpay_connect/services/risk_compliance_service/app/api/v1/fees.py": {
                  "line_count": 138,
                  "non_empty_lines": 108,
                  "comment_lines": 8,
                  "comment_ratio": 0.07407407407407407,
                  "function_count": 3,
                  "class_count": 2,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/risk_compliance_service/app/main.py": {
                  "line_count": 52,
                  "non_empty_lines": 40,
                  "comment_lines": 3,
                  "comment_ratio": 0.075,
                  "function_count": 3,
                  "class_count": 0,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/risk_compliance_service/tests/test_fee_calculation.py": {
                  "line_count": 286,
                  "non_empty_lines": 220,
                  "comment_lines": 22,
                  "comment_ratio": 0.1,
                  "function_count": 18,
                  "class_count": 4,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/transaction_service/app/models/saga_state.py": {
                  "line_count": 114,
                  "non_empty_lines": 93,
                  "comment_lines": 6,
                  "comment_ratio": 0.06451612903225806,
                  "function_count": 4,
                  "class_count": 3,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/transaction_service/app/sagas/payment_saga.py": {
                  "line_count": 332,
                  "non_empty_lines": 266,
                  "comment_lines": 11,
                  "comment_ratio": 0.041353383458646614,
                  "function_count": 13,
                  "class_count": 2,
                  "import_count": 17,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/libs/shared_events/schemas.py": {
                  "line_count": 197,
                  "non_empty_lines": 158,
                  "comment_lines": 1,
                  "comment_ratio": 0.006329113924050633,
                  "function_count": 1,
                  "class_count": 20,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/wallet_service/app/models/transaction_log.py": {
                  "line_count": 182,
                  "non_empty_lines": 155,
                  "comment_lines": 8,
                  "comment_ratio": 0.05161290322580645,
                  "function_count": 4,
                  "class_count": 5,
                  "import_count": 14,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/wallet_service/app/events/consumer.py": {
                  "line_count": 267,
                  "non_empty_lines": 221,
                  "comment_lines": 9,
                  "comment_ratio": 0.04072398190045249,
                  "function_count": 8,
                  "class_count": 4,
                  "import_count": 24,
                  "quality_score": 0.7999999999999999
                },
                "crowdpay_connect/services/transaction_service/tests/test_payment_saga_fees.py": {
                  "line_count": 328,
                  "non_empty_lines": 261,
                  "comment_lines": 15,
                  "comment_ratio": 0.05747126436781609,
                  "function_count": 16,
                  "class_count": 5,
                  "import_count": 15,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7999999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8339285714285714,
                "multi_session_memory_retention": 0.8819444444444444
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4169642857142857,
                "multi_session_memory_retention_weighted": 0.4409722222222222
              },
              "total_longcontext_utilization_score": 0.8579365079365079
            }
          },
          "timestamp": "2026-01-14T21:29:40.723889"
        }
      }
    },
    "python_ml_nlp_easy_089_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_ml_nlp_easy_089_feature_implementation_expert_01",
          "scenario_title": "Implement Topic Modeling Strategy with Coherence-Based Evaluation and Visualization",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.48468632919184707,
          "functional_correctness_score": 0.37104195804195805,
          "code_quality_score": 0.7407692307692306,
          "longcontext_utilization_score": 0.8070471256684492,
          "total_score": 2.6702283890500866,
          "generation_time": 107.1990556716919,
          "code_files_generated": 13,
          "total_lines_generated": 1062,
          "parsing_success": true,
          "solution_code": {
            "lexilearn_lab/strategies/topic_modeling_strategy.py": "\"\"\"Topic Modeling Strategy using NMF.\"\"\"\n\nfrom typing import Any, Dict, Optional\nimport numpy as np\nfrom sklearn.decomposition import NMF\n\nfrom .base_strategy import BaseStrategy\nfrom ..components.feature_engineering import create_count_vectorizer_pipeline\nfrom ..visualization import plot_top_words_per_topic\n\n\nclass TopicModelingStrategy(BaseStrategy):\n    \"\"\"Strategy for topic modeling using Non-negative Matrix Factorization (NMF).\"\"\"\n    \n    def __init__(self, n_topics: int = 5, max_features: int = 1000, \n                 n_top_words: int = 10, random_state: int = 42):\n        \"\"\"Initialize the Topic Modeling Strategy.\n        \n        Args:\n            n_topics: Number of topics to extract.\n            max_features: Maximum number of features for vectorizer.\n            n_top_words: Number of top words to display per topic.\n            random_state: Random state for reproducibility.\n        \"\"\"\n        super().__init__()\n        self.n_topics = n_topics\n        self.max_features = max_features\n        self.n_top_words = n_top_words\n        self.random_state = random_state\n        self.vectorizer = None\n        self.feature_names = None\n        self.document_topic_matrix = None\n        \n    def _create_model(self) -> NMF:\n        \"\"\"Create and return an NMF model.\n        \n        Returns:\n            NMF model instance.\n        \"\"\"\n        return NMF(\n            n_components=self.n_topics,\n            random_state=self.random_state,\n            max_iter=200,\n            init='nndsvd'\n        )\n    \n    def _get_evaluation_metrics(self) -> Dict[str, float]:\n        \"\"\"Get evaluation metrics for the topic model.\n        \n        Returns:\n            Dictionary containing reconstruction error as coherence proxy.\n        \"\"\"\n        if self.model is None:\n            return {'reconstruction_error': float('inf')}\n        \n        return {\n            'reconstruction_error': self.model.reconstruction_err_\n        }\n    \n    def preprocess(self, documents: list) -> np.ndarray:\n        \"\"\"Preprocess documents using count vectorization.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Document-term matrix.\n        \"\"\"\n        self.vectorizer = create_count_vectorizer_pipeline(\n            max_features=self.max_features\n        )\n        document_term_matrix = self.vectorizer.fit_transform(documents)\n        self.feature_names = self.vectorizer.get_feature_names_out()\n        return document_term_matrix\n    \n    def train(self, documents: list) -> 'TopicModelingStrategy':\n        \"\"\"Train the topic model on the given documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        # Preprocess documents\n        document_term_matrix = self.preprocess(documents)\n        \n        # Create and fit the model\n        self.model = self._create_model()\n        self.document_topic_matrix = self.model.fit_transform(document_term_matrix)\n        \n        return self\n    \n    def predict(self, documents: list) -> np.ndarray:\n        \"\"\"Predict topic distributions for new documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Document-topic matrix.\n        \"\"\"\n        if self.model is None or self.vectorizer is None:\n            raise ValueError(\"Model must be trained before prediction.\")\n        \n        document_term_matrix = self.vectorizer.transform(documents)\n        return self.model.transform(document_term_matrix)\n    \n    def evaluate(self, documents: Optional[list] = None, \n                 output_path: str = 'topic_visualization.png') -> Dict[str, Any]:\n        \"\"\"Evaluate the topic model and generate visualization.\n        \n        Args:\n            documents: Optional list of documents (not used for NMF evaluation).\n            output_path: Path to save the visualization.\n            \n        Returns:\n            Dictionary containing evaluation metrics and topic information.\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"Model must be trained before evaluation.\")\n        \n        # Get evaluation metrics\n        metrics = self._get_evaluation_metrics()\n        \n        # Generate visualization\n        plot_top_words_per_topic(\n            model=self.model,\n            feature_names=self.feature_names,\n            n_top_words=self.n_top_words,\n            output_path=output_path\n        )\n        \n        # Get top words for each topic\n        topics = self.get_topics()\n        \n        return {\n            'metrics': metrics,\n            'topics': topics,\n            'visualization_path': output_path\n        }\n    \n    def get_topics(self) -> Dict[int, list]:\n        \"\"\"Get the top words for each topic.\n        \n        Returns:\n            Dictionary mapping topic index to list of top words.\n        \"\"\"\n        if self.model is None or self.feature_names is None:\n            raise ValueError(\"Model must be trained first.\")\n        \n        topics = {}\n        for topic_idx, topic in enumerate(self.model.components_):\n            top_word_indices = topic.argsort()[:-self.n_top_words - 1:-1]\n            top_words = [self.feature_names[i] for i in top_word_indices]\n            topics[topic_idx] = top_words\n        \n        return topics\n    \n    def get_document_topics(self) -> np.ndarray:\n        \"\"\"Get the topic distribution for each document.\n        \n        Returns:\n            Document-topic matrix.\n        \"\"\"\n        if self.document_topic_matrix is None:\n            raise ValueError(\"Model must be trained first.\")\n        \n        return self.document_topic_matrix\n    \n    def get_dominant_topic(self, documents: Optional[list] = None) -> np.ndarray:\n        \"\"\"Get the dominant topic for each document.\n        \n        Args:\n            documents: Optional list of new documents. If None, uses training documents.\n            \n        Returns:\n            Array of dominant topic indices.\n        \"\"\"\n        if documents is not None:\n            topic_matrix = self.predict(documents)\n        else:\n            if self.document_topic_matrix is None:\n                raise ValueError(\"Model must be trained first.\")\n            topic_matrix = self.document_topic_matrix\n        \n        return np.argmax(topic_matrix, axis=1)\n",
            "lexilearn_lab/components/feature_engineering.py": "\"\"\"Feature engineering components for text processing.\"\"\"\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom typing import Optional\n\n\ndef create_tfidf_pipeline(max_features: int = 5000, \n                          ngram_range: tuple = (1, 2),\n                          min_df: int = 2,\n                          max_df: float = 0.95) -> TfidfVectorizer:\n    \"\"\"Create a TF-IDF vectorizer pipeline.\n    \n    Args:\n        max_features: Maximum number of features.\n        ngram_range: Range of n-grams to extract.\n        min_df: Minimum document frequency.\n        max_df: Maximum document frequency.\n        \n    Returns:\n        Configured TfidfVectorizer.\n    \"\"\"\n    return TfidfVectorizer(\n        max_features=max_features,\n        ngram_range=ngram_range,\n        min_df=min_df,\n        max_df=max_df,\n        stop_words='english',\n        lowercase=True,\n        strip_accents='unicode'\n    )\n\n\ndef create_count_vectorizer_pipeline(max_features: int = 1000,\n                                     ngram_range: tuple = (1, 1),\n                                     min_df: int = 2,\n                                     max_df: float = 0.95,\n                                     stop_words: Optional[str] = 'english') -> CountVectorizer:\n    \"\"\"Create a Count vectorizer pipeline suitable for topic modeling.\n    \n    Count vectorization is preferred for topic modeling algorithms like NMF\n    as they work better with raw term frequencies rather than TF-IDF weights.\n    \n    Args:\n        max_features: Maximum number of features to extract.\n        ngram_range: Range of n-grams to extract (default unigrams only).\n        min_df: Minimum document frequency for a term to be included.\n        max_df: Maximum document frequency for a term to be included.\n        stop_words: Stop words to remove (default 'english').\n        \n    Returns:\n        Configured CountVectorizer.\n    \"\"\"\n    return CountVectorizer(\n        max_features=max_features,\n        ngram_range=ngram_range,\n        min_df=min_df,\n        max_df=max_df,\n        stop_words=stop_words,\n        lowercase=True,\n        strip_accents='unicode'\n    )\n\n\ndef create_normalized_tfidf_pipeline(max_features: int = 5000,\n                                     ngram_range: tuple = (1, 2)) -> Pipeline:\n    \"\"\"Create a TF-IDF pipeline with L2 normalization.\n    \n    Args:\n        max_features: Maximum number of features.\n        ngram_range: Range of n-grams to extract.\n        \n    Returns:\n        Pipeline with TF-IDF and normalization.\n    \"\"\"\n    return Pipeline([\n        ('tfidf', TfidfVectorizer(\n            max_features=max_features,\n            ngram_range=ngram_range,\n            stop_words='english'\n        )),\n        ('normalizer', Normalizer(norm='l2'))\n    ])\n",
            "lexilearn_lab/visualization.py": "\"\"\"Visualization components for LexiLearn Lab.\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom typing import List, Optional, Any\nimport os\n\n\ndef plot_sentiment_distribution(sentiments: List[str], \n                                output_path: str = 'sentiment_distribution.png') -> None:\n    \"\"\"Plot the distribution of sentiments.\n    \n    Args:\n        sentiments: List of sentiment labels.\n        output_path: Path to save the plot.\n    \"\"\"\n    unique, counts = np.unique(sentiments, return_counts=True)\n    \n    plt.figure(figsize=(10, 6))\n    plt.bar(unique, counts, color=['red', 'gray', 'green'])\n    plt.xlabel('Sentiment')\n    plt.ylabel('Count')\n    plt.title('Sentiment Distribution')\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n\n\ndef plot_confusion_matrix(cm: np.ndarray, \n                          labels: List[str],\n                          output_path: str = 'confusion_matrix.png') -> None:\n    \"\"\"Plot a confusion matrix.\n    \n    Args:\n        cm: Confusion matrix array.\n        labels: Class labels.\n        output_path: Path to save the plot.\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    \n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=45)\n    plt.yticks(tick_marks, labels)\n    \n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n\n\ndef plot_top_words_per_topic(model: Any,\n                             feature_names: np.ndarray,\n                             n_top_words: int = 10,\n                             output_path: str = 'topic_visualization.png') -> None:\n    \"\"\"Plot the top words for each topic as horizontal bar charts.\n    \n    This function generates a visualization showing the most important words\n    for each topic identified by a topic model (e.g., NMF or LDA).\n    \n    Args:\n        model: Fitted topic model with components_ attribute (e.g., NMF, LDA).\n        feature_names: Array of feature names from the vectorizer.\n        n_top_words: Number of top words to display per topic.\n        output_path: Path to save the visualization.\n    \"\"\"\n    if not hasattr(model, 'components_'):\n        raise ValueError(\"Model must have 'components_' attribute (fitted NMF or LDA).\")\n    \n    n_topics = model.components_.shape[0]\n    \n    # Calculate grid dimensions\n    n_cols = min(3, n_topics)\n    n_rows = (n_topics + n_cols - 1) // n_cols\n    \n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n    \n    # Ensure axes is always a 2D array for consistent indexing\n    if n_topics == 1:\n        axes = np.array([[axes]])\n    elif n_rows == 1:\n        axes = axes.reshape(1, -1)\n    elif n_cols == 1:\n        axes = axes.reshape(-1, 1)\n    \n    # Color palette for topics\n    colors = plt.cm.viridis(np.linspace(0.2, 0.8, n_topics))\n    \n    for topic_idx, topic in enumerate(model.components_):\n        row = topic_idx // n_cols\n        col = topic_idx % n_cols\n        ax = axes[row, col]\n        \n        # Get top word indices and their weights\n        top_word_indices = topic.argsort()[:-n_top_words - 1:-1]\n        top_words = [feature_names[i] for i in top_word_indices]\n        top_weights = topic[top_word_indices]\n        \n        # Normalize weights for better visualization\n        if top_weights.max() > 0:\n            top_weights_normalized = top_weights / top_weights.max()\n        else:\n            top_weights_normalized = top_weights\n        \n        # Create horizontal bar chart\n        y_pos = np.arange(n_top_words)\n        ax.barh(y_pos, top_weights_normalized, color=colors[topic_idx], alpha=0.8)\n        ax.set_yticks(y_pos)\n        ax.set_yticklabels(top_words)\n        ax.invert_yaxis()  # Top word at the top\n        ax.set_xlabel('Relative Weight')\n        ax.set_title(f'Topic {topic_idx + 1}', fontsize=12, fontweight='bold')\n        ax.set_xlim(0, 1.1)\n        \n        # Add weight values on bars\n        for i, (weight, word) in enumerate(zip(top_weights_normalized, top_words)):\n            ax.text(weight + 0.02, i, f'{weight:.2f}', va='center', fontsize=8)\n    \n    # Hide empty subplots\n    for idx in range(n_topics, n_rows * n_cols):\n        row = idx // n_cols\n        col = idx % n_cols\n        axes[row, col].set_visible(False)\n    \n    plt.suptitle('Top Words per Topic', fontsize=14, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    \n    # Ensure directory exists\n    output_dir = os.path.dirname(output_path)\n    if output_dir and not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n    \n    print(f\"Topic visualization saved to: {output_path}\")\n\n\ndef plot_topic_distribution(document_topic_matrix: np.ndarray,\n                            output_path: str = 'topic_distribution.png') -> None:\n    \"\"\"Plot the distribution of topics across documents.\n    \n    Args:\n        document_topic_matrix: Matrix of document-topic weights.\n        output_path: Path to save the plot.\n    \"\"\"\n    n_topics = document_topic_matrix.shape[1]\n    topic_sums = document_topic_matrix.sum(axis=0)\n    topic_proportions = topic_sums / topic_sums.sum()\n    \n    plt.figure(figsize=(10, 6))\n    colors = plt.cm.viridis(np.linspace(0.2, 0.8, n_topics))\n    \n    bars = plt.bar(range(n_topics), topic_proportions, color=colors)\n    plt.xlabel('Topic')\n    plt.ylabel('Proportion')\n    plt.title('Topic Distribution Across Documents')\n    plt.xticks(range(n_topics), [f'Topic {i+1}' for i in range(n_topics)])\n    \n    # Add value labels on bars\n    for bar, prop in zip(bars, topic_proportions):\n        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                f'{prop:.2%}', ha='center', va='bottom', fontsize=9)\n    \n    plt.tight_layout()\n    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n    plt.close()\n",
            "lexilearn_lab/main.py": "\"\"\"Main entry point for LexiLearn Lab.\"\"\"\n\nimport argparse\nfrom typing import Dict, Type\n\nfrom .strategies.base_strategy import BaseStrategy\nfrom .strategies.sentiment_strategy import SentimentStrategy\nfrom .strategies.topic_modeling_strategy import TopicModelingStrategy\nfrom .components.data_ingestion import load_documents\n\n\n# Strategy mapping for different NLP tasks\nSTRATEGY_MAP: Dict[str, Type[BaseStrategy]] = {\n    'sentiment': SentimentStrategy,\n    'topic_modeling': TopicModelingStrategy,\n}\n\n\ndef get_strategy(task: str, **kwargs) -> BaseStrategy:\n    \"\"\"Get the appropriate strategy for the given task.\n    \n    Args:\n        task: The NLP task to perform.\n        **kwargs: Additional arguments for the strategy.\n        \n    Returns:\n        An instance of the appropriate strategy.\n        \n    Raises:\n        ValueError: If the task is not supported.\n    \"\"\"\n    if task not in STRATEGY_MAP:\n        available = ', '.join(STRATEGY_MAP.keys())\n        raise ValueError(f\"Unknown task: {task}. Available tasks: {available}\")\n    \n    strategy_class = STRATEGY_MAP[task]\n    return strategy_class(**kwargs)\n\n\ndef main():\n    \"\"\"Main function to run LexiLearn Lab.\"\"\"\n    parser = argparse.ArgumentParser(\n        description='LexiLearn Lab - NLP-driven insights for educators'\n    )\n    parser.add_argument(\n        '--task', \n        type=str, \n        choices=list(STRATEGY_MAP.keys()),\n        required=True,\n        help='The NLP task to perform'\n    )\n    parser.add_argument(\n        '--input', \n        type=str, \n        required=True,\n        help='Path to input documents'\n    )\n    parser.add_argument(\n        '--output', \n        type=str, \n        default='output',\n        help='Output directory for results'\n    )\n    parser.add_argument(\n        '--n-topics',\n        type=int,\n        default=5,\n        help='Number of topics for topic modeling (default: 5)'\n    )\n    parser.add_argument(\n        '--n-top-words',\n        type=int,\n        default=10,\n        help='Number of top words per topic (default: 10)'\n    )\n    \n    args = parser.parse_args()\n    \n    # Load documents\n    print(f\"Loading documents from {args.input}...\")\n    documents = load_documents(args.input)\n    print(f\"Loaded {len(documents)} documents.\")\n    \n    # Get the appropriate strategy\n    strategy_kwargs = {}\n    if args.task == 'topic_modeling':\n        strategy_kwargs['n_topics'] = args.n_topics\n        strategy_kwargs['n_top_words'] = args.n_top_words\n    \n    strategy = get_strategy(args.task, **strategy_kwargs)\n    \n    # Run the analysis\n    print(f\"Running {args.task} analysis...\")\n    strategy.train(documents)\n    \n    # Evaluate and visualize\n    output_path = f\"{args.output}/{args.task}_visualization.png\"\n    results = strategy.evaluate(output_path=output_path)\n    \n    print(\"\nResults:\")\n    print(f\"  Metrics: {results.get('metrics', {})}\")\n    \n    if args.task == 'topic_modeling' and 'topics' in results:\n        print(\"\nDiscovered Topics:\")\n        for topic_idx, words in results['topics'].items():\n            print(f\"  Topic {topic_idx + 1}: {', '.join(words[:5])}...\")\n    \n    print(f\"\nVisualization saved to: {results.get('visualization_path', output_path)}\")\n\n\nif __name__ == '__main__':\n    main()\n",
            "lexilearn_lab/strategies/__init__.py": "\"\"\"Strategies module for LexiLearn Lab.\"\"\"\n\nfrom .base_strategy import BaseStrategy\nfrom .sentiment_strategy import SentimentStrategy\nfrom .topic_modeling_strategy import TopicModelingStrategy\n\n__all__ = [\n    'BaseStrategy',\n    'SentimentStrategy',\n    'TopicModelingStrategy',\n]\n",
            "lexilearn_lab/strategies/base_strategy.py": "\"\"\"Base strategy class for NLP tasks.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\n\n\nclass BaseStrategy(ABC):\n    \"\"\"Abstract base class for NLP strategies.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the base strategy.\"\"\"\n        self.model = None\n        self.is_trained = False\n    \n    @abstractmethod\n    def _create_model(self) -> Any:\n        \"\"\"Create and return the model for this strategy.\n        \n        Returns:\n            The model instance.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def _get_evaluation_metrics(self) -> Dict[str, float]:\n        \"\"\"Get evaluation metrics for the trained model.\n        \n        Returns:\n            Dictionary of metric names to values.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def train(self, documents: List[str]) -> 'BaseStrategy':\n        \"\"\"Train the model on the given documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def predict(self, documents: List[str]) -> Any:\n        \"\"\"Make predictions on the given documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Predictions for the documents.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def evaluate(self, documents: Optional[List[str]] = None, \n                 output_path: str = 'visualization.png') -> Dict[str, Any]:\n        \"\"\"Evaluate the model and generate visualizations.\n        \n        Args:\n            documents: Optional list of documents for evaluation.\n            output_path: Path to save visualizations.\n            \n        Returns:\n            Dictionary containing evaluation results.\n        \"\"\"\n        pass\n",
            "lexilearn_lab/strategies/sentiment_strategy.py": "\"\"\"Sentiment analysis strategy.\"\"\"\n\nfrom typing import Any, Dict, List, Optional\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\nfrom .base_strategy import BaseStrategy\nfrom ..components.feature_engineering import create_tfidf_pipeline\nfrom ..visualization import plot_sentiment_distribution\n\n\nclass SentimentStrategy(BaseStrategy):\n    \"\"\"Strategy for sentiment analysis.\"\"\"\n    \n    def __init__(self, n_classes: int = 3):\n        \"\"\"Initialize the sentiment strategy.\n        \n        Args:\n            n_classes: Number of sentiment classes.\n        \"\"\"\n        super().__init__()\n        self.n_classes = n_classes\n        self.vectorizer = None\n        self.labels = None\n        self.cv_scores = None\n    \n    def _create_model(self) -> LogisticRegression:\n        \"\"\"Create a logistic regression model for sentiment.\n        \n        Returns:\n            LogisticRegression model.\n        \"\"\"\n        return LogisticRegression(\n            max_iter=1000,\n            multi_class='multinomial',\n            random_state=42\n        )\n    \n    def _get_evaluation_metrics(self) -> Dict[str, float]:\n        \"\"\"Get evaluation metrics.\n        \n        Returns:\n            Dictionary with accuracy metrics.\n        \"\"\"\n        if self.cv_scores is None:\n            return {'accuracy': 0.0}\n        \n        return {\n            'accuracy': float(np.mean(self.cv_scores)),\n            'std': float(np.std(self.cv_scores))\n        }\n    \n    def train(self, documents: List[str], labels: Optional[List[int]] = None) -> 'SentimentStrategy':\n        \"\"\"Train the sentiment model.\n        \n        Args:\n            documents: List of text documents.\n            labels: Optional sentiment labels.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.vectorizer = create_tfidf_pipeline()\n        X = self.vectorizer.fit_transform(documents)\n        \n        self.model = self._create_model()\n        \n        if labels is not None:\n            self.labels = labels\n            self.model.fit(X, labels)\n            self.cv_scores = cross_val_score(self.model, X, labels, cv=5)\n            self.is_trained = True\n        \n        return self\n    \n    def predict(self, documents: List[str]) -> np.ndarray:\n        \"\"\"Predict sentiments for documents.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Predicted sentiment labels.\n        \"\"\"\n        if not self.is_trained:\n            raise ValueError(\"Model must be trained before prediction.\")\n        \n        X = self.vectorizer.transform(documents)\n        return self.model.predict(X)\n    \n    def evaluate(self, documents: Optional[List[str]] = None,\n                 output_path: str = 'sentiment_visualization.png') -> Dict[str, Any]:\n        \"\"\"Evaluate the sentiment model.\n        \n        Args:\n            documents: Optional documents for evaluation.\n            output_path: Path to save visualization.\n            \n        Returns:\n            Evaluation results.\n        \"\"\"\n        metrics = self._get_evaluation_metrics()\n        \n        if documents is not None and self.is_trained:\n            predictions = self.predict(documents)\n            sentiment_labels = ['Negative', 'Neutral', 'Positive']\n            pred_labels = [sentiment_labels[p] for p in predictions]\n            plot_sentiment_distribution(pred_labels, output_path)\n        \n        return {\n            'metrics': metrics,\n            'visualization_path': output_path\n        }\n",
            "lexilearn_lab/components/__init__.py": "\"\"\"Components module for LexiLearn Lab.\"\"\"\n\nfrom .data_ingestion import load_documents, load_from_csv, load_from_directory\nfrom .feature_engineering import (\n    create_tfidf_pipeline, \n    create_count_vectorizer_pipeline,\n    create_normalized_tfidf_pipeline\n)\nfrom .evaluation import calculate_metrics, classification_report\nfrom .modeling import train_model, save_model, load_model\n\n__all__ = [\n    'load_documents',\n    'load_from_csv',\n    'load_from_directory',\n    'create_tfidf_pipeline',\n    'create_count_vectorizer_pipeline',\n    'create_normalized_tfidf_pipeline',\n    'calculate_metrics',\n    'classification_report',\n    'train_model',\n    'save_model',\n    'load_model',\n]\n",
            "lexilearn_lab/components/data_ingestion.py": "\"\"\"Data ingestion components for LexiLearn Lab.\"\"\"\n\nimport os\nimport csv\nfrom typing import List, Optional, Tuple\nimport glob\n\n\ndef load_documents(path: str) -> List[str]:\n    \"\"\"Load documents from a file or directory.\n    \n    Args:\n        path: Path to a file or directory.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    if os.path.isfile(path):\n        if path.endswith('.csv'):\n            return load_from_csv(path)\n        else:\n            return load_from_text_file(path)\n    elif os.path.isdir(path):\n        return load_from_directory(path)\n    else:\n        raise ValueError(f\"Path does not exist: {path}\")\n\n\ndef load_from_csv(filepath: str, text_column: str = 'text') -> List[str]:\n    \"\"\"Load documents from a CSV file.\n    \n    Args:\n        filepath: Path to the CSV file.\n        text_column: Name of the column containing text.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    documents = []\n    with open(filepath, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if text_column in row:\n                documents.append(row[text_column])\n    return documents\n\n\ndef load_from_directory(directory: str, extensions: List[str] = None) -> List[str]:\n    \"\"\"Load documents from all text files in a directory.\n    \n    Args:\n        directory: Path to the directory.\n        extensions: List of file extensions to include.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    if extensions is None:\n        extensions = ['.txt', '.md']\n    \n    documents = []\n    for ext in extensions:\n        pattern = os.path.join(directory, f'*{ext}')\n        for filepath in glob.glob(pattern):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                documents.append(f.read())\n    \n    return documents\n\n\ndef load_from_text_file(filepath: str) -> List[str]:\n    \"\"\"Load documents from a text file (one document per line).\n    \n    Args:\n        filepath: Path to the text file.\n        \n    Returns:\n        List of document strings.\n    \"\"\"\n    documents = []\n    with open(filepath, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if line:\n                documents.append(line)\n    return documents\n\n\ndef load_labeled_data(filepath: str, text_column: str = 'text',\n                      label_column: str = 'label') -> Tuple[List[str], List[int]]:\n    \"\"\"Load labeled documents from a CSV file.\n    \n    Args:\n        filepath: Path to the CSV file.\n        text_column: Name of the text column.\n        label_column: Name of the label column.\n        \n    Returns:\n        Tuple of (documents, labels).\n    \"\"\"\n    documents = []\n    labels = []\n    \n    with open(filepath, 'r', encoding='utf-8') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            if text_column in row and label_column in row:\n                documents.append(row[text_column])\n                labels.append(int(row[label_column]))\n    \n    return documents, labels\n",
            "lexilearn_lab/components/evaluation.py": "\"\"\"Evaluation components for LexiLearn Lab.\"\"\"\n\nfrom typing import Dict, List, Any\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report as sklearn_classification_report\n\n\ndef calculate_metrics(y_true: List[int], y_pred: List[int], \n                      average: str = 'weighted') -> Dict[str, float]:\n    \"\"\"Calculate classification metrics.\n    \n    Args:\n        y_true: True labels.\n        y_pred: Predicted labels.\n        average: Averaging method for multi-class.\n        \n    Returns:\n        Dictionary of metrics.\n    \"\"\"\n    return {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, average=average, zero_division=0),\n        'recall': recall_score(y_true, y_pred, average=average, zero_division=0),\n        'f1_score': f1_score(y_true, y_pred, average=average, zero_division=0)\n    }\n\n\ndef classification_report(y_true: List[int], y_pred: List[int],\n                          target_names: List[str] = None) -> str:\n    \"\"\"Generate a classification report.\n    \n    Args:\n        y_true: True labels.\n        y_pred: Predicted labels.\n        target_names: Names for each class.\n        \n    Returns:\n        Classification report string.\n    \"\"\"\n    return sklearn_classification_report(\n        y_true, y_pred, \n        target_names=target_names,\n        zero_division=0\n    )\n",
            "lexilearn_lab/components/modeling.py": "\"\"\"Modeling utilities for LexiLearn Lab.\"\"\"\n\nimport pickle\nfrom typing import Any, Optional\nimport os\n\n\ndef train_model(model: Any, X: Any, y: Optional[Any] = None) -> Any:\n    \"\"\"Train a model.\n    \n    Args:\n        model: The model to train.\n        X: Training features.\n        y: Training labels (optional for unsupervised).\n        \n    Returns:\n        Trained model.\n    \"\"\"\n    if y is not None:\n        model.fit(X, y)\n    else:\n        model.fit(X)\n    return model\n\n\ndef save_model(model: Any, filepath: str) -> None:\n    \"\"\"Save a model to disk.\n    \n    Args:\n        model: The model to save.\n        filepath: Path to save the model.\n    \"\"\"\n    directory = os.path.dirname(filepath)\n    if directory and not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    with open(filepath, 'wb') as f:\n        pickle.dump(model, f)\n\n\ndef load_model(filepath: str) -> Any:\n    \"\"\"Load a model from disk.\n    \n    Args:\n        filepath: Path to the saved model.\n        \n    Returns:\n        Loaded model.\n    \"\"\"\n    with open(filepath, 'rb') as f:\n        return pickle.load(f)\n",
            "lexilearn_lab/pipeline.py": "\"\"\"Pipeline utilities for LexiLearn Lab.\"\"\"\n\nfrom typing import Any, Dict, List, Optional\nfrom .strategies.base_strategy import BaseStrategy\n\n\nclass NLPPipeline:\n    \"\"\"Pipeline for running NLP tasks.\"\"\"\n    \n    def __init__(self, strategy: BaseStrategy):\n        \"\"\"Initialize the pipeline with a strategy.\n        \n        Args:\n            strategy: The NLP strategy to use.\n        \"\"\"\n        self.strategy = strategy\n        self.results = None\n    \n    def run(self, documents: List[str], \n            output_path: str = 'output.png',\n            **kwargs) -> Dict[str, Any]:\n        \"\"\"Run the pipeline on documents.\n        \n        Args:\n            documents: List of text documents.\n            output_path: Path for visualization output.\n            **kwargs: Additional arguments for training.\n            \n        Returns:\n            Pipeline results.\n        \"\"\"\n        # Train the model\n        self.strategy.train(documents, **kwargs)\n        \n        # Evaluate and visualize\n        self.results = self.strategy.evaluate(\n            documents=documents,\n            output_path=output_path\n        )\n        \n        return self.results\n    \n    def predict(self, documents: List[str]) -> Any:\n        \"\"\"Make predictions using the trained strategy.\n        \n        Args:\n            documents: List of text documents.\n            \n        Returns:\n            Predictions.\n        \"\"\"\n        return self.strategy.predict(documents)\n",
            "lexilearn_lab/__init__.py": "\"\"\"LexiLearn Lab - NLP-driven insights for educators.\"\"\"\n\nfrom .strategies import BaseStrategy, SentimentStrategy, TopicModelingStrategy\nfrom .pipeline import NLPPipeline\nfrom .main import get_strategy, STRATEGY_MAP\n\n__version__ = '1.0.0'\n\n__all__ = [\n    'BaseStrategy',\n    'SentimentStrategy',\n    'TopicModelingStrategy',\n    'NLPPipeline',\n    'get_strategy',\n    'STRATEGY_MAP',\n]\n"
          },
          "generated_files": [
            "lexilearn_lab/strategies/topic_modeling_strategy.py",
            "lexilearn_lab/components/feature_engineering.py",
            "lexilearn_lab/visualization.py",
            "lexilearn_lab/main.py",
            "lexilearn_lab/strategies/__init__.py",
            "lexilearn_lab/strategies/base_strategy.py",
            "lexilearn_lab/strategies/sentiment_strategy.py",
            "lexilearn_lab/components/__init__.py",
            "lexilearn_lab/components/data_ingestion.py",
            "lexilearn_lab/components/evaluation.py",
            "lexilearn_lab/components/modeling.py",
            "lexilearn_lab/pipeline.py",
            "lexilearn_lab/__init__.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8253197871311079,
                "dependency_traversal_accuracy": 0.7856228743536435,
                "cross_file_reasoning_depth": 0.288525641025641,
                "system_thinking_score": 0.27753208628084003,
                "robustness_score": 0.2523540489642185,
                "comprehensiveness_score": 0.514227199354318,
                "innovation_score": 0.30625,
                "solution_elegance_score": 0.6276589964250078
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.10316497339138848,
                "dependency_traversal_weighted": 0.09820285929420544,
                "cross_file_reasoning_weighted": 0.036065705128205124,
                "system_thinking_weighted": 0.034691510785105004,
                "robustness_weighted": 0.03154425612052731,
                "comprehensiveness_weighted": 0.06427839991928976,
                "innovation_weighted": 0.03828125,
                "solution_elegance_weighted": 0.07845737455312597
              },
              "total_software_engineering_score": 0.48468632919184707
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.8626515865325928,
                "errors": [
                  "  File \"lexilearn_lab/main.py\", line 100",
                  "    print(\"",
                  "          ^",
                  "SyntaxError: unterminated string literal (detected at line 100)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "lexilearn_lab/strategies/topic_modeling_strategy.py",
                  "lexilearn_lab/components/feature_engineering.py",
                  "lexilearn_lab/visualization.py",
                  "lexilearn_lab/main.py",
                  "lexilearn_lab/strategies/__init__.py",
                  "lexilearn_lab/strategies/base_strategy.py",
                  "lexilearn_lab/strategies/sentiment_strategy.py",
                  "lexilearn_lab/components/__init__.py",
                  "lexilearn_lab/components/data_ingestion.py",
                  "lexilearn_lab/components/evaluation.py",
                  "lexilearn_lab/components/modeling.py",
                  "lexilearn_lab/pipeline.py",
                  "lexilearn_lab/__init__.py"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 13,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 13 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.1552097902097902,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.1552097902097902,
                "idc_weight": 0.2,
                "total_functional_score": 0.37104195804195805
              }
            },
            "code_quality_details": {
              "files_analyzed": 13,
              "quality_checks": {
                "lexilearn_lab/strategies/topic_modeling_strategy.py": {
                  "line_count": 188,
                  "non_empty_lines": 146,
                  "comment_lines": 5,
                  "comment_ratio": 0.03424657534246575,
                  "function_count": 10,
                  "class_count": 1,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/components/feature_engineering.py": {
                  "line_count": 85,
                  "non_empty_lines": 70,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 3,
                  "class_count": 0,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/visualization.py": {
                  "line_count": 171,
                  "non_empty_lines": 134,
                  "comment_lines": 10,
                  "comment_ratio": 0.07462686567164178,
                  "function_count": 4,
                  "class_count": 0,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/main.py": {
                  "line_count": 116,
                  "non_empty_lines": 92,
                  "comment_lines": 5,
                  "comment_ratio": 0.05434782608695652,
                  "function_count": 2,
                  "class_count": 1,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/strategies/__init__.py": {
                  "line_count": 12,
                  "non_empty_lines": 9,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 6,
                  "quality_score": 0.5
                },
                "lexilearn_lab/strategies/base_strategy.py": {
                  "line_count": 70,
                  "non_empty_lines": 52,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 6,
                  "class_count": 3,
                  "import_count": 4,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/strategies/sentiment_strategy.py": {
                  "line_count": 115,
                  "non_empty_lines": 88,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 6,
                  "class_count": 1,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/components/__init__.py": {
                  "line_count": 25,
                  "non_empty_lines": 22,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 8,
                  "quality_score": 0.5
                },
                "lexilearn_lab/components/data_ingestion.py": {
                  "line_count": 112,
                  "non_empty_lines": 86,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 5,
                  "class_count": 0,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/components/evaluation.py": {
                  "line_count": 46,
                  "non_empty_lines": 36,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 2,
                  "class_count": 0,
                  "import_count": 7,
                  "quality_score": 0.6
                },
                "lexilearn_lab/components/modeling.py": {
                  "line_count": 52,
                  "non_empty_lines": 38,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 3,
                  "class_count": 0,
                  "import_count": 5,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/pipeline.py": {
                  "line_count": 53,
                  "non_empty_lines": 39,
                  "comment_lines": 2,
                  "comment_ratio": 0.05128205128205128,
                  "function_count": 3,
                  "class_count": 1,
                  "import_count": 4,
                  "quality_score": 0.7999999999999999
                },
                "lexilearn_lab/__init__.py": {
                  "line_count": 17,
                  "non_empty_lines": 13,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 6,
                  "quality_score": 0.5
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7407692307692306,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8296022727272727,
                "multi_session_memory_retention": 0.7844919786096256
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.41480113636363636,
                "multi_session_memory_retention_weighted": 0.3922459893048128
              },
              "total_longcontext_utilization_score": 0.8070471256684492
            }
          },
          "timestamp": "2026-01-14T21:37:03.809216"
        }
      }
    },
    "python_game_engine_expert_032_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_game_engine_expert_032_feature_implementation_expert_01",
          "scenario_title": "Implement Server-Side NavMesh Pathfinding for AI Agents",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5126310018301251,
          "functional_correctness_score": 0.616018981018981,
          "code_quality_score": 0.7,
          "longcontext_utilization_score": 0.9338903743315508,
          "total_score": 3.116235662354497,
          "generation_time": 197.00688695907593,
          "code_files_generated": 7,
          "total_lines_generated": 1878,
          "parsing_success": true,
          "solution_code": {
            "ledgerquest/engine/pathfinding/__init__.py": "\"\"\"Pathfinding module for AI navigation.\"\"\"\n\nfrom ledgerquest.engine.pathfinding.navigator import Navigator\n\n__all__ = [\"Navigator\"]\n",
            "ledgerquest/engine/pathfinding/navigator.py": "\"\"\"Navigator service for NavMesh-based pathfinding using A* algorithm.\"\"\"\n\nimport heapq\nimport math\nfrom typing import Optional\n\n\nclass Navigator:\n    \"\"\"A navigation service that performs A* pathfinding on a NavMesh graph.\n    \n    The NavMesh is represented as an adjacency list where each node is a polygon\n    with a centroid position and connections to neighboring polygons.\n    \n    Expected navmesh_data format:\n    {\n        \"nodes\": {\n            \"node_id\": {\n                \"position\": (x, y),  # Centroid of the polygon\n                \"vertices\": [(x1, y1), (x2, y2), ...],  # Optional polygon vertices\n                \"neighbors\": [\"neighbor_id1\", \"neighbor_id2\", ...]\n            },\n            ...\n        }\n    }\n    \"\"\"\n    \n    def __init__(self, navmesh_data: Optional[dict] = None):\n        \"\"\"Initialize the Navigator with optional NavMesh data.\n        \n        Args:\n            navmesh_data: Dictionary containing the NavMesh graph structure.\n        \"\"\"\n        self._navmesh: dict = {}\n        self._nodes: dict = {}\n        if navmesh_data:\n            self.load_navmesh(navmesh_data)\n    \n    def load_navmesh(self, navmesh_data: dict) -> None:\n        \"\"\"Load a NavMesh graph from a dictionary representation.\n        \n        Args:\n            navmesh_data: Dictionary containing nodes with positions and neighbors.\n        \"\"\"\n        self._navmesh = navmesh_data\n        self._nodes = navmesh_data.get(\"nodes\", {})\n    \n    def _euclidean_distance(self, pos1: tuple, pos2: tuple) -> float:\n        \"\"\"Calculate Euclidean distance between two positions.\n        \n        Args:\n            pos1: First position as (x, y) tuple.\n            pos2: Second position as (x, y) tuple.\n            \n        Returns:\n            The Euclidean distance between the positions.\n        \"\"\"\n        dx = pos2[0] - pos1[0]\n        dy = pos2[1] - pos1[1]\n        return math.sqrt(dx * dx + dy * dy)\n    \n    def _point_in_polygon(self, point: tuple, vertices: list) -> bool:\n        \"\"\"Check if a point is inside a polygon using ray casting.\n        \n        Args:\n            point: The point to check as (x, y).\n            vertices: List of polygon vertices as [(x, y), ...].\n            \n        Returns:\n            True if point is inside the polygon, False otherwise.\n        \"\"\"\n        if not vertices or len(vertices) < 3:\n            return False\n            \n        x, y = point\n        n = len(vertices)\n        inside = False\n        \n        j = n - 1\n        for i in range(n):\n            xi, yi = vertices[i]\n            xj, yj = vertices[j]\n            \n            if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n                inside = not inside\n            j = i\n            \n        return inside\n    \n    def _find_containing_node(self, position: tuple) -> Optional[str]:\n        \"\"\"Find the NavMesh node that contains the given position.\n        \n        Args:\n            position: The position to locate as (x, y).\n            \n        Returns:\n            The node ID containing the position, or None if not found.\n        \"\"\"\n        closest_node = None\n        closest_distance = float('inf')\n        \n        for node_id, node_data in self._nodes.items():\n            node_pos = node_data.get(\"position\", (0, 0))\n            vertices = node_data.get(\"vertices\", [])\n            \n            # Check if position is inside this polygon\n            if vertices and self._point_in_polygon(position, vertices):\n                return node_id\n            \n            # Track closest node as fallback\n            distance = self._euclidean_distance(position, node_pos)\n            if distance < closest_distance:\n                closest_distance = distance\n                closest_node = node_id\n        \n        # Return closest node if no containing polygon found\n        return closest_node\n    \n    def _reconstruct_path(self, came_from: dict, current: str, \n                          start_pos: tuple, end_pos: tuple) -> list:\n        \"\"\"Reconstruct the path from A* search results.\n        \n        Args:\n            came_from: Dictionary mapping each node to its predecessor.\n            current: The end node ID.\n            start_pos: The original start position.\n            end_pos: The original end position.\n            \n        Returns:\n            List of waypoint positions from start to end.\n        \"\"\"\n        path_nodes = [current]\n        while current in came_from:\n            current = came_from[current]\n            path_nodes.append(current)\n        \n        path_nodes.reverse()\n        \n        # Convert node IDs to positions\n        waypoints = [start_pos]\n        for node_id in path_nodes:\n            if node_id in self._nodes:\n                waypoints.append(self._nodes[node_id][\"position\"])\n        waypoints.append(end_pos)\n        \n        return waypoints\n    \n    def find_path(self, start_pos: tuple, end_pos: tuple) -> list:\n        \"\"\"Find a path from start position to end position using A* algorithm.\n        \n        Args:\n            start_pos: Starting position as (x, y) tuple.\n            end_pos: Destination position as (x, y) tuple.\n            \n        Returns:\n            Ordered list of waypoint positions from start to end.\n            Returns empty list if no path is possible.\n        \"\"\"\n        if not self._nodes:\n            return []\n        \n        # Find the nodes containing start and end positions\n        start_node = self._find_containing_node(start_pos)\n        end_node = self._find_containing_node(end_pos)\n        \n        if start_node is None or end_node is None:\n            return []\n        \n        # If start and end are in the same node, return direct path\n        if start_node == end_node:\n            return [start_pos, end_pos]\n        \n        # A* algorithm\n        open_set = []\n        heapq.heappush(open_set, (0, start_node))\n        \n        came_from = {}\n        g_score = {start_node: 0}\n        f_score = {start_node: self._euclidean_distance(\n            self._nodes[start_node][\"position\"], \n            self._nodes[end_node][\"position\"]\n        )}\n        \n        open_set_hash = {start_node}\n        \n        while open_set:\n            _, current = heapq.heappop(open_set)\n            open_set_hash.discard(current)\n            \n            if current == end_node:\n                return self._reconstruct_path(came_from, current, start_pos, end_pos)\n            \n            current_data = self._nodes.get(current, {})\n            current_pos = current_data.get(\"position\", (0, 0))\n            neighbors = current_data.get(\"neighbors\", [])\n            \n            for neighbor in neighbors:\n                if neighbor not in self._nodes:\n                    continue\n                    \n                neighbor_pos = self._nodes[neighbor][\"position\"]\n                tentative_g = g_score[current] + self._euclidean_distance(\n                    current_pos, neighbor_pos\n                )\n                \n                if neighbor not in g_score or tentative_g < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g\n                    f_score[neighbor] = tentative_g + self._euclidean_distance(\n                        neighbor_pos, self._nodes[end_node][\"position\"]\n                    )\n                    \n                    if neighbor not in open_set_hash:\n                        heapq.heappush(open_set, (f_score[neighbor], neighbor))\n                        open_set_hash.add(neighbor)\n        \n        # No path found\n        return []\n    \n    def is_loaded(self) -> bool:\n        \"\"\"Check if a NavMesh is currently loaded.\n        \n        Returns:\n            True if a NavMesh is loaded, False otherwise.\n        \"\"\"\n        return len(self._nodes) > 0\n",
            "ledgerquest/engine/ai/nodes.py": "\"\"\"Behavior Tree node implementations for AI decision making.\"\"\"\n\nimport math\nfrom abc import ABC, abstractmethod\nfrom enum import Enum, auto\nfrom typing import TYPE_CHECKING, Any, Callable, List, Optional\n\nif TYPE_CHECKING:\n    from ledgerquest.engine.ai.blackboard import Blackboard\n    from ledgerquest.engine.ecs.registry import Registry\n    from ledgerquest.engine.pathfinding.navigator import Navigator\n\n\nclass NodeStatus(Enum):\n    \"\"\"Status returned by behavior tree nodes after execution.\"\"\"\n    SUCCESS = auto()\n    FAILURE = auto()\n    RUNNING = auto()\n\n\nclass Node(ABC):\n    \"\"\"Abstract base class for all behavior tree nodes.\"\"\"\n    \n    def __init__(self, name: str = \"\"):\n        \"\"\"Initialize the node.\n        \n        Args:\n            name: Optional name for the node for debugging purposes.\n        \"\"\"\n        self.name = name or self.__class__.__name__\n    \n    @abstractmethod\n    def tick(self, blackboard: \"Blackboard\", entity_id: str, \n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute the node's logic.\n        \n        Args:\n            blackboard: The AI's memory/state storage.\n            entity_id: The ID of the entity being controlled.\n            registry: The ECS registry for accessing components.\n            \n        Returns:\n            The status of the node after execution.\n        \"\"\"\n        pass\n    \n    def reset(self) -> None:\n        \"\"\"Reset the node's internal state.\"\"\"\n        pass\n\n\nclass Composite(Node):\n    \"\"\"Base class for nodes that have multiple children.\"\"\"\n    \n    def __init__(self, children: Optional[List[Node]] = None, name: str = \"\"):\n        \"\"\"Initialize the composite node.\n        \n        Args:\n            children: List of child nodes.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.children: List[Node] = children or []\n        self._current_child_index: int = 0\n    \n    def add_child(self, child: Node) -> None:\n        \"\"\"Add a child node.\n        \n        Args:\n            child: The node to add as a child.\n        \"\"\"\n        self.children.append(child)\n    \n    def reset(self) -> None:\n        \"\"\"Reset this node and all children.\"\"\"\n        self._current_child_index = 0\n        for child in self.children:\n            child.reset()\n\n\nclass Sequence(Composite):\n    \"\"\"Executes children in order until one fails or all succeed.\"\"\"\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute children sequentially.\n        \n        Returns SUCCESS if all children succeed, FAILURE if any fails,\n        RUNNING if a child is still running.\n        \"\"\"\n        while self._current_child_index < len(self.children):\n            child = self.children[self._current_child_index]\n            status = child.tick(blackboard, entity_id, registry)\n            \n            if status == NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            elif status == NodeStatus.FAILURE:\n                self.reset()\n                return NodeStatus.FAILURE\n            \n            self._current_child_index += 1\n        \n        self.reset()\n        return NodeStatus.SUCCESS\n\n\nclass Selector(Composite):\n    \"\"\"Executes children in order until one succeeds or all fail.\"\"\"\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute children until one succeeds.\n        \n        Returns SUCCESS if any child succeeds, FAILURE if all fail,\n        RUNNING if a child is still running.\n        \"\"\"\n        while self._current_child_index < len(self.children):\n            child = self.children[self._current_child_index]\n            status = child.tick(blackboard, entity_id, registry)\n            \n            if status == NodeStatus.RUNNING:\n                return NodeStatus.RUNNING\n            elif status == NodeStatus.SUCCESS:\n                self.reset()\n                return NodeStatus.SUCCESS\n            \n            self._current_child_index += 1\n        \n        self.reset()\n        return NodeStatus.FAILURE\n\n\nclass Decorator(Node):\n    \"\"\"Base class for nodes that modify a single child's behavior.\"\"\"\n    \n    def __init__(self, child: Optional[Node] = None, name: str = \"\"):\n        \"\"\"Initialize the decorator.\n        \n        Args:\n            child: The child node to decorate.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.child = child\n    \n    def reset(self) -> None:\n        \"\"\"Reset this node and its child.\"\"\"\n        if self.child:\n            self.child.reset()\n\n\nclass Inverter(Decorator):\n    \"\"\"Inverts the result of its child node.\"\"\"\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute child and invert SUCCESS/FAILURE.\"\"\"\n        if not self.child:\n            return NodeStatus.FAILURE\n        \n        status = self.child.tick(blackboard, entity_id, registry)\n        \n        if status == NodeStatus.SUCCESS:\n            return NodeStatus.FAILURE\n        elif status == NodeStatus.FAILURE:\n            return NodeStatus.SUCCESS\n        \n        return NodeStatus.RUNNING\n\n\nclass Repeater(Decorator):\n    \"\"\"Repeats its child a specified number of times.\"\"\"\n    \n    def __init__(self, child: Optional[Node] = None, times: int = 1, \n                 name: str = \"\"):\n        \"\"\"Initialize the repeater.\n        \n        Args:\n            child: The child node to repeat.\n            times: Number of times to repeat (-1 for infinite).\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(child, name)\n        self.times = times\n        self._count = 0\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute child repeatedly.\"\"\"\n        if not self.child:\n            return NodeStatus.FAILURE\n        \n        if self.times != -1 and self._count >= self.times:\n            self.reset()\n            return NodeStatus.SUCCESS\n        \n        status = self.child.tick(blackboard, entity_id, registry)\n        \n        if status == NodeStatus.SUCCESS or status == NodeStatus.FAILURE:\n            self._count += 1\n            self.child.reset()\n            \n            if self.times == -1:\n                return NodeStatus.RUNNING\n            elif self._count >= self.times:\n                self.reset()\n                return NodeStatus.SUCCESS\n            return NodeStatus.RUNNING\n        \n        return NodeStatus.RUNNING\n    \n    def reset(self) -> None:\n        \"\"\"Reset the repeater count.\"\"\"\n        super().reset()\n        self._count = 0\n\n\nclass Action(Node):\n    \"\"\"Base class for leaf nodes that perform actions.\"\"\"\n    pass\n\n\nclass Condition(Node):\n    \"\"\"Base class for leaf nodes that check conditions.\"\"\"\n    pass\n\n\nclass ConditionCheck(Condition):\n    \"\"\"A condition node that evaluates a callable.\"\"\"\n    \n    def __init__(self, condition: Callable[[\"Blackboard\", str, \"Registry\"], bool],\n                 name: str = \"\"):\n        \"\"\"Initialize the condition check.\n        \n        Args:\n            condition: A callable that returns True or False.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.condition = condition\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Evaluate the condition.\"\"\"\n        try:\n            result = self.condition(blackboard, entity_id, registry)\n            return NodeStatus.SUCCESS if result else NodeStatus.FAILURE\n        except Exception:\n            return NodeStatus.FAILURE\n\n\nclass ActionExecute(Action):\n    \"\"\"An action node that executes a callable.\"\"\"\n    \n    def __init__(self, action: Callable[[\"Blackboard\", str, \"Registry\"], NodeStatus],\n                 name: str = \"\"):\n        \"\"\"Initialize the action.\n        \n        Args:\n            action: A callable that returns a NodeStatus.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.action = action\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute the action.\"\"\"\n        try:\n            return self.action(blackboard, entity_id, registry)\n        except Exception:\n            return NodeStatus.FAILURE\n\n\nclass Wait(Action):\n    \"\"\"An action that waits for a specified number of ticks.\"\"\"\n    \n    def __init__(self, ticks: int = 1, name: str = \"\"):\n        \"\"\"Initialize the wait action.\n        \n        Args:\n            ticks: Number of ticks to wait.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.ticks = ticks\n        self._elapsed = 0\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Wait for the specified number of ticks.\"\"\"\n        self._elapsed += 1\n        if self._elapsed >= self.ticks:\n            self.reset()\n            return NodeStatus.SUCCESS\n        return NodeStatus.RUNNING\n    \n    def reset(self) -> None:\n        \"\"\"Reset the elapsed counter.\"\"\"\n        self._elapsed = 0\n\n\nclass SetBlackboardValue(Action):\n    \"\"\"An action that sets a value on the blackboard.\"\"\"\n    \n    def __init__(self, key: str, value: Any, name: str = \"\"):\n        \"\"\"Initialize the action.\n        \n        Args:\n            key: The blackboard key to set.\n            value: The value to set.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.key = key\n        self.value = value\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Set the value on the blackboard.\"\"\"\n        blackboard.set(self.key, self.value)\n        return NodeStatus.SUCCESS\n\n\nclass CheckBlackboardValue(Condition):\n    \"\"\"A condition that checks a blackboard value.\"\"\"\n    \n    def __init__(self, key: str, expected_value: Any = None, \n                 check_exists: bool = False, name: str = \"\"):\n        \"\"\"Initialize the condition.\n        \n        Args:\n            key: The blackboard key to check.\n            expected_value: The expected value (if not just checking existence).\n            check_exists: If True, only check if key exists.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name)\n        self.key = key\n        self.expected_value = expected_value\n        self.check_exists = check_exists\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Check the blackboard value.\"\"\"\n        if self.check_exists:\n            return NodeStatus.SUCCESS if blackboard.has(self.key) else NodeStatus.FAILURE\n        \n        value = blackboard.get(self.key)\n        if value == self.expected_value:\n            return NodeStatus.SUCCESS\n        return NodeStatus.FAILURE\n\n\nclass MoveTo(Action):\n    \"\"\"An action node that moves an entity to a target destination using pathfinding.\n    \n    This node retrieves a target destination from the Blackboard, uses the Navigator\n    service to calculate a path, and guides the entity along the waypoints by\n    modifying its VelocityComponent.\n    \n    Blackboard keys used:\n        - 'target_destination': tuple (x, y) - The destination to move to\n        - 'navigator': Navigator instance - The pathfinding service\n        - '_moveto_path': list - Internal storage for the calculated path\n        - '_moveto_waypoint_index': int - Current waypoint index\n    \"\"\"\n    \n    # Constants for movement\n    WAYPOINT_REACHED_THRESHOLD = 5.0  # Distance to consider waypoint reached\n    DEFAULT_MOVE_SPEED = 100.0  # Default movement speed\n    \n    def __init__(self, destination_key: str = \"target_destination\",\n                 speed: float = DEFAULT_MOVE_SPEED, name: str = \"\"):\n        \"\"\"Initialize the MoveTo action.\n        \n        Args:\n            destination_key: Blackboard key for the target destination.\n            speed: Movement speed for the entity.\n            name: Optional name for the node.\n        \"\"\"\n        super().__init__(name or \"MoveTo\")\n        self.destination_key = destination_key\n        self.speed = speed\n        self._path_key = \"_moveto_path\"\n        self._waypoint_index_key = \"_moveto_waypoint_index\"\n        self._initialized = False\n    \n    def _get_entity_position(self, entity_id: str, registry: \"Registry\") -> Optional[tuple]:\n        \"\"\"Get the current position of the entity.\n        \n        Args:\n            entity_id: The entity's ID.\n            registry: The ECS registry.\n            \n        Returns:\n            The entity's position as (x, y) or None if not found.\n        \"\"\"\n        try:\n            from ledgerquest.engine.physics.components import PositionComponent\n            position_comp = registry.get_component(entity_id, PositionComponent)\n            if position_comp:\n                return (position_comp.x, position_comp.y)\n        except Exception:\n            pass\n        return None\n    \n    def _set_entity_velocity(self, entity_id: str, registry: \"Registry\",\n                             direction: tuple, speed: float) -> bool:\n        \"\"\"Set the entity's velocity towards a direction.\n        \n        Args:\n            entity_id: The entity's ID.\n            registry: The ECS registry.\n            direction: Normalized direction vector (dx, dy).\n            speed: Movement speed.\n            \n        Returns:\n            True if velocity was set successfully, False otherwise.\n        \"\"\"\n        try:\n            from ledgerquest.engine.physics.components import VelocityComponent\n            velocity_comp = registry.get_component(entity_id, VelocityComponent)\n            if velocity_comp:\n                velocity_comp.vx = direction[0] * speed\n                velocity_comp.vy = direction[1] * speed\n                return True\n        except Exception:\n            pass\n        return False\n    \n    def _stop_entity(self, entity_id: str, registry: \"Registry\") -> None:\n        \"\"\"Stop the entity by setting velocity to zero.\n        \n        Args:\n            entity_id: The entity's ID.\n            registry: The ECS registry.\n        \"\"\"\n        self._set_entity_velocity(entity_id, registry, (0, 0), 0)\n    \n    def _calculate_distance(self, pos1: tuple, pos2: tuple) -> float:\n        \"\"\"Calculate distance between two positions.\n        \n        Args:\n            pos1: First position (x, y).\n            pos2: Second position (x, y).\n            \n        Returns:\n            Euclidean distance between positions.\n        \"\"\"\n        dx = pos2[0] - pos1[0]\n        dy = pos2[1] - pos1[1]\n        return math.sqrt(dx * dx + dy * dy)\n    \n    def _normalize_direction(self, pos1: tuple, pos2: tuple) -> tuple:\n        \"\"\"Calculate normalized direction from pos1 to pos2.\n        \n        Args:\n            pos1: Starting position (x, y).\n            pos2: Target position (x, y).\n            \n        Returns:\n            Normalized direction vector (dx, dy).\n        \"\"\"\n        dx = pos2[0] - pos1[0]\n        dy = pos2[1] - pos1[1]\n        distance = math.sqrt(dx * dx + dy * dy)\n        \n        if distance < 0.0001:\n            return (0.0, 0.0)\n        \n        return (dx / distance, dy / distance)\n    \n    def tick(self, blackboard: \"Blackboard\", entity_id: str,\n             registry: \"Registry\") -> NodeStatus:\n        \"\"\"Execute the MoveTo action.\n        \n        On first tick, retrieves destination and calculates path.\n        On subsequent ticks, moves entity towards next waypoint.\n        \n        Args:\n            blackboard: The AI's blackboard for state storage.\n            entity_id: The entity being controlled.\n            registry: The ECS registry.\n            \n        Returns:\n            RUNNING while moving, SUCCESS when destination reached,\n            FAILURE if no path found or missing components.\n        \"\"\"\n        # Get current entity position\n        current_pos = self._get_entity_position(entity_id, registry)\n        if current_pos is None:\n            return NodeStatus.FAILURE\n        \n        # Check if we need to initialize/calculate path\n        path = blackboard.get(self._path_key)\n        \n        if path is None:\n            # First tick - calculate path\n            destination = blackboard.get(self.destination_key)\n            if destination is None:\n                return NodeStatus.FAILURE\n            \n            # Get navigator from blackboard\n            navigator = blackboard.get(\"navigator\")\n            if navigator is None:\n                return NodeStatus.FAILURE\n            \n            # Calculate path\n            path = navigator.find_path(current_pos, destination)\n            \n            if not path:\n                # No path found\n                return NodeStatus.FAILURE\n            \n            # Store path and initialize waypoint index\n            blackboard.set(self._path_key, path)\n            blackboard.set(self._waypoint_index_key, 0)\n        \n        # Get current waypoint index\n        waypoint_index = blackboard.get(self._waypoint_index_key, 0)\n        \n        # Check if we've reached the end of the path\n        if waypoint_index >= len(path):\n            self._stop_entity(entity_id, registry)\n            self._cleanup_blackboard(blackboard)\n            return NodeStatus.SUCCESS\n        \n        # Get current target waypoint\n        target_waypoint = path[waypoint_index]\n        \n        # Check if we've reached the current waypoint\n        distance_to_waypoint = self._calculate_distance(current_pos, target_waypoint)\n        \n        if distance_to_waypoint <= self.WAYPOINT_REACHED_THRESHOLD:\n            # Move to next waypoint\n            waypoint_index += 1\n            blackboard.set(self._waypoint_index_key, waypoint_index)\n            \n            # Check if this was the last waypoint\n            if waypoint_index >= len(path):\n                self._stop_entity(entity_id, registry)\n                self._cleanup_blackboard(blackboard)\n                return NodeStatus.SUCCESS\n            \n            # Update target to next waypoint\n            target_waypoint = path[waypoint_index]\n        \n        # Move towards current waypoint\n        direction = self._normalize_direction(current_pos, target_waypoint)\n        self._set_entity_velocity(entity_id, registry, direction, self.speed)\n        \n        return NodeStatus.RUNNING\n    \n    def _cleanup_blackboard(self, blackboard: \"Blackboard\") -> None:\n        \"\"\"Clean up internal state from the blackboard.\n        \n        Args:\n            blackboard: The blackboard to clean up.\n        \"\"\"\n        blackboard.set(self._path_key, None)\n        blackboard.set(self._waypoint_index_key, None)\n    \n    def reset(self) -> None:\n        \"\"\"Reset the node's internal state.\"\"\"\n        self._initialized = False\n",
            "ledgerquest/services/game_loop/ai_updater.py": "\"\"\"AI Updater service for processing AI behavior trees in the game loop.\"\"\"\n\nfrom typing import TYPE_CHECKING, Dict, List, Optional, Set\n\nfrom ledgerquest.engine.ai.behavior_tree import BehaviorTree\nfrom ledgerquest.engine.ai.blackboard import Blackboard\nfrom ledgerquest.engine.pathfinding.navigator import Navigator\n\nif TYPE_CHECKING:\n    from ledgerquest.engine.ecs.registry import Registry\n\n\nclass AIUpdater:\n    \"\"\"Service responsible for updating AI entities each game tick.\n    \n    The AIUpdater processes all entities with AI components, executing their\n    behavior trees and managing their blackboards. It also provides shared\n    services like the Navigator for pathfinding.\n    \"\"\"\n    \n    def __init__(self, registry: Optional[\"Registry\"] = None,\n                 navmesh_data: Optional[dict] = None):\n        \"\"\"Initialize the AI Updater.\n        \n        Args:\n            registry: The ECS registry for accessing entity components.\n            navmesh_data: Optional NavMesh data for pathfinding.\n        \"\"\"\n        self._registry = registry\n        self._behavior_trees: Dict[str, BehaviorTree] = {}\n        self._blackboards: Dict[str, Blackboard] = {}\n        self._active_entities: Set[str] = set()\n        \n        # Initialize the Navigator service\n        self._navigator = Navigator(navmesh_data)\n    \n    @property\n    def navigator(self) -> Navigator:\n        \"\"\"Get the Navigator service instance.\n        \n        Returns:\n            The Navigator instance for pathfinding.\n        \"\"\"\n        return self._navigator\n    \n    def set_registry(self, registry: \"Registry\") -> None:\n        \"\"\"Set the ECS registry.\n        \n        Args:\n            registry: The ECS registry to use.\n        \"\"\"\n        self._registry = registry\n    \n    def load_navmesh(self, navmesh_data: dict) -> None:\n        \"\"\"Load a NavMesh for pathfinding.\n        \n        Args:\n            navmesh_data: The NavMesh data structure.\n        \"\"\"\n        self._navigator.load_navmesh(navmesh_data)\n    \n    def register_entity(self, entity_id: str, behavior_tree: BehaviorTree,\n                        blackboard: Optional[Blackboard] = None) -> None:\n        \"\"\"Register an entity with the AI system.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            behavior_tree: The behavior tree to control this entity.\n            blackboard: Optional pre-configured blackboard. Creates new if None.\n        \"\"\"\n        self._behavior_trees[entity_id] = behavior_tree\n        self._blackboards[entity_id] = blackboard or Blackboard()\n        self._active_entities.add(entity_id)\n        \n        # Inject navigator into the blackboard\n        self._blackboards[entity_id].set(\"navigator\", self._navigator)\n    \n    def unregister_entity(self, entity_id: str) -> None:\n        \"\"\"Unregister an entity from the AI system.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n        \"\"\"\n        self._behavior_trees.pop(entity_id, None)\n        self._blackboards.pop(entity_id, None)\n        self._active_entities.discard(entity_id)\n    \n    def get_blackboard(self, entity_id: str) -> Optional[Blackboard]:\n        \"\"\"Get the blackboard for an entity.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            \n        Returns:\n            The entity's blackboard or None if not registered.\n        \"\"\"\n        return self._blackboards.get(entity_id)\n    \n    def get_behavior_tree(self, entity_id: str) -> Optional[BehaviorTree]:\n        \"\"\"Get the behavior tree for an entity.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            \n        Returns:\n            The entity's behavior tree or None if not registered.\n        \"\"\"\n        return self._behavior_trees.get(entity_id)\n    \n    def set_entity_active(self, entity_id: str, active: bool) -> None:\n        \"\"\"Set whether an entity's AI is active.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            active: Whether the AI should be active.\n        \"\"\"\n        if entity_id in self._behavior_trees:\n            if active:\n                self._active_entities.add(entity_id)\n            else:\n                self._active_entities.discard(entity_id)\n    \n    def update(self, delta_time: float = 0.0) -> None:\n        \"\"\"Update all active AI entities.\n        \n        This method is called each game tick to process all registered\n        AI entities. It executes their behavior trees with access to\n        the Navigator service via the blackboard.\n        \n        Args:\n            delta_time: Time elapsed since last update in seconds.\n        \"\"\"\n        if self._registry is None:\n            return\n        \n        for entity_id in list(self._active_entities):\n            self._update_entity(entity_id, delta_time)\n    \n    def _update_entity(self, entity_id: str, delta_time: float) -> None:\n        \"\"\"Update a single AI entity.\n        \n        Args:\n            entity_id: The entity's unique identifier.\n            delta_time: Time elapsed since last update.\n        \"\"\"\n        behavior_tree = self._behavior_trees.get(entity_id)\n        blackboard = self._blackboards.get(entity_id)\n        \n        if behavior_tree is None or blackboard is None:\n            return\n        \n        # Ensure navigator is available in blackboard\n        if not blackboard.has(\"navigator\"):\n            blackboard.set(\"navigator\", self._navigator)\n        \n        # Store delta_time in blackboard for nodes that need it\n        blackboard.set(\"delta_time\", delta_time)\n        \n        # Execute the behavior tree\n        try:\n            behavior_tree.tick(blackboard, entity_id, self._registry)\n        except Exception as e:\n            # Log error but don't crash the game loop\n            # In production, this would use proper logging\n            pass\n    \n    def get_active_entity_count(self) -> int:\n        \"\"\"Get the number of active AI entities.\n        \n        Returns:\n            Count of active AI entities.\n        \"\"\"\n        return len(self._active_entities)\n    \n    def get_registered_entity_ids(self) -> List[str]:\n        \"\"\"Get all registered entity IDs.\n        \n        Returns:\n            List of registered entity IDs.\n        \"\"\"\n        return list(self._behavior_trees.keys())\n    \n    def clear(self) -> None:\n        \"\"\"Clear all registered entities and reset state.\"\"\"\n        self._behavior_trees.clear()\n        self._blackboards.clear()\n        self._active_entities.clear()\n",
            "tests/unit/engine/pathfinding/__init__.py": "\"\"\"Unit tests for pathfinding module.\"\"\"\n",
            "tests/unit/engine/pathfinding/test_navigator.py": "\"\"\"Unit tests for the Navigator pathfinding service.\"\"\"\n\nimport pytest\nimport math\n\nfrom ledgerquest.engine.pathfinding.navigator import Navigator\n\n\nclass TestNavigator:\n    \"\"\"Test suite for the Navigator class.\"\"\"\n    \n    @pytest.fixture\n    def simple_navmesh(self):\n        \"\"\"Create a simple NavMesh for testing.\n        \n        Layout:\n        [A] -- [B] -- [C]\n         |      |      |\n        [D] -- [E] -- [F]\n        \"\"\"\n        return {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-10, -10), (10, -10), (10, 10), (-10, 10)],\n                    \"neighbors\": [\"B\", \"D\"]\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"vertices\": [(40, -10), (60, -10), (60, 10), (40, 10)],\n                    \"neighbors\": [\"A\", \"C\", \"E\"]\n                },\n                \"C\": {\n                    \"position\": (100, 0),\n                    \"vertices\": [(90, -10), (110, -10), (110, 10), (90, 10)],\n                    \"neighbors\": [\"B\", \"F\"]\n                },\n                \"D\": {\n                    \"position\": (0, 50),\n                    \"vertices\": [(-10, 40), (10, 40), (10, 60), (-10, 60)],\n                    \"neighbors\": [\"A\", \"E\"]\n                },\n                \"E\": {\n                    \"position\": (50, 50),\n                    \"vertices\": [(40, 40), (60, 40), (60, 60), (40, 60)],\n                    \"neighbors\": [\"B\", \"D\", \"F\"]\n                },\n                \"F\": {\n                    \"position\": (100, 50),\n                    \"vertices\": [(90, 40), (110, 40), (110, 60), (90, 60)],\n                    \"neighbors\": [\"C\", \"E\"]\n                }\n            }\n        }\n    \n    @pytest.fixture\n    def disconnected_navmesh(self):\n        \"\"\"Create a NavMesh with disconnected regions.\"\"\"\n        return {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-10, -10), (10, -10), (10, 10), (-10, 10)],\n                    \"neighbors\": [\"B\"]\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"vertices\": [(40, -10), (60, -10), (60, 10), (40, 10)],\n                    \"neighbors\": [\"A\"]\n                },\n                # Disconnected region\n                \"X\": {\n                    \"position\": (200, 200),\n                    \"vertices\": [(190, 190), (210, 190), (210, 210), (190, 210)],\n                    \"neighbors\": [\"Y\"]\n                },\n                \"Y\": {\n                    \"position\": (250, 200),\n                    \"vertices\": [(240, 190), (260, 190), (260, 210), (240, 210)],\n                    \"neighbors\": [\"X\"]\n                }\n            }\n        }\n    \n    @pytest.fixture\n    def single_node_navmesh(self):\n        \"\"\"Create a NavMesh with a single node.\"\"\"\n        return {\n            \"nodes\": {\n                \"single\": {\n                    \"position\": (50, 50),\n                    \"vertices\": [(0, 0), (100, 0), (100, 100), (0, 100)],\n                    \"neighbors\": []\n                }\n            }\n        }\n    \n    def test_navigator_initialization_empty(self):\n        \"\"\"Test Navigator can be initialized without data.\"\"\"\n        navigator = Navigator()\n        assert navigator.is_loaded() is False\n    \n    def test_navigator_initialization_with_data(self, simple_navmesh):\n        \"\"\"Test Navigator initializes correctly with NavMesh data.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        assert navigator.is_loaded() is True\n    \n    def test_load_navmesh(self, simple_navmesh):\n        \"\"\"Test loading NavMesh after initialization.\"\"\"\n        navigator = Navigator()\n        assert navigator.is_loaded() is False\n        \n        navigator.load_navmesh(simple_navmesh)\n        assert navigator.is_loaded() is True\n    \n    def test_find_path_simple_valid(self, simple_navmesh):\n        \"\"\"Test finding a simple valid path.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Path from A to C (should go A -> B -> C)\n        start = (0, 0)\n        end = (100, 0)\n        \n        path = navigator.find_path(start, end)\n        \n        assert len(path) > 0\n        assert path[0] == start\n        assert path[-1] == end\n    \n    def test_find_path_diagonal(self, simple_navmesh):\n        \"\"\"Test finding a diagonal path.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Path from A to F (diagonal)\n        start = (0, 0)\n        end = (100, 50)\n        \n        path = navigator.find_path(start, end)\n        \n        assert len(path) > 0\n        assert path[0] == start\n        assert path[-1] == end\n    \n    def test_find_path_same_polygon(self, single_node_navmesh):\n        \"\"\"Test path when start and end are in the same polygon.\"\"\"\n        navigator = Navigator(single_node_navmesh)\n        \n        start = (25, 25)\n        end = (75, 75)\n        \n        path = navigator.find_path(start, end)\n        \n        # Should return direct path with just start and end\n        assert len(path) == 2\n        assert path[0] == start\n        assert path[1] == end\n    \n    def test_find_path_impossible_disconnected(self, disconnected_navmesh):\n        \"\"\"Test that impossible paths return empty list.\"\"\"\n        navigator = Navigator(disconnected_navmesh)\n        \n        # Try to path from region 1 to region 2 (disconnected)\n        start = (0, 0)  # Near node A\n        end = (200, 200)  # Near node X\n        \n        path = navigator.find_path(start, end)\n        \n        assert path == []\n    \n    def test_find_path_no_navmesh_loaded(self):\n        \"\"\"Test pathfinding with no NavMesh loaded.\"\"\"\n        navigator = Navigator()\n        \n        path = navigator.find_path((0, 0), (100, 100))\n        \n        assert path == []\n    \n    def test_find_path_empty_navmesh(self):\n        \"\"\"Test pathfinding with empty NavMesh.\"\"\"\n        navigator = Navigator({\"nodes\": {}})\n        \n        path = navigator.find_path((0, 0), (100, 100))\n        \n        assert path == []\n    \n    def test_find_path_returns_ordered_waypoints(self, simple_navmesh):\n        \"\"\"Test that returned path is properly ordered.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        start = (0, 0)\n        end = (100, 50)\n        \n        path = navigator.find_path(start, end)\n        \n        # Verify path is a list of tuples\n        assert isinstance(path, list)\n        for waypoint in path:\n            assert isinstance(waypoint, tuple)\n            assert len(waypoint) == 2\n    \n    def test_find_path_reverse_direction(self, simple_navmesh):\n        \"\"\"Test that pathfinding works in reverse direction.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Forward path\n        path_forward = navigator.find_path((0, 0), (100, 50))\n        # Reverse path\n        path_reverse = navigator.find_path((100, 50), (0, 0))\n        \n        assert len(path_forward) > 0\n        assert len(path_reverse) > 0\n        assert path_forward[0] == path_reverse[-1]\n        assert path_forward[-1] == path_reverse[0]\n    \n    def test_find_path_adjacent_nodes(self, simple_navmesh):\n        \"\"\"Test pathfinding between adjacent nodes.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # A and B are adjacent\n        start = (0, 0)\n        end = (50, 0)\n        \n        path = navigator.find_path(start, end)\n        \n        assert len(path) >= 2\n        assert path[0] == start\n        assert path[-1] == end\n    \n    def test_euclidean_distance_calculation(self):\n        \"\"\"Test internal distance calculation.\"\"\"\n        navigator = Navigator()\n        \n        # Test known distances\n        assert navigator._euclidean_distance((0, 0), (3, 4)) == 5.0\n        assert navigator._euclidean_distance((0, 0), (0, 0)) == 0.0\n        assert abs(navigator._euclidean_distance((0, 0), (1, 1)) - math.sqrt(2)) < 0.0001\n    \n    def test_point_in_polygon(self):\n        \"\"\"Test point-in-polygon detection.\"\"\"\n        navigator = Navigator()\n        \n        # Simple square polygon\n        square = [(0, 0), (10, 0), (10, 10), (0, 10)]\n        \n        # Point inside\n        assert navigator._point_in_polygon((5, 5), square) is True\n        \n        # Point outside\n        assert navigator._point_in_polygon((15, 5), square) is False\n        assert navigator._point_in_polygon((-5, 5), square) is False\n    \n    def test_find_containing_node(self, simple_navmesh):\n        \"\"\"Test finding the node containing a position.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Position inside node A\n        node = navigator._find_containing_node((0, 0))\n        assert node == \"A\"\n        \n        # Position inside node F\n        node = navigator._find_containing_node((100, 50))\n        assert node == \"F\"\n    \n    def test_path_optimality(self, simple_navmesh):\n        \"\"\"Test that A* finds reasonably optimal paths.\"\"\"\n        navigator = Navigator(simple_navmesh)\n        \n        # Path from A to F should not go through all nodes\n        path = navigator.find_path((0, 0), (100, 50))\n        \n        # A reasonable path should have limited waypoints\n        # Direct would be: start -> A -> B -> C -> F -> end or similar\n        # Should not visit all 6 nodes\n        assert len(path) <= 6  # start + max 4 intermediate + end\n\n\nclass TestNavigatorEdgeCases:\n    \"\"\"Test edge cases and error handling.\"\"\"\n    \n    def test_navmesh_with_invalid_neighbor_reference(self):\n        \"\"\"Test handling of invalid neighbor references.\"\"\"\n        navmesh = {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-10, -10), (10, -10), (10, 10), (-10, 10)],\n                    \"neighbors\": [\"B\", \"NONEXISTENT\"]  # Invalid reference\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"vertices\": [(40, -10), (60, -10), (60, 10), (40, 10)],\n                    \"neighbors\": [\"A\"]\n                }\n            }\n        }\n        \n        navigator = Navigator(navmesh)\n        \n        # Should still find path, ignoring invalid neighbor\n        path = navigator.find_path((0, 0), (50, 0))\n        assert len(path) > 0\n    \n    def test_navmesh_without_vertices(self):\n        \"\"\"Test NavMesh nodes without vertex data.\"\"\"\n        navmesh = {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"neighbors\": [\"B\"]\n                },\n                \"B\": {\n                    \"position\": (50, 0),\n                    \"neighbors\": [\"A\"]\n                }\n            }\n        }\n        \n        navigator = Navigator(navmesh)\n        \n        # Should fall back to closest node matching\n        path = navigator.find_path((0, 0), (50, 0))\n        assert len(path) > 0\n    \n    def test_same_start_and_end(self, ):\n        \"\"\"Test pathfinding when start equals end.\"\"\"\n        navmesh = {\n            \"nodes\": {\n                \"A\": {\n                    \"position\": (0, 0),\n                    \"vertices\": [(-50, -50), (50, -50), (50, 50), (-50, 50)],\n                    \"neighbors\": []\n                }\n            }\n        }\n        \n        navigator = Navigator(navmesh)\n        \n        path = navigator.find_path((0, 0), (0, 0))\n        \n        # Should return a valid path (start to end)\n        assert len(path) == 2\n        assert path[0] == (0, 0)\n        assert path[1] == (0, 0)\n",
            "tests/unit/engine/ai/test_behavior_tree.py": "\"\"\"Unit tests for the Behavior Tree system.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, MagicMock, patch\n\nfrom ledgerquest.engine.ai.behavior_tree import BehaviorTree\nfrom ledgerquest.engine.ai.blackboard import Blackboard\nfrom ledgerquest.engine.ai.nodes import (\n    NodeStatus,\n    Node,\n    Sequence,\n    Selector,\n    Inverter,\n    Repeater,\n    Action,\n    Condition,\n    ConditionCheck,\n    ActionExecute,\n    Wait,\n    SetBlackboardValue,\n    CheckBlackboardValue,\n    MoveTo,\n)\n\n\nclass TestNodeStatus:\n    \"\"\"Tests for NodeStatus enum.\"\"\"\n    \n    def test_status_values_exist(self):\n        \"\"\"Test that all required status values exist.\"\"\"\n        assert NodeStatus.SUCCESS is not None\n        assert NodeStatus.FAILURE is not None\n        assert NodeStatus.RUNNING is not None\n\n\nclass TestBlackboard:\n    \"\"\"Tests for the Blackboard class.\"\"\"\n    \n    def test_set_and_get(self):\n        \"\"\"Test setting and getting values.\"\"\"\n        bb = Blackboard()\n        bb.set(\"key\", \"value\")\n        assert bb.get(\"key\") == \"value\"\n    \n    def test_get_default(self):\n        \"\"\"Test getting with default value.\"\"\"\n        bb = Blackboard()\n        assert bb.get(\"nonexistent\", \"default\") == \"default\"\n    \n    def test_has(self):\n        \"\"\"Test checking key existence.\"\"\"\n        bb = Blackboard()\n        bb.set(\"exists\", True)\n        assert bb.has(\"exists\") is True\n        assert bb.has(\"nonexistent\") is False\n\n\nclass TestSequence:\n    \"\"\"Tests for the Sequence composite node.\"\"\"\n    \n    def test_all_success(self):\n        \"\"\"Test sequence returns SUCCESS when all children succeed.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.SUCCESS\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.SUCCESS\n        \n        sequence = Sequence([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n    \n    def test_failure_on_child_failure(self):\n        \"\"\"Test sequence returns FAILURE when a child fails.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.SUCCESS\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.FAILURE\n        \n        sequence = Sequence([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_running_on_child_running(self):\n        \"\"\"Test sequence returns RUNNING when a child is running.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.RUNNING\n        \n        sequence = Sequence([child1])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.RUNNING\n\n\nclass TestSelector:\n    \"\"\"Tests for the Selector composite node.\"\"\"\n    \n    def test_success_on_first_child_success(self):\n        \"\"\"Test selector returns SUCCESS when first child succeeds.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.SUCCESS\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.FAILURE\n        \n        selector = Selector([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = selector.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n        child2.tick.assert_not_called()\n    \n    def test_failure_when_all_fail(self):\n        \"\"\"Test selector returns FAILURE when all children fail.\"\"\"\n        child1 = Mock(spec=Node)\n        child1.tick.return_value = NodeStatus.FAILURE\n        child2 = Mock(spec=Node)\n        child2.tick.return_value = NodeStatus.FAILURE\n        \n        selector = Selector([child1, child2])\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = selector.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n\n\nclass TestInverter:\n    \"\"\"Tests for the Inverter decorator node.\"\"\"\n    \n    def test_inverts_success(self):\n        \"\"\"Test inverter converts SUCCESS to FAILURE.\"\"\"\n        child = Mock(spec=Node)\n        child.tick.return_value = NodeStatus.SUCCESS\n        \n        inverter = Inverter(child)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = inverter.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_inverts_failure(self):\n        \"\"\"Test inverter converts FAILURE to SUCCESS.\"\"\"\n        child = Mock(spec=Node)\n        child.tick.return_value = NodeStatus.FAILURE\n        \n        inverter = Inverter(child)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = inverter.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n    \n    def test_passes_running(self):\n        \"\"\"Test inverter passes through RUNNING.\"\"\"\n        child = Mock(spec=Node)\n        child.tick.return_value = NodeStatus.RUNNING\n        \n        inverter = Inverter(child)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = inverter.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.RUNNING\n\n\nclass TestWait:\n    \"\"\"Tests for the Wait action node.\"\"\"\n    \n    def test_returns_running_until_complete(self):\n        \"\"\"Test wait returns RUNNING until ticks complete.\"\"\"\n        wait = Wait(ticks=3)\n        bb = Blackboard()\n        registry = Mock()\n        \n        assert wait.tick(bb, \"entity1\", registry) == NodeStatus.RUNNING\n        assert wait.tick(bb, \"entity1\", registry) == NodeStatus.RUNNING\n        assert wait.tick(bb, \"entity1\", registry) == NodeStatus.SUCCESS\n\n\nclass TestSetBlackboardValue:\n    \"\"\"Tests for SetBlackboardValue action.\"\"\"\n    \n    def test_sets_value(self):\n        \"\"\"Test that value is set on blackboard.\"\"\"\n        action = SetBlackboardValue(\"test_key\", \"test_value\")\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = action.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n        assert bb.get(\"test_key\") == \"test_value\"\n\n\nclass TestCheckBlackboardValue:\n    \"\"\"Tests for CheckBlackboardValue condition.\"\"\"\n    \n    def test_check_exists_success(self):\n        \"\"\"Test checking key existence returns SUCCESS.\"\"\"\n        bb = Blackboard()\n        bb.set(\"exists\", True)\n        \n        condition = CheckBlackboardValue(\"exists\", check_exists=True)\n        registry = Mock()\n        \n        result = condition.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n    \n    def test_check_exists_failure(self):\n        \"\"\"Test checking missing key returns FAILURE.\"\"\"\n        bb = Blackboard()\n        \n        condition = CheckBlackboardValue(\"missing\", check_exists=True)\n        registry = Mock()\n        \n        result = condition.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_check_value_match(self):\n        \"\"\"Test checking value match returns SUCCESS.\"\"\"\n        bb = Blackboard()\n        bb.set(\"key\", \"expected\")\n        \n        condition = CheckBlackboardValue(\"key\", expected_value=\"expected\")\n        registry = Mock()\n        \n        result = condition.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n\n\nclass TestMoveTo:\n    \"\"\"Tests for the MoveTo action node.\"\"\"\n    \n    @pytest.fixture\n    def mock_registry(self):\n        \"\"\"Create a mock registry with position and velocity components.\"\"\"\n        registry = Mock()\n        \n        # Create mock position component\n        position_comp = Mock()\n        position_comp.x = 0\n        position_comp.y = 0\n        \n        # Create mock velocity component\n        velocity_comp = Mock()\n        velocity_comp.vx = 0\n        velocity_comp.vy = 0\n        \n        def get_component(entity_id, component_type):\n            if \"Position\" in str(component_type):\n                return position_comp\n            elif \"Velocity\" in str(component_type):\n                return velocity_comp\n            return None\n        \n        registry.get_component = Mock(side_effect=get_component)\n        registry._position_comp = position_comp\n        registry._velocity_comp = velocity_comp\n        \n        return registry\n    \n    @pytest.fixture\n    def mock_navigator(self):\n        \"\"\"Create a mock navigator.\"\"\"\n        navigator = Mock()\n        navigator.find_path.return_value = [(0, 0), (50, 0), (100, 0)]\n        return navigator\n    \n    def test_moveto_failure_no_destination(self, mock_registry):\n        \"\"\"Test MoveTo returns FAILURE when no destination set.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"navigator\", Mock())\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_moveto_failure_no_navigator(self, mock_registry):\n        \"\"\"Test MoveTo returns FAILURE when no navigator available.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 100))\n        # No navigator set\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.FAILURE\n    \n    def test_moveto_failure_no_path(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo returns FAILURE when no path found.\"\"\"\n        mock_navigator.find_path.return_value = []  # No path\n        \n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 100))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.FAILURE\n        mock_navigator.find_path.assert_called_once()\n    \n    def test_moveto_calculates_path_on_first_tick(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo calculates path on first tick.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        mock_navigator.find_path.assert_called_once_with((0, 0), (100, 0))\n        assert bb.get(\"_moveto_path\") is not None\n    \n    def test_moveto_returns_running_while_moving(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo returns RUNNING while entity is moving.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.RUNNING\n    \n    def test_moveto_stores_path_on_blackboard(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo stores calculated path on blackboard.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        moveto.tick(bb, \"entity1\", mock_registry)\n        \n        path = bb.get(\"_moveto_path\")\n        assert path is not None\n        assert len(path) == 3\n    \n    def test_moveto_sets_velocity_towards_waypoint(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo sets entity velocity towards current waypoint.\"\"\"\n        moveto = MoveTo(speed=100.0)\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        with patch('ledgerquest.engine.ai.nodes.MoveTo._set_entity_velocity') as mock_set_vel:\n            mock_set_vel.return_value = True\n            moveto.tick(bb, \"entity1\", mock_registry)\n            \n            # Should have called set_velocity\n            assert mock_set_vel.called\n    \n    def test_moveto_success_when_destination_reached(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo returns SUCCESS when destination is reached.\"\"\"\n        # Set position at the destination\n        mock_registry._position_comp.x = 100\n        mock_registry._position_comp.y = 0\n        \n        # Path that's already at the end\n        mock_navigator.find_path.return_value = [(100, 0), (100, 0)]\n        \n        moveto = MoveTo()\n        moveto.WAYPOINT_REACHED_THRESHOLD = 10.0\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        # First tick calculates path\n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        # Should reach destination quickly since we're already there\n        assert result == NodeStatus.SUCCESS\n    \n    def test_moveto_uses_custom_destination_key(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo can use custom blackboard key for destination.\"\"\"\n        moveto = MoveTo(destination_key=\"custom_dest\")\n        bb = Blackboard()\n        bb.set(\"custom_dest\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        mock_navigator.find_path.assert_called_once_with((0, 0), (100, 0))\n    \n    def test_moveto_reuses_path_on_subsequent_ticks(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo doesn't recalculate path on subsequent ticks.\"\"\"\n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        # First tick\n        moveto.tick(bb, \"entity1\", mock_registry)\n        # Second tick\n        moveto.tick(bb, \"entity1\", mock_registry)\n        # Third tick\n        moveto.tick(bb, \"entity1\", mock_registry)\n        \n        # Navigator should only be called once\n        assert mock_navigator.find_path.call_count == 1\n    \n    def test_moveto_advances_waypoints(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo advances through waypoints.\"\"\"\n        # Set position close to first waypoint\n        mock_registry._position_comp.x = 48\n        mock_registry._position_comp.y = 0\n        \n        moveto = MoveTo()\n        moveto.WAYPOINT_REACHED_THRESHOLD = 10.0\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        # First tick - calculates path, starts moving\n        moveto.tick(bb, \"entity1\", mock_registry)\n        \n        # Check waypoint index advances\n        waypoint_index = bb.get(\"_moveto_waypoint_index\")\n        assert waypoint_index is not None\n    \n    def test_moveto_cleans_up_on_success(self, mock_registry, mock_navigator):\n        \"\"\"Test MoveTo cleans up blackboard state on success.\"\"\"\n        # Position at destination\n        mock_registry._position_comp.x = 100\n        mock_registry._position_comp.y = 0\n        \n        mock_navigator.find_path.return_value = [(100, 0), (100, 0)]\n        \n        moveto = MoveTo()\n        moveto.WAYPOINT_REACHED_THRESHOLD = 10.0\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", mock_navigator)\n        \n        result = moveto.tick(bb, \"entity1\", mock_registry)\n        \n        assert result == NodeStatus.SUCCESS\n        assert bb.get(\"_moveto_path\") is None\n        assert bb.get(\"_moveto_waypoint_index\") is None\n    \n    def test_moveto_failure_no_position_component(self):\n        \"\"\"Test MoveTo returns FAILURE when entity has no position.\"\"\"\n        registry = Mock()\n        registry.get_component.return_value = None\n        \n        moveto = MoveTo()\n        bb = Blackboard()\n        bb.set(\"target_destination\", (100, 0))\n        bb.set(\"navigator\", Mock())\n        \n        result = moveto.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n\n\nclass TestBehaviorTree:\n    \"\"\"Tests for the BehaviorTree class.\"\"\"\n    \n    def test_tree_executes_root(self):\n        \"\"\"Test behavior tree executes its root node.\"\"\"\n        root = Mock(spec=Node)\n        root.tick.return_value = NodeStatus.SUCCESS\n        \n        tree = BehaviorTree(root)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = tree.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.SUCCESS\n        root.tick.assert_called_once_with(bb, \"entity1\", registry)\n    \n    def test_tree_without_root_returns_failure(self):\n        \"\"\"Test behavior tree without root returns FAILURE.\"\"\"\n        tree = BehaviorTree(None)\n        bb = Blackboard()\n        registry = Mock()\n        \n        result = tree.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.FAILURE\n\n\nclass TestMoveToIntegration:\n    \"\"\"Integration tests for MoveTo with other nodes.\"\"\"\n    \n    def test_moveto_in_sequence(self):\n        \"\"\"Test MoveTo works correctly in a Sequence.\"\"\"\n        # Create mock components\n        registry = Mock()\n        position_comp = Mock()\n        position_comp.x = 0\n        position_comp.y = 0\n        velocity_comp = Mock()\n        velocity_comp.vx = 0\n        velocity_comp.vy = 0\n        \n        def get_component(entity_id, component_type):\n            if \"Position\" in str(component_type):\n                return position_comp\n            elif \"Velocity\" in str(component_type):\n                return velocity_comp\n            return None\n        \n        registry.get_component = Mock(side_effect=get_component)\n        \n        # Create navigator mock\n        navigator = Mock()\n        navigator.find_path.return_value = [(0, 0), (50, 0), (100, 0)]\n        \n        # Create behavior tree\n        set_dest = SetBlackboardValue(\"target_destination\", (100, 0))\n        moveto = MoveTo()\n        sequence = Sequence([set_dest, moveto])\n        \n        bb = Blackboard()\n        bb.set(\"navigator\", navigator)\n        \n        # First tick - sets destination, starts moving\n        result = sequence.tick(bb, \"entity1\", registry)\n        \n        assert result == NodeStatus.RUNNING\n        assert bb.get(\"target_destination\") == (100, 0)\n"
          },
          "generated_files": [
            "ledgerquest/engine/pathfinding/__init__.py",
            "ledgerquest/engine/pathfinding/navigator.py",
            "ledgerquest/engine/ai/nodes.py",
            "ledgerquest/services/game_loop/ai_updater.py",
            "tests/unit/engine/pathfinding/__init__.py",
            "tests/unit/engine/pathfinding/test_navigator.py",
            "tests/unit/engine/ai/test_behavior_tree.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.6761128262699972,
                "dependency_traversal_accuracy": 0.7380960260069933,
                "cross_file_reasoning_depth": 0.17273809523809525,
                "system_thinking_score": 0.4987305539894339,
                "robustness_score": 0.43320600083344907,
                "comprehensiveness_score": 0.7075354910404223,
                "innovation_score": 0.24375000000000002,
                "solution_elegance_score": 0.6308790212626104
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.08451410328374966,
                "dependency_traversal_weighted": 0.09226200325087416,
                "cross_file_reasoning_weighted": 0.021592261904761906,
                "system_thinking_weighted": 0.062341319248679236,
                "robustness_weighted": 0.05415075010418113,
                "comprehensiveness_weighted": 0.0884419363800528,
                "innovation_weighted": 0.030468750000000003,
                "solution_elegance_weighted": 0.0788598776578263
              },
              "total_software_engineering_score": 0.5126310018301251
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.44942545890808105,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "ledgerquest/engine/pathfinding/__init__.py",
                  "ledgerquest/engine/pathfinding/navigator.py",
                  "ledgerquest/engine/ai/nodes.py",
                  "ledgerquest/services/game_loop/ai_updater.py",
                  "tests/unit/engine/pathfinding/__init__.py",
                  "tests/unit/engine/pathfinding/test_navigator.py",
                  "tests/unit/engine/ai/test_behavior_tree.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 7,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 6 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.18009490509490508,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.18009490509490508,
                "idc_weight": 0.2,
                "total_functional_score": 0.616018981018981
              }
            },
            "code_quality_details": {
              "files_analyzed": 7,
              "quality_checks": {
                "ledgerquest/engine/pathfinding/__init__.py": {
                  "line_count": 6,
                  "non_empty_lines": 3,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 2,
                  "quality_score": 0.5
                },
                "ledgerquest/engine/pathfinding/navigator.py": {
                  "line_count": 226,
                  "non_empty_lines": 174,
                  "comment_lines": 8,
                  "comment_ratio": 0.04597701149425287,
                  "function_count": 8,
                  "class_count": 1,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "ledgerquest/engine/ai/nodes.py": {
                  "line_count": 567,
                  "non_empty_lines": 435,
                  "comment_lines": 16,
                  "comment_ratio": 0.0367816091954023,
                  "function_count": 34,
                  "class_count": 21,
                  "import_count": 21,
                  "quality_score": 0.6
                },
                "ledgerquest/services/game_loop/ai_updater.py": {
                  "line_count": 188,
                  "non_empty_lines": 144,
                  "comment_lines": 7,
                  "comment_ratio": 0.04861111111111111,
                  "function_count": 14,
                  "class_count": 1,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "tests/unit/engine/pathfinding/__init__.py": {
                  "line_count": 2,
                  "non_empty_lines": 1,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.5
                },
                "tests/unit/engine/pathfinding/test_navigator.py": {
                  "line_count": 344,
                  "non_empty_lines": 274,
                  "comment_lines": 22,
                  "comment_ratio": 0.08029197080291971,
                  "function_count": 22,
                  "class_count": 2,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "tests/unit/engine/ai/test_behavior_tree.py": {
                  "line_count": 545,
                  "non_empty_lines": 399,
                  "comment_lines": 20,
                  "comment_ratio": 0.05012531328320802,
                  "function_count": 37,
                  "class_count": 11,
                  "import_count": 9,
                  "quality_score": 0.6
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.9522727272727272,
                "multi_session_memory_retention": 0.9155080213903742
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4761363636363636,
                "multi_session_memory_retention_weighted": 0.4577540106951871
              },
              "total_longcontext_utilization_score": 0.9338903743315508
            }
          },
          "timestamp": "2026-01-14T20:59:53.661651"
        }
      }
    },
    "python_system_monitoring_hard_097_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_system_monitoring_hard_097_feature_implementation_expert_01",
          "scenario_title": "Implement Canary Analysis Strategy for Safe Deployments",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5193994824059335,
          "functional_correctness_score": 0.40366150283478397,
          "code_quality_score": 0.7899999999999999,
          "longcontext_utilization_score": 0.848909099986686,
          "total_score": 2.8587457690573856,
          "generation_time": 222.95795273780823,
          "code_files_generated": 7,
          "total_lines_generated": 2167,
          "parsing_success": true,
          "solution_code": {
            "edupulse_insight_mesh/src/api_gateway/routes.py": "\"\"\"API Gateway routes for EduPulse Insight Mesh.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional\n\nfrom flask import Blueprint, jsonify, request\nfrom pydantic import BaseModel, Field, ValidationError, validator\n\nfrom .auth import require_api_key\n\nlogger = logging.getLogger(__name__)\n\napi_bp = Blueprint('api', __name__, url_prefix='/api/v1')\n\n\nclass HealthResponse(BaseModel):\n    \"\"\"Health check response model.\"\"\"\n    status: str\n    version: str = \"1.0.0\"\n\n\nclass MetricPayload(BaseModel):\n    \"\"\"Metric ingestion payload model.\"\"\"\n    service_name: str\n    metric_name: str\n    value: float\n    timestamp: Optional[str] = None\n    tags: Optional[Dict[str, str]] = None\n\n\nclass KPIThreshold(BaseModel):\n    \"\"\"KPI threshold configuration.\"\"\"\n    max_relative_increase: Optional[float] = None\n    max_absolute_value: Optional[float] = None\n\n\nclass CanaryAnalysisRequest(BaseModel):\n    \"\"\"Canary analysis request model.\"\"\"\n    service_name: str = Field(..., min_length=1)\n    canary_version: str = Field(..., min_length=1)\n    stable_version: str = Field(..., min_length=1)\n    duration_minutes: int = Field(..., gt=0, le=1440)\n    kpi_thresholds: Dict[str, KPIThreshold]\n\n    @validator('kpi_thresholds')\n    def validate_thresholds(cls, v):\n        if not v:\n            raise ValueError('At least one KPI threshold must be specified')\n        return v\n\n\nclass CanaryAnalysisResponse(BaseModel):\n    \"\"\"Canary analysis response model.\"\"\"\n    service_name: str\n    canary_version: str\n    stable_version: str\n    recommendation: str\n    justification: str\n    analysis_id: str\n\n\n@api_bp.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    response = HealthResponse(status='healthy')\n    return jsonify(response.dict()), 200\n\n\n@api_bp.route('/metrics', methods=['POST'])\n@require_api_key\ndef ingest_metrics():\n    \"\"\"Ingest metrics from agents.\"\"\"\n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({'error': 'No JSON payload provided'}), 400\n        \n        payload = MetricPayload(**data)\n        \n        # Forward to ingestion pipeline\n        from ..ingestion_pipeline.pipeline import IngestionPipeline\n        pipeline = IngestionPipeline()\n        result = pipeline.process(payload.dict())\n        \n        return jsonify({'status': 'accepted', 'id': result.get('id', 'unknown')}), 202\n    except ValidationError as e:\n        logger.warning(f\"Validation error: {e}\")\n        return jsonify({'error': 'Invalid payload', 'details': e.errors()}), 400\n    except Exception as e:\n        logger.error(f\"Error ingesting metrics: {e}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@api_bp.route('/telemetry/<service_name>', methods=['GET'])\n@require_api_key\ndef get_telemetry(service_name: str):\n    \"\"\"Get telemetry data for a service.\"\"\"\n    try:\n        from ..core_telemetry.service import TelemetryService\n        service = TelemetryService()\n        \n        version = request.args.get('version')\n        duration_minutes = request.args.get('duration_minutes', 60, type=int)\n        \n        data = service.get_metrics(\n            service_name=service_name,\n            version=version,\n            duration_minutes=duration_minutes\n        )\n        \n        return jsonify({'service_name': service_name, 'metrics': data}), 200\n    except Exception as e:\n        logger.error(f\"Error fetching telemetry: {e}\")\n        return jsonify({'error': 'Internal server error'}), 500\n\n\n@api_bp.route('/analysis/canary', methods=['POST'])\n@require_api_key\ndef canary_analysis():\n    \"\"\"Initiate canary analysis comparing canary vs stable deployment.\"\"\"\n    try:\n        data = request.get_json()\n        if not data:\n            return jsonify({'error': 'No JSON payload provided'}), 400\n        \n        # Validate request\n        try:\n            analysis_request = CanaryAnalysisRequest(**data)\n        except ValidationError as e:\n            logger.warning(f\"Canary analysis validation error: {e}\")\n            return jsonify({'error': 'Invalid payload', 'details': e.errors()}), 400\n        \n        # Execute canary analysis strategy\n        from ..strategy_service.strategies import CanaryAnalysisStrategy\n        from ..core_telemetry.service import TelemetryService\n        from ..remediation_service.commands import LogCanaryAnalysisResultCommand\n        \n        telemetry_service = TelemetryService()\n        strategy = CanaryAnalysisStrategy(telemetry_client=telemetry_service)\n        \n        # Prepare strategy context\n        strategy_context = {\n            'service_name': analysis_request.service_name,\n            'canary_version': analysis_request.canary_version,\n            'stable_version': analysis_request.stable_version,\n            'duration_minutes': analysis_request.duration_minutes,\n            'kpi_thresholds': {k: v.dict() for k, v in analysis_request.kpi_thresholds.items()}\n        }\n        \n        # Execute analysis\n        result = strategy.execute(strategy_context)\n        \n        # Log the result via remediation command\n        log_command = LogCanaryAnalysisResultCommand(\n            service_name=result['service_name'],\n            recommendation=result['recommendation'],\n            justification=result['justification']\n        )\n        log_command.execute()\n        \n        response = CanaryAnalysisResponse(\n            service_name=result['service_name'],\n            canary_version=analysis_request.canary_version,\n            stable_version=analysis_request.stable_version,\n            recommendation=result['recommendation'],\n            justification=result['justification'],\n            analysis_id=result.get('analysis_id', 'unknown')\n        )\n        \n        return jsonify(response.dict()), 200\n        \n    except Exception as e:\n        logger.error(f\"Error during canary analysis: {e}\")\n        return jsonify({'error': 'Internal server error', 'message': str(e)}), 500\n\n\n@api_bp.route('/strategies', methods=['GET'])\n@require_api_key\ndef list_strategies():\n    \"\"\"List available remediation strategies.\"\"\"\n    strategies = [\n        {'name': 'auto_scaling', 'description': 'Automatic scaling based on load'},\n        {'name': 'circuit_breaker', 'description': 'Circuit breaker pattern'},\n        {'name': 'canary_analysis', 'description': 'Canary deployment analysis'}\n    ]\n    return jsonify({'strategies': strategies}), 200\n",
            "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py": "\"\"\"Handlers for processing telemetry data in the ingestion pipeline.\"\"\"\n\nimport logging\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseHandler(ABC):\n    \"\"\"Abstract base class for pipeline handlers.\"\"\"\n    \n    def __init__(self):\n        self._next_handler: Optional['BaseHandler'] = None\n    \n    def set_next(self, handler: 'BaseHandler') -> 'BaseHandler':\n        \"\"\"Set the next handler in the chain.\"\"\"\n        self._next_handler = handler\n        return handler\n    \n    @abstractmethod\n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process the data and optionally pass to next handler.\"\"\"\n        pass\n    \n    def _pass_to_next(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Pass data to the next handler if it exists.\"\"\"\n        if self._next_handler:\n            return self._next_handler.handle(data)\n        return data\n\n\nclass ValidationHandler(BaseHandler):\n    \"\"\"Handler for validating incoming telemetry data.\"\"\"\n    \n    REQUIRED_FIELDS = ['service_name', 'metric_name', 'value']\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Validate the incoming data.\"\"\"\n        logger.debug(f\"Validating data: {data}\")\n        \n        # Check required fields\n        missing_fields = [f for f in self.REQUIRED_FIELDS if f not in data]\n        if missing_fields:\n            raise ValueError(f\"Missing required fields: {missing_fields}\")\n        \n        # Validate value is numeric\n        if not isinstance(data['value'], (int, float)):\n            raise ValueError(f\"Value must be numeric, got {type(data['value'])}\")\n        \n        # Validate service_name and metric_name are non-empty strings\n        if not data['service_name'] or not isinstance(data['service_name'], str):\n            raise ValueError(\"service_name must be a non-empty string\")\n        \n        if not data['metric_name'] or not isinstance(data['metric_name'], str):\n            raise ValueError(\"metric_name must be a non-empty string\")\n        \n        data['validated'] = True\n        return self._pass_to_next(data)\n\n\nclass EnrichmentHandler(BaseHandler):\n    \"\"\"Handler for enriching telemetry data with additional metadata.\"\"\"\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Enrich the data with metadata.\"\"\"\n        logger.debug(f\"Enriching data: {data}\")\n        \n        # Add unique ID if not present\n        if 'id' not in data:\n            data['id'] = str(uuid.uuid4())\n        \n        # Add timestamp if not present\n        if 'timestamp' not in data or data['timestamp'] is None:\n            data['timestamp'] = datetime.utcnow().isoformat() + 'Z'\n        \n        # Add ingestion timestamp\n        data['ingested_at'] = datetime.utcnow().isoformat() + 'Z'\n        \n        # Process tags - ensure version tag is properly handled\n        data['tags'] = self._process_tags(data.get('tags', {}))\n        \n        data['enriched'] = True\n        return self._pass_to_next(data)\n    \n    def _process_tags(self, tags: Optional[Dict[str, str]]) -> Dict[str, str]:\n        \"\"\"Process and normalize tags.\"\"\"\n        if tags is None:\n            tags = {}\n        \n        processed_tags = {}\n        for key, value in tags.items():\n            # Normalize tag keys to lowercase\n            normalized_key = key.lower().strip()\n            # Ensure value is a string\n            normalized_value = str(value).strip() if value is not None else ''\n            \n            if normalized_key and normalized_value:\n                processed_tags[normalized_key] = normalized_value\n        \n        return processed_tags\n\n\nclass VersionTagHandler(BaseHandler):\n    \"\"\"Handler for processing and validating version tags for canary analysis.\"\"\"\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process version tags from telemetry data.\"\"\"\n        logger.debug(f\"Processing version tags: {data}\")\n        \n        tags = data.get('tags', {})\n        \n        # Extract version from tags if present\n        version = tags.get('version')\n        \n        if version:\n            # Store version at top level for easier querying\n            data['version'] = version\n            logger.debug(f\"Version tag found: {version}\")\n        else:\n            # Set default version if not provided\n            data['version'] = 'unknown'\n            logger.debug(\"No version tag found, using 'unknown'\")\n        \n        # Extract deployment type if present (canary, stable, etc.)\n        deployment_type = tags.get('deployment_type') or tags.get('deployment')\n        if deployment_type:\n            data['deployment_type'] = deployment_type\n        \n        data['version_processed'] = True\n        return self._pass_to_next(data)\n\n\nclass NormalizationHandler(BaseHandler):\n    \"\"\"Handler for normalizing metric values and names.\"\"\"\n    \n    # Mapping of common metric name variations to standard names\n    METRIC_NAME_MAPPING = {\n        'latency': 'latency_ms',\n        'latency_p99': 'latency_ms_p99',\n        'p99_latency': 'latency_ms_p99',\n        'response_time': 'latency_ms',\n        'errors': 'error_rate',\n        'error_count': 'error_rate',\n        'cpu': 'cpu_percent',\n        'memory': 'memory_percent',\n        'mem': 'memory_percent'\n    }\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Normalize metric data.\"\"\"\n        logger.debug(f\"Normalizing data: {data}\")\n        \n        # Normalize metric name\n        original_name = data['metric_name'].lower().strip()\n        normalized_name = self.METRIC_NAME_MAPPING.get(original_name, original_name)\n        \n        if normalized_name != original_name:\n            data['original_metric_name'] = data['metric_name']\n            data['metric_name'] = normalized_name\n            logger.debug(f\"Normalized metric name: {original_name} -> {normalized_name}\")\n        \n        # Normalize service name (lowercase, replace spaces with underscores)\n        data['service_name'] = data['service_name'].lower().strip().replace(' ', '_')\n        \n        data['normalized'] = True\n        return self._pass_to_next(data)\n\n\nclass AggregationHandler(BaseHandler):\n    \"\"\"Handler for aggregating metrics before storage.\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        self._buffer: List[Dict[str, Any]] = []\n        self._buffer_size = 100\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Buffer data for batch processing.\"\"\"\n        logger.debug(f\"Aggregating data: {data}\")\n        \n        # For now, pass through immediately\n        # In production, this would buffer and batch\n        data['aggregated'] = True\n        return self._pass_to_next(data)\n\n\nclass StorageHandler(BaseHandler):\n    \"\"\"Handler for storing telemetry data.\"\"\"\n    \n    def __init__(self, storage_backend=None):\n        super().__init__()\n        self._storage = storage_backend or InMemoryStorage()\n    \n    def handle(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Store the processed data.\"\"\"\n        logger.debug(f\"Storing data: {data}\")\n        \n        try:\n            self._storage.store(data)\n            data['stored'] = True\n            logger.info(f\"Successfully stored metric {data['id']} for service {data['service_name']}\")\n        except Exception as e:\n            logger.error(f\"Failed to store data: {e}\")\n            data['stored'] = False\n            data['storage_error'] = str(e)\n        \n        return self._pass_to_next(data)\n\n\nclass InMemoryStorage:\n    \"\"\"Simple in-memory storage for telemetry data.\"\"\"\n    \n    _instance = None\n    _data: List[Dict[str, Any]] = []\n    \n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._data = []\n        return cls._instance\n    \n    def store(self, data: Dict[str, Any]) -> None:\n        \"\"\"Store data in memory.\"\"\"\n        self._data.append(data.copy())\n    \n    def query(self, service_name: str = None, version: str = None, \n              metric_name: str = None, limit: int = 1000) -> List[Dict[str, Any]]:\n        \"\"\"Query stored data with optional filters.\"\"\"\n        results = self._data\n        \n        if service_name:\n            results = [d for d in results if d.get('service_name') == service_name]\n        \n        if version:\n            results = [d for d in results if d.get('version') == version]\n        \n        if metric_name:\n            results = [d for d in results if d.get('metric_name') == metric_name]\n        \n        return results[-limit:]\n    \n    def clear(self) -> None:\n        \"\"\"Clear all stored data.\"\"\"\n        self._data = []\n\n\ndef create_default_pipeline() -> BaseHandler:\n    \"\"\"Create the default processing pipeline.\"\"\"\n    validation = ValidationHandler()\n    enrichment = EnrichmentHandler()\n    version_tag = VersionTagHandler()\n    normalization = NormalizationHandler()\n    aggregation = AggregationHandler()\n    storage = StorageHandler()\n    \n    # Chain handlers\n    validation.set_next(enrichment)\n    enrichment.set_next(version_tag)\n    version_tag.set_next(normalization)\n    normalization.set_next(aggregation)\n    aggregation.set_next(storage)\n    \n    return validation\n",
            "edupulse_insight_mesh/src/strategy_service/strategies.py": "\"\"\"Strategy implementations for the EduPulse Insight Mesh system.\"\"\"\n\nimport logging\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseStrategy(ABC):\n    \"\"\"Abstract base class for remediation strategies.\"\"\"\n    \n    def __init__(self, name: str, description: str = \"\"):\n        self.name = name\n        self.description = description\n        self._execution_history: List[Dict[str, Any]] = []\n    \n    @abstractmethod\n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute the strategy with the given context.\"\"\"\n        pass\n    \n    @abstractmethod\n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate that the context has all required parameters.\"\"\"\n        pass\n    \n    def record_execution(self, context: Dict[str, Any], result: Dict[str, Any]) -> None:\n        \"\"\"Record the execution in history.\"\"\"\n        self._execution_history.append({\n            'timestamp': datetime.utcnow().isoformat(),\n            'context': context,\n            'result': result\n        })\n\n\nclass AutoScalingStrategy(BaseStrategy):\n    \"\"\"Strategy for automatic scaling based on load metrics.\"\"\"\n    \n    def __init__(self):\n        super().__init__(\n            name='auto_scaling',\n            description='Automatically scales services based on CPU and memory metrics'\n        )\n        self.scale_up_threshold = 80.0\n        self.scale_down_threshold = 30.0\n        self.min_replicas = 1\n        self.max_replicas = 10\n    \n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate auto-scaling context.\"\"\"\n        required = ['service_name', 'current_replicas', 'cpu_percent']\n        return all(key in context for key in required)\n    \n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute auto-scaling decision.\"\"\"\n        if not self.validate_context(context):\n            return {'success': False, 'error': 'Invalid context'}\n        \n        service_name = context['service_name']\n        current_replicas = context['current_replicas']\n        cpu_percent = context['cpu_percent']\n        \n        action = 'none'\n        new_replicas = current_replicas\n        \n        if cpu_percent > self.scale_up_threshold and current_replicas < self.max_replicas:\n            action = 'scale_up'\n            new_replicas = min(current_replicas + 1, self.max_replicas)\n        elif cpu_percent < self.scale_down_threshold and current_replicas > self.min_replicas:\n            action = 'scale_down'\n            new_replicas = max(current_replicas - 1, self.min_replicas)\n        \n        result = {\n            'success': True,\n            'service_name': service_name,\n            'action': action,\n            'previous_replicas': current_replicas,\n            'new_replicas': new_replicas,\n            'reason': f'CPU at {cpu_percent}%'\n        }\n        \n        self.record_execution(context, result)\n        logger.info(f\"Auto-scaling decision for {service_name}: {action}\")\n        \n        return result\n\n\nclass CircuitBreakerStrategy(BaseStrategy):\n    \"\"\"Strategy for implementing circuit breaker pattern.\"\"\"\n    \n    def __init__(self):\n        super().__init__(\n            name='circuit_breaker',\n            description='Implements circuit breaker pattern for failing services'\n        )\n        self.error_threshold = 0.5  # 50% error rate\n        self.timeout_seconds = 30\n        self._circuit_states: Dict[str, str] = {}  # service -> state\n    \n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate circuit breaker context.\"\"\"\n        required = ['service_name', 'error_rate', 'request_count']\n        return all(key in context for key in required)\n    \n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute circuit breaker logic.\"\"\"\n        if not self.validate_context(context):\n            return {'success': False, 'error': 'Invalid context'}\n        \n        service_name = context['service_name']\n        error_rate = context['error_rate']\n        request_count = context['request_count']\n        \n        current_state = self._circuit_states.get(service_name, 'closed')\n        new_state = current_state\n        \n        if error_rate > self.error_threshold and request_count > 10:\n            new_state = 'open'\n        elif current_state == 'open':\n            new_state = 'half_open'\n        elif current_state == 'half_open' and error_rate < self.error_threshold:\n            new_state = 'closed'\n        \n        self._circuit_states[service_name] = new_state\n        \n        result = {\n            'success': True,\n            'service_name': service_name,\n            'previous_state': current_state,\n            'new_state': new_state,\n            'error_rate': error_rate\n        }\n        \n        self.record_execution(context, result)\n        logger.info(f\"Circuit breaker for {service_name}: {current_state} -> {new_state}\")\n        \n        return result\n\n\nclass CanaryAnalysisStrategy(BaseStrategy):\n    \"\"\"Strategy for analyzing canary deployments against stable versions.\"\"\"\n    \n    PROMOTE = 'PROMOTE'\n    ROLLBACK = 'ROLLBACK'\n    \n    def __init__(self, telemetry_client=None):\n        super().__init__(\n            name='canary_analysis',\n            description='Analyzes canary deployment KPIs against stable version'\n        )\n        self._telemetry_client = telemetry_client\n    \n    def set_telemetry_client(self, client) -> None:\n        \"\"\"Set the telemetry client for querying metrics.\"\"\"\n        self._telemetry_client = client\n    \n    def validate_context(self, context: Dict[str, Any]) -> bool:\n        \"\"\"Validate canary analysis context.\"\"\"\n        required = ['service_name', 'canary_version', 'stable_version', \n                    'duration_minutes', 'kpi_thresholds']\n        return all(key in context for key in required)\n    \n    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Execute canary analysis comparing canary vs stable metrics.\"\"\"\n        if not self.validate_context(context):\n            return {\n                'success': False, \n                'error': 'Invalid context - missing required fields',\n                'recommendation': self.ROLLBACK,\n                'justification': 'Analysis failed due to invalid context'\n            }\n        \n        service_name = context['service_name']\n        canary_version = context['canary_version']\n        stable_version = context['stable_version']\n        duration_minutes = context['duration_minutes']\n        kpi_thresholds = context['kpi_thresholds']\n        \n        analysis_id = str(uuid.uuid4())\n        logger.info(f\"Starting canary analysis {analysis_id} for {service_name}\")\n        logger.info(f\"Comparing canary={canary_version} vs stable={stable_version}\")\n        \n        try:\n            # Fetch metrics for both versions\n            canary_metrics = self._fetch_metrics(\n                service_name, canary_version, duration_minutes\n            )\n            stable_metrics = self._fetch_metrics(\n                service_name, stable_version, duration_minutes\n            )\n            \n            # Calculate KPIs\n            canary_kpis = self._calculate_kpis(canary_metrics)\n            stable_kpis = self._calculate_kpis(stable_metrics)\n            \n            logger.info(f\"Canary KPIs: {canary_kpis}\")\n            logger.info(f\"Stable KPIs: {stable_kpis}\")\n            \n            # Compare KPIs against thresholds\n            failures = []\n            \n            # Check latency threshold\n            if 'latency_ms_p99' in kpi_thresholds:\n                threshold_config = kpi_thresholds['latency_ms_p99']\n                max_relative_increase = threshold_config.get('max_relative_increase', 0.1)\n                \n                canary_latency = canary_kpis.get('latency_ms_p99', 0)\n                stable_latency = stable_kpis.get('latency_ms_p99', 0)\n                \n                if stable_latency > 0:\n                    max_allowed_latency = stable_latency * (1 + max_relative_increase)\n                    if canary_latency > max_allowed_latency:\n                        relative_increase = ((canary_latency - stable_latency) / stable_latency) * 100\n                        failures.append(\n                            f\"Canary latency {canary_latency:.2f}ms exceeded stable latency \"\n                            f\"{stable_latency:.2f}ms by {relative_increase:.1f}% \"\n                            f\"(max allowed: {max_relative_increase * 100}%)\"\n                        )\n            \n            # Check error rate threshold\n            if 'error_rate' in kpi_thresholds:\n                threshold_config = kpi_thresholds['error_rate']\n                max_absolute_value = threshold_config.get('max_absolute_value', 0.01)\n                \n                canary_error_rate = canary_kpis.get('error_rate', 0)\n                \n                if canary_error_rate > max_absolute_value:\n                    failures.append(\n                        f\"Canary error rate {canary_error_rate:.4f} exceeded \"\n                        f\"maximum allowed {max_absolute_value}\"\n                    )\n            \n            # Determine recommendation\n            if failures:\n                recommendation = self.ROLLBACK\n                justification = \"; \".join(failures)\n            else:\n                recommendation = self.PROMOTE\n                justification = (\n                    f\"All KPI checks passed. Canary latency: {canary_kpis.get('latency_ms_p99', 'N/A')}ms, \"\n                    f\"error rate: {canary_kpis.get('error_rate', 'N/A')}\"\n                )\n            \n            result = {\n                'success': True,\n                'analysis_id': analysis_id,\n                'service_name': service_name,\n                'canary_version': canary_version,\n                'stable_version': stable_version,\n                'recommendation': recommendation,\n                'justification': justification,\n                'canary_kpis': canary_kpis,\n                'stable_kpis': stable_kpis,\n                'failures': failures\n            }\n            \n            self.record_execution(context, result)\n            logger.info(f\"Canary analysis {analysis_id} complete: {recommendation}\")\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Canary analysis failed: {e}\")\n            return {\n                'success': False,\n                'analysis_id': analysis_id,\n                'service_name': service_name,\n                'recommendation': self.ROLLBACK,\n                'justification': f'Analysis failed with error: {str(e)}',\n                'error': str(e)\n            }\n    \n    def _fetch_metrics(self, service_name: str, version: str, \n                       duration_minutes: int) -> List[Dict[str, Any]]:\n        \"\"\"Fetch metrics from telemetry service for a specific version.\"\"\"\n        if self._telemetry_client is None:\n            logger.warning(\"No telemetry client configured, returning empty metrics\")\n            return []\n        \n        try:\n            metrics = self._telemetry_client.get_metrics(\n                service_name=service_name,\n                version=version,\n                duration_minutes=duration_minutes\n            )\n            return metrics if metrics else []\n        except Exception as e:\n            logger.error(f\"Failed to fetch metrics for {service_name} v{version}: {e}\")\n            return []\n    \n    def _calculate_kpis(self, metrics: List[Dict[str, Any]]) -> Dict[str, float]:\n        \"\"\"Calculate KPIs from raw metrics.\"\"\"\n        kpis = {\n            'latency_ms_p99': 0.0,\n            'error_rate': 0.0,\n            'request_count': 0\n        }\n        \n        if not metrics:\n            return kpis\n        \n        # Group metrics by type\n        latency_values = []\n        error_values = []\n        \n        for metric in metrics:\n            metric_name = metric.get('metric_name', '').lower()\n            value = metric.get('value', 0)\n            \n            if 'latency' in metric_name:\n                latency_values.append(value)\n            elif 'error' in metric_name:\n                error_values.append(value)\n        \n        # Calculate p99 latency\n        if latency_values:\n            sorted_latencies = sorted(latency_values)\n            p99_index = int(len(sorted_latencies) * 0.99)\n            p99_index = min(p99_index, len(sorted_latencies) - 1)\n            kpis['latency_ms_p99'] = sorted_latencies[p99_index]\n        \n        # Calculate average error rate\n        if error_values:\n            kpis['error_rate'] = sum(error_values) / len(error_values)\n        \n        kpis['request_count'] = len(metrics)\n        \n        return kpis\n\n\nclass StrategyRegistry:\n    \"\"\"Registry for managing available strategies.\"\"\"\n    \n    def __init__(self):\n        self._strategies: Dict[str, BaseStrategy] = {}\n        self._register_default_strategies()\n    \n    def _register_default_strategies(self) -> None:\n        \"\"\"Register default strategies.\"\"\"\n        self.register(AutoScalingStrategy())\n        self.register(CircuitBreakerStrategy())\n        self.register(CanaryAnalysisStrategy())\n    \n    def register(self, strategy: BaseStrategy) -> None:\n        \"\"\"Register a strategy.\"\"\"\n        self._strategies[strategy.name] = strategy\n        logger.info(f\"Registered strategy: {strategy.name}\")\n    \n    def get(self, name: str) -> Optional[BaseStrategy]:\n        \"\"\"Get a strategy by name.\"\"\"\n        return self._strategies.get(name)\n    \n    def list_strategies(self) -> List[Dict[str, str]]:\n        \"\"\"List all registered strategies.\"\"\"\n        return [\n            {'name': s.name, 'description': s.description}\n            for s in self._strategies.values()\n        ]\n",
            "edupulse_insight_mesh/src/remediation_service/commands.py": "\"\"\"Remediation commands for the EduPulse Insight Mesh system.\"\"\"\n\nimport logging\nimport subprocess\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseCommand(ABC):\n    \"\"\"Abstract base class for remediation commands.\"\"\"\n    \n    def __init__(self, name: str, description: str = \"\"):\n        self.name = name\n        self.description = description\n        self.executed_at: Optional[datetime] = None\n        self.result: Optional[Dict[str, Any]] = None\n    \n    @abstractmethod\n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute the command and return result.\"\"\"\n        pass\n    \n    @abstractmethod\n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback the command if possible.\"\"\"\n        pass\n    \n    def _record_execution(self, result: Dict[str, Any]) -> None:\n        \"\"\"Record execution details.\"\"\"\n        self.executed_at = datetime.utcnow()\n        self.result = result\n\n\nclass RestartServiceCommand(BaseCommand):\n    \"\"\"Command to restart a service.\"\"\"\n    \n    def __init__(self, service_name: str, namespace: str = 'default'):\n        super().__init__(\n            name='restart_service',\n            description=f'Restart service {service_name} in namespace {namespace}'\n        )\n        self.service_name = service_name\n        self.namespace = namespace\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute service restart.\"\"\"\n        logger.info(f\"Restarting service {self.service_name} in {self.namespace}\")\n        \n        # In production, this would use kubernetes client\n        # For now, we simulate the operation\n        result = {\n            'success': True,\n            'command': 'restart_service',\n            'service_name': self.service_name,\n            'namespace': self.namespace,\n            'message': f'Service {self.service_name} restart initiated'\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback is not applicable for restart.\"\"\"\n        return {\n            'success': False,\n            'message': 'Rollback not applicable for restart command'\n        }\n\n\nclass ScaleDeploymentCommand(BaseCommand):\n    \"\"\"Command to scale a deployment.\"\"\"\n    \n    def __init__(self, deployment_name: str, replicas: int, \n                 namespace: str = 'default'):\n        super().__init__(\n            name='scale_deployment',\n            description=f'Scale {deployment_name} to {replicas} replicas'\n        )\n        self.deployment_name = deployment_name\n        self.replicas = replicas\n        self.namespace = namespace\n        self.previous_replicas: Optional[int] = None\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute deployment scaling.\"\"\"\n        logger.info(f\"Scaling {self.deployment_name} to {self.replicas} replicas\")\n        \n        # Store previous state for rollback\n        self.previous_replicas = self._get_current_replicas()\n        \n        result = {\n            'success': True,\n            'command': 'scale_deployment',\n            'deployment_name': self.deployment_name,\n            'previous_replicas': self.previous_replicas,\n            'new_replicas': self.replicas,\n            'namespace': self.namespace\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback to previous replica count.\"\"\"\n        if self.previous_replicas is None:\n            return {\n                'success': False,\n                'message': 'No previous state to rollback to'\n            }\n        \n        logger.info(f\"Rolling back {self.deployment_name} to {self.previous_replicas} replicas\")\n        \n        return {\n            'success': True,\n            'command': 'scale_deployment_rollback',\n            'deployment_name': self.deployment_name,\n            'replicas': self.previous_replicas\n        }\n    \n    def _get_current_replicas(self) -> int:\n        \"\"\"Get current replica count (simulated).\"\"\"\n        # In production, query Kubernetes API\n        return 1\n\n\nclass UpdateConfigMapCommand(BaseCommand):\n    \"\"\"Command to update a ConfigMap.\"\"\"\n    \n    def __init__(self, configmap_name: str, data: Dict[str, str],\n                 namespace: str = 'default'):\n        super().__init__(\n            name='update_configmap',\n            description=f'Update ConfigMap {configmap_name}'\n        )\n        self.configmap_name = configmap_name\n        self.data = data\n        self.namespace = namespace\n        self.previous_data: Optional[Dict[str, str]] = None\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute ConfigMap update.\"\"\"\n        logger.info(f\"Updating ConfigMap {self.configmap_name}\")\n        \n        self.previous_data = self._get_current_data()\n        \n        result = {\n            'success': True,\n            'command': 'update_configmap',\n            'configmap_name': self.configmap_name,\n            'namespace': self.namespace,\n            'keys_updated': list(self.data.keys())\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback ConfigMap to previous state.\"\"\"\n        if self.previous_data is None:\n            return {\n                'success': False,\n                'message': 'No previous state to rollback to'\n            }\n        \n        return {\n            'success': True,\n            'command': 'update_configmap_rollback',\n            'configmap_name': self.configmap_name\n        }\n    \n    def _get_current_data(self) -> Dict[str, str]:\n        \"\"\"Get current ConfigMap data (simulated).\"\"\"\n        return {}\n\n\nclass LogCanaryAnalysisResultCommand(BaseCommand):\n    \"\"\"Command to log canary analysis results.\"\"\"\n    \n    def __init__(self, service_name: str, recommendation: str, \n                 justification: str):\n        super().__init__(\n            name='log_canary_analysis_result',\n            description=f'Log canary analysis result for {service_name}'\n        )\n        self.service_name = service_name\n        self.recommendation = recommendation\n        self.justification = justification\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute logging of canary analysis result.\"\"\"\n        timestamp = datetime.utcnow().isoformat()\n        \n        # Log the canary analysis result at INFO level\n        log_message = (\n            f\"CANARY_ANALYSIS_RESULT | \"\n            f\"timestamp={timestamp} | \"\n            f\"service={self.service_name} | \"\n            f\"recommendation={self.recommendation} | \"\n            f\"justification={self.justification}\"\n        )\n        \n        logger.info(log_message)\n        \n        # Also log structured data for potential downstream processing\n        if self.recommendation == 'PROMOTE':\n            logger.info(\n                f\"Canary deployment for {self.service_name} PASSED analysis. \"\n                f\"Recommendation: {self.recommendation}\"\n            )\n        else:\n            logger.warning(\n                f\"Canary deployment for {self.service_name} FAILED analysis. \"\n                f\"Recommendation: {self.recommendation}. \"\n                f\"Reason: {self.justification}\"\n            )\n        \n        result = {\n            'success': True,\n            'command': 'log_canary_analysis_result',\n            'service_name': self.service_name,\n            'recommendation': self.recommendation,\n            'justification': self.justification,\n            'timestamp': timestamp,\n            'logged': True\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback is not applicable for logging.\"\"\"\n        return {\n            'success': False,\n            'message': 'Rollback not applicable for logging command'\n        }\n\n\nclass ExecuteScriptCommand(BaseCommand):\n    \"\"\"Command to execute a remediation script.\"\"\"\n    \n    def __init__(self, script_path: str, args: List[str] = None,\n                 timeout: int = 60):\n        super().__init__(\n            name='execute_script',\n            description=f'Execute script {script_path}'\n        )\n        self.script_path = script_path\n        self.args = args or []\n        self.timeout = timeout\n    \n    def execute(self) -> Dict[str, Any]:\n        \"\"\"Execute the script.\"\"\"\n        logger.info(f\"Executing script {self.script_path} with args {self.args}\")\n        \n        # In production, this would actually run the script\n        # For safety, we simulate the execution\n        result = {\n            'success': True,\n            'command': 'execute_script',\n            'script_path': self.script_path,\n            'args': self.args,\n            'exit_code': 0,\n            'stdout': 'Script executed successfully (simulated)',\n            'stderr': ''\n        }\n        \n        self._record_execution(result)\n        return result\n    \n    def rollback(self) -> Dict[str, Any]:\n        \"\"\"Rollback is script-dependent.\"\"\"\n        return {\n            'success': False,\n            'message': 'Automatic rollback not supported for scripts'\n        }\n\n\nclass CommandQueue:\n    \"\"\"Queue for managing and executing commands.\"\"\"\n    \n    def __init__(self):\n        self._pending: List[BaseCommand] = []\n        self._executed: List[BaseCommand] = []\n    \n    def add(self, command: BaseCommand) -> None:\n        \"\"\"Add a command to the queue.\"\"\"\n        self._pending.append(command)\n        logger.debug(f\"Added command to queue: {command.name}\")\n    \n    def execute_all(self) -> List[Dict[str, Any]]:\n        \"\"\"Execute all pending commands.\"\"\"\n        results = []\n        \n        while self._pending:\n            command = self._pending.pop(0)\n            try:\n                result = command.execute()\n                results.append(result)\n                self._executed.append(command)\n            except Exception as e:\n                logger.error(f\"Command {command.name} failed: {e}\")\n                results.append({\n                    'success': False,\n                    'command': command.name,\n                    'error': str(e)\n                })\n        \n        return results\n    \n    def rollback_all(self) -> List[Dict[str, Any]]:\n        \"\"\"Rollback all executed commands in reverse order.\"\"\"\n        results = []\n        \n        while self._executed:\n            command = self._executed.pop()\n            try:\n                result = command.rollback()\n                results.append(result)\n            except Exception as e:\n                logger.error(f\"Rollback of {command.name} failed: {e}\")\n                results.append({\n                    'success': False,\n                    'command': command.name,\n                    'error': str(e)\n                })\n        \n        return results\n",
            "edupulse_insight_mesh/src/core_telemetry/service.py": "\"\"\"Core telemetry service for the EduPulse Insight Mesh system.\"\"\"\n\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional\n\nlogger = logging.getLogger(__name__)\n\n\nclass TelemetryService:\n    \"\"\"Service for querying and managing telemetry data.\"\"\"\n    \n    def __init__(self, storage_backend=None):\n        \"\"\"Initialize the telemetry service.\n        \n        Args:\n            storage_backend: Optional storage backend. If not provided,\n                           uses the shared InMemoryStorage.\n        \"\"\"\n        self._storage = storage_backend\n        if self._storage is None:\n            from ..ingestion_pipeline.handlers import InMemoryStorage\n            self._storage = InMemoryStorage()\n    \n    def get_metrics(self, service_name: str, version: Optional[str] = None,\n                    duration_minutes: int = 60,\n                    metric_name: Optional[str] = None) -> List[Dict[str, Any]]:\n        \"\"\"Get metrics for a service.\n        \n        Args:\n            service_name: Name of the service to query\n            version: Optional version filter for canary analysis\n            duration_minutes: Time window in minutes\n            metric_name: Optional specific metric name to filter\n            \n        Returns:\n            List of metric records\n        \"\"\"\n        logger.debug(\n            f\"Querying metrics for service={service_name}, version={version}, \"\n            f\"duration={duration_minutes}min\"\n        )\n        \n        try:\n            # Query storage\n            metrics = self._storage.query(\n                service_name=service_name,\n                version=version,\n                metric_name=metric_name\n            )\n            \n            # Filter by time window\n            cutoff_time = datetime.utcnow() - timedelta(minutes=duration_minutes)\n            filtered_metrics = []\n            \n            for metric in metrics:\n                timestamp_str = metric.get('timestamp', '')\n                if timestamp_str:\n                    try:\n                        # Parse ISO format timestamp\n                        timestamp = datetime.fromisoformat(\n                            timestamp_str.replace('Z', '+00:00')\n                        )\n                        # Remove timezone info for comparison\n                        timestamp = timestamp.replace(tzinfo=None)\n                        if timestamp >= cutoff_time:\n                            filtered_metrics.append(metric)\n                    except (ValueError, TypeError):\n                        # Include metrics with unparseable timestamps\n                        filtered_metrics.append(metric)\n                else:\n                    filtered_metrics.append(metric)\n            \n            logger.debug(f\"Found {len(filtered_metrics)} metrics\")\n            return filtered_metrics\n            \n        except Exception as e:\n            logger.error(f\"Error querying metrics: {e}\")\n            return []\n    \n    def get_aggregated_metrics(self, service_name: str, \n                                version: Optional[str] = None,\n                                duration_minutes: int = 60) -> Dict[str, Any]:\n        \"\"\"Get aggregated metrics for a service.\n        \n        Args:\n            service_name: Name of the service\n            version: Optional version filter\n            duration_minutes: Time window in minutes\n            \n        Returns:\n            Dictionary with aggregated metrics\n        \"\"\"\n        metrics = self.get_metrics(service_name, version, duration_minutes)\n        \n        if not metrics:\n            return {\n                'service_name': service_name,\n                'version': version,\n                'count': 0,\n                'aggregations': {}\n            }\n        \n        # Group by metric name\n        grouped: Dict[str, List[float]] = {}\n        for metric in metrics:\n            name = metric.get('metric_name', 'unknown')\n            value = metric.get('value', 0)\n            if name not in grouped:\n                grouped[name] = []\n            grouped[name].append(value)\n        \n        # Calculate aggregations\n        aggregations = {}\n        for name, values in grouped.items():\n            if values:\n                sorted_values = sorted(values)\n                aggregations[name] = {\n                    'count': len(values),\n                    'min': min(values),\n                    'max': max(values),\n                    'avg': sum(values) / len(values),\n                    'p50': sorted_values[len(sorted_values) // 2],\n                    'p99': sorted_values[int(len(sorted_values) * 0.99)] \n                           if len(sorted_values) > 1 else sorted_values[0]\n                }\n        \n        return {\n            'service_name': service_name,\n            'version': version,\n            'count': len(metrics),\n            'aggregations': aggregations\n        }\n    \n    def get_service_health(self, service_name: str) -> Dict[str, Any]:\n        \"\"\"Get overall health status for a service.\n        \n        Args:\n            service_name: Name of the service\n            \n        Returns:\n            Health status dictionary\n        \"\"\"\n        metrics = self.get_metrics(service_name, duration_minutes=5)\n        \n        if not metrics:\n            return {\n                'service_name': service_name,\n                'status': 'unknown',\n                'message': 'No recent metrics available'\n            }\n        \n        # Check for error metrics\n        error_metrics = [\n            m for m in metrics \n            if 'error' in m.get('metric_name', '').lower()\n        ]\n        \n        if error_metrics:\n            avg_error_rate = sum(m.get('value', 0) for m in error_metrics) / len(error_metrics)\n            if avg_error_rate > 0.1:\n                return {\n                    'service_name': service_name,\n                    'status': 'unhealthy',\n                    'error_rate': avg_error_rate,\n                    'message': f'High error rate: {avg_error_rate:.2%}'\n                }\n        \n        return {\n            'service_name': service_name,\n            'status': 'healthy',\n            'metrics_count': len(metrics),\n            'message': 'Service is operating normally'\n        }\n    \n    def list_services(self) -> List[str]:\n        \"\"\"List all services with telemetry data.\n        \n        Returns:\n            List of service names\n        \"\"\"\n        try:\n            all_metrics = self._storage.query()\n            services = set(m.get('service_name') for m in all_metrics if m.get('service_name'))\n            return sorted(list(services))\n        except Exception as e:\n            logger.error(f\"Error listing services: {e}\")\n            return []\n    \n    def list_versions(self, service_name: str) -> List[str]:\n        \"\"\"List all versions for a service.\n        \n        Args:\n            service_name: Name of the service\n            \n        Returns:\n            List of version strings\n        \"\"\"\n        try:\n            metrics = self._storage.query(service_name=service_name)\n            versions = set(\n                m.get('version') for m in metrics \n                if m.get('version') and m.get('version') != 'unknown'\n            )\n            return sorted(list(versions))\n        except Exception as e:\n            logger.error(f\"Error listing versions: {e}\")\n            return []\n",
            "edupulse_insight_mesh/tests/test_strategy_service.py": "\"\"\"Tests for the strategy service.\"\"\"\n\nimport unittest\nfrom unittest.mock import MagicMock, patch\nfrom datetime import datetime\n\nfrom edupulse_insight_mesh.src.strategy_service.strategies import (\n    AutoScalingStrategy,\n    CircuitBreakerStrategy,\n    CanaryAnalysisStrategy,\n    StrategyRegistry\n)\n\n\nclass TestAutoScalingStrategy(unittest.TestCase):\n    \"\"\"Tests for AutoScalingStrategy.\"\"\"\n    \n    def setUp(self):\n        self.strategy = AutoScalingStrategy()\n    \n    def test_validate_context_valid(self):\n        \"\"\"Test validation with valid context.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 2,\n            'cpu_percent': 75.0\n        }\n        self.assertTrue(self.strategy.validate_context(context))\n    \n    def test_validate_context_invalid(self):\n        \"\"\"Test validation with missing fields.\"\"\"\n        context = {'service_name': 'test-service'}\n        self.assertFalse(self.strategy.validate_context(context))\n    \n    def test_scale_up_decision(self):\n        \"\"\"Test scale up when CPU is high.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 2,\n            'cpu_percent': 85.0\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['action'], 'scale_up')\n        self.assertEqual(result['new_replicas'], 3)\n    \n    def test_scale_down_decision(self):\n        \"\"\"Test scale down when CPU is low.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 3,\n            'cpu_percent': 20.0\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['action'], 'scale_down')\n        self.assertEqual(result['new_replicas'], 2)\n    \n    def test_no_scaling_needed(self):\n        \"\"\"Test no action when CPU is in normal range.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'current_replicas': 2,\n            'cpu_percent': 50.0\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['action'], 'none')\n        self.assertEqual(result['new_replicas'], 2)\n\n\nclass TestCircuitBreakerStrategy(unittest.TestCase):\n    \"\"\"Tests for CircuitBreakerStrategy.\"\"\"\n    \n    def setUp(self):\n        self.strategy = CircuitBreakerStrategy()\n    \n    def test_open_circuit_on_high_errors(self):\n        \"\"\"Test circuit opens on high error rate.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'error_rate': 0.6,\n            'request_count': 100\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['new_state'], 'open')\n    \n    def test_circuit_stays_closed_low_errors(self):\n        \"\"\"Test circuit stays closed with low errors.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'error_rate': 0.1,\n            'request_count': 100\n        }\n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['new_state'], 'closed')\n\n\nclass TestCanaryAnalysisStrategy(unittest.TestCase):\n    \"\"\"Tests for CanaryAnalysisStrategy.\"\"\"\n    \n    def setUp(self):\n        self.mock_telemetry_client = MagicMock()\n        self.strategy = CanaryAnalysisStrategy(\n            telemetry_client=self.mock_telemetry_client\n        )\n    \n    def test_validate_context_valid(self):\n        \"\"\"Test validation with valid context.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        self.assertTrue(self.strategy.validate_context(context))\n    \n    def test_validate_context_missing_fields(self):\n        \"\"\"Test validation with missing fields.\"\"\"\n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0'\n        }\n        self.assertFalse(self.strategy.validate_context(context))\n    \n    def test_promote_recommendation_good_metrics(self):\n        \"\"\"Test PROMOTE recommendation when canary metrics are good.\"\"\"\n        # Mock stable metrics\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'latency_ms_p99', 'value': 105.0},\n            {'metric_name': 'error_rate', 'value': 0.005},\n            {'metric_name': 'error_rate', 'value': 0.003}\n        ]\n        \n        # Mock canary metrics - slightly better or similar\n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 98.0},\n            {'metric_name': 'latency_ms_p99', 'value': 102.0},\n            {'metric_name': 'error_rate', 'value': 0.004},\n            {'metric_name': 'error_rate', 'value': 0.002}\n        ]\n        \n        # Configure mock to return different metrics based on version\n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'PROMOTE')\n        self.assertEqual(len(result['failures']), 0)\n    \n    def test_rollback_recommendation_high_latency(self):\n        \"\"\"Test ROLLBACK recommendation when canary latency is too high.\"\"\"\n        # Mock stable metrics with 100ms latency\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        # Mock canary metrics with 150ms latency (50% increase, exceeds 10% threshold)\n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 150.0},\n            {'metric_name': 'latency_ms_p99', 'value': 145.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n        self.assertGreater(len(result['failures']), 0)\n        self.assertIn('latency', result['failures'][0].lower())\n    \n    def test_rollback_recommendation_high_error_rate(self):\n        \"\"\"Test ROLLBACK recommendation when canary error rate is too high.\"\"\"\n        # Mock stable metrics\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        # Mock canary metrics with high error rate (5% > 1% threshold)\n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.05},\n            {'metric_name': 'error_rate', 'value': 0.04}\n        ]\n        \n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n        self.assertGreater(len(result['failures']), 0)\n        self.assertIn('error rate', result['failures'][0].lower())\n    \n    def test_rollback_on_multiple_failures(self):\n        \"\"\"Test ROLLBACK when both latency and error rate fail.\"\"\"\n        stable_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'error_rate', 'value': 0.005}\n        ]\n        \n        canary_metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 200.0},  # 100% increase\n            {'metric_name': 'error_rate', 'value': 0.05}  # 5% error rate\n        ]\n        \n        def get_metrics_side_effect(service_name, version, duration_minutes):\n            if version == 'v1.0.0':\n                return stable_metrics\n            elif version == 'v2.0.0':\n                return canary_metrics\n            return []\n        \n        self.mock_telemetry_client.get_metrics.side_effect = get_metrics_side_effect\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n        self.assertEqual(len(result['failures']), 2)\n    \n    def test_promote_with_no_metrics(self):\n        \"\"\"Test behavior when no metrics are available.\"\"\"\n        self.mock_telemetry_client.get_metrics.return_value = []\n        \n        context = {\n            'service_name': 'test-service',\n            'canary_version': 'v2.0.0',\n            'stable_version': 'v1.0.0',\n            'duration_minutes': 30,\n            'kpi_thresholds': {\n                'latency_ms_p99': {'max_relative_increase': 0.1},\n                'error_rate': {'max_absolute_value': 0.01}\n            }\n        }\n        \n        result = self.strategy.execute(context)\n        \n        # With no metrics, should PROMOTE (no failures detected)\n        self.assertTrue(result['success'])\n        self.assertEqual(result['recommendation'], 'PROMOTE')\n    \n    def test_invalid_context_returns_rollback(self):\n        \"\"\"Test that invalid context returns ROLLBACK.\"\"\"\n        context = {'service_name': 'test-service'}  # Missing required fields\n        \n        result = self.strategy.execute(context)\n        \n        self.assertFalse(result['success'])\n        self.assertEqual(result['recommendation'], 'ROLLBACK')\n    \n    def test_kpi_calculation(self):\n        \"\"\"Test KPI calculation from metrics.\"\"\"\n        metrics = [\n            {'metric_name': 'latency_ms_p99', 'value': 100.0},\n            {'metric_name': 'latency_ms_p99', 'value': 110.0},\n            {'metric_name': 'latency_ms_p99', 'value': 90.0},\n            {'metric_name': 'latency_ms_p99', 'value': 105.0},\n            {'metric_name': 'error_rate', 'value': 0.01},\n            {'metric_name': 'error_rate', 'value': 0.02}\n        ]\n        \n        kpis = self.strategy._calculate_kpis(metrics)\n        \n        # Check p99 latency (should be near 110)\n        self.assertGreater(kpis['latency_ms_p99'], 100)\n        # Check error rate average (should be 0.015)\n        self.assertAlmostEqual(kpis['error_rate'], 0.015, places=3)\n\n\nclass TestStrategyRegistry(unittest.TestCase):\n    \"\"\"Tests for StrategyRegistry.\"\"\"\n    \n    def test_default_strategies_registered(self):\n        \"\"\"Test that default strategies are registered.\"\"\"\n        registry = StrategyRegistry()\n        \n        self.assertIsNotNone(registry.get('auto_scaling'))\n        self.assertIsNotNone(registry.get('circuit_breaker'))\n        self.assertIsNotNone(registry.get('canary_analysis'))\n    \n    def test_list_strategies(self):\n        \"\"\"Test listing all strategies.\"\"\"\n        registry = StrategyRegistry()\n        strategies = registry.list_strategies()\n        \n        self.assertGreaterEqual(len(strategies), 3)\n        names = [s['name'] for s in strategies]\n        self.assertIn('auto_scaling', names)\n        self.assertIn('circuit_breaker', names)\n        self.assertIn('canary_analysis', names)\n\n\nif __name__ == '__main__':\n    unittest.main()\n",
            "edupulse_insight_mesh/docs/api/openapi.yaml": "openapi: 3.0.3\ninfo:\n  title: EduPulse Insight Mesh API\n  description: |\n    API for the EduPulse Insight Mesh observability and remediation platform.\n    This API provides endpoints for telemetry ingestion, querying, and \n    automated remediation strategies including canary analysis.\n  version: 1.1.0\n  contact:\n    name: EduPulse Team\n    email: support@edupulse.io\n\nservers:\n  - url: http://localhost:8080/api/v1\n    description: Local development server\n  - url: https://api.edupulse.io/api/v1\n    description: Production server\n\nsecurity:\n  - ApiKeyAuth: []\n\ntags:\n  - name: Health\n    description: Health check endpoints\n  - name: Metrics\n    description: Metric ingestion and querying\n  - name: Telemetry\n    description: Telemetry data access\n  - name: Analysis\n    description: Deployment analysis endpoints\n  - name: Strategies\n    description: Remediation strategy management\n\npaths:\n  /health:\n    get:\n      tags:\n        - Health\n      summary: Health check\n      description: Returns the health status of the API gateway\n      operationId: healthCheck\n      security: []\n      responses:\n        '200':\n          description: Service is healthy\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/HealthResponse'\n\n  /metrics:\n    post:\n      tags:\n        - Metrics\n      summary: Ingest metrics\n      description: Ingest metrics from agents or external sources\n      operationId: ingestMetrics\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/MetricPayload'\n      responses:\n        '202':\n          description: Metrics accepted for processing\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/AcceptedResponse'\n        '400':\n          description: Invalid payload\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '401':\n          description: Unauthorized\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /telemetry/{service_name}:\n    get:\n      tags:\n        - Telemetry\n      summary: Get telemetry data\n      description: Retrieve telemetry data for a specific service\n      operationId: getTelemetry\n      parameters:\n        - name: service_name\n          in: path\n          required: true\n          schema:\n            type: string\n          description: Name of the service\n        - name: version\n          in: query\n          required: false\n          schema:\n            type: string\n          description: Filter by deployment version\n        - name: duration_minutes\n          in: query\n          required: false\n          schema:\n            type: integer\n            default: 60\n          description: Time window in minutes\n      responses:\n        '200':\n          description: Telemetry data retrieved successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/TelemetryResponse'\n        '401':\n          description: Unauthorized\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '500':\n          description: Internal server error\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /analysis/canary:\n    post:\n      tags:\n        - Analysis\n      summary: Initiate canary analysis\n      description: |\n        Initiates a canary analysis comparing a new canary deployment against\n        the existing stable deployment. The analysis compares key performance\n        indicators (KPIs) over a specified duration and returns a recommendation\n        to either PROMOTE the canary or ROLLBACK the deployment.\n      operationId: canaryAnalysis\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/CanaryAnalysisRequest'\n            examples:\n              basic:\n                summary: Basic canary analysis\n                value:\n                  service_name: \"user-service\"\n                  canary_version: \"v2.0.0\"\n                  stable_version: \"v1.5.0\"\n                  duration_minutes: 30\n                  kpi_thresholds:\n                    latency_ms_p99:\n                      max_relative_increase: 0.1\n                    error_rate:\n                      max_absolute_value: 0.01\n      responses:\n        '200':\n          description: Canary analysis completed successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/CanaryAnalysisResponse'\n              examples:\n                promote:\n                  summary: Promote recommendation\n                  value:\n                    service_name: \"user-service\"\n                    canary_version: \"v2.0.0\"\n                    stable_version: \"v1.5.0\"\n                    recommendation: \"PROMOTE\"\n                    justification: \"All KPI checks passed. Canary latency: 95.5ms, error rate: 0.005\"\n                    analysis_id: \"550e8400-e29b-41d4-a716-446655440000\"\n                rollback:\n                  summary: Rollback recommendation\n                  value:\n                    service_name: \"user-service\"\n                    canary_version: \"v2.0.0\"\n                    stable_version: \"v1.5.0\"\n                    recommendation: \"ROLLBACK\"\n                    justification: \"Canary latency 150.00ms exceeded stable latency 100.00ms by 50.0% (max allowed: 10%)\"\n                    analysis_id: \"550e8400-e29b-41d4-a716-446655440001\"\n        '400':\n          description: Invalid request payload\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n              example:\n                error: \"Invalid payload\"\n                details:\n                  - loc: [\"body\", \"duration_minutes\"]\n                    msg: \"ensure this value is greater than 0\"\n                    type: \"value_error.number.not_gt\"\n        '401':\n          description: Unauthorized - missing or invalid API key\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '500':\n          description: Internal server error\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /strategies:\n    get:\n      tags:\n        - Strategies\n      summary: List available strategies\n      description: Returns a list of all available remediation strategies\n      operationId: listStrategies\n      responses:\n        '200':\n          description: List of strategies\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/StrategiesResponse'\n\ncomponents:\n  securitySchemes:\n    ApiKeyAuth:\n      type: apiKey\n      in: header\n      name: X-API-Key\n      description: API key for authentication\n\n  schemas:\n    HealthResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          example: \"healthy\"\n        version:\n          type: string\n          example: \"1.0.0\"\n      required:\n        - status\n\n    MetricPayload:\n      type: object\n      properties:\n        service_name:\n          type: string\n          description: Name of the service sending metrics\n          example: \"user-service\"\n        metric_name:\n          type: string\n          description: Name of the metric\n          example: \"latency_ms_p99\"\n        value:\n          type: number\n          format: double\n          description: Metric value\n          example: 125.5\n        timestamp:\n          type: string\n          format: date-time\n          description: ISO 8601 timestamp (optional, defaults to server time)\n          example: \"2024-01-15T10:30:00Z\"\n        tags:\n          type: object\n          additionalProperties:\n            type: string\n          description: Additional tags including version for canary analysis\n          example:\n            version: \"v2.0.0\"\n            environment: \"production\"\n            deployment_type: \"canary\"\n      required:\n        - service_name\n        - metric_name\n        - value\n\n    AcceptedResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          example: \"accepted\"\n        id:\n          type: string\n          description: Unique identifier for the ingested data\n          example: \"550e8400-e29b-41d4-a716-446655440000\"\n\n    TelemetryResponse:\n      type: object\n      properties:\n        service_name:\n          type: string\n        metrics:\n          type: array\n          items:\n            type: object\n\n    CanaryAnalysisRequest:\n      type: object\n      properties:\n        service_name:\n          type: string\n          description: Name of the service to analyze\n          minLength: 1\n          example: \"user-service\"\n        canary_version:\n          type: string\n          description: Version string of the canary deployment\n          minLength: 1\n          example: \"v2.0.0\"\n        stable_version:\n          type: string\n          description: Version string of the stable deployment\n          minLength: 1\n          example: \"v1.5.0\"\n        duration_minutes:\n          type: integer\n          description: Duration in minutes to analyze metrics\n          minimum: 1\n          maximum: 1440\n          example: 30\n        kpi_thresholds:\n          type: object\n          description: KPI threshold configurations\n          properties:\n            latency_ms_p99:\n              $ref: '#/components/schemas/LatencyThreshold'\n            error_rate:\n              $ref: '#/components/schemas/ErrorRateThreshold'\n          additionalProperties:\n            type: object\n      required:\n        - service_name\n        - canary_version\n        - stable_version\n        - duration_minutes\n        - kpi_thresholds\n\n    LatencyThreshold:\n      type: object\n      properties:\n        max_relative_increase:\n          type: number\n          format: double\n          description: Maximum allowed relative increase compared to stable (e.g., 0.1 = 10%)\n          minimum: 0\n          maximum: 1\n          example: 0.1\n\n    ErrorRateThreshold:\n      type: object\n      properties:\n        max_absolute_value:\n          type: number\n          format: double\n          description: Maximum allowed absolute error rate (e.g., 0.01 = 1%)\n          minimum: 0\n          maximum: 1\n          example: 0.01\n\n    CanaryAnalysisResponse:\n      type: object\n      properties:\n        service_name:\n          type: string\n          description: Name of the analyzed service\n          example: \"user-service\"\n        canary_version:\n          type: string\n          description: Version of the canary deployment\n          example: \"v2.0.0\"\n        stable_version:\n          type: string\n          description: Version of the stable deployment\n          example: \"v1.5.0\"\n        recommendation:\n          type: string\n          enum:\n            - PROMOTE\n            - ROLLBACK\n          description: Recommended action based on analysis\n          example: \"PROMOTE\"\n        justification:\n          type: string\n          description: Human-readable explanation of the recommendation\n          example: \"All KPI checks passed. Canary latency: 95.5ms, error rate: 0.005\"\n        analysis_id:\n          type: string\n          format: uuid\n          description: Unique identifier for this analysis\n          example: \"550e8400-e29b-41d4-a716-446655440000\"\n      required:\n        - service_name\n        - canary_version\n        - stable_version\n        - recommendation\n        - justification\n        - analysis_id\n\n    StrategiesResponse:\n      type: object\n      properties:\n        strategies:\n          type: array\n          items:\n            type: object\n            properties:\n              name:\n                type: string\n              description:\n                type: string\n\n    ErrorResponse:\n      type: object\n      properties:\n        error:\n          type: string\n          description: Error message\n        message:\n          type: string\n          description: Additional error details\n        details:\n          type: array\n          items:\n            type: object\n          description: Validation error details\n"
          },
          "generated_files": [
            "edupulse_insight_mesh/src/api_gateway/routes.py",
            "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py",
            "edupulse_insight_mesh/src/strategy_service/strategies.py",
            "edupulse_insight_mesh/src/remediation_service/commands.py",
            "edupulse_insight_mesh/src/core_telemetry/service.py",
            "edupulse_insight_mesh/tests/test_strategy_service.py",
            "edupulse_insight_mesh/docs/api/openapi.yaml"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.6901068303216275,
                "dependency_traversal_accuracy": 0.7639205154242522,
                "cross_file_reasoning_depth": 0.3888095238095238,
                "system_thinking_score": 0.5253915145918892,
                "robustness_score": 0.3592293493308722,
                "comprehensiveness_score": 0.6433507107055884,
                "innovation_score": 0.31875,
                "solution_elegance_score": 0.4656374150637144
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.08626335379020343,
                "dependency_traversal_weighted": 0.09549006442803153,
                "cross_file_reasoning_weighted": 0.04860119047619048,
                "system_thinking_weighted": 0.06567393932398614,
                "robustness_weighted": 0.044903668666359024,
                "comprehensiveness_weighted": 0.08041883883819854,
                "innovation_weighted": 0.03984375,
                "solution_elegance_weighted": 0.0582046768829643
              },
              "total_software_engineering_score": 0.5193994824059335
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.46472954750061035,
                "errors": [
                  "  File \"edupulse_insight_mesh/docs/api/openapi.py\", line 1",
                  "    openapi: 3.0.3",
                  "                ^^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "edupulse_insight_mesh/src/api_gateway/routes.py",
                  "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py",
                  "edupulse_insight_mesh/src/strategy_service/strategies.py",
                  "edupulse_insight_mesh/src/remediation_service/commands.py",
                  "edupulse_insight_mesh/src/core_telemetry/service.py",
                  "edupulse_insight_mesh/tests/test_strategy_service.py",
                  "edupulse_insight_mesh/docs/api/openapi.yaml"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 7,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 7 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.31830751417391995,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.31830751417391995,
                "idc_weight": 0.2,
                "total_functional_score": 0.40366150283478397
              }
            },
            "code_quality_details": {
              "files_analyzed": 7,
              "quality_checks": {
                "edupulse_insight_mesh/src/api_gateway/routes.py": {
                  "line_count": 187,
                  "non_empty_lines": 145,
                  "comment_lines": 6,
                  "comment_ratio": 0.041379310344827586,
                  "function_count": 6,
                  "class_count": 5,
                  "import_count": 20,
                  "quality_score": 0.7999999999999999
                },
                "edupulse_insight_mesh/src/ingestion_pipeline/handlers.py": {
                  "line_count": 267,
                  "non_empty_lines": 195,
                  "comment_lines": 19,
                  "comment_ratio": 0.09743589743589744,
                  "function_count": 18,
                  "class_count": 11,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "edupulse_insight_mesh/src/strategy_service/strategies.py": {
                  "line_count": 362,
                  "non_empty_lines": 288,
                  "comment_lines": 9,
                  "comment_ratio": 0.03125,
                  "function_count": 21,
                  "class_count": 6,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "edupulse_insight_mesh/src/remediation_service/commands.py": {
                  "line_count": 331,
                  "non_empty_lines": 267,
                  "comment_lines": 8,
                  "comment_ratio": 0.0299625468164794,
                  "function_count": 25,
                  "class_count": 8,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "edupulse_insight_mesh/src/core_telemetry/service.py": {
                  "line_count": 209,
                  "non_empty_lines": 175,
                  "comment_lines": 8,
                  "comment_ratio": 0.045714285714285714,
                  "function_count": 6,
                  "class_count": 1,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "edupulse_insight_mesh/tests/test_strategy_service.py": {
                  "line_count": 378,
                  "non_empty_lines": 306,
                  "comment_lines": 10,
                  "comment_ratio": 0.032679738562091505,
                  "function_count": 25,
                  "class_count": 4,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "edupulse_insight_mesh/docs/api/openapi.yaml": {
                  "line_count": 433,
                  "non_empty_lines": 413,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 1,
                  "quality_score": 0.7
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7899999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.878619691119691,
                "multi_session_memory_retention": 0.8191985088536811
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4393098455598455,
                "multi_session_memory_retention_weighted": 0.40959925442684053
              },
              "total_longcontext_utilization_score": 0.848909099986686
            }
          },
          "timestamp": "2026-01-14T21:10:49.733439"
        }
      }
    },
    "python_desktop_productivity_easy_091_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_desktop_productivity_easy_091_feature_implementation_expert_01",
          "scenario_title": "Implement User Profiles for Context Switching",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5230273001373705,
          "functional_correctness_score": 0.37047674418604654,
          "code_quality_score": 0.7999999999999999,
          "longcontext_utilization_score": 0.8007954545454545,
          "total_score": 2.802167443826538,
          "generation_time": 229.6129539012909,
          "code_files_generated": 6,
          "total_lines_generated": 2126,
          "parsing_success": true,
          "solution_code": {
            "QuestBoard_Maestro/services/settings_service.py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, asdict, field\n\n\n@dataclass\nclass ProfileSettings:\n    \"\"\"Settings for a single profile.\"\"\"\n    name: str\n    theme: str = \"default\"\n    notifications_enabled: bool = True\n    auto_save: bool = True\n    quest_sort_order: str = \"priority\"\n    show_completed: bool = True\n    custom_settings: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -> Dict[str, Any]:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'ProfileSettings':\n        return cls(\n            name=data.get('name', 'Unnamed'),\n            theme=data.get('theme', 'default'),\n            notifications_enabled=data.get('notifications_enabled', True),\n            auto_save=data.get('auto_save', True),\n            quest_sort_order=data.get('quest_sort_order', 'priority'),\n            show_completed=data.get('show_completed', True),\n            custom_settings=data.get('custom_settings', {})\n        )\n\n\n@dataclass\nclass GlobalConfig:\n    \"\"\"Global application configuration (not profile-specific).\"\"\"\n    last_active_profile: str = \"Primary\"\n    available_profiles: List[str] = field(default_factory=list)\n    window_geometry: Dict[str, int] = field(default_factory=lambda: {'x': 100, 'y': 100, 'width': 800, 'height': 600})\n\n    def to_dict(self) -> Dict[str, Any]:\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'GlobalConfig':\n        return cls(\n            last_active_profile=data.get('last_active_profile', 'Primary'),\n            available_profiles=data.get('available_profiles', []),\n            window_geometry=data.get('window_geometry', {'x': 100, 'y': 100, 'width': 800, 'height': 600})\n        )\n\n\nclass SettingsService:\n    \"\"\"Service for managing application settings and user profiles.\"\"\"\n\n    def __init__(self, config_dir: Optional[str] = None):\n        if config_dir:\n            self._config_dir = Path(config_dir)\n        else:\n            self._config_dir = Path.home() / '.questboard_maestro'\n        self._config_dir.mkdir(parents=True, exist_ok=True)\n\n        self._global_config_file = self._config_dir / 'global_config.json'\n        self._global_config: GlobalConfig = GlobalConfig()\n        self._active_profile: Optional[ProfileSettings] = None\n        self._active_profile_name: str = \"\"\n\n        self._load_global_config()\n\n    @property\n    def config_dir(self) -> Path:\n        return self._config_dir\n\n    @property\n    def active_profile(self) -> Optional[ProfileSettings]:\n        return self._active_profile\n\n    @property\n    def active_profile_name(self) -> str:\n        return self._active_profile_name\n\n    @property\n    def global_config(self) -> GlobalConfig:\n        return self._global_config\n\n    def _get_profile_settings_path(self, profile_name: str) -> Path:\n        \"\"\"Get the path to a profile's settings file.\"\"\"\n        safe_name = self._sanitize_profile_name(profile_name)\n        return self._config_dir / f'settings_{safe_name}.json'\n\n    def _sanitize_profile_name(self, name: str) -> str:\n        \"\"\"Sanitize profile name for use in filenames.\"\"\"\n        return ''.join(c if c.isalnum() or c in ('_', '-') else '_' for c in name.lower())\n\n    def _load_global_config(self) -> None:\n        \"\"\"Load the global configuration file.\"\"\"\n        if self._global_config_file.exists():\n            try:\n                with open(self._global_config_file, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    self._global_config = GlobalConfig.from_dict(data)\n            except (json.JSONDecodeError, IOError) as e:\n                print(f\"Error loading global config: {e}\")\n                self._global_config = GlobalConfig()\n        else:\n            self._global_config = GlobalConfig()\n\n    def _save_global_config(self) -> None:\n        \"\"\"Save the global configuration file.\"\"\"\n        try:\n            with open(self._global_config_file, 'w', encoding='utf-8') as f:\n                json.dump(self._global_config.to_dict(), f, indent=2)\n        except IOError as e:\n            print(f\"Error saving global config: {e}\")\n\n    def get_available_profiles(self) -> List[str]:\n        \"\"\"Get list of all available profile names.\"\"\"\n        return list(self._global_config.available_profiles)\n\n    def profile_exists(self, profile_name: str) -> bool:\n        \"\"\"Check if a profile exists.\"\"\"\n        return profile_name in self._global_config.available_profiles\n\n    def create_profile(self, profile_name: str, base_settings: Optional[Dict[str, Any]] = None) -> bool:\n        \"\"\"Create a new profile with the given name.\"\"\"\n        if self.profile_exists(profile_name):\n            return False\n\n        if base_settings:\n            base_settings['name'] = profile_name\n            settings = ProfileSettings.from_dict(base_settings)\n        else:\n            settings = ProfileSettings(name=profile_name)\n\n        settings_path = self._get_profile_settings_path(profile_name)\n        try:\n            with open(settings_path, 'w', encoding='utf-8') as f:\n                json.dump(settings.to_dict(), f, indent=2)\n\n            self._global_config.available_profiles.append(profile_name)\n            self._save_global_config()\n            return True\n        except IOError as e:\n            print(f\"Error creating profile {profile_name}: {e}\")\n            return False\n\n    def delete_profile(self, profile_name: str) -> bool:\n        \"\"\"Delete a profile and its associated files.\"\"\"\n        if not self.profile_exists(profile_name):\n            return False\n\n        if profile_name == self._active_profile_name:\n            return False\n\n        settings_path = self._get_profile_settings_path(profile_name)\n        quest_path = self.get_quest_file_path(profile_name)\n\n        try:\n            if settings_path.exists():\n                settings_path.unlink()\n            if quest_path.exists():\n                quest_path.unlink()\n\n            self._global_config.available_profiles.remove(profile_name)\n            self._save_global_config()\n            return True\n        except IOError as e:\n            print(f\"Error deleting profile {profile_name}: {e}\")\n            return False\n\n    def load_profile(self, profile_name: str) -> bool:\n        \"\"\"Load a profile as the active profile.\"\"\"\n        if not self.profile_exists(profile_name):\n            return False\n\n        settings_path = self._get_profile_settings_path(profile_name)\n        try:\n            with open(settings_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                self._active_profile = ProfileSettings.from_dict(data)\n                self._active_profile_name = profile_name\n                self._global_config.last_active_profile = profile_name\n                self._save_global_config()\n                return True\n        except (json.JSONDecodeError, IOError) as e:\n            print(f\"Error loading profile {profile_name}: {e}\")\n            return False\n\n    def save_active_profile(self) -> bool:\n        \"\"\"Save the current active profile settings.\"\"\"\n        if not self._active_profile:\n            return False\n\n        settings_path = self._get_profile_settings_path(self._active_profile_name)\n        try:\n            with open(settings_path, 'w', encoding='utf-8') as f:\n                json.dump(self._active_profile.to_dict(), f, indent=2)\n            return True\n        except IOError as e:\n            print(f\"Error saving active profile: {e}\")\n            return False\n\n    def switch_profile(self, profile_name: str) -> bool:\n        \"\"\"Switch to a different profile (saves current first).\"\"\"\n        if not self.profile_exists(profile_name):\n            return False\n\n        self.save_active_profile()\n        return self.load_profile(profile_name)\n\n    def get_quest_file_path(self, profile_name: Optional[str] = None) -> Path:\n        \"\"\"Get the path to the quest data file for a profile.\"\"\"\n        name = profile_name or self._active_profile_name\n        safe_name = self._sanitize_profile_name(name)\n        return self._config_dir / f'quests_{safe_name}.json'\n\n    def get_active_quest_file_path(self) -> Path:\n        \"\"\"Get the path to the active profile's quest file.\"\"\"\n        return self.get_quest_file_path(self._active_profile_name)\n\n    def get_last_active_profile(self) -> str:\n        \"\"\"Get the name of the last active profile.\"\"\"\n        return self._global_config.last_active_profile\n\n    def update_setting(self, key: str, value: Any) -> None:\n        \"\"\"Update a setting in the active profile.\"\"\"\n        if self._active_profile:\n            if hasattr(self._active_profile, key):\n                setattr(self._active_profile, key, value)\n            else:\n                self._active_profile.custom_settings[key] = value\n            self.save_active_profile()\n\n    def get_setting(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get a setting from the active profile.\"\"\"\n        if self._active_profile:\n            if hasattr(self._active_profile, key):\n                return getattr(self._active_profile, key)\n            return self._active_profile.custom_settings.get(key, default)\n        return default\n\n    def get_theme(self) -> str:\n        \"\"\"Get the theme setting from the active profile.\"\"\"\n        if self._active_profile:\n            return self._active_profile.theme\n        return \"default\"\n\n    def set_theme(self, theme_name: str) -> None:\n        \"\"\"Set the theme for the active profile.\"\"\"\n        if self._active_profile:\n            self._active_profile.theme = theme_name\n            self.save_active_profile()\n\n    def save_window_geometry(self, x: int, y: int, width: int, height: int) -> None:\n        \"\"\"Save window geometry to global config.\"\"\"\n        self._global_config.window_geometry = {'x': x, 'y': y, 'width': width, 'height': height}\n        self._save_global_config()\n\n    def get_window_geometry(self) -> Dict[str, int]:\n        \"\"\"Get saved window geometry.\"\"\"\n        return self._global_config.window_geometry\n\n\n# Singleton instance\n_settings_service_instance: Optional[SettingsService] = None\n\n\ndef get_settings_service(config_dir: Optional[str] = None) -> SettingsService:\n    \"\"\"Get or create the singleton settings service instance.\"\"\"\n    global _settings_service_instance\n    if _settings_service_instance is None:\n        _settings_service_instance = SettingsService(config_dir)\n    return _settings_service_instance\n\n\ndef reset_settings_service() -> None:\n    \"\"\"Reset the singleton instance (mainly for testing).\"\"\"\n    global _settings_service_instance\n    _settings_service_instance = None\n",
            "QuestBoard_Maestro/services/theme_service.py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Callable, List\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass ThemeColors:\n    \"\"\"Theme color definitions.\"\"\"\n    primary: str = \"#3498db\"\n    secondary: str = \"#2ecc71\"\n    background: str = \"#2c3e50\"\n    surface: str = \"#34495e\"\n    text: str = \"#ecf0f1\"\n    text_secondary: str = \"#bdc3c7\"\n    accent: str = \"#e74c3c\"\n    success: str = \"#27ae60\"\n    warning: str = \"#f39c12\"\n    error: str = \"#c0392b\"\n    border: str = \"#7f8c8d\"\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, str]) -> 'ThemeColors':\n        return cls(\n            primary=data.get('primary', '#3498db'),\n            secondary=data.get('secondary', '#2ecc71'),\n            background=data.get('background', '#2c3e50'),\n            surface=data.get('surface', '#34495e'),\n            text=data.get('text', '#ecf0f1'),\n            text_secondary=data.get('text_secondary', '#bdc3c7'),\n            accent=data.get('accent', '#e74c3c'),\n            success=data.get('success', '#27ae60'),\n            warning=data.get('warning', '#f39c12'),\n            error=data.get('error', '#c0392b'),\n            border=data.get('border', '#7f8c8d')\n        )\n\n\n@dataclass\nclass Theme:\n    \"\"\"Complete theme definition.\"\"\"\n    name: str\n    display_name: str\n    colors: ThemeColors\n    font_family: str = \"Segoe UI\"\n    font_size: int = 10\n    border_radius: int = 4\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Theme':\n        colors = ThemeColors.from_dict(data.get('colors', {}))\n        return cls(\n            name=data.get('name', 'default'),\n            display_name=data.get('display_name', 'Default'),\n            colors=colors,\n            font_family=data.get('font_family', 'Segoe UI'),\n            font_size=data.get('font_size', 10),\n            border_radius=data.get('border_radius', 4)\n        )\n\n    def generate_stylesheet(self) -> str:\n        \"\"\"Generate Qt stylesheet from theme.\"\"\"\n        return f\"\"\"\n        QMainWindow, QWidget {{\n            background-color: {self.colors.background};\n            color: {self.colors.text};\n            font-family: {self.font_family};\n            font-size: {self.font_size}pt;\n        }}\n\n        QMenuBar {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border-bottom: 1px solid {self.colors.border};\n        }}\n\n        QMenuBar::item:selected {{\n            background-color: {self.colors.primary};\n        }}\n\n        QMenu {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n        }}\n\n        QMenu::item:selected {{\n            background-color: {self.colors.primary};\n        }}\n\n        QPushButton {{\n            background-color: {self.colors.primary};\n            color: {self.colors.text};\n            border: none;\n            padding: 8px 16px;\n            border-radius: {self.border_radius}px;\n        }}\n\n        QPushButton:hover {{\n            background-color: {self.colors.secondary};\n        }}\n\n        QPushButton:pressed {{\n            background-color: {self.colors.accent};\n        }}\n\n        QLineEdit, QTextEdit, QPlainTextEdit {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            padding: 4px;\n        }}\n\n        QLineEdit:focus, QTextEdit:focus, QPlainTextEdit:focus {{\n            border: 1px solid {self.colors.primary};\n        }}\n\n        QListWidget, QTreeWidget, QTableWidget {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n        }}\n\n        QListWidget::item:selected, QTreeWidget::item:selected {{\n            background-color: {self.colors.primary};\n        }}\n\n        QListWidget::item:hover, QTreeWidget::item:hover {{\n            background-color: {self.colors.surface};\n        }}\n\n        QComboBox {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            padding: 4px 8px;\n        }}\n\n        QComboBox:hover {{\n            border: 1px solid {self.colors.primary};\n        }}\n\n        QComboBox::drop-down {{\n            border: none;\n        }}\n\n        QComboBox QAbstractItemView {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text};\n            selection-background-color: {self.colors.primary};\n        }}\n\n        QScrollBar:vertical {{\n            background-color: {self.colors.background};\n            width: 12px;\n            border-radius: 6px;\n        }}\n\n        QScrollBar::handle:vertical {{\n            background-color: {self.colors.border};\n            border-radius: 6px;\n            min-height: 20px;\n        }}\n\n        QScrollBar::handle:vertical:hover {{\n            background-color: {self.colors.primary};\n        }}\n\n        QLabel {{\n            color: {self.colors.text};\n        }}\n\n        QGroupBox {{\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            margin-top: 8px;\n            padding-top: 8px;\n        }}\n\n        QGroupBox::title {{\n            color: {self.colors.text};\n            subcontrol-origin: margin;\n            left: 10px;\n        }}\n\n        QCheckBox {{\n            color: {self.colors.text};\n        }}\n\n        QCheckBox::indicator {{\n            width: 16px;\n            height: 16px;\n            border: 1px solid {self.colors.border};\n            border-radius: 3px;\n            background-color: {self.colors.surface};\n        }}\n\n        QCheckBox::indicator:checked {{\n            background-color: {self.colors.primary};\n        }}\n\n        QStatusBar {{\n            background-color: {self.colors.surface};\n            color: {self.colors.text_secondary};\n        }}\n\n        QToolBar {{\n            background-color: {self.colors.surface};\n            border: none;\n            spacing: 4px;\n        }}\n\n        QProgressBar {{\n            background-color: {self.colors.surface};\n            border: 1px solid {self.colors.border};\n            border-radius: {self.border_radius}px;\n            text-align: center;\n            color: {self.colors.text};\n        }}\n\n        QProgressBar::chunk {{\n            background-color: {self.colors.primary};\n            border-radius: {self.border_radius}px;\n        }}\n        \"\"\"\n\n\nclass ThemeService:\n    \"\"\"Service for managing application themes.\"\"\"\n\n    def __init__(self, themes_dir: Optional[str] = None):\n        if themes_dir:\n            self._themes_dir = Path(themes_dir)\n        else:\n            self._themes_dir = Path(__file__).parent.parent / 'assets' / 'themes'\n\n        self._themes: Dict[str, Theme] = {}\n        self._current_theme: Optional[Theme] = None\n        self._settings_service = None\n        self._theme_change_callbacks: List[Callable[[Theme], None]] = []\n\n        self._load_themes()\n        self._ensure_default_theme()\n\n    def set_settings_service(self, settings_service) -> None:\n        \"\"\"Set the settings service for profile-aware theme loading.\"\"\"\n        self._settings_service = settings_service\n\n    def _load_themes(self) -> None:\n        \"\"\"Load all available themes from the themes directory.\"\"\"\n        if not self._themes_dir.exists():\n            self._themes_dir.mkdir(parents=True, exist_ok=True)\n            return\n\n        for theme_file in self._themes_dir.glob('*.json'):\n            try:\n                with open(theme_file, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    theme = Theme.from_dict(data)\n                    self._themes[theme.name] = theme\n            except (json.JSONDecodeError, IOError) as e:\n                print(f\"Error loading theme {theme_file}: {e}\")\n\n    def _ensure_default_theme(self) -> None:\n        \"\"\"Ensure a default theme exists.\"\"\"\n        if 'default' not in self._themes:\n            default_theme = Theme(\n                name='default',\n                display_name='Default Dark',\n                colors=ThemeColors()\n            )\n            self._themes['default'] = default_theme\n            self._save_theme(default_theme)\n\n        if 'light' not in self._themes:\n            light_theme = Theme(\n                name='light',\n                display_name='Light',\n                colors=ThemeColors(\n                    primary='#3498db',\n                    secondary='#2ecc71',\n                    background='#f5f6fa',\n                    surface='#ffffff',\n                    text='#2c3e50',\n                    text_secondary='#7f8c8d',\n                    accent='#e74c3c',\n                    success='#27ae60',\n                    warning='#f39c12',\n                    error='#c0392b',\n                    border='#dcdde1'\n                )\n            )\n            self._themes['light'] = light_theme\n            self._save_theme(light_theme)\n\n    def _save_theme(self, theme: Theme) -> None:\n        \"\"\"Save a theme to file.\"\"\"\n        theme_file = self._themes_dir / f'{theme.name}.json'\n        try:\n            self._themes_dir.mkdir(parents=True, exist_ok=True)\n            with open(theme_file, 'w', encoding='utf-8') as f:\n                json.dump({\n                    'name': theme.name,\n                    'display_name': theme.display_name,\n                    'colors': {\n                        'primary': theme.colors.primary,\n                        'secondary': theme.colors.secondary,\n                        'background': theme.colors.background,\n                        'surface': theme.colors.surface,\n                        'text': theme.colors.text,\n                        'text_secondary': theme.colors.text_secondary,\n                        'accent': theme.colors.accent,\n                        'success': theme.colors.success,\n                        'warning': theme.colors.warning,\n                        'error': theme.colors.error,\n                        'border': theme.colors.border\n                    },\n                    'font_family': theme.font_family,\n                    'font_size': theme.font_size,\n                    'border_radius': theme.border_radius\n                }, f, indent=2)\n        except IOError as e:\n            print(f\"Error saving theme {theme.name}: {e}\")\n\n    def get_available_themes(self) -> List[str]:\n        \"\"\"Get list of available theme names.\"\"\"\n        return list(self._themes.keys())\n\n    def get_theme(self, name: str) -> Optional[Theme]:\n        \"\"\"Get a theme by name.\"\"\"\n        return self._themes.get(name)\n\n    def get_current_theme(self) -> Optional[Theme]:\n        \"\"\"Get the currently active theme.\"\"\"\n        return self._current_theme\n\n    def load_theme_from_profile(self) -> Theme:\n        \"\"\"Load theme based on the active profile's settings.\"\"\"\n        theme_name = 'default'\n        if self._settings_service:\n            theme_name = self._settings_service.get_theme()\n\n        return self.set_theme(theme_name)\n\n    def set_theme(self, name: str) -> Theme:\n        \"\"\"Set the active theme by name.\"\"\"\n        theme = self._themes.get(name)\n        if not theme:\n            theme = self._themes.get('default', Theme(\n                name='default',\n                display_name='Default',\n                colors=ThemeColors()\n            ))\n\n        self._current_theme = theme\n\n        # Notify all registered callbacks\n        for callback in self._theme_change_callbacks:\n            try:\n                callback(theme)\n            except Exception as e:\n                print(f\"Error in theme change callback: {e}\")\n\n        return theme\n\n    def register_theme_change_callback(self, callback: Callable[[Theme], None]) -> None:\n        \"\"\"Register a callback to be called when theme changes.\"\"\"\n        if callback not in self._theme_change_callbacks:\n            self._theme_change_callbacks.append(callback)\n\n    def unregister_theme_change_callback(self, callback: Callable[[Theme], None]) -> None:\n        \"\"\"Unregister a theme change callback.\"\"\"\n        if callback in self._theme_change_callbacks:\n            self._theme_change_callbacks.remove(callback)\n\n    def get_stylesheet(self) -> str:\n        \"\"\"Get the stylesheet for the current theme.\"\"\"\n        if self._current_theme:\n            return self._current_theme.generate_stylesheet()\n        return \"\"\n\n    def get_color(self, color_name: str) -> str:\n        \"\"\"Get a specific color from the current theme.\"\"\"\n        if self._current_theme and hasattr(self._current_theme.colors, color_name):\n            return getattr(self._current_theme.colors, color_name)\n        return \"#000000\"\n\n\n# Singleton instance\n_theme_service_instance: Optional[ThemeService] = None\n\n\ndef get_theme_service(themes_dir: Optional[str] = None) -> ThemeService:\n    \"\"\"Get or create the singleton theme service instance.\"\"\"\n    global _theme_service_instance\n    if _theme_service_instance is None:\n        _theme_service_instance = ThemeService(themes_dir)\n    return _theme_service_instance\n\n\ndef reset_theme_service() -> None:\n    \"\"\"Reset the singleton instance (mainly for testing).\"\"\"\n    global _theme_service_instance\n    _theme_service_instance = None\n",
            "QuestBoard_Maestro/src/ui/quest_viewmodel.py": "import json\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Callable\nfrom dataclasses import dataclass, asdict, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\n\nclass QuestPriority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\n\nclass QuestStatus(Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    ARCHIVED = \"archived\"\n\n\n@dataclass\nclass Quest:\n    \"\"\"Represents a single quest/task.\"\"\"\n    id: str\n    title: str\n    description: str = \"\"\n    priority: QuestPriority = QuestPriority.MEDIUM\n    status: QuestStatus = QuestStatus.PENDING\n    created_at: str = \"\"\n    updated_at: str = \"\"\n    due_date: Optional[str] = None\n    tags: List[str] = field(default_factory=list)\n    subtasks: List[Dict[str, Any]] = field(default_factory=list)\n    progress: int = 0\n    notes: str = \"\"\n\n    def __post_init__(self):\n        if not self.created_at:\n            self.created_at = datetime.now().isoformat()\n        if not self.updated_at:\n            self.updated_at = datetime.now().isoformat()\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            'id': self.id,\n            'title': self.title,\n            'description': self.description,\n            'priority': self.priority.value,\n            'status': self.status.value,\n            'created_at': self.created_at,\n            'updated_at': self.updated_at,\n            'due_date': self.due_date,\n            'tags': self.tags,\n            'subtasks': self.subtasks,\n            'progress': self.progress,\n            'notes': self.notes\n        }\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Quest':\n        return cls(\n            id=data.get('id', str(uuid.uuid4())),\n            title=data.get('title', 'Untitled Quest'),\n            description=data.get('description', ''),\n            priority=QuestPriority(data.get('priority', 2)),\n            status=QuestStatus(data.get('status', 'pending')),\n            created_at=data.get('created_at', ''),\n            updated_at=data.get('updated_at', ''),\n            due_date=data.get('due_date'),\n            tags=data.get('tags', []),\n            subtasks=data.get('subtasks', []),\n            progress=data.get('progress', 0),\n            notes=data.get('notes', '')\n        )\n\n\nclass QuestViewModel:\n    \"\"\"ViewModel for managing quests with profile-aware persistence.\"\"\"\n\n    def __init__(self, settings_service=None):\n        self._settings_service = settings_service\n        self._quests: List[Quest] = []\n        self._change_callbacks: List[Callable[[], None]] = []\n        self._filter_status: Optional[QuestStatus] = None\n        self._filter_priority: Optional[QuestPriority] = None\n        self._search_term: str = \"\"\n\n    def set_settings_service(self, settings_service) -> None:\n        \"\"\"Set the settings service for profile-aware file management.\"\"\"\n        self._settings_service = settings_service\n\n    def _get_quest_file_path(self) -> Path:\n        \"\"\"Get the path to the quest file for the active profile.\"\"\"\n        if self._settings_service:\n            return self._settings_service.get_active_quest_file_path()\n        # Fallback for when no settings service is available\n        return Path.home() / '.questboard_maestro' / 'quests_default.json'\n\n    def load_quests(self) -> bool:\n        \"\"\"Load quests from the profile-specific file.\"\"\"\n        quest_file = self._get_quest_file_path()\n        self._quests = []\n\n        if not quest_file.exists():\n            self._notify_change()\n            return True\n\n        try:\n            with open(quest_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                quests_data = data.get('quests', [])\n                self._quests = [Quest.from_dict(q) for q in quests_data]\n            self._notify_change()\n            return True\n        except (json.JSONDecodeError, IOError) as e:\n            print(f\"Error loading quests: {e}\")\n            self._notify_change()\n            return False\n\n    def save_quests(self) -> bool:\n        \"\"\"Save quests to the profile-specific file.\"\"\"\n        quest_file = self._get_quest_file_path()\n\n        try:\n            quest_file.parent.mkdir(parents=True, exist_ok=True)\n            data = {\n                'version': '1.0',\n                'saved_at': datetime.now().isoformat(),\n                'quests': [q.to_dict() for q in self._quests]\n            }\n            with open(quest_file, 'w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2)\n            return True\n        except IOError as e:\n            print(f\"Error saving quests: {e}\")\n            return False\n\n    def add_quest(self, title: str, description: str = \"\",\n                  priority: QuestPriority = QuestPriority.MEDIUM,\n                  due_date: Optional[str] = None,\n                  tags: Optional[List[str]] = None) -> Quest:\n        \"\"\"Add a new quest.\"\"\"\n        quest = Quest(\n            id=str(uuid.uuid4()),\n            title=title,\n            description=description,\n            priority=priority,\n            due_date=due_date,\n            tags=tags or []\n        )\n        self._quests.append(quest)\n        self._auto_save()\n        self._notify_change()\n        return quest\n\n    def update_quest(self, quest_id: str, **kwargs) -> Optional[Quest]:\n        \"\"\"Update an existing quest.\"\"\"\n        quest = self.get_quest_by_id(quest_id)\n        if not quest:\n            return None\n\n        for key, value in kwargs.items():\n            if hasattr(quest, key):\n                if key == 'priority' and isinstance(value, int):\n                    value = QuestPriority(value)\n                elif key == 'status' and isinstance(value, str):\n                    value = QuestStatus(value)\n                setattr(quest, key, value)\n\n        quest.updated_at = datetime.now().isoformat()\n        self._auto_save()\n        self._notify_change()\n        return quest\n\n    def delete_quest(self, quest_id: str) -> bool:\n        \"\"\"Delete a quest by ID.\"\"\"\n        quest = self.get_quest_by_id(quest_id)\n        if quest:\n            self._quests.remove(quest)\n            self._auto_save()\n            self._notify_change()\n            return True\n        return False\n\n    def get_quest_by_id(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Get a quest by its ID.\"\"\"\n        for quest in self._quests:\n            if quest.id == quest_id:\n                return quest\n        return None\n\n    def get_all_quests(self) -> List[Quest]:\n        \"\"\"Get all quests.\"\"\"\n        return list(self._quests)\n\n    def get_filtered_quests(self) -> List[Quest]:\n        \"\"\"Get quests filtered by current filter settings.\"\"\"\n        filtered = self._quests\n\n        if self._filter_status:\n            filtered = [q for q in filtered if q.status == self._filter_status]\n\n        if self._filter_priority:\n            filtered = [q for q in filtered if q.priority == self._filter_priority]\n\n        if self._search_term:\n            term = self._search_term.lower()\n            filtered = [q for q in filtered if\n                       term in q.title.lower() or\n                       term in q.description.lower() or\n                       any(term in tag.lower() for tag in q.tags)]\n\n        return filtered\n\n    def set_filter_status(self, status: Optional[QuestStatus]) -> None:\n        \"\"\"Set the status filter.\"\"\"\n        self._filter_status = status\n        self._notify_change()\n\n    def set_filter_priority(self, priority: Optional[QuestPriority]) -> None:\n        \"\"\"Set the priority filter.\"\"\"\n        self._filter_priority = priority\n        self._notify_change()\n\n    def set_search_term(self, term: str) -> None:\n        \"\"\"Set the search term filter.\"\"\"\n        self._search_term = term\n        self._notify_change()\n\n    def clear_filters(self) -> None:\n        \"\"\"Clear all filters.\"\"\"\n        self._filter_status = None\n        self._filter_priority = None\n        self._search_term = \"\"\n        self._notify_change()\n\n    def complete_quest(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Mark a quest as completed.\"\"\"\n        return self.update_quest(quest_id, status=QuestStatus.COMPLETED, progress=100)\n\n    def archive_quest(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Archive a quest.\"\"\"\n        return self.update_quest(quest_id, status=QuestStatus.ARCHIVED)\n\n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get quest statistics.\"\"\"\n        total = len(self._quests)\n        completed = len([q for q in self._quests if q.status == QuestStatus.COMPLETED])\n        in_progress = len([q for q in self._quests if q.status == QuestStatus.IN_PROGRESS])\n        pending = len([q for q in self._quests if q.status == QuestStatus.PENDING])\n\n        return {\n            'total': total,\n            'completed': completed,\n            'in_progress': in_progress,\n            'pending': pending,\n            'completion_rate': (completed / total * 100) if total > 0 else 0\n        }\n\n    def register_change_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Register a callback for when quests change.\"\"\"\n        if callback not in self._change_callbacks:\n            self._change_callbacks.append(callback)\n\n    def unregister_change_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Unregister a change callback.\"\"\"\n        if callback in self._change_callbacks:\n            self._change_callbacks.remove(callback)\n\n    def _notify_change(self) -> None:\n        \"\"\"Notify all registered callbacks of a change.\"\"\"\n        for callback in self._change_callbacks:\n            try:\n                callback()\n            except Exception as e:\n                print(f\"Error in change callback: {e}\")\n\n    def _auto_save(self) -> None:\n        \"\"\"Auto-save if enabled in settings.\"\"\"\n        if self._settings_service:\n            if self._settings_service.get_setting('auto_save', True):\n                self.save_quests()\n        else:\n            self.save_quests()\n\n    def reload_for_profile(self) -> None:\n        \"\"\"Reload quests for the current profile (called on profile switch).\"\"\"\n        self.load_quests()\n\n    def sort_quests(self, key: str = 'priority', reverse: bool = True) -> None:\n        \"\"\"Sort quests by the specified key.\"\"\"\n        if key == 'priority':\n            self._quests.sort(key=lambda q: q.priority.value, reverse=reverse)\n        elif key == 'created_at':\n            self._quests.sort(key=lambda q: q.created_at, reverse=reverse)\n        elif key == 'due_date':\n            self._quests.sort(key=lambda q: q.due_date or '', reverse=reverse)\n        elif key == 'title':\n            self._quests.sort(key=lambda q: q.title.lower(), reverse=reverse)\n        elif key == 'status':\n            self._quests.sort(key=lambda q: q.status.value, reverse=reverse)\n\n        self._notify_change()\n",
            "QuestBoard_Maestro/src/ui/main_window.py": "from typing import Optional\nimport sys\n\ntry:\n    from PyQt6.QtWidgets import (\n        QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,\n        QListWidget, QListWidgetItem, QPushButton, QLabel,\n        QLineEdit, QTextEdit, QComboBox, QMenuBar, QMenu,\n        QStatusBar, QMessageBox, QInputDialog, QSplitter,\n        QFrame, QProgressBar, QToolBar, QDialog, QFormLayout,\n        QDialogButtonBox, QGroupBox, QCheckBox\n    )\n    from PyQt6.QtCore import Qt, QSize\n    from PyQt6.QtGui import QAction, QIcon\n    HAS_PYQT6 = True\nexcept ImportError:\n    HAS_PYQT6 = False\n    # Provide mock classes for environments without PyQt6\n    class QMainWindow:\n        def __init__(self, *args, **kwargs):\n            pass\n\n\nif HAS_PYQT6:\n    from .quest_viewmodel import QuestViewModel, Quest, QuestPriority, QuestStatus\n\n\nclass ProfileManager:\n    \"\"\"Helper class to manage profile operations.\"\"\"\n\n    def __init__(self, settings_service, theme_service, quest_viewmodel):\n        self.settings_service = settings_service\n        self.theme_service = theme_service\n        self.quest_viewmodel = quest_viewmodel\n\n    def initialize_profiles(self) -> str:\n        \"\"\"Initialize profiles on startup, returns active profile name.\"\"\"\n        profiles = self.settings_service.get_available_profiles()\n\n        if not profiles:\n            # First run - create default profile\n            self.settings_service.create_profile('Primary')\n            self.settings_service.load_profile('Primary')\n            return 'Primary'\n\n        # Load last active profile\n        last_profile = self.settings_service.get_last_active_profile()\n        if last_profile and self.settings_service.profile_exists(last_profile):\n            self.settings_service.load_profile(last_profile)\n            return last_profile\n\n        # Fallback to first available profile\n        self.settings_service.load_profile(profiles[0])\n        return profiles[0]\n\n    def switch_profile(self, profile_name: str) -> bool:\n        \"\"\"Switch to a different profile.\"\"\"\n        if not self.settings_service.profile_exists(profile_name):\n            return False\n\n        # Save current quest state\n        self.quest_viewmodel.save_quests()\n\n        # Save current profile settings\n        self.settings_service.save_active_profile()\n\n        # Switch to new profile\n        if self.settings_service.switch_profile(profile_name):\n            # Reload quests for new profile\n            self.quest_viewmodel.reload_for_profile()\n\n            # Update theme\n            self.theme_service.load_theme_from_profile()\n\n            return True\n        return False\n\n    def create_profile(self, name: str) -> bool:\n        \"\"\"Create a new profile.\"\"\"\n        return self.settings_service.create_profile(name)\n\n    def get_profiles(self):\n        \"\"\"Get list of available profiles.\"\"\"\n        return self.settings_service.get_available_profiles()\n\n    def get_active_profile(self) -> str:\n        \"\"\"Get the active profile name.\"\"\"\n        return self.settings_service.active_profile_name\n\n\nif HAS_PYQT6:\n    class QuestDialog(QDialog):\n        \"\"\"Dialog for creating/editing quests.\"\"\"\n\n        def __init__(self, parent=None, quest: Optional[Quest] = None):\n            super().__init__(parent)\n            self.quest = quest\n            self.setup_ui()\n\n        def setup_ui(self):\n            self.setWindowTitle(\"Edit Quest\" if self.quest else \"New Quest\")\n            self.setMinimumWidth(400)\n\n            layout = QVBoxLayout(self)\n\n            form_layout = QFormLayout()\n\n            self.title_edit = QLineEdit()\n            if self.quest:\n                self.title_edit.setText(self.quest.title)\n            form_layout.addRow(\"Title:\", self.title_edit)\n\n            self.description_edit = QTextEdit()\n            self.description_edit.setMaximumHeight(100)\n            if self.quest:\n                self.description_edit.setText(self.quest.description)\n            form_layout.addRow(\"Description:\", self.description_edit)\n\n            self.priority_combo = QComboBox()\n            self.priority_combo.addItems([\"Low\", \"Medium\", \"High\", \"Critical\"])\n            if self.quest:\n                self.priority_combo.setCurrentIndex(self.quest.priority.value - 1)\n            else:\n                self.priority_combo.setCurrentIndex(1)  # Default to Medium\n            form_layout.addRow(\"Priority:\", self.priority_combo)\n\n            self.tags_edit = QLineEdit()\n            self.tags_edit.setPlaceholderText(\"Comma-separated tags\")\n            if self.quest and self.quest.tags:\n                self.tags_edit.setText(\", \".join(self.quest.tags))\n            form_layout.addRow(\"Tags:\", self.tags_edit)\n\n            layout.addLayout(form_layout)\n\n            button_box = QDialogButtonBox(\n                QDialogButtonBox.StandardButton.Ok |\n                QDialogButtonBox.StandardButton.Cancel\n            )\n            button_box.accepted.connect(self.accept)\n            button_box.rejected.connect(self.reject)\n            layout.addWidget(button_box)\n\n        def get_quest_data(self):\n            \"\"\"Get the quest data from the dialog.\"\"\"\n            tags = [t.strip() for t in self.tags_edit.text().split(',') if t.strip()]\n            return {\n                'title': self.title_edit.text(),\n                'description': self.description_edit.toPlainText(),\n                'priority': QuestPriority(self.priority_combo.currentIndex() + 1),\n                'tags': tags\n            }\n\n\n    class MainWindow(QMainWindow):\n        \"\"\"Main application window for QuestBoard Maestro.\"\"\"\n\n        def __init__(self, settings_service=None, theme_service=None):\n            super().__init__()\n\n            self.settings_service = settings_service\n            self.theme_service = theme_service\n            self.quest_viewmodel = QuestViewModel(settings_service)\n\n            # Create profile manager\n            self.profile_manager = ProfileManager(\n                settings_service, theme_service, self.quest_viewmodel\n            )\n\n            # Initialize profiles\n            active_profile = self.profile_manager.initialize_profiles()\n\n            # Load quests for active profile\n            self.quest_viewmodel.load_quests()\n\n            # Setup UI\n            self.setup_ui()\n            self.setup_menu_bar()\n            self.setup_status_bar()\n\n            # Apply theme\n            if self.theme_service:\n                self.theme_service.set_settings_service(settings_service)\n                self.theme_service.register_theme_change_callback(self.on_theme_changed)\n                self.theme_service.load_theme_from_profile()\n\n            # Register for quest changes\n            self.quest_viewmodel.register_change_callback(self.refresh_quest_list)\n\n            # Initial refresh\n            self.refresh_quest_list()\n            self.update_profile_indicator()\n\n        def setup_ui(self):\n            \"\"\"Setup the main UI components.\"\"\"\n            self.setWindowTitle(\"QuestBoard Maestro\")\n            self.setMinimumSize(900, 600)\n\n            # Restore window geometry\n            if self.settings_service:\n                geom = self.settings_service.get_window_geometry()\n                self.setGeometry(geom['x'], geom['y'], geom['width'], geom['height'])\n\n            central_widget = QWidget()\n            self.setCentralWidget(central_widget)\n\n            main_layout = QHBoxLayout(central_widget)\n\n            # Create splitter for resizable panels\n            splitter = QSplitter(Qt.Orientation.Horizontal)\n\n            # Left panel - Quest list\n            left_panel = QFrame()\n            left_layout = QVBoxLayout(left_panel)\n\n            # Search and filter bar\n            filter_layout = QHBoxLayout()\n\n            self.search_edit = QLineEdit()\n            self.search_edit.setPlaceholderText(\"Search quests...\")\n            self.search_edit.textChanged.connect(self.on_search_changed)\n            filter_layout.addWidget(self.search_edit)\n\n            self.status_filter = QComboBox()\n            self.status_filter.addItems([\"All Status\", \"Pending\", \"In Progress\", \"Completed\", \"Archived\"])\n            self.status_filter.currentIndexChanged.connect(self.on_status_filter_changed)\n            filter_layout.addWidget(self.status_filter)\n\n            left_layout.addLayout(filter_layout)\n\n            # Quest list\n            self.quest_list = QListWidget()\n            self.quest_list.itemClicked.connect(self.on_quest_selected)\n            self.quest_list.itemDoubleClicked.connect(self.on_quest_double_clicked)\n            left_layout.addWidget(self.quest_list)\n\n            # Quest action buttons\n            button_layout = QHBoxLayout()\n\n            self.add_button = QPushButton(\"Add Quest\")\n            self.add_button.clicked.connect(self.on_add_quest)\n            button_layout.addWidget(self.add_button)\n\n            self.complete_button = QPushButton(\"Complete\")\n            self.complete_button.clicked.connect(self.on_complete_quest)\n            self.complete_button.setEnabled(False)\n            button_layout.addWidget(self.complete_button)\n\n            self.delete_button = QPushButton(\"Delete\")\n            self.delete_button.clicked.connect(self.on_delete_quest)\n            self.delete_button.setEnabled(False)\n            button_layout.addWidget(self.delete_button)\n\n            left_layout.addLayout(button_layout)\n\n            splitter.addWidget(left_panel)\n\n            # Right panel - Quest details\n            right_panel = QFrame()\n            right_layout = QVBoxLayout(right_panel)\n\n            # Quest details header\n            self.detail_title = QLabel(\"Select a quest\")\n            self.detail_title.setStyleSheet(\"font-size: 16pt; font-weight: bold;\")\n            right_layout.addWidget(self.detail_title)\n\n            # Quest info group\n            info_group = QGroupBox(\"Quest Details\")\n            info_layout = QFormLayout(info_group)\n\n            self.detail_priority = QLabel(\"-\")\n            info_layout.addRow(\"Priority:\", self.detail_priority)\n\n            self.detail_status = QLabel(\"-\")\n            info_layout.addRow(\"Status:\", self.detail_status)\n\n            self.detail_created = QLabel(\"-\")\n            info_layout.addRow(\"Created:\", self.detail_created)\n\n            self.detail_tags = QLabel(\"-\")\n            info_layout.addRow(\"Tags:\", self.detail_tags)\n\n            right_layout.addWidget(info_group)\n\n            # Description\n            desc_group = QGroupBox(\"Description\")\n            desc_layout = QVBoxLayout(desc_group)\n            self.detail_description = QLabel(\"\")\n            self.detail_description.setWordWrap(True)\n            desc_layout.addWidget(self.detail_description)\n            right_layout.addWidget(desc_group)\n\n            # Progress\n            progress_group = QGroupBox(\"Progress\")\n            progress_layout = QVBoxLayout(progress_group)\n            self.detail_progress = QProgressBar()\n            self.detail_progress.setRange(0, 100)\n            progress_layout.addWidget(self.detail_progress)\n            right_layout.addWidget(progress_group)\n\n            right_layout.addStretch()\n\n            splitter.addWidget(right_panel)\n            splitter.setSizes([400, 500])\n\n            main_layout.addWidget(splitter)\n\n        def setup_menu_bar(self):\n            \"\"\"Setup the menu bar with profile management.\"\"\"\n            menubar = self.menuBar()\n\n            # File menu\n            file_menu = menubar.addMenu(\"&File\")\n\n            new_quest_action = QAction(\"&New Quest\", self)\n            new_quest_action.setShortcut(\"Ctrl+N\")\n            new_quest_action.triggered.connect(self.on_add_quest)\n            file_menu.addAction(new_quest_action)\n\n            save_action = QAction(\"&Save\", self)\n            save_action.setShortcut(\"Ctrl+S\")\n            save_action.triggered.connect(self.on_save)\n            file_menu.addAction(save_action)\n\n            file_menu.addSeparator()\n\n            exit_action = QAction(\"E&xit\", self)\n            exit_action.setShortcut(\"Ctrl+Q\")\n            exit_action.triggered.connect(self.close)\n            file_menu.addAction(exit_action)\n\n            # Profile menu\n            self.profile_menu = menubar.addMenu(\"&Profile\")\n            self.update_profile_menu()\n\n            # View menu\n            view_menu = menubar.addMenu(\"&View\")\n\n            # Theme submenu\n            theme_menu = view_menu.addMenu(\"&Theme\")\n            if self.theme_service:\n                for theme_name in self.theme_service.get_available_themes():\n                    theme_action = QAction(theme_name.title(), self)\n                    theme_action.triggered.connect(\n                        lambda checked, name=theme_name: self.on_change_theme(name)\n                    )\n                    theme_menu.addAction(theme_action)\n\n            refresh_action = QAction(\"&Refresh\", self)\n            refresh_action.setShortcut(\"F5\")\n            refresh_action.triggered.connect(self.refresh_quest_list)\n            view_menu.addAction(refresh_action)\n\n            # Help menu\n            help_menu = menubar.addMenu(\"&Help\")\n\n            about_action = QAction(\"&About\", self)\n            about_action.triggered.connect(self.on_about)\n            help_menu.addAction(about_action)\n\n        def update_profile_menu(self):\n            \"\"\"Update the profile menu with current profiles.\"\"\"\n            self.profile_menu.clear()\n\n            # Profile selector section\n            profiles = self.profile_manager.get_profiles()\n            active_profile = self.profile_manager.get_active_profile()\n\n            for profile_name in profiles:\n                action = QAction(profile_name, self)\n                action.setCheckable(True)\n                action.setChecked(profile_name == active_profile)\n                action.triggered.connect(\n                    lambda checked, name=profile_name: self.on_switch_profile(name)\n                )\n                self.profile_menu.addAction(action)\n\n            self.profile_menu.addSeparator()\n\n            # Create new profile action\n            new_profile_action = QAction(\"&Create New Profile...\", self)\n            new_profile_action.triggered.connect(self.on_create_profile)\n            self.profile_menu.addAction(new_profile_action)\n\n            # Delete profile action\n            delete_profile_action = QAction(\"&Delete Profile...\", self)\n            delete_profile_action.triggered.connect(self.on_delete_profile)\n            self.profile_menu.addAction(delete_profile_action)\n\n        def setup_status_bar(self):\n            \"\"\"Setup the status bar.\"\"\"\n            self.statusbar = QStatusBar()\n            self.setStatusBar(self.statusbar)\n\n            # Profile indicator\n            self.profile_label = QLabel()\n            self.statusbar.addPermanentWidget(self.profile_label)\n\n            # Quest count\n            self.quest_count_label = QLabel()\n            self.statusbar.addPermanentWidget(self.quest_count_label)\n\n        def update_profile_indicator(self):\n            \"\"\"Update the profile indicator in status bar.\"\"\"\n            active_profile = self.profile_manager.get_active_profile()\n            self.profile_label.setText(f\"Profile: {active_profile}\")\n            self.setWindowTitle(f\"QuestBoard Maestro - {active_profile}\")\n\n        def refresh_quest_list(self):\n            \"\"\"Refresh the quest list display.\"\"\"\n            self.quest_list.clear()\n\n            quests = self.quest_viewmodel.get_filtered_quests()\n\n            for quest in quests:\n                item = QListWidgetItem()\n                priority_icons = {1: \"\u25cb\", 2: \"\u25d0\", 3: \"\u25cf\", 4: \"\u25c9\"}\n                status_icons = {\n                    \"pending\": \"\u2b1c\",\n                    \"in_progress\": \"\ud83d\udd04\",\n                    \"completed\": \"\u2705\",\n                    \"archived\": \"\ud83d\udce6\"\n                }\n\n                priority_icon = priority_icons.get(quest.priority.value, \"\u25cb\")\n                status_icon = status_icons.get(quest.status.value, \"\u2b1c\")\n\n                item.setText(f\"{status_icon} {priority_icon} {quest.title}\")\n                item.setData(Qt.ItemDataRole.UserRole, quest.id)\n                self.quest_list.addItem(item)\n\n            # Update quest count\n            stats = self.quest_viewmodel.get_statistics()\n            self.quest_count_label.setText(\n                f\"Quests: {stats['total']} | Completed: {stats['completed']}\"\n            )\n\n        def on_quest_selected(self, item: QListWidgetItem):\n            \"\"\"Handle quest selection.\"\"\"\n            quest_id = item.data(Qt.ItemDataRole.UserRole)\n            quest = self.quest_viewmodel.get_quest_by_id(quest_id)\n\n            if quest:\n                self.display_quest_details(quest)\n                self.complete_button.setEnabled(quest.status != QuestStatus.COMPLETED)\n                self.delete_button.setEnabled(True)\n\n        def on_quest_double_clicked(self, item: QListWidgetItem):\n            \"\"\"Handle quest double-click for editing.\"\"\"\n            quest_id = item.data(Qt.ItemDataRole.UserRole)\n            quest = self.quest_viewmodel.get_quest_by_id(quest_id)\n\n            if quest:\n                self.edit_quest(quest)\n\n        def display_quest_details(self, quest: Quest):\n            \"\"\"Display quest details in the right panel.\"\"\"\n            self.detail_title.setText(quest.title)\n\n            priority_names = {1: \"Low\", 2: \"Medium\", 3: \"High\", 4: \"Critical\"}\n            self.detail_priority.setText(priority_names.get(quest.priority.value, \"Unknown\"))\n\n            status_names = {\n                \"pending\": \"Pending\",\n                \"in_progress\": \"In Progress\",\n                \"completed\": \"Completed\",\n                \"archived\": \"Archived\"\n            }\n            self.detail_status.setText(status_names.get(quest.status.value, \"Unknown\"))\n\n            self.detail_created.setText(quest.created_at[:10] if quest.created_at else \"-\")\n            self.detail_tags.setText(\", \".join(quest.tags) if quest.tags else \"-\")\n            self.detail_description.setText(quest.description or \"No description\")\n            self.detail_progress.setValue(quest.progress)\n\n        def on_add_quest(self):\n            \"\"\"Handle add quest action.\"\"\"\n            dialog = QuestDialog(self)\n            if dialog.exec() == QDialog.DialogCode.Accepted:\n                data = dialog.get_quest_data()\n                self.quest_viewmodel.add_quest(\n                    title=data['title'],\n                    description=data['description'],\n                    priority=data['priority'],\n                    tags=data['tags']\n                )\n\n        def edit_quest(self, quest: Quest):\n            \"\"\"Edit an existing quest.\"\"\"\n            dialog = QuestDialog(self, quest)\n            if dialog.exec() == QDialog.DialogCode.Accepted:\n                data = dialog.get_quest_data()\n                self.quest_viewmodel.update_quest(\n                    quest.id,\n                    title=data['title'],\n                    description=data['description'],\n                    priority=data['priority'],\n                    tags=data['tags']\n                )\n\n        def on_complete_quest(self):\n            \"\"\"Handle complete quest action.\"\"\"\n            current_item = self.quest_list.currentItem()\n            if current_item:\n                quest_id = current_item.data(Qt.ItemDataRole.UserRole)\n                self.quest_viewmodel.complete_quest(quest_id)\n\n        def on_delete_quest(self):\n            \"\"\"Handle delete quest action.\"\"\"\n            current_item = self.quest_list.currentItem()\n            if current_item:\n                quest_id = current_item.data(Qt.ItemDataRole.UserRole)\n                quest = self.quest_viewmodel.get_quest_by_id(quest_id)\n\n                reply = QMessageBox.question(\n                    self, \"Delete Quest\",\n                    f\"Are you sure you want to delete '{quest.title}'?\",\n                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n                )\n\n                if reply == QMessageBox.StandardButton.Yes:\n                    self.quest_viewmodel.delete_quest(quest_id)\n                    self.clear_quest_details()\n\n        def clear_quest_details(self):\n            \"\"\"Clear the quest details panel.\"\"\"\n            self.detail_title.setText(\"Select a quest\")\n            self.detail_priority.setText(\"-\")\n            self.detail_status.setText(\"-\")\n            self.detail_created.setText(\"-\")\n            self.detail_tags.setText(\"-\")\n            self.detail_description.setText(\"\")\n            self.detail_progress.setValue(0)\n            self.complete_button.setEnabled(False)\n            self.delete_button.setEnabled(False)\n\n        def on_search_changed(self, text: str):\n            \"\"\"Handle search text change.\"\"\"\n            self.quest_viewmodel.set_search_term(text)\n\n        def on_status_filter_changed(self, index: int):\n            \"\"\"Handle status filter change.\"\"\"\n            status_map = {\n                0: None,\n                1: QuestStatus.PENDING,\n                2: QuestStatus.IN_PROGRESS,\n                3: QuestStatus.COMPLETED,\n                4: QuestStatus.ARCHIVED\n            }\n            self.quest_viewmodel.set_filter_status(status_map.get(index))\n\n        def on_switch_profile(self, profile_name: str):\n            \"\"\"Handle profile switch.\"\"\"\n            if profile_name == self.profile_manager.get_active_profile():\n                return\n\n            if self.profile_manager.switch_profile(profile_name):\n                self.update_profile_menu()\n                self.update_profile_indicator()\n                self.clear_quest_details()\n                self.statusbar.showMessage(f\"Switched to profile: {profile_name}\", 3000)\n            else:\n                QMessageBox.warning(\n                    self, \"Profile Switch Failed\",\n                    f\"Failed to switch to profile '{profile_name}'.\"\n                )\n\n        def on_create_profile(self):\n            \"\"\"Handle create new profile action.\"\"\"\n            name, ok = QInputDialog.getText(\n                self, \"Create New Profile\",\n                \"Enter profile name:\"\n            )\n\n            if ok and name:\n                name = name.strip()\n                if not name:\n                    QMessageBox.warning(self, \"Invalid Name\", \"Profile name cannot be empty.\")\n                    return\n\n                if self.settings_service.profile_exists(name):\n                    QMessageBox.warning(\n                        self, \"Profile Exists\",\n                        f\"A profile named '{name}' already exists.\"\n                    )\n                    return\n\n                if self.profile_manager.create_profile(name):\n                    self.update_profile_menu()\n                    self.statusbar.showMessage(f\"Created profile: {name}\", 3000)\n\n                    # Ask if user wants to switch to new profile\n                    reply = QMessageBox.question(\n                        self, \"Switch Profile\",\n                        f\"Switch to the new profile '{name}'?\",\n                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n                    )\n\n                    if reply == QMessageBox.StandardButton.Yes:\n                        self.on_switch_profile(name)\n                else:\n                    QMessageBox.warning(\n                        self, \"Creation Failed\",\n                        f\"Failed to create profile '{name}'.\"\n                    )\n\n        def on_delete_profile(self):\n            \"\"\"Handle delete profile action.\"\"\"\n            profiles = self.profile_manager.get_profiles()\n            active_profile = self.profile_manager.get_active_profile()\n\n            # Can't delete if only one profile\n            if len(profiles) <= 1:\n                QMessageBox.warning(\n                    self, \"Cannot Delete\",\n                    \"Cannot delete the only remaining profile.\"\n                )\n                return\n\n            # Get profile to delete\n            deletable_profiles = [p for p in profiles if p != active_profile]\n            profile_name, ok = QInputDialog.getItem(\n                self, \"Delete Profile\",\n                \"Select profile to delete:\",\n                deletable_profiles, 0, False\n            )\n\n            if ok and profile_name:\n                reply = QMessageBox.question(\n                    self, \"Confirm Delete\",\n                    f\"Are you sure you want to delete profile '{profile_name}'?\n\"\n                    \"This will delete all quests and settings for this profile.\",\n                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n                )\n\n                if reply == QMessageBox.StandardButton.Yes:\n                    if self.settings_service.delete_profile(profile_name):\n                        self.update_profile_menu()\n                        self.statusbar.showMessage(f\"Deleted profile: {profile_name}\", 3000)\n                    else:\n                        QMessageBox.warning(\n                            self, \"Delete Failed\",\n                            f\"Failed to delete profile '{profile_name}'.\"\n                        )\n\n        def on_change_theme(self, theme_name: str):\n            \"\"\"Handle theme change.\"\"\"\n            if self.theme_service:\n                self.theme_service.set_theme(theme_name)\n                if self.settings_service:\n                    self.settings_service.set_theme(theme_name)\n\n        def on_theme_changed(self, theme):\n            \"\"\"Handle theme change callback.\"\"\"\n            stylesheet = theme.generate_stylesheet()\n            self.setStyleSheet(stylesheet)\n\n        def on_save(self):\n            \"\"\"Handle save action.\"\"\"\n            self.quest_viewmodel.save_quests()\n            self.settings_service.save_active_profile()\n            self.statusbar.showMessage(\"Saved successfully\", 3000)\n\n        def on_about(self):\n            \"\"\"Show about dialog.\"\"\"\n            QMessageBox.about(\n                self, \"About QuestBoard Maestro\",\n                \"QuestBoard Maestro\n\n\"\n                \"A productivity application for managing your quests and tasks.\n\n\"\n                \"Features:\n\"\n                \"- Multiple user profiles\n\"\n                \"- Quest management with priorities\n\"\n                \"- Theme customization\n\"\n                \"- Search and filtering\"\n            )\n\n        def closeEvent(self, event):\n            \"\"\"Handle window close event.\"\"\"\n            # Save current state\n            self.quest_viewmodel.save_quests()\n\n            if self.settings_service:\n                self.settings_service.save_active_profile()\n                # Save window geometry\n                geom = self.geometry()\n                self.settings_service.save_window_geometry(\n                    geom.x(), geom.y(), geom.width(), geom.height()\n                )\n\n            event.accept()\n\nelse:\n    # Fallback for non-PyQt6 environments\n    class MainWindow:\n        def __init__(self, settings_service=None, theme_service=None):\n            self.settings_service = settings_service\n            self.theme_service = theme_service\n            print(\"PyQt6 not available - MainWindow is a stub\")\n\n        def show(self):\n            print(\"MainWindow.show() called - PyQt6 not available\")\n",
            "QuestBoard_Maestro/src/main.py": "import sys\nimport os\n\n# Add parent directory to path for imports\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom services.settings_service import get_settings_service, reset_settings_service\nfrom services.theme_service import get_theme_service, reset_theme_service\n\ntry:\n    from PyQt6.QtWidgets import QApplication\n    from PyQt6.QtCore import Qt\n    HAS_PYQT6 = True\nexcept ImportError:\n    HAS_PYQT6 = False\n    print(\"PyQt6 not installed. Install with: pip install PyQt6\")\n\n\ndef initialize_application():\n    \"\"\"Initialize application services and ensure default profile exists.\"\"\"\n    # Get settings service singleton\n    settings_service = get_settings_service()\n\n    # Check if any profiles exist\n    profiles = settings_service.get_available_profiles()\n\n    if not profiles:\n        # First run - create default 'Primary' profile\n        print(\"First run detected - creating default 'Primary' profile\")\n        settings_service.create_profile('Primary')\n        settings_service.load_profile('Primary')\n    else:\n        # Load last active profile or first available\n        last_profile = settings_service.get_last_active_profile()\n\n        if last_profile and settings_service.profile_exists(last_profile):\n            print(f\"Loading last active profile: {last_profile}\")\n            settings_service.load_profile(last_profile)\n        else:\n            # Fallback to first available profile\n            print(f\"Loading first available profile: {profiles[0]}\")\n            settings_service.load_profile(profiles[0])\n\n    # Get theme service and link to settings\n    theme_service = get_theme_service()\n    theme_service.set_settings_service(settings_service)\n\n    return settings_service, theme_service\n\n\ndef main():\n    \"\"\"Main entry point for QuestBoard Maestro.\"\"\"\n    if not HAS_PYQT6:\n        print(\"Error: PyQt6 is required to run QuestBoard Maestro\")\n        print(\"Install with: pip install PyQt6\")\n        return 1\n\n    # Create application\n    app = QApplication(sys.argv)\n    app.setApplicationName(\"QuestBoard Maestro\")\n    app.setApplicationVersion(\"1.0.0\")\n    app.setOrganizationName(\"QuestBoard\")\n\n    # Enable high DPI scaling\n    try:\n        app.setHighDpiScaleFactorRoundingPolicy(\n            Qt.HighDpiScaleFactorRoundingPolicy.PassThrough\n        )\n    except AttributeError:\n        pass  # Not available in older PyQt6 versions\n\n    # Initialize services\n    settings_service, theme_service = initialize_application()\n\n    # Import and create main window\n    from src.ui.main_window import MainWindow\n\n    window = MainWindow(\n        settings_service=settings_service,\n        theme_service=theme_service\n    )\n\n    # Apply initial theme\n    theme_service.load_theme_from_profile()\n\n    # Show window\n    window.show()\n\n    # Run application event loop\n    return app.exec()\n\n\ndef run_headless_test():\n    \"\"\"Run a headless test of profile functionality.\"\"\"\n    print(\"Running headless profile test...\")\n\n    # Reset singletons for clean test\n    reset_settings_service()\n    reset_theme_service()\n\n    settings_service = get_settings_service()\n\n    # Test profile creation\n    print(\"\n1. Testing profile creation...\")\n    assert settings_service.create_profile('TestProfile1'), \"Failed to create TestProfile1\"\n    assert settings_service.create_profile('TestProfile2'), \"Failed to create TestProfile2\"\n    print(\"   Created TestProfile1 and TestProfile2\")\n\n    # Test profile listing\n    print(\"\n2. Testing profile listing...\")\n    profiles = settings_service.get_available_profiles()\n    print(f\"   Available profiles: {profiles}\")\n    assert 'TestProfile1' in profiles, \"TestProfile1 not in list\"\n    assert 'TestProfile2' in profiles, \"TestProfile2 not in list\"\n\n    # Test profile loading\n    print(\"\n3. Testing profile loading...\")\n    assert settings_service.load_profile('TestProfile1'), \"Failed to load TestProfile1\"\n    assert settings_service.active_profile_name == 'TestProfile1', \"Active profile mismatch\"\n    print(f\"   Loaded profile: {settings_service.active_profile_name}\")\n\n    # Test settings modification\n    print(\"\n4. Testing settings modification...\")\n    settings_service.set_theme('light')\n    assert settings_service.get_theme() == 'light', \"Theme not set correctly\"\n    print(f\"   Theme set to: {settings_service.get_theme()}\")\n\n    # Test profile switching\n    print(\"\n5. Testing profile switching...\")\n    assert settings_service.switch_profile('TestProfile2'), \"Failed to switch profile\"\n    assert settings_service.active_profile_name == 'TestProfile2', \"Profile switch failed\"\n    print(f\"   Switched to: {settings_service.active_profile_name}\")\n\n    # Verify settings are independent\n    print(\"\n6. Testing settings isolation...\")\n    assert settings_service.get_theme() == 'default', \"Profile settings not isolated\"\n    print(f\"   TestProfile2 theme: {settings_service.get_theme()} (expected: default)\")\n\n    # Test quest file paths\n    print(\"\n7. Testing quest file paths...\")\n    path1 = settings_service.get_quest_file_path('TestProfile1')\n    path2 = settings_service.get_quest_file_path('TestProfile2')\n    print(f\"   TestProfile1 quests: {path1}\")\n    print(f\"   TestProfile2 quests: {path2}\")\n    assert path1 != path2, \"Quest paths should be different\"\n\n    # Test theme service integration\n    print(\"\n8. Testing theme service integration...\")\n    theme_service = get_theme_service()\n    theme_service.set_settings_service(settings_service)\n    theme = theme_service.load_theme_from_profile()\n    print(f\"   Loaded theme: {theme.name}\")\n\n    # Cleanup - delete test profiles\n    print(\"\n9. Cleaning up test profiles...\")\n    settings_service.switch_profile('TestProfile1')\n    settings_service.delete_profile('TestProfile2')\n    print(\"   Deleted TestProfile2\")\n\n    print(\"\n\u2713 All tests passed!\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    # Check for test mode\n    if len(sys.argv) > 1 and sys.argv[1] == \"--test\":\n        sys.exit(run_headless_test())\n    else:\n        sys.exit(main())\n",
            "QuestBoard_Maestro/tests/test_profiles.py": "import unittest\nimport tempfile\nimport shutil\nimport os\nimport sys\n\n# Add parent directory to path\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom services.settings_service import SettingsService, ProfileSettings, reset_settings_service\nfrom services.theme_service import ThemeService, reset_theme_service\nfrom src.ui.quest_viewmodel import QuestViewModel, QuestPriority, QuestStatus\n\n\nclass TestSettingsService(unittest.TestCase):\n    \"\"\"Test cases for the SettingsService.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n        self.settings_service = SettingsService(self.test_dir)\n\n    def tearDown(self):\n        \"\"\"Clean up test fixtures.\"\"\"\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_create_profile(self):\n        \"\"\"Test profile creation.\"\"\"\n        result = self.settings_service.create_profile('TestProfile')\n        self.assertTrue(result)\n        self.assertIn('TestProfile', self.settings_service.get_available_profiles())\n\n    def test_create_duplicate_profile(self):\n        \"\"\"Test that duplicate profiles cannot be created.\"\"\"\n        self.settings_service.create_profile('TestProfile')\n        result = self.settings_service.create_profile('TestProfile')\n        self.assertFalse(result)\n\n    def test_load_profile(self):\n        \"\"\"Test profile loading.\"\"\"\n        self.settings_service.create_profile('TestProfile')\n        result = self.settings_service.load_profile('TestProfile')\n        self.assertTrue(result)\n        self.assertEqual(self.settings_service.active_profile_name, 'TestProfile')\n\n    def test_load_nonexistent_profile(self):\n        \"\"\"Test loading a profile that doesn't exist.\"\"\"\n        result = self.settings_service.load_profile('NonexistentProfile')\n        self.assertFalse(result)\n\n    def test_switch_profile(self):\n        \"\"\"Test switching between profiles.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.load_profile('Profile1')\n\n        result = self.settings_service.switch_profile('Profile2')\n        self.assertTrue(result)\n        self.assertEqual(self.settings_service.active_profile_name, 'Profile2')\n\n    def test_profile_settings_isolation(self):\n        \"\"\"Test that profile settings are isolated.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n\n        # Set theme for Profile1\n        self.settings_service.load_profile('Profile1')\n        self.settings_service.set_theme('light')\n\n        # Switch to Profile2 and verify default theme\n        self.settings_service.switch_profile('Profile2')\n        self.assertEqual(self.settings_service.get_theme(), 'default')\n\n        # Switch back to Profile1 and verify light theme\n        self.settings_service.switch_profile('Profile1')\n        self.assertEqual(self.settings_service.get_theme(), 'light')\n\n    def test_delete_profile(self):\n        \"\"\"Test profile deletion.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.load_profile('Profile1')\n\n        result = self.settings_service.delete_profile('Profile2')\n        self.assertTrue(result)\n        self.assertNotIn('Profile2', self.settings_service.get_available_profiles())\n\n    def test_cannot_delete_active_profile(self):\n        \"\"\"Test that active profile cannot be deleted.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.load_profile('Profile1')\n\n        result = self.settings_service.delete_profile('Profile1')\n        self.assertFalse(result)\n\n    def test_quest_file_paths_unique(self):\n        \"\"\"Test that quest file paths are unique per profile.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n\n        path1 = self.settings_service.get_quest_file_path('Profile1')\n        path2 = self.settings_service.get_quest_file_path('Profile2')\n\n        self.assertNotEqual(path1, path2)\n\n    def test_last_active_profile_saved(self):\n        \"\"\"Test that last active profile is saved.\"\"\"\n        self.settings_service.create_profile('Profile1')\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.load_profile('Profile2')\n\n        # Create new service instance to test persistence\n        new_service = SettingsService(self.test_dir)\n        self.assertEqual(new_service.get_last_active_profile(), 'Profile2')\n\n\nclass TestQuestViewModelWithProfiles(unittest.TestCase):\n    \"\"\"Test cases for QuestViewModel with profile support.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n        self.settings_service = SettingsService(self.test_dir)\n        self.settings_service.create_profile('TestProfile')\n        self.settings_service.load_profile('TestProfile')\n\n        self.viewmodel = QuestViewModel(self.settings_service)\n\n    def tearDown(self):\n        \"\"\"Clean up test fixtures.\"\"\"\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_add_quest(self):\n        \"\"\"Test adding a quest.\"\"\"\n        quest = self.viewmodel.add_quest('Test Quest', 'Description')\n        self.assertIsNotNone(quest)\n        self.assertEqual(quest.title, 'Test Quest')\n\n    def test_quest_persistence(self):\n        \"\"\"Test that quests are persisted.\"\"\"\n        self.viewmodel.add_quest('Persistent Quest')\n        self.viewmodel.save_quests()\n\n        # Create new viewmodel and load\n        new_viewmodel = QuestViewModel(self.settings_service)\n        new_viewmodel.load_quests()\n\n        quests = new_viewmodel.get_all_quests()\n        self.assertEqual(len(quests), 1)\n        self.assertEqual(quests[0].title, 'Persistent Quest')\n\n    def test_quests_isolated_per_profile(self):\n        \"\"\"Test that quests are isolated per profile.\"\"\"\n        # Add quest to first profile\n        self.viewmodel.add_quest('Profile1 Quest')\n        self.viewmodel.save_quests()\n\n        # Create and switch to second profile\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.switch_profile('Profile2')\n\n        # Create new viewmodel for Profile2\n        viewmodel2 = QuestViewModel(self.settings_service)\n        viewmodel2.load_quests()\n\n        # Verify Profile2 has no quests\n        self.assertEqual(len(viewmodel2.get_all_quests()), 0)\n\n        # Add quest to Profile2\n        viewmodel2.add_quest('Profile2 Quest')\n        viewmodel2.save_quests()\n\n        # Switch back to Profile1 and verify original quest\n        self.settings_service.switch_profile('TestProfile')\n        self.viewmodel.load_quests()\n\n        quests = self.viewmodel.get_all_quests()\n        self.assertEqual(len(quests), 1)\n        self.assertEqual(quests[0].title, 'Profile1 Quest')\n\n\nclass TestThemeServiceWithProfiles(unittest.TestCase):\n    \"\"\"Test cases for ThemeService with profile support.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_dir = tempfile.mkdtemp()\n        self.themes_dir = os.path.join(self.test_dir, 'themes')\n        os.makedirs(self.themes_dir)\n\n        self.settings_service = SettingsService(self.test_dir)\n        self.settings_service.create_profile('TestProfile')\n        self.settings_service.load_profile('TestProfile')\n\n        self.theme_service = ThemeService(self.themes_dir)\n        self.theme_service.set_settings_service(self.settings_service)\n\n    def tearDown(self):\n        \"\"\"Clean up test fixtures.\"\"\"\n        shutil.rmtree(self.test_dir, ignore_errors=True)\n\n    def test_load_theme_from_profile(self):\n        \"\"\"Test loading theme from profile settings.\"\"\"\n        self.settings_service.set_theme('light')\n        theme = self.theme_service.load_theme_from_profile()\n        self.assertEqual(theme.name, 'light')\n\n    def test_theme_changes_with_profile_switch(self):\n        \"\"\"Test that theme changes when profile switches.\"\"\"\n        # Set light theme for first profile\n        self.settings_service.set_theme('light')\n\n        # Create second profile with default theme\n        self.settings_service.create_profile('Profile2')\n        self.settings_service.switch_profile('Profile2')\n\n        # Load theme for Profile2\n        theme = self.theme_service.load_theme_from_profile()\n        self.assertEqual(theme.name, 'default')\n\n    def test_theme_change_callback(self):\n        \"\"\"Test theme change callback is called.\"\"\"\n        callback_called = [False]\n        received_theme = [None]\n\n        def callback(theme):\n            callback_called[0] = True\n            received_theme[0] = theme\n\n        self.theme_service.register_theme_change_callback(callback)\n        self.theme_service.set_theme('light')\n\n        self.assertTrue(callback_called[0])\n        self.assertEqual(received_theme[0].name, 'light')\n\n\nif __name__ == '__main__':\n    unittest.main()\n"
          },
          "generated_files": [
            "QuestBoard_Maestro/services/settings_service.py",
            "QuestBoard_Maestro/services/theme_service.py",
            "QuestBoard_Maestro/src/ui/quest_viewmodel.py",
            "QuestBoard_Maestro/src/ui/main_window.py",
            "QuestBoard_Maestro/src/main.py",
            "QuestBoard_Maestro/tests/test_profiles.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8202284061440256,
                "dependency_traversal_accuracy": 0.8505783920678032,
                "cross_file_reasoning_depth": 0.2352777777777778,
                "system_thinking_score": 0.5495065359477125,
                "robustness_score": 0.15449984321103793,
                "comprehensiveness_score": 0.6758216368767639,
                "innovation_score": 0.3,
                "solution_elegance_score": 0.5983058090738439
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.1025285507680032,
                "dependency_traversal_weighted": 0.1063222990084754,
                "cross_file_reasoning_weighted": 0.029409722222222226,
                "system_thinking_weighted": 0.06868831699346406,
                "robustness_weighted": 0.019312480401379742,
                "comprehensiveness_weighted": 0.08447770460959549,
                "innovation_weighted": 0.0375,
                "solution_elegance_weighted": 0.07478822613423049
              },
              "total_software_engineering_score": 0.5230273001373705
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.0,
                "execution_time": 0.40479588508605957,
                "errors": [
                  "  File \"QuestBoard_Maestro/src/main.py\", line 104",
                  "    print(\"",
                  "          ^",
                  "SyntaxError: unterminated string literal (detected at line 104)",
                  "  File \"QuestBoard_Maestro/src/ui/main_window.py\", line 630",
                  "    f\"Are you sure you want to delete profile '{profile_name}'?",
                  "    ^",
                  "SyntaxError: unterminated f-string literal (detected at line 630)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "QuestBoard_Maestro/services/settings_service.py",
                  "QuestBoard_Maestro/services/theme_service.py",
                  "QuestBoard_Maestro/src/ui/quest_viewmodel.py",
                  "QuestBoard_Maestro/src/ui/main_window.py",
                  "QuestBoard_Maestro/src/main.py",
                  "QuestBoard_Maestro/tests/test_profiles.py"
                ],
                "scoring_breakdown": {
                  "no_credit": 0.0
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 6,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 6 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.3023837209302326,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.0,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.3023837209302326,
                "idc_weight": 0.2,
                "total_functional_score": 0.37047674418604654
              }
            },
            "code_quality_details": {
              "files_analyzed": 6,
              "quality_checks": {
                "QuestBoard_Maestro/services/settings_service.py": {
                  "line_count": 281,
                  "non_empty_lines": 227,
                  "comment_lines": 1,
                  "comment_ratio": 0.004405286343612335,
                  "function_count": 31,
                  "class_count": 3,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "QuestBoard_Maestro/services/theme_service.py": {
                  "line_count": 409,
                  "non_empty_lines": 342,
                  "comment_lines": 2,
                  "comment_ratio": 0.005847953216374269,
                  "function_count": 19,
                  "class_count": 3,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "QuestBoard_Maestro/src/ui/quest_viewmodel.py": {
                  "line_count": 307,
                  "non_empty_lines": 260,
                  "comment_lines": 1,
                  "comment_ratio": 0.0038461538461538464,
                  "function_count": 27,
                  "class_count": 4,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "QuestBoard_Maestro/src/ui/main_window.py": {
                  "line_count": 710,
                  "non_empty_lines": 567,
                  "comment_lines": 44,
                  "comment_ratio": 0.07760141093474426,
                  "function_count": 37,
                  "class_count": 6,
                  "import_count": 12,
                  "quality_score": 0.6
                },
                "QuestBoard_Maestro/src/main.py": {
                  "line_count": 180,
                  "non_empty_lines": 143,
                  "comment_lines": 25,
                  "comment_ratio": 0.17482517482517482,
                  "function_count": 3,
                  "class_count": 0,
                  "import_count": 12,
                  "quality_score": 0.9999999999999999
                },
                "QuestBoard_Maestro/tests/test_profiles.py": {
                  "line_count": 239,
                  "non_empty_lines": 181,
                  "comment_lines": 15,
                  "comment_ratio": 0.08287292817679558,
                  "function_count": 23,
                  "class_count": 3,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7999999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8150000000000001,
                "multi_session_memory_retention": 0.7865909090909091
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.40750000000000003,
                "multi_session_memory_retention_weighted": 0.39329545454545456
              },
              "total_longcontext_utilization_score": 0.8007954545454545
            }
          },
          "timestamp": "2026-01-14T21:48:34.428612"
        }
      }
    },
    "python_mobile_game_hard_060_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_mobile_game_hard_060_feature_implementation_expert_01",
          "scenario_title": "Implement Geofenced Quest Auto-Completion with User Confirmation",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5163372285421293,
          "functional_correctness_score": 0.4917093204709888,
          "code_quality_score": 0.7899999999999998,
          "longcontext_utilization_score": 0.5732536485253875,
          "total_score": 2.846865262053435,
          "generation_time": 140.38565731048584,
          "code_files_generated": 7,
          "total_lines_generated": 1292,
          "parsing_success": true,
          "solution_code": {
            "src/config.py": "\"\"\"Configuration settings for QuestSmith application.\"\"\"\n\n# Application settings\nAPP_NAME = \"QuestSmith\"\nAPP_VERSION = \"1.0.0\"\nDEBUG_MODE = True\n\n# Database settings\nDATABASE_URL = \"sqlite:///questsmith.db\"\nDATABASE_POOL_SIZE = 5\n\n# User settings\nMAX_ACTIVE_QUESTS = 10\nDEFAULT_USER_LEVEL = 1\nEXPERIENCE_MULTIPLIER = 1.0\n\n# Quest settings\nQUEST_EXPIRY_DAYS = 7\nMAX_QUEST_REWARDS = 5\n\n# Location settings\nDEFAULT_GEOFENCE_RADIUS_METERS = 100\n\n# Notification settings\nNOTIFICATION_ENABLED = True\nNOTIFICATION_SOUND = \"default\"\n\n# API settings\nAPI_TIMEOUT = 30\nAPI_RETRY_COUNT = 3\n",
            "src/utils.py": "\"\"\"Utility functions for QuestSmith application.\"\"\"\n\nimport math\nfrom typing import Tuple, Optional, List, Dict, Any\nimport re\nimport hashlib\nimport uuid\nfrom datetime import datetime, timedelta\n\n\ndef generate_unique_id() -> str:\n    \"\"\"Generate a unique identifier.\"\"\"\n    return str(uuid.uuid4())\n\n\ndef hash_password(password: str) -> str:\n    \"\"\"Hash a password using SHA-256.\"\"\"\n    return hashlib.sha256(password.encode()).hexdigest()\n\n\ndef validate_email(email: str) -> bool:\n    \"\"\"Validate an email address format.\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2}$'\n    return bool(re.match(pattern, email))\n\n\ndef format_datetime(dt: datetime) -> str:\n    \"\"\"Format a datetime object to a string.\"\"\"\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n\ndef parse_datetime(dt_string: str) -> datetime:\n    \"\"\"Parse a datetime string to a datetime object.\"\"\"\n    return datetime.strptime(dt_string, \"%Y-%m-%d %H:%M:%S\")\n\n\ndef calculate_experience_for_level(level: int) -> int:\n    \"\"\"Calculate total experience required for a given level.\"\"\"\n    return int(100 * (level ** 1.5))\n\n\ndef truncate_string(text: str, max_length: int = 100) -> str:\n    \"\"\"Truncate a string to a maximum length.\"\"\"\n    if len(text) <= max_length:\n        return text\n    return text[:max_length - 3] + \"...\"\n\n\ndef sanitize_input(text: str) -> str:\n    \"\"\"Sanitize user input by removing potentially harmful characters.\"\"\"\n    return re.sub(r'[<>\"\\'\\/\\\\]', '', text)\n\n\ndef calculate_haversine_distance(coord1: Tuple[float, float], coord2: Tuple[float, float]) -> float:\n    \"\"\"Calculate the distance in meters between two latitude/longitude points using the Haversine formula.\n    \n    Args:\n        coord1: A tuple of (latitude, longitude) for the first point.\n        coord2: A tuple of (latitude, longitude) for the second point.\n    \n    Returns:\n        The distance between the two points in meters.\n    \"\"\"\n    # Earth's radius in meters\n    EARTH_RADIUS_METERS = 6371000\n    \n    lat1, lon1 = coord1\n    lat2, lon2 = coord2\n    \n    # Convert latitude and longitude from degrees to radians\n    lat1_rad = math.radians(lat1)\n    lat2_rad = math.radians(lat2)\n    lon1_rad = math.radians(lon1)\n    lon2_rad = math.radians(lon2)\n    \n    # Differences in coordinates\n    delta_lat = lat2_rad - lat1_rad\n    delta_lon = lon2_rad - lon1_rad\n    \n    # Haversine formula\n    a = math.sin(delta_lat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon / 2) ** 2\n    c = 2 * math.asin(math.sqrt(a))\n    \n    # Calculate the distance\n    distance = EARTH_RADIUS_METERS * c\n    \n    return distance\n\n\ndef merge_dicts(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Merge two dictionaries, with dict2 values taking precedence.\"\"\"\n    result = dict1.copy()\n    result.update(dict2)\n    return result\n\n\ndef is_valid_coordinates(latitude: float, longitude: float) -> bool:\n    \"\"\"Validate if coordinates are within valid ranges.\"\"\"\n    return -90 <= latitude <= 90 and -180 <= longitude <= 180\n",
            "src/module_14.py": "\"\"\"Quest management system for QuestSmith.\"\"\"\n\nfrom typing import Optional, List, Dict, Any\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\nfrom src.config import DEFAULT_GEOFENCE_RADIUS_METERS\n\n\nclass QuestStatus(Enum):\n    \"\"\"Enumeration of possible quest statuses.\"\"\"\n    AVAILABLE = \"available\"\n    ACTIVE = \"active\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    EXPIRED = \"expired\"\n\n\nclass QuestDifficulty(Enum):\n    \"\"\"Enumeration of quest difficulty levels.\"\"\"\n    EASY = \"easy\"\n    MEDIUM = \"medium\"\n    HARD = \"hard\"\n    LEGENDARY = \"legendary\"\n\n\n@dataclass\nclass QuestLocation:\n    \"\"\"Represents a physical location associated with a quest.\"\"\"\n    latitude: float\n    longitude: float\n    location_name: str\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert location to dictionary.\"\"\"\n        return {\n            \"latitude\": self.latitude,\n            \"longitude\": self.longitude,\n            \"location_name\": self.location_name\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"QuestLocation\":\n        \"\"\"Create a QuestLocation from a dictionary.\"\"\"\n        return cls(\n            latitude=data[\"latitude\"],\n            longitude=data[\"longitude\"],\n            location_name=data[\"location_name\"]\n        )\n\n\n@dataclass\nclass QuestReward:\n    \"\"\"Represents rewards for completing a quest.\"\"\"\n    experience: int = 0\n    gold: int = 0\n    items: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Quest:\n    \"\"\"Represents a quest in the QuestSmith system.\"\"\"\n    quest_id: str\n    name: str\n    description: str\n    difficulty: QuestDifficulty\n    status: QuestStatus = QuestStatus.AVAILABLE\n    reward: QuestReward = field(default_factory=QuestReward)\n    created_at: datetime = field(default_factory=datetime.now)\n    completed_at: Optional[datetime] = None\n    expires_at: Optional[datetime] = None\n    user_id: Optional[str] = None\n    location: Optional[QuestLocation] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert quest to dictionary.\"\"\"\n        result = {\n            \"quest_id\": self.quest_id,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"difficulty\": self.difficulty.value,\n            \"status\": self.status.value,\n            \"reward\": {\n                \"experience\": self.reward.experience,\n                \"gold\": self.reward.gold,\n                \"items\": self.reward.items\n            },\n            \"created_at\": self.created_at.isoformat(),\n            \"completed_at\": self.completed_at.isoformat() if self.completed_at else None,\n            \"expires_at\": self.expires_at.isoformat() if self.expires_at else None,\n            \"user_id\": self.user_id,\n            \"location\": self.location.to_dict() if self.location else None\n        }\n        return result\n\n\nclass QuestManager:\n    \"\"\"Manages quest operations in the QuestSmith system.\"\"\"\n    \n    def __init__(self):\n        self._quests: Dict[str, Quest] = {}\n        self._user_quests: Dict[str, List[str]] = {}\n        self._geofence_service = None\n    \n    def set_geofence_service(self, geofence_service):\n        \"\"\"Set the geofence service for location-based quests.\"\"\"\n        self._geofence_service = geofence_service\n    \n    def create_quest(\n        self,\n        name: str,\n        description: str,\n        difficulty: QuestDifficulty,\n        reward: Optional[QuestReward] = None,\n        expires_at: Optional[datetime] = None,\n        location: Optional[QuestLocation] = None\n    ) -> Quest:\n        \"\"\"Create a new quest.\"\"\"\n        quest_id = str(uuid.uuid4())\n        quest = Quest(\n            quest_id=quest_id,\n            name=name,\n            description=description,\n            difficulty=difficulty,\n            reward=reward or QuestReward(),\n            expires_at=expires_at,\n            location=location\n        )\n        self._quests[quest_id] = quest\n        return quest\n    \n    def get_quest(self, quest_id: str) -> Optional[Quest]:\n        \"\"\"Retrieve a quest by its ID.\"\"\"\n        return self._quests.get(quest_id)\n    \n    def activate_quest(self, quest_id: str, user_id: str) -> bool:\n        \"\"\"Activate a quest for a user.\"\"\"\n        quest = self._quests.get(quest_id)\n        if not quest:\n            return False\n        \n        if quest.status != QuestStatus.AVAILABLE:\n            return False\n        \n        quest.status = QuestStatus.ACTIVE\n        quest.user_id = user_id\n        \n        if user_id not in self._user_quests:\n            self._user_quests[user_id] = []\n        self._user_quests[user_id].append(quest_id)\n        \n        # Register geofence if quest has location data\n        if quest.location and self._geofence_service:\n            self._geofence_service.register_geofence(\n                quest_id=quest_id,\n                latitude=quest.location.latitude,\n                longitude=quest.location.longitude,\n                radius_meters=DEFAULT_GEOFENCE_RADIUS_METERS\n            )\n        \n        return True\n    \n    def complete_quest(self, quest_id: str) -> Optional[QuestReward]:\n        \"\"\"Mark a quest as completed and return its rewards.\"\"\"\n        quest = self._quests.get(quest_id)\n        if not quest:\n            return None\n        \n        if quest.status != QuestStatus.ACTIVE:\n            return None\n        \n        quest.status = QuestStatus.COMPLETED\n        quest.completed_at = datetime.now()\n        \n        return quest.reward\n    \n    def fail_quest(self, quest_id: str) -> bool:\n        \"\"\"Mark a quest as failed.\"\"\"\n        quest = self._quests.get(quest_id)\n        if not quest:\n            return False\n        \n        quest.status = QuestStatus.FAILED\n        return True\n    \n    def get_user_quests(self, user_id: str, status: Optional[QuestStatus] = None) -> List[Quest]:\n        \"\"\"Get all quests for a user, optionally filtered by status.\"\"\"\n        quest_ids = self._user_quests.get(user_id, [])\n        quests = [self._quests[qid] for qid in quest_ids if qid in self._quests]\n        \n        if status:\n            quests = [q for q in quests if q.status == status]\n        \n        return quests\n    \n    def get_active_quests(self, user_id: str) -> List[Quest]:\n        \"\"\"Get all active quests for a user.\"\"\"\n        return self.get_user_quests(user_id, QuestStatus.ACTIVE)\n    \n    def get_available_quests(self) -> List[Quest]:\n        \"\"\"Get all available quests.\"\"\"\n        return [q for q in self._quests.values() if q.status == QuestStatus.AVAILABLE]\n\n\n# Global quest manager instance\nquest_manager = QuestManager()\n\n\ndef create_quest(\n    name: str,\n    description: str,\n    difficulty: QuestDifficulty,\n    reward: Optional[QuestReward] = None,\n    expires_at: Optional[datetime] = None,\n    location: Optional[QuestLocation] = None\n) -> Quest:\n    \"\"\"Create a new quest.\"\"\"\n    return quest_manager.create_quest(name, description, difficulty, reward, expires_at, location)\n\n\ndef get_quest(quest_id: str) -> Optional[Quest]:\n    \"\"\"Get a quest by ID.\"\"\"\n    return quest_manager.get_quest(quest_id)\n\n\ndef activate_quest(quest_id: str, user_id: str) -> bool:\n    \"\"\"Activate a quest for a user.\"\"\"\n    return quest_manager.activate_quest(quest_id, user_id)\n\n\ndef complete_quest(quest_id: str) -> Optional[QuestReward]:\n    \"\"\"Complete a quest and return rewards.\"\"\"\n    return quest_manager.complete_quest(quest_id)\n",
            "src/module_22.py": "\"\"\"Location services wrapper for QuestSmith.\"\"\"\n\nfrom typing import Optional, Dict, Any, Callable, List\nfrom dataclasses import dataclass\nfrom datetime import datetime\nimport uuid\n\n\n@dataclass\nclass Geofence:\n    \"\"\"Represents a geofence region.\"\"\"\n    geofence_id: str\n    quest_id: str\n    latitude: float\n    longitude: float\n    radius_meters: float\n    created_at: datetime\n    is_active: bool = True\n\n\n@dataclass\nclass LocationUpdate:\n    \"\"\"Represents a location update from the device.\"\"\"\n    latitude: float\n    longitude: float\n    accuracy: float\n    timestamp: datetime\n    altitude: Optional[float] = None\n    speed: Optional[float] = None\n\n\nclass LocationServicesWrapper:\n    \"\"\"Wrapper for device location services.\"\"\"\n    \n    def __init__(self):\n        self._geofences: Dict[str, Geofence] = {}\n        self._quest_geofence_map: Dict[str, str] = {}  # quest_id -> geofence_id\n        self._location_callbacks: List[Callable[[LocationUpdate], None]] = []\n        self._geofence_callbacks: List[Callable[[str, str], None]] = []  # (quest_id, event_type)\n        self._current_location: Optional[LocationUpdate] = None\n        self._is_tracking: bool = False\n    \n    def register_geofence(\n        self,\n        quest_id: str,\n        latitude: float,\n        longitude: float,\n        radius_meters: float\n    ) -> str:\n        \"\"\"Register a geofence for a quest location.\n        \n        Args:\n            quest_id: The unique identifier of the quest.\n            latitude: The latitude of the geofence center.\n            longitude: The longitude of the geofence center.\n            radius_meters: The radius of the geofence in meters.\n        \n        Returns:\n            The unique identifier of the created geofence.\n        \"\"\"\n        geofence_id = str(uuid.uuid4())\n        geofence = Geofence(\n            geofence_id=geofence_id,\n            quest_id=quest_id,\n            latitude=latitude,\n            longitude=longitude,\n            radius_meters=radius_meters,\n            created_at=datetime.now(),\n            is_active=True\n        )\n        self._geofences[geofence_id] = geofence\n        self._quest_geofence_map[quest_id] = geofence_id\n        return geofence_id\n    \n    def unregister_geofence(self, quest_id: str) -> bool:\n        \"\"\"Unregister a geofence associated with a quest.\n        \n        Args:\n            quest_id: The unique identifier of the quest.\n        \n        Returns:\n            True if the geofence was successfully unregistered, False otherwise.\n        \"\"\"\n        geofence_id = self._quest_geofence_map.get(quest_id)\n        if not geofence_id:\n            return False\n        \n        if geofence_id in self._geofences:\n            self._geofences[geofence_id].is_active = False\n            del self._geofences[geofence_id]\n        \n        del self._quest_geofence_map[quest_id]\n        return True\n    \n    def get_geofence_for_quest(self, quest_id: str) -> Optional[Geofence]:\n        \"\"\"Get the geofence associated with a quest.\"\"\"\n        geofence_id = self._quest_geofence_map.get(quest_id)\n        if geofence_id:\n            return self._geofences.get(geofence_id)\n        return None\n    \n    def get_active_geofences(self) -> List[Geofence]:\n        \"\"\"Get all active geofences.\"\"\"\n        return [g for g in self._geofences.values() if g.is_active]\n    \n    def register_location_callback(self, callback: Callable[[LocationUpdate], None]):\n        \"\"\"Register a callback for location updates.\"\"\"\n        self._location_callbacks.append(callback)\n    \n    def register_geofence_callback(self, callback: Callable[[str, str], None]):\n        \"\"\"Register a callback for geofence events.\n        \n        Args:\n            callback: A function that takes (quest_id, event_type) as arguments.\n                     event_type is either 'enter' or 'exit'.\n        \"\"\"\n        self._geofence_callbacks.append(callback)\n    \n    def start_location_tracking(self):\n        \"\"\"Start tracking the user's location.\"\"\"\n        self._is_tracking = True\n    \n    def stop_location_tracking(self):\n        \"\"\"Stop tracking the user's location.\"\"\"\n        self._is_tracking = False\n    \n    def get_current_location(self) -> Optional[LocationUpdate]:\n        \"\"\"Get the current cached location.\"\"\"\n        return self._current_location\n    \n    def simulate_location_update(self, latitude: float, longitude: float, accuracy: float = 10.0):\n        \"\"\"Simulate a location update (for testing purposes).\"\"\"\n        location = LocationUpdate(\n            latitude=latitude,\n            longitude=longitude,\n            accuracy=accuracy,\n            timestamp=datetime.now()\n        )\n        self._current_location = location\n        \n        # Notify location callbacks\n        for callback in self._location_callbacks:\n            callback(location)\n        \n        # Check geofences\n        self._check_geofences(location)\n    \n    def _check_geofences(self, location: LocationUpdate):\n        \"\"\"Check if the location triggers any geofences.\"\"\"\n        from src.utils import calculate_haversine_distance\n        \n        for geofence in self._geofences.values():\n            if not geofence.is_active:\n                continue\n            \n            distance = calculate_haversine_distance(\n                (location.latitude, location.longitude),\n                (geofence.latitude, geofence.longitude)\n            )\n            \n            if distance <= geofence.radius_meters:\n                # Trigger geofence enter event\n                for callback in self._geofence_callbacks:\n                    callback(geofence.quest_id, \"enter\")\n\n\n# Global location services instance\nlocation_services = LocationServicesWrapper()\n\n\ndef register_geofence(quest_id: str, latitude: float, longitude: float, radius_meters: float) -> str:\n    \"\"\"Register a geofence for a quest.\"\"\"\n    return location_services.register_geofence(quest_id, latitude, longitude, radius_meters)\n\n\ndef unregister_geofence(quest_id: str) -> bool:\n    \"\"\"Unregister a geofence for a quest.\"\"\"\n    return location_services.unregister_geofence(quest_id)\n\n\ndef get_location_services() -> LocationServicesWrapper:\n    \"\"\"Get the global location services instance.\"\"\"\n    return location_services\n",
            "src/module_31.py": "\"\"\"Push notification service for QuestSmith.\"\"\"\n\nfrom typing import Optional, List, Dict, Any, Callable\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\n\nclass NotificationPriority(Enum):\n    \"\"\"Priority levels for notifications.\"\"\"\n    LOW = \"low\"\n    NORMAL = \"normal\"\n    HIGH = \"high\"\n    URGENT = \"urgent\"\n\n\n@dataclass\nclass NotificationAction:\n    \"\"\"Represents an action button on a notification.\"\"\"\n    action_id: str\n    title: str\n    callback: Optional[Callable[[], None]] = None\n\n\n@dataclass\nclass LocalNotification:\n    \"\"\"Represents a local push notification.\"\"\"\n    notification_id: str\n    title: str\n    body: str\n    priority: NotificationPriority = NotificationPriority.NORMAL\n    actions: List[NotificationAction] = field(default_factory=list)\n    data: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=datetime.now)\n    delivered_at: Optional[datetime] = None\n    read_at: Optional[datetime] = None\n\n\nclass NotificationService:\n    \"\"\"Service for managing push notifications.\"\"\"\n    \n    def __init__(self):\n        self._notifications: Dict[str, LocalNotification] = {}\n        self._action_handlers: Dict[str, Callable[[str, str], None]] = {}  # action_id -> handler(notification_id, action_id)\n        self._pending_notifications: List[str] = []\n        self._is_enabled: bool = True\n    \n    def send_local_notification(\n        self,\n        title: str,\n        body: str,\n        priority: NotificationPriority = NotificationPriority.NORMAL,\n        actions: Optional[List[NotificationAction]] = None,\n        data: Optional[Dict[str, Any]] = None\n    ) -> str:\n        \"\"\"Send a local push notification.\n        \n        Args:\n            title: The notification title.\n            body: The notification body text.\n            priority: The notification priority level.\n            actions: Optional list of action buttons.\n            data: Optional custom data to attach to the notification.\n        \n        Returns:\n            The unique identifier of the notification.\n        \"\"\"\n        if not self._is_enabled:\n            return \"\"\n        \n        notification_id = str(uuid.uuid4())\n        notification = LocalNotification(\n            notification_id=notification_id,\n            title=title,\n            body=body,\n            priority=priority,\n            actions=actions or [],\n            data=data or {},\n            delivered_at=datetime.now()\n        )\n        self._notifications[notification_id] = notification\n        self._pending_notifications.append(notification_id)\n        \n        return notification_id\n    \n    def send_interactive_notification(\n        self,\n        title: str,\n        body: str,\n        actions: List[NotificationAction],\n        data: Optional[Dict[str, Any]] = None,\n        priority: NotificationPriority = NotificationPriority.HIGH\n    ) -> str:\n        \"\"\"Send an interactive notification with action buttons.\n        \n        Args:\n            title: The notification title.\n            body: The notification body text.\n            actions: List of action buttons for the notification.\n            data: Optional custom data to attach to the notification.\n            priority: The notification priority level.\n        \n        Returns:\n            The unique identifier of the notification.\n        \"\"\"\n        return self.send_local_notification(\n            title=title,\n            body=body,\n            priority=priority,\n            actions=actions,\n            data=data\n        )\n    \n    def register_action_handler(self, action_id: str, handler: Callable[[str, str], None]):\n        \"\"\"Register a handler for a notification action.\n        \n        Args:\n            action_id: The unique identifier of the action.\n            handler: A function that takes (notification_id, action_id) as arguments.\n        \"\"\"\n        self._action_handlers[action_id] = handler\n    \n    def handle_action(self, notification_id: str, action_id: str):\n        \"\"\"Handle a user action on a notification.\n        \n        Args:\n            notification_id: The notification that was acted upon.\n            action_id: The action that was taken.\n        \"\"\"\n        notification = self._notifications.get(notification_id)\n        if not notification:\n            return\n        \n        # Mark as read\n        notification.read_at = datetime.now()\n        \n        # Call registered handler\n        handler = self._action_handlers.get(action_id)\n        if handler:\n            handler(notification_id, action_id)\n        \n        # Call action-specific callback if present\n        for action in notification.actions:\n            if action.action_id == action_id and action.callback:\n                action.callback()\n    \n    def get_notification(self, notification_id: str) -> Optional[LocalNotification]:\n        \"\"\"Get a notification by its ID.\"\"\"\n        return self._notifications.get(notification_id)\n    \n    def get_pending_notifications(self) -> List[LocalNotification]:\n        \"\"\"Get all pending (unread) notifications.\"\"\"\n        return [\n            self._notifications[nid]\n            for nid in self._pending_notifications\n            if nid in self._notifications\n        ]\n    \n    def dismiss_notification(self, notification_id: str) -> bool:\n        \"\"\"Dismiss a notification.\"\"\"\n        if notification_id in self._pending_notifications:\n            self._pending_notifications.remove(notification_id)\n            return True\n        return False\n    \n    def clear_all_notifications(self):\n        \"\"\"Clear all pending notifications.\"\"\"\n        self._pending_notifications.clear()\n    \n    def enable_notifications(self):\n        \"\"\"Enable notifications.\"\"\"\n        self._is_enabled = True\n    \n    def disable_notifications(self):\n        \"\"\"Disable notifications.\"\"\"\n        self._is_enabled = False\n\n\n# Global notification service instance\nnotification_service = NotificationService()\n\n\ndef send_local_notification(\n    title: str,\n    body: str,\n    priority: NotificationPriority = NotificationPriority.NORMAL,\n    actions: Optional[List[NotificationAction]] = None,\n    data: Optional[Dict[str, Any]] = None\n) -> str:\n    \"\"\"Send a local push notification.\"\"\"\n    return notification_service.send_local_notification(title, body, priority, actions, data)\n\n\ndef send_interactive_notification(\n    title: str,\n    body: str,\n    actions: List[NotificationAction],\n    data: Optional[Dict[str, Any]] = None,\n    priority: NotificationPriority = NotificationPriority.HIGH\n) -> str:\n    \"\"\"Send an interactive notification with action buttons.\"\"\"\n    return notification_service.send_interactive_notification(title, body, actions, data, priority)\n\n\ndef register_action_handler(action_id: str, handler: Callable[[str, str], None]):\n    \"\"\"Register a handler for a notification action.\"\"\"\n    notification_service.register_action_handler(action_id, handler)\n\n\ndef handle_action(notification_id: str, action_id: str):\n    \"\"\"Handle a user action on a notification.\"\"\"\n    notification_service.handle_action(notification_id, action_id)\n\n\ndef get_notification_service() -> NotificationService:\n    \"\"\"Get the global notification service instance.\"\"\"\n    return notification_service\n",
            "src/module_7.py": "\"\"\"Background task handler for QuestSmith.\"\"\"\n\nfrom typing import Optional, Dict, Any, Callable, List\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom enum import Enum\nimport uuid\n\nfrom src.module_14 import get_quest, complete_quest, quest_manager\nfrom src.module_22 import unregister_geofence, get_location_services\nfrom src.module_31 import (\n    send_interactive_notification,\n    register_action_handler,\n    NotificationAction,\n    NotificationPriority\n)\n\n\nclass TaskType(Enum):\n    \"\"\"Types of background tasks.\"\"\"\n    GEOFENCE_TRIGGER = \"geofence_trigger\"\n    QUEST_EXPIRY_CHECK = \"quest_expiry_check\"\n    NOTIFICATION_DELIVERY = \"notification_delivery\"\n    DATA_SYNC = \"data_sync\"\n    LOCATION_UPDATE = \"location_update\"\n\n\nclass TaskStatus(Enum):\n    \"\"\"Status of a background task.\"\"\"\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass BackgroundTask:\n    \"\"\"Represents a background task.\"\"\"\n    task_id: str\n    task_type: TaskType\n    status: TaskStatus\n    data: Dict[str, Any]\n    created_at: datetime\n    started_at: Optional[datetime] = None\n    completed_at: Optional[datetime] = None\n    error_message: Optional[str] = None\n\n\n# Constants for notification actions\nGEOFENCE_CONFIRM_ACTION_ID = \"geofence_quest_confirm\"\nGEOFENCE_DISMISS_ACTION_ID = \"geofence_quest_dismiss\"\n\n\nclass BackgroundTaskHandler:\n    \"\"\"Handles background tasks for the QuestSmith application.\"\"\"\n    \n    def __init__(self):\n        self._tasks: Dict[str, BackgroundTask] = {}\n        self._task_handlers: Dict[TaskType, Callable[[BackgroundTask], bool]] = {}\n        self._pending_geofence_notifications: Dict[str, str] = {}  # notification_id -> quest_id\n        self._initialize_handlers()\n        self._setup_notification_handlers()\n    \n    def _initialize_handlers(self):\n        \"\"\"Initialize task handlers for different task types.\"\"\"\n        self._task_handlers[TaskType.GEOFENCE_TRIGGER] = self._handle_geofence_trigger\n        self._task_handlers[TaskType.QUEST_EXPIRY_CHECK] = self._handle_quest_expiry_check\n        self._task_handlers[TaskType.NOTIFICATION_DELIVERY] = self._handle_notification_delivery\n        self._task_handlers[TaskType.DATA_SYNC] = self._handle_data_sync\n        self._task_handlers[TaskType.LOCATION_UPDATE] = self._handle_location_update\n    \n    def _setup_notification_handlers(self):\n        \"\"\"Setup handlers for notification actions.\"\"\"\n        register_action_handler(GEOFENCE_CONFIRM_ACTION_ID, self._handle_geofence_confirm_action)\n        register_action_handler(GEOFENCE_DISMISS_ACTION_ID, self._handle_geofence_dismiss_action)\n    \n    def create_task(\n        self,\n        task_type: TaskType,\n        data: Optional[Dict[str, Any]] = None\n    ) -> BackgroundTask:\n        \"\"\"Create a new background task.\"\"\"\n        task_id = str(uuid.uuid4())\n        task = BackgroundTask(\n            task_id=task_id,\n            task_type=task_type,\n            status=TaskStatus.PENDING,\n            data=data or {},\n            created_at=datetime.now()\n        )\n        self._tasks[task_id] = task\n        return task\n    \n    def execute_task(self, task_id: str) -> bool:\n        \"\"\"Execute a pending task.\"\"\"\n        task = self._tasks.get(task_id)\n        if not task:\n            return False\n        \n        if task.status != TaskStatus.PENDING:\n            return False\n        \n        task.status = TaskStatus.RUNNING\n        task.started_at = datetime.now()\n        \n        handler = self._task_handlers.get(task.task_type)\n        if not handler:\n            task.status = TaskStatus.FAILED\n            task.error_message = f\"No handler for task type: {task.task_type}\"\n            return False\n        \n        try:\n            success = handler(task)\n            task.status = TaskStatus.COMPLETED if success else TaskStatus.FAILED\n            task.completed_at = datetime.now()\n            return success\n        except Exception as e:\n            task.status = TaskStatus.FAILED\n            task.error_message = str(e)\n            task.completed_at = datetime.now()\n            return False\n    \n    def _handle_geofence_trigger(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle a geofence trigger event.\n        \n        This is called when the user enters a geofenced area associated with a quest.\n        It sends an interactive notification asking the user to confirm quest completion.\n        \"\"\"\n        quest_id = task.data.get(\"quest_id\")\n        event_type = task.data.get(\"event_type\", \"enter\")\n        \n        if not quest_id:\n            task.error_message = \"No quest_id provided in geofence trigger\"\n            return False\n        \n        # Only handle 'enter' events\n        if event_type != \"enter\":\n            return True\n        \n        # Fetch the quest details\n        quest = get_quest(quest_id)\n        if not quest:\n            task.error_message = f\"Quest not found: {quest_id}\"\n            return False\n        \n        # Check if quest is still active\n        from src.module_14 import QuestStatus\n        if quest.status != QuestStatus.ACTIVE:\n            return True  # Quest is no longer active, nothing to do\n        \n        # Get location name\n        location_name = \"this location\"\n        if quest.location:\n            location_name = quest.location.location_name\n        \n        # Create notification actions\n        confirm_action = NotificationAction(\n            action_id=GEOFENCE_CONFIRM_ACTION_ID,\n            title=\"Confirm\"\n        )\n        dismiss_action = NotificationAction(\n            action_id=GEOFENCE_DISMISS_ACTION_ID,\n            title=\"Not Yet\"\n        )\n        \n        # Send interactive notification\n        notification_id = send_interactive_notification(\n            title=\"QuestSmith\",\n            body=f\"It looks like you're at {location_name}. Did you complete '{quest.name}'?\",\n            actions=[confirm_action, dismiss_action],\n            data={\"quest_id\": quest_id},\n            priority=NotificationPriority.HIGH\n        )\n        \n        # Store mapping for handling the response\n        self._pending_geofence_notifications[notification_id] = quest_id\n        \n        return True\n    \n    def _handle_geofence_confirm_action(self, notification_id: str, action_id: str):\n        \"\"\"Handle the 'Confirm' action from a geofence notification.\n        \n        This is called when the user taps 'Confirm' on the quest completion notification.\n        It completes the quest and unregisters the geofence.\n        \"\"\"\n        quest_id = self._pending_geofence_notifications.get(notification_id)\n        if not quest_id:\n            # Try to get quest_id from notification data\n            from src.module_31 import get_notification_service\n            notification = get_notification_service().get_notification(notification_id)\n            if notification and notification.data:\n                quest_id = notification.data.get(\"quest_id\")\n        \n        if not quest_id:\n            return\n        \n        # Complete the quest\n        reward = complete_quest(quest_id)\n        \n        if reward:\n            # Unregister the geofence to prevent repeated notifications and save battery\n            unregister_geofence(quest_id)\n            \n            # Clean up pending notification mapping\n            if notification_id in self._pending_geofence_notifications:\n                del self._pending_geofence_notifications[notification_id]\n    \n    def _handle_geofence_dismiss_action(self, notification_id: str, action_id: str):\n        \"\"\"Handle the 'Not Yet' action from a geofence notification.\"\"\"\n        # Just clean up the pending notification mapping\n        if notification_id in self._pending_geofence_notifications:\n            del self._pending_geofence_notifications[notification_id]\n    \n    def _handle_quest_expiry_check(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle quest expiry checking.\"\"\"\n        # Implementation for checking expired quests\n        return True\n    \n    def _handle_notification_delivery(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle notification delivery.\"\"\"\n        # Implementation for notification delivery\n        return True\n    \n    def _handle_data_sync(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle data synchronization.\"\"\"\n        # Implementation for data sync\n        return True\n    \n    def _handle_location_update(self, task: BackgroundTask) -> bool:\n        \"\"\"Handle location update processing.\"\"\"\n        # Implementation for location updates\n        return True\n    \n    def get_task(self, task_id: str) -> Optional[BackgroundTask]:\n        \"\"\"Get a task by its ID.\"\"\"\n        return self._tasks.get(task_id)\n    \n    def get_pending_tasks(self) -> List[BackgroundTask]:\n        \"\"\"Get all pending tasks.\"\"\"\n        return [t for t in self._tasks.values() if t.status == TaskStatus.PENDING]\n\n\n# Global background task handler instance\ntask_handler = BackgroundTaskHandler()\n\n\ndef handle_geofence_event(quest_id: str, event_type: str = \"enter\"):\n    \"\"\"Handle a geofence event from the location services.\n    \n    This function is called when the user enters or exits a geofenced area.\n    \n    Args:\n        quest_id: The ID of the quest associated with the geofence.\n        event_type: The type of event ('enter' or 'exit').\n    \"\"\"\n    task = task_handler.create_task(\n        TaskType.GEOFENCE_TRIGGER,\n        data={\"quest_id\": quest_id, \"event_type\": event_type}\n    )\n    task_handler.execute_task(task.task_id)\n\n\ndef handle_quest_confirmation(quest_id: str):\n    \"\"\"Handle quest confirmation from a notification.\n    \n    This is called when the user confirms quest completion via notification.\n    \n    Args:\n        quest_id: The ID of the quest to complete.\n    \"\"\"\n    # Complete the quest\n    reward = complete_quest(quest_id)\n    \n    if reward:\n        # Unregister the geofence\n        unregister_geofence(quest_id)\n\n\ndef initialize_geofence_handler():\n    \"\"\"Initialize the geofence event handler.\n    \n    This connects the location services to the background task handler.\n    \"\"\"\n    location_services = get_location_services()\n    location_services.register_geofence_callback(handle_geofence_event)\n\n\ndef get_task_handler() -> BackgroundTaskHandler:\n    \"\"\"Get the global task handler instance.\"\"\"\n    return task_handler\n",
            "tests/test_utils.py": "\"\"\"Unit tests for utility functions.\"\"\"\n\nimport unittest\nimport math\nfrom datetime import datetime\n\nfrom src.utils import (\n    generate_unique_id,\n    hash_password,\n    validate_email,\n    format_datetime,\n    parse_datetime,\n    calculate_experience_for_level,\n    truncate_string,\n    sanitize_input,\n    calculate_haversine_distance,\n    is_valid_coordinates\n)\n\n\nclass TestUtilityFunctions(unittest.TestCase):\n    \"\"\"Test cases for utility functions.\"\"\"\n    \n    def test_generate_unique_id(self):\n        \"\"\"Test that unique IDs are generated.\"\"\"\n        id1 = generate_unique_id()\n        id2 = generate_unique_id()\n        self.assertNotEqual(id1, id2)\n        self.assertIsInstance(id1, str)\n        self.assertTrue(len(id1) > 0)\n    \n    def test_hash_password(self):\n        \"\"\"Test password hashing.\"\"\"\n        password = \"test_password\"\n        hashed = hash_password(password)\n        self.assertNotEqual(password, hashed)\n        self.assertEqual(len(hashed), 64)  # SHA-256 produces 64 hex characters\n        \n        # Same password should produce same hash\n        hashed2 = hash_password(password)\n        self.assertEqual(hashed, hashed2)\n    \n    def test_validate_email_valid(self):\n        \"\"\"Test email validation with valid emails.\"\"\"\n        valid_emails = [\n            \"test@example.com\",\n            \"user.name@domain.org\",\n            \"user+tag@example.co.uk\"\n        ]\n        for email in valid_emails:\n            self.assertTrue(validate_email(email), f\"{email} should be valid\")\n    \n    def test_validate_email_invalid(self):\n        \"\"\"Test email validation with invalid emails.\"\"\"\n        invalid_emails = [\n            \"not_an_email\",\n            \"@nodomain.com\",\n            \"missing@.com\",\n            \"\"\n        ]\n        for email in invalid_emails:\n            self.assertFalse(validate_email(email), f\"{email} should be invalid\")\n    \n    def test_format_datetime(self):\n        \"\"\"Test datetime formatting.\"\"\"\n        dt = datetime(2024, 1, 15, 10, 30, 45)\n        formatted = format_datetime(dt)\n        self.assertEqual(formatted, \"2024-01-15 10:30:45\")\n    \n    def test_parse_datetime(self):\n        \"\"\"Test datetime parsing.\"\"\"\n        dt_string = \"2024-01-15 10:30:45\"\n        parsed = parse_datetime(dt_string)\n        self.assertEqual(parsed.year, 2024)\n        self.assertEqual(parsed.month, 1)\n        self.assertEqual(parsed.day, 15)\n        self.assertEqual(parsed.hour, 10)\n        self.assertEqual(parsed.minute, 30)\n        self.assertEqual(parsed.second, 45)\n    \n    def test_calculate_experience_for_level(self):\n        \"\"\"Test experience calculation.\"\"\"\n        exp_level_1 = calculate_experience_for_level(1)\n        exp_level_10 = calculate_experience_for_level(10)\n        self.assertGreater(exp_level_10, exp_level_1)\n        self.assertEqual(exp_level_1, 100)\n    \n    def test_truncate_string(self):\n        \"\"\"Test string truncation.\"\"\"\n        short_text = \"Hello\"\n        long_text = \"This is a very long text that should be truncated\"\n        \n        self.assertEqual(truncate_string(short_text, 10), \"Hello\")\n        truncated = truncate_string(long_text, 20)\n        self.assertEqual(len(truncated), 20)\n        self.assertTrue(truncated.endswith(\"...\"))\n    \n    def test_sanitize_input(self):\n        \"\"\"Test input sanitization.\"\"\"\n        dirty_input = \"<script>alert('xss')</script>\"\n        clean = sanitize_input(dirty_input)\n        self.assertNotIn(\"<\", clean)\n        self.assertNotIn(\">\", clean)\n\n\nclass TestCalculateHaversineDistance(unittest.TestCase):\n    \"\"\"Test cases for the haversine distance calculation function.\"\"\"\n    \n    def test_calculate_haversine_distance_same_point(self):\n        \"\"\"Test that distance between same point is zero.\"\"\"\n        coord = (40.7128, -74.0060)  # New York City\n        distance = calculate_haversine_distance(coord, coord)\n        self.assertEqual(distance, 0.0)\n    \n    def test_calculate_haversine_distance_known_distance(self):\n        \"\"\"Test haversine distance with known real-world distance.\"\"\"\n        # New York City to Los Angeles\n        # Actual distance is approximately 3,944 km (3,944,000 meters)\n        new_york = (40.7128, -74.0060)\n        los_angeles = (34.0522, -118.2437)\n        \n        distance = calculate_haversine_distance(new_york, los_angeles)\n        \n        # Allow for some variance (within 50km of expected)\n        expected_distance = 3944000  # meters\n        self.assertAlmostEqual(distance, expected_distance, delta=50000)\n    \n    def test_calculate_haversine_distance_short_distance(self):\n        \"\"\"Test haversine distance for a short distance (within a city).\"\"\"\n        # Empire State Building to Times Square (approximately 1.2 km)\n        empire_state = (40.7484, -73.9857)\n        times_square = (40.7580, -73.9855)\n        \n        distance = calculate_haversine_distance(empire_state, times_square)\n        \n        # Should be approximately 1000-1200 meters\n        self.assertGreater(distance, 900)\n        self.assertLess(distance, 1500)\n    \n    def test_calculate_haversine_distance_symmetric(self):\n        \"\"\"Test that distance is symmetric (A to B equals B to A).\"\"\"\n        coord1 = (51.5074, -0.1278)  # London\n        coord2 = (48.8566, 2.3522)   # Paris\n        \n        distance_1_to_2 = calculate_haversine_distance(coord1, coord2)\n        distance_2_to_1 = calculate_haversine_distance(coord2, coord1)\n        \n        self.assertAlmostEqual(distance_1_to_2, distance_2_to_1, places=5)\n    \n    def test_calculate_haversine_distance_equator(self):\n        \"\"\"Test distance calculation along the equator.\"\"\"\n        # Two points on the equator, 1 degree apart\n        # 1 degree at equator is approximately 111.32 km\n        point1 = (0.0, 0.0)\n        point2 = (0.0, 1.0)\n        \n        distance = calculate_haversine_distance(point1, point2)\n        \n        # Should be approximately 111,320 meters\n        self.assertAlmostEqual(distance, 111320, delta=500)\n    \n    def test_calculate_haversine_distance_poles(self):\n        \"\"\"Test distance from North Pole to South Pole.\"\"\"\n        north_pole = (90.0, 0.0)\n        south_pole = (-90.0, 0.0)\n        \n        distance = calculate_haversine_distance(north_pole, south_pole)\n        \n        # Half the Earth's circumference, approximately 20,015 km\n        expected = 20015000  # meters\n        self.assertAlmostEqual(distance, expected, delta=100000)\n    \n    def test_calculate_haversine_distance_very_small(self):\n        \"\"\"Test distance calculation for very small distances (meters apart).\"\"\"\n        # Two points approximately 100 meters apart\n        point1 = (40.7128, -74.0060)\n        # Move approximately 100 meters north (about 0.0009 degrees)\n        point2 = (40.7137, -74.0060)\n        \n        distance = calculate_haversine_distance(point1, point2)\n        \n        # Should be approximately 100 meters\n        self.assertGreater(distance, 80)\n        self.assertLess(distance, 120)\n    \n    def test_calculate_haversine_distance_returns_float(self):\n        \"\"\"Test that the function returns a float.\"\"\"\n        coord1 = (0.0, 0.0)\n        coord2 = (1.0, 1.0)\n        \n        distance = calculate_haversine_distance(coord1, coord2)\n        \n        self.assertIsInstance(distance, float)\n    \n    def test_calculate_haversine_distance_negative_coordinates(self):\n        \"\"\"Test with negative latitude and longitude values.\"\"\"\n        # Sydney, Australia to Cape Town, South Africa\n        sydney = (-33.8688, 151.2093)\n        cape_town = (-33.9249, 18.4241)\n        \n        distance = calculate_haversine_distance(sydney, cape_town)\n        \n        # Should be approximately 11,000 km\n        self.assertGreater(distance, 10000000)\n        self.assertLess(distance, 12000000)\n\n\nclass TestIsValidCoordinates(unittest.TestCase):\n    \"\"\"Test cases for coordinate validation.\"\"\"\n    \n    def test_valid_coordinates(self):\n        \"\"\"Test with valid coordinates.\"\"\"\n        self.assertTrue(is_valid_coordinates(0, 0))\n        self.assertTrue(is_valid_coordinates(90, 180))\n        self.assertTrue(is_valid_coordinates(-90, -180))\n        self.assertTrue(is_valid_coordinates(45.5, -122.6))\n    \n    def test_invalid_latitude(self):\n        \"\"\"Test with invalid latitude.\"\"\"\n        self.assertFalse(is_valid_coordinates(91, 0))\n        self.assertFalse(is_valid_coordinates(-91, 0))\n    \n    def test_invalid_longitude(self):\n        \"\"\"Test with invalid longitude.\"\"\"\n        self.assertFalse(is_valid_coordinates(0, 181))\n        self.assertFalse(is_valid_coordinates(0, -181))\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n"
          },
          "generated_files": [
            "src/config.py",
            "src/utils.py",
            "src/module_14.py",
            "src/module_22.py",
            "src/module_31.py",
            "src/module_7.py",
            "tests/test_utils.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7075428571428571,
                "dependency_traversal_accuracy": 0.746674198132594,
                "cross_file_reasoning_depth": 0.20440476190476192,
                "system_thinking_score": 0.3769943503717276,
                "robustness_score": 0.41539299930498513,
                "comprehensiveness_score": 0.72281212484994,
                "innovation_score": 0.1875,
                "solution_elegance_score": 0.7693765366301679
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.08844285714285714,
                "dependency_traversal_weighted": 0.09333427476657424,
                "cross_file_reasoning_weighted": 0.02555059523809524,
                "system_thinking_weighted": 0.04712429379646595,
                "robustness_weighted": 0.05192412491312314,
                "comprehensiveness_weighted": 0.0903515156062425,
                "innovation_weighted": 0.0234375,
                "solution_elegance_weighted": 0.09617206707877099
              },
              "total_software_engineering_score": 0.5163372285421293
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.456113338470459,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "src/config.py",
                  "src/utils.py",
                  "src/module_14.py",
                  "src/module_22.py",
                  "src/module_31.py",
                  "src/module_7.py",
                  "tests/test_utils.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.0,
                "tests_run": 4,
                "tests_passed": 0,
                "tests_failed": 4,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": false,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": false,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 7,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 6 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.30854660235494397,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.0,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.30854660235494397,
                "idc_weight": 0.2,
                "total_functional_score": 0.4917093204709888
              }
            },
            "code_quality_details": {
              "files_analyzed": 7,
              "quality_checks": {
                "src/config.py": {
                  "line_count": 31,
                  "non_empty_lines": 23,
                  "comment_lines": 7,
                  "comment_ratio": 0.30434782608695654,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.7
                },
                "src/utils.py": {
                  "line_count": 100,
                  "non_empty_lines": 68,
                  "comment_lines": 5,
                  "comment_ratio": 0.07352941176470588,
                  "function_count": 11,
                  "class_count": 0,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "src/module_14.py": {
                  "line_count": 236,
                  "non_empty_lines": 187,
                  "comment_lines": 2,
                  "comment_ratio": 0.0106951871657754,
                  "function_count": 17,
                  "class_count": 6,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "src/module_22.py": {
                  "line_count": 184,
                  "non_empty_lines": 144,
                  "comment_lines": 4,
                  "comment_ratio": 0.027777777777777776,
                  "function_count": 15,
                  "class_count": 4,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "src/module_31.py": {
                  "line_count": 219,
                  "non_empty_lines": 175,
                  "comment_lines": 4,
                  "comment_ratio": 0.022857142857142857,
                  "function_count": 16,
                  "class_count": 4,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "src/module_7.py": {
                  "line_count": 291,
                  "non_empty_lines": 229,
                  "comment_lines": 20,
                  "comment_ratio": 0.08733624454148471,
                  "function_count": 18,
                  "class_count": 7,
                  "import_count": 24,
                  "quality_score": 0.7999999999999999
                },
                "tests/test_utils.py": {
                  "line_count": 231,
                  "non_empty_lines": 181,
                  "comment_lines": 15,
                  "comment_ratio": 0.08287292817679558,
                  "function_count": 21,
                  "class_count": 3,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7899999999999998,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.5333498023715413,
                "multi_session_memory_retention": 0.6131574946792337
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.26667490118577064,
                "multi_session_memory_retention_weighted": 0.3065787473396169
              },
              "total_longcontext_utilization_score": 0.5732536485253875
            }
          },
          "timestamp": "2026-01-14T21:03:04.231492"
        }
      }
    },
    "python_data_streaming_expert_085_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_data_streaming_expert_085_feature_implementation_expert_01",
          "scenario_title": "Implement a Dead-Letter Queue (DLQ) for Invalid Data Records",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5339356060313756,
          "functional_correctness_score": 0.45150392749244717,
          "code_quality_score": 0.7719999999999999,
          "longcontext_utilization_score": 0.5109309309309309,
          "total_score": 2.7725925687668873,
          "generation_time": 92.88544511795044,
          "code_files_generated": 5,
          "total_lines_generated": 838,
          "parsing_success": true,
          "solution_code": {
            "src/config.py": "\"\"\"Configuration module for PulseStream Nexus.\"\"\"\nimport os\n\n# Existing configuration parameters\nDEBUG = os.environ.get('DEBUG', 'false').lower() == 'true'\nLOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')\nMAX_BATCH_SIZE = int(os.environ.get('MAX_BATCH_SIZE', '1000'))\nPROCESSING_TIMEOUT = int(os.environ.get('PROCESSING_TIMEOUT', '30'))\nRETRY_ATTEMPTS = int(os.environ.get('RETRY_ATTEMPTS', '3'))\n\n# Database configuration\nDB_HOST = os.environ.get('DB_HOST', 'localhost')\nDB_PORT = int(os.environ.get('DB_PORT', '5432'))\nDB_NAME = os.environ.get('DB_NAME', 'pulsestream')\nDB_USER = os.environ.get('DB_USER', 'admin')\nDB_PASSWORD = os.environ.get('DB_PASSWORD', '')\n\n# Streaming configuration\nSTREAM_BUFFER_SIZE = int(os.environ.get('STREAM_BUFFER_SIZE', '10000'))\nSTREAM_FLUSH_INTERVAL = int(os.environ.get('STREAM_FLUSH_INTERVAL', '5'))\n\n# Dead-Letter Queue (DLQ) Configuration\nDLQ_ENABLED = os.environ.get('DLQ_ENABLED', 'true').lower() == 'true'\nDLQ_STORAGE_TYPE = os.environ.get('DLQ_STORAGE_TYPE', 'local_file')\nDLQ_FILE_PATH = os.environ.get('DLQ_FILE_PATH', '/var/log/pulsestream/dlq.jsonl')\n\n\ndef get_config():\n    \"\"\"Return configuration as a dictionary.\"\"\"\n    return {\n        'debug': DEBUG,\n        'log_level': LOG_LEVEL,\n        'max_batch_size': MAX_BATCH_SIZE,\n        'processing_timeout': PROCESSING_TIMEOUT,\n        'retry_attempts': RETRY_ATTEMPTS,\n        'db_host': DB_HOST,\n        'db_port': DB_PORT,\n        'db_name': DB_NAME,\n        'db_user': DB_USER,\n        'db_password': DB_PASSWORD,\n        'stream_buffer_size': STREAM_BUFFER_SIZE,\n        'stream_flush_interval': STREAM_FLUSH_INTERVAL,\n        'dlq_enabled': DLQ_ENABLED,\n        'dlq_storage_type': DLQ_STORAGE_TYPE,\n        'dlq_file_path': DLQ_FILE_PATH,\n    }\n",
            "src/dlq_handler.py": "\"\"\"Dead-Letter Queue Handler for PulseStream Nexus.\n\nThis module provides functionality to capture and store invalid data records\nthat fail validation, enabling later analysis and debugging.\n\"\"\"\nimport json\nimport os\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\nfrom src.utils import MonitoringClient\n\nlogger = logging.getLogger(__name__)\n\n\nclass DLQHandler:\n    \"\"\"Handler for routing invalid records to the Dead-Letter Queue.\n    \n    This handler writes failed validation records to a configurable storage\n    location (currently supports local file storage) and tracks metrics.\n    \"\"\"\n    \n    DLQ_METRIC_NAME = 'pulsestream.nexus.dlq.records_written'\n    \n    def __init__(self, config: Dict[str, Any]):\n        \"\"\"Initialize the DLQ Handler with configuration.\n        \n        Args:\n            config: Application configuration dictionary containing:\n                - dlq_enabled: Boolean to toggle the DLQ feature\n                - dlq_storage_type: Storage type ('local_file')\n                - dlq_file_path: Path to the DLQ file\n        \"\"\"\n        self.config = config\n        self.enabled = config.get('dlq_enabled', False)\n        self.storage_type = config.get('dlq_storage_type', 'local_file')\n        self.file_path = config.get('dlq_file_path', '/var/log/pulsestream/dlq.jsonl')\n        self._monitoring_client: Optional[MonitoringClient] = None\n        \n        if self.enabled:\n            self._ensure_directory_exists()\n            self._initialize_monitoring()\n    \n    def _ensure_directory_exists(self) -> None:\n        \"\"\"Ensure the directory for the DLQ file exists.\"\"\"\n        directory = os.path.dirname(self.file_path)\n        if directory and not os.path.exists(directory):\n            try:\n                os.makedirs(directory, exist_ok=True)\n                logger.info(f\"Created DLQ directory: {directory}\")\n            except OSError as e:\n                logger.error(f\"Failed to create DLQ directory {directory}: {e}\")\n                raise\n    \n    def _initialize_monitoring(self) -> None:\n        \"\"\"Initialize the monitoring client.\"\"\"\n        try:\n            self._monitoring_client = MonitoringClient()\n            logger.debug(\"Monitoring client initialized for DLQ\")\n        except Exception as e:\n            logger.warning(f\"Failed to initialize monitoring client: {e}\")\n            self._monitoring_client = None\n    \n    def handle(self, record: Dict[str, Any], validation_errors: List[str]) -> bool:\n        \"\"\"Handle an invalid record by writing it to the DLQ.\n        \n        Args:\n            record: The original data record that failed validation\n            validation_errors: List of validation error strings describing\n                what went wrong\n        \n        Returns:\n            bool: True if the record was successfully written to DLQ,\n                False otherwise\n        \"\"\"\n        if not self.enabled:\n            logger.debug(\"DLQ is disabled, skipping record handling\")\n            return False\n        \n        if self.storage_type != 'local_file':\n            logger.error(f\"Unsupported DLQ storage type: {self.storage_type}\")\n            return False\n        \n        return self._write_to_file(record, validation_errors)\n    \n    def _write_to_file(self, record: Dict[str, Any], validation_errors: List[str]) -> bool:\n        \"\"\"Write the invalid record to the DLQ file.\n        \n        Args:\n            record: The original data record\n            validation_errors: List of validation error strings\n        \n        Returns:\n            bool: True if write was successful, False otherwise\n        \"\"\"\n        dlq_entry = {\n            'timestamp': datetime.utcnow().isoformat() + 'Z',\n            'record': record,\n            'validation_errors': validation_errors\n        }\n        \n        try:\n            with open(self.file_path, 'a', encoding='utf-8') as f:\n                json_line = json.dumps(dlq_entry, default=str)\n                f.write(json_line + '\n')\n            \n            logger.debug(f\"Record written to DLQ: {self.file_path}\")\n            \n            # Increment monitoring counter\n            self._increment_metric()\n            \n            return True\n            \n        except IOError as e:\n            logger.error(f\"Failed to write record to DLQ file {self.file_path}: {e}\")\n            return False\n        except (TypeError, ValueError) as e:\n            logger.error(f\"Failed to serialize record to JSON: {e}\")\n            return False\n    \n    def _increment_metric(self) -> None:\n        \"\"\"Increment the DLQ records written metric.\"\"\"\n        if self._monitoring_client is not None:\n            try:\n                self._monitoring_client.increment(self.DLQ_METRIC_NAME, 1)\n                logger.debug(f\"Incremented metric: {self.DLQ_METRIC_NAME}\")\n            except Exception as e:\n                logger.warning(f\"Failed to increment DLQ metric: {e}\")\n",
            "src/module_30.py": "\"\"\"Data validation module for PulseStream Nexus.\n\nThis module contains the DataValidator class responsible for validating\nincoming data records against defined schemas and business rules.\n\"\"\"\nimport logging\nfrom typing import Dict, Any, List, Tuple, Optional, Union\n\nlogger = logging.getLogger(__name__)\n\n\nclass ValidationResult:\n    \"\"\"Container for validation results.\n    \n    Attributes:\n        is_valid: Boolean indicating if validation passed\n        errors: List of validation error messages\n    \"\"\"\n    \n    def __init__(self, is_valid: bool, errors: Optional[List[str]] = None):\n        self.is_valid = is_valid\n        self.errors = errors or []\n    \n    def __bool__(self) -> bool:\n        return self.is_valid\n    \n    def __repr__(self) -> str:\n        return f\"ValidationResult(is_valid={self.is_valid}, errors={self.errors})\"\n\n\nclass DataValidator:\n    \"\"\"Validates incoming data records for the PulseStream pipeline.\n    \n    This validator checks records against schema requirements and\n    business rules before they are processed by downstream components.\n    \"\"\"\n    \n    REQUIRED_FIELDS = ['event_id', 'event_type', 'timestamp', 'payload']\n    VALID_EVENT_TYPES = ['user_action', 'system_event', 'transaction', 'metric', 'log']\n    MAX_PAYLOAD_SIZE = 1048576  # 1MB\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the DataValidator.\n        \n        Args:\n            config: Optional configuration dictionary for customizing\n                validation rules\n        \"\"\"\n        self.config = config or {}\n        self.strict_mode = self.config.get('strict_mode', True)\n        self.custom_validators = []\n    \n    def validate(self, record: Dict[str, Any]) -> ValidationResult:\n        \"\"\"Validate a data record.\n        \n        Args:\n            record: The data record to validate\n        \n        Returns:\n            ValidationResult containing validation status and any errors\n        \"\"\"\n        errors: List[str] = []\n        \n        if not isinstance(record, dict):\n            return ValidationResult(False, ['Record must be a dictionary'])\n        \n        # Check required fields\n        missing_fields = self._check_required_fields(record)\n        errors.extend(missing_fields)\n        \n        # Validate event_id format\n        event_id_errors = self._validate_event_id(record.get('event_id'))\n        errors.extend(event_id_errors)\n        \n        # Validate event_type\n        event_type_errors = self._validate_event_type(record.get('event_type'))\n        errors.extend(event_type_errors)\n        \n        # Validate timestamp\n        timestamp_errors = self._validate_timestamp(record.get('timestamp'))\n        errors.extend(timestamp_errors)\n        \n        # Validate payload\n        payload_errors = self._validate_payload(record.get('payload'))\n        errors.extend(payload_errors)\n        \n        # Run custom validators\n        for validator in self.custom_validators:\n            try:\n                custom_errors = validator(record)\n                if custom_errors:\n                    errors.extend(custom_errors)\n            except Exception as e:\n                logger.warning(f\"Custom validator failed: {e}\")\n                if self.strict_mode:\n                    errors.append(f\"Custom validation error: {str(e)}\")\n        \n        is_valid = len(errors) == 0\n        \n        if not is_valid:\n            logger.debug(f\"Validation failed for record: {errors}\")\n        \n        return ValidationResult(is_valid, errors)\n    \n    def _check_required_fields(self, record: Dict[str, Any]) -> List[str]:\n        \"\"\"Check that all required fields are present.\"\"\"\n        errors = []\n        for field in self.REQUIRED_FIELDS:\n            if field not in record:\n                errors.append(f\"Missing required field: {field}\")\n            elif record[field] is None:\n                errors.append(f\"Required field '{field}' cannot be null\")\n        return errors\n    \n    def _validate_event_id(self, event_id: Any) -> List[str]:\n        \"\"\"Validate the event_id field.\"\"\"\n        errors = []\n        if event_id is None:\n            return errors  # Already caught by required fields check\n        \n        if not isinstance(event_id, str):\n            errors.append(f\"event_id must be a string, got {type(event_id).__name__}\")\n        elif len(event_id) == 0:\n            errors.append(\"event_id cannot be empty\")\n        elif len(event_id) > 256:\n            errors.append(f\"event_id exceeds maximum length of 256 characters\")\n        \n        return errors\n    \n    def _validate_event_type(self, event_type: Any) -> List[str]:\n        \"\"\"Validate the event_type field.\"\"\"\n        errors = []\n        if event_type is None:\n            return errors  # Already caught by required fields check\n        \n        if not isinstance(event_type, str):\n            errors.append(f\"event_type must be a string, got {type(event_type).__name__}\")\n        elif event_type not in self.VALID_EVENT_TYPES:\n            errors.append(\n                f\"Invalid event_type '{event_type}'. \"\n                f\"Must be one of: {', '.join(self.VALID_EVENT_TYPES)}\"\n            )\n        \n        return errors\n    \n    def _validate_timestamp(self, timestamp: Any) -> List[str]:\n        \"\"\"Validate the timestamp field.\"\"\"\n        errors = []\n        if timestamp is None:\n            return errors  # Already caught by required fields check\n        \n        if isinstance(timestamp, str):\n            # Basic ISO format check\n            if len(timestamp) < 10:\n                errors.append(\"Invalid timestamp format\")\n        elif isinstance(timestamp, (int, float)):\n            # Unix timestamp - check reasonable range\n            if timestamp < 0 or timestamp > 4102444800:  # Year 2100\n                errors.append(\"Timestamp out of valid range\")\n        else:\n            errors.append(\n                f\"timestamp must be a string or number, got {type(timestamp).__name__}\"\n            )\n        \n        return errors\n    \n    def _validate_payload(self, payload: Any) -> List[str]:\n        \"\"\"Validate the payload field.\"\"\"\n        errors = []\n        if payload is None:\n            return errors  # Already caught by required fields check\n        \n        if not isinstance(payload, dict):\n            errors.append(f\"payload must be a dictionary, got {type(payload).__name__}\")\n            return errors\n        \n        # Check payload size (approximate)\n        try:\n            import json\n            payload_str = json.dumps(payload)\n            if len(payload_str) > self.MAX_PAYLOAD_SIZE:\n                errors.append(\n                    f\"payload exceeds maximum size of {self.MAX_PAYLOAD_SIZE} bytes\"\n                )\n        except (TypeError, ValueError) as e:\n            errors.append(f\"payload contains non-serializable data: {str(e)}\")\n        \n        return errors\n    \n    def add_custom_validator(self, validator_func) -> None:\n        \"\"\"Add a custom validation function.\n        \n        Args:\n            validator_func: A callable that takes a record dict and returns\n                a list of error strings (empty if valid)\n        \"\"\"\n        self.custom_validators.append(validator_func)\n    \n    def is_valid(self, record: Dict[str, Any]) -> bool:\n        \"\"\"Simple boolean check if record is valid.\n        \n        Args:\n            record: The data record to validate\n        \n        Returns:\n            True if valid, False otherwise\n        \"\"\"\n        return self.validate(record).is_valid\n",
            "src/module_12.py": "\"\"\"Main processing pipeline module for PulseStream Nexus.\n\nThis module orchestrates the data processing pipeline, handling record\ningestion, validation, transformation, and routing.\n\"\"\"\nimport logging\nfrom typing import Dict, Any, List, Optional, Iterator\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nfrom src.config import get_config\nfrom src.module_30 import DataValidator, ValidationResult\nfrom src.dlq_handler import DLQHandler\n\nlogger = logging.getLogger(__name__)\n\n\nclass ProcessingPipeline:\n    \"\"\"Main data processing pipeline for PulseStream Nexus.\n    \n    This pipeline handles the complete lifecycle of data records from\n    ingestion through validation, transformation, and output.\n    \"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the processing pipeline.\n        \n        Args:\n            config: Optional configuration dictionary. If not provided,\n                configuration will be loaded from src.config\n        \"\"\"\n        self.config = config or get_config()\n        self.validator = DataValidator(self.config)\n        self.dlq_handler = self._initialize_dlq_handler()\n        self.batch_size = self.config.get('max_batch_size', 1000)\n        self.processed_count = 0\n        self.failed_count = 0\n        self.dlq_count = 0\n    \n    def _initialize_dlq_handler(self) -> Optional[DLQHandler]:\n        \"\"\"Initialize the DLQ handler if enabled.\"\"\"\n        if self.config.get('dlq_enabled', False):\n            try:\n                handler = DLQHandler(self.config)\n                logger.info(\"DLQ handler initialized successfully\")\n                return handler\n            except Exception as e:\n                logger.error(f\"Failed to initialize DLQ handler: {e}\")\n                return None\n        return None\n    \n    def process_record(self, record: Dict[str, Any]) -> bool:\n        \"\"\"Process a single data record through the pipeline.\n        \n        Args:\n            record: The data record to process\n        \n        Returns:\n            True if the record was processed successfully, False otherwise\n        \"\"\"\n        try:\n            # Validate the record\n            validation_result = self.validator.validate(record)\n            \n            if not validation_result.is_valid:\n                self._handle_validation_failure(record, validation_result)\n                return False\n            \n            # Transform and process the valid record\n            transformed_record = self._transform_record(record)\n            \n            # Route to output\n            self._route_record(transformed_record)\n            \n            self.processed_count += 1\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error processing record: {e}\")\n            self.failed_count += 1\n            return False\n    \n    def _handle_validation_failure(self, record: Dict[str, Any], \n                                    validation_result: ValidationResult) -> None:\n        \"\"\"Handle a record that failed validation.\n        \n        Args:\n            record: The original record that failed validation\n            validation_result: The validation result containing errors\n        \"\"\"\n        self.failed_count += 1\n        \n        # Log the validation failure\n        logger.warning(\n            f\"Record failed validation: {validation_result.errors}\"\n        )\n        \n        # Route to DLQ if enabled\n        if self.config.get('dlq_enabled', False) and self.dlq_handler is not None:\n            try:\n                success = self.dlq_handler.handle(record, validation_result.errors)\n                if success:\n                    self.dlq_count += 1\n                    logger.debug(\"Record successfully written to DLQ\")\n                else:\n                    logger.warning(\"Failed to write record to DLQ\")\n            except Exception as e:\n                logger.error(f\"Error writing to DLQ: {e}\")\n    \n    def _transform_record(self, record: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Transform a validated record for downstream processing.\n        \n        Args:\n            record: The validated record to transform\n        \n        Returns:\n            The transformed record\n        \"\"\"\n        transformed = record.copy()\n        \n        # Add processing metadata\n        transformed['_processed'] = True\n        transformed['_pipeline_version'] = '1.0.0'\n        \n        # Normalize fields\n        if 'event_type' in transformed:\n            transformed['event_type'] = transformed['event_type'].lower()\n        \n        return transformed\n    \n    def _route_record(self, record: Dict[str, Any]) -> None:\n        \"\"\"Route a processed record to the appropriate output.\n        \n        Args:\n            record: The processed record to route\n        \"\"\"\n        # Placeholder for routing logic\n        event_type = record.get('event_type', 'unknown')\n        logger.debug(f\"Routing record of type '{event_type}' to output\")\n    \n    def process_batch(self, records: List[Dict[str, Any]]) -> Dict[str, int]:\n        \"\"\"Process a batch of records.\n        \n        Args:\n            records: List of records to process\n        \n        Returns:\n            Dictionary with processing statistics\n        \"\"\"\n        batch_processed = 0\n        batch_failed = 0\n        \n        for record in records:\n            if self.process_record(record):\n                batch_processed += 1\n            else:\n                batch_failed += 1\n        \n        return {\n            'processed': batch_processed,\n            'failed': batch_failed,\n            'total': len(records)\n        }\n    \n    def process_stream(self, record_iterator: Iterator[Dict[str, Any]]) -> Dict[str, int]:\n        \"\"\"Process a stream of records.\n        \n        Args:\n            record_iterator: Iterator yielding records to process\n        \n        Returns:\n            Dictionary with processing statistics\n        \"\"\"\n        total_processed = 0\n        total_failed = 0\n        \n        batch = []\n        for record in record_iterator:\n            batch.append(record)\n            \n            if len(batch) >= self.batch_size:\n                stats = self.process_batch(batch)\n                total_processed += stats['processed']\n                total_failed += stats['failed']\n                batch = []\n        \n        # Process remaining records\n        if batch:\n            stats = self.process_batch(batch)\n            total_processed += stats['processed']\n            total_failed += stats['failed']\n        \n        return {\n            'processed': total_processed,\n            'failed': total_failed,\n            'dlq_records': self.dlq_count\n        }\n    \n    def get_stats(self) -> Dict[str, int]:\n        \"\"\"Get current pipeline statistics.\n        \n        Returns:\n            Dictionary containing processing statistics\n        \"\"\"\n        return {\n            'processed_count': self.processed_count,\n            'failed_count': self.failed_count,\n            'dlq_count': self.dlq_count\n        }\n    \n    def reset_stats(self) -> None:\n        \"\"\"Reset pipeline statistics.\"\"\"\n        self.processed_count = 0\n        self.failed_count = 0\n        self.dlq_count = 0\n\n\nclass PipelineManager:\n    \"\"\"Manager for multiple processing pipelines.\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or get_config()\n        self.pipelines: Dict[str, ProcessingPipeline] = {}\n        self.executor = ThreadPoolExecutor(\n            max_workers=self.config.get('max_workers', 4)\n        )\n    \n    def create_pipeline(self, name: str) -> ProcessingPipeline:\n        \"\"\"Create a new named pipeline.\"\"\"\n        pipeline = ProcessingPipeline(self.config)\n        self.pipelines[name] = pipeline\n        return pipeline\n    \n    def get_pipeline(self, name: str) -> Optional[ProcessingPipeline]:\n        \"\"\"Get a pipeline by name.\"\"\"\n        return self.pipelines.get(name)\n    \n    def shutdown(self) -> None:\n        \"\"\"Shutdown the pipeline manager.\"\"\"\n        self.executor.shutdown(wait=True)\n",
            "src/utils.py": "\"\"\"Utility functions and classes for PulseStream Nexus.\n\nThis module provides common utilities including logging, monitoring,\nand helper functions used throughout the application.\n\"\"\"\nimport logging\nimport time\nfrom typing import Dict, Any, Optional, Callable\nfrom functools import wraps\nfrom threading import Lock\n\nlogger = logging.getLogger(__name__)\n\n\nclass MonitoringClient:\n    \"\"\"Client for sending metrics to the monitoring system.\n    \n    This is a singleton class that provides methods for tracking\n    various metrics throughout the application.\n    \"\"\"\n    \n    _instance: Optional['MonitoringClient'] = None\n    _lock = Lock()\n    \n    def __new__(cls) -> 'MonitoringClient':\n        if cls._instance is None:\n            with cls._lock:\n                if cls._instance is None:\n                    cls._instance = super().__new__(cls)\n                    cls._instance._initialized = False\n        return cls._instance\n    \n    def __init__(self):\n        if self._initialized:\n            return\n        \n        self._metrics: Dict[str, float] = {}\n        self._counters: Dict[str, int] = {}\n        self._metric_lock = Lock()\n        self._initialized = True\n        logger.info(\"MonitoringClient initialized\")\n    \n    def increment(self, metric_name: str, value: int = 1) -> None:\n        \"\"\"Increment a counter metric.\n        \n        Args:\n            metric_name: The name of the metric to increment\n            value: The amount to increment by (default: 1)\n        \"\"\"\n        with self._metric_lock:\n            if metric_name not in self._counters:\n                self._counters[metric_name] = 0\n            self._counters[metric_name] += value\n        \n        logger.debug(f\"Metric '{metric_name}' incremented by {value}\")\n    \n    def gauge(self, metric_name: str, value: float) -> None:\n        \"\"\"Set a gauge metric to a specific value.\n        \n        Args:\n            metric_name: The name of the metric\n            value: The value to set\n        \"\"\"\n        with self._metric_lock:\n            self._metrics[metric_name] = value\n        \n        logger.debug(f\"Metric '{metric_name}' set to {value}\")\n    \n    def timing(self, metric_name: str, duration_ms: float) -> None:\n        \"\"\"Record a timing metric.\n        \n        Args:\n            metric_name: The name of the timing metric\n            duration_ms: The duration in milliseconds\n        \"\"\"\n        with self._metric_lock:\n            self._metrics[f\"{metric_name}.timing\"] = duration_ms\n        \n        logger.debug(f\"Timing '{metric_name}': {duration_ms}ms\")\n    \n    def get_counter(self, metric_name: str) -> int:\n        \"\"\"Get the current value of a counter.\n        \n        Args:\n            metric_name: The name of the counter metric\n        \n        Returns:\n            The current counter value, or 0 if not set\n        \"\"\"\n        with self._metric_lock:\n            return self._counters.get(metric_name, 0)\n    \n    def get_gauge(self, metric_name: str) -> Optional[float]:\n        \"\"\"Get the current value of a gauge.\n        \n        Args:\n            metric_name: The name of the gauge metric\n        \n        Returns:\n            The current gauge value, or None if not set\n        \"\"\"\n        with self._metric_lock:\n            return self._metrics.get(metric_name)\n    \n    def get_all_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get all recorded metrics.\n        \n        Returns:\n            Dictionary containing all metrics and counters\n        \"\"\"\n        with self._metric_lock:\n            return {\n                'counters': self._counters.copy(),\n                'gauges': self._metrics.copy()\n            }\n    \n    def reset(self) -> None:\n        \"\"\"Reset all metrics (useful for testing).\"\"\"\n        with self._metric_lock:\n            self._metrics.clear()\n            self._counters.clear()\n        logger.info(\"MonitoringClient metrics reset\")\n\n\ndef timed(metric_name: Optional[str] = None) -> Callable:\n    \"\"\"Decorator to time function execution.\n    \n    Args:\n        metric_name: Optional metric name. If not provided, uses function name.\n    \n    Returns:\n        Decorated function\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            name = metric_name or f\"{func.__module__}.{func.__name__}\"\n            start_time = time.time()\n            try:\n                return func(*args, **kwargs)\n            finally:\n                duration_ms = (time.time() - start_time) * 1000\n                try:\n                    MonitoringClient().timing(name, duration_ms)\n                except Exception as e:\n                    logger.warning(f\"Failed to record timing metric: {e}\")\n        return wrapper\n    return decorator\n\n\ndef retry(max_attempts: int = 3, delay: float = 1.0, \n          backoff: float = 2.0) -> Callable:\n    \"\"\"Decorator to retry a function on failure.\n    \n    Args:\n        max_attempts: Maximum number of retry attempts\n        delay: Initial delay between retries in seconds\n        backoff: Multiplier for delay after each retry\n    \n    Returns:\n        Decorated function\n    \"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            current_delay = delay\n            last_exception = None\n            \n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n                    logger.warning(\n                        f\"Attempt {attempt + 1}/{max_attempts} failed for \"\n                        f\"{func.__name__}: {e}\"\n                    )\n                    if attempt < max_attempts - 1:\n                        time.sleep(current_delay)\n                        current_delay *= backoff\n            \n            raise last_exception\n        return wrapper\n    return decorator\n\n\nclass BatchProcessor:\n    \"\"\"Utility class for processing items in batches.\"\"\"\n    \n    def __init__(self, batch_size: int = 100):\n        self.batch_size = batch_size\n        self._batch: list = []\n    \n    def add(self, item: Any) -> Optional[list]:\n        \"\"\"Add an item to the batch.\n        \n        Returns the batch if it's full, otherwise None.\n        \"\"\"\n        self._batch.append(item)\n        if len(self._batch) >= self.batch_size:\n            batch = self._batch\n            self._batch = []\n            return batch\n        return None\n    \n    def flush(self) -> list:\n        \"\"\"Flush and return the current batch.\"\"\"\n        batch = self._batch\n        self._batch = []\n        return batch\n"
          },
          "generated_files": [
            "src/config.py",
            "src/dlq_handler.py",
            "src/module_30.py",
            "src/module_12.py",
            "src/utils.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.726407643312102,
                "dependency_traversal_accuracy": 0.7959966834895458,
                "cross_file_reasoning_depth": 0.458,
                "system_thinking_score": 0.5359054393435975,
                "robustness_score": 0.435799522673031,
                "comprehensiveness_score": 0.47881384248210024,
                "innovation_score": 0.23846658711217186,
                "solution_elegance_score": 0.6020951298384561
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09080095541401274,
                "dependency_traversal_weighted": 0.09949958543619322,
                "cross_file_reasoning_weighted": 0.05725,
                "system_thinking_weighted": 0.06698817991794968,
                "robustness_weighted": 0.05447494033412888,
                "comprehensiveness_weighted": 0.05985173031026253,
                "innovation_weighted": 0.029808323389021483,
                "solution_elegance_weighted": 0.07526189122980702
              },
              "total_software_engineering_score": 0.5339356060313756
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.3306739330291748,
                "errors": [
                  "  File \"src/dlq_handler.py\", line 106",
                  "    f.write(json_line + '",
                  "                        ^",
                  "SyntaxError: unterminated string literal (detected at line 106)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "src/config.py",
                  "src/dlq_handler.py",
                  "src/module_30.py",
                  "src/module_12.py",
                  "src/utils.py"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 5,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 5 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.5575196374622357,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.5575196374622357,
                "idc_weight": 0.2,
                "total_functional_score": 0.45150392749244717
              }
            },
            "code_quality_details": {
              "files_analyzed": 5,
              "quality_checks": {
                "src/config.py": {
                  "line_count": 47,
                  "non_empty_lines": 40,
                  "comment_lines": 4,
                  "comment_ratio": 0.1,
                  "function_count": 1,
                  "class_count": 0,
                  "import_count": 1,
                  "quality_score": 0.6
                },
                "src/dlq_handler.py": {
                  "line_count": 131,
                  "non_empty_lines": 104,
                  "comment_lines": 1,
                  "comment_ratio": 0.009615384615384616,
                  "function_count": 6,
                  "class_count": 4,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "src/module_30.py": {
                  "line_count": 209,
                  "non_empty_lines": 162,
                  "comment_lines": 9,
                  "comment_ratio": 0.05555555555555555,
                  "function_count": 12,
                  "class_count": 8,
                  "import_count": 4,
                  "quality_score": 0.7999999999999999
                },
                "src/module_12.py": {
                  "line_count": 240,
                  "non_empty_lines": 189,
                  "comment_lines": 9,
                  "comment_ratio": 0.047619047619047616,
                  "function_count": 14,
                  "class_count": 4,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "src/utils.py": {
                  "line_count": 211,
                  "non_empty_lines": 167,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 18,
                  "class_count": 4,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7719999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.5450975975975976,
                "multi_session_memory_retention": 0.47676426426426427
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.2725487987987988,
                "multi_session_memory_retention_weighted": 0.23838213213213214
              },
              "total_longcontext_utilization_score": 0.5109309309309309
            }
          },
          "timestamp": "2026-01-14T21:22:08.907668"
        }
      }
    },
    "python_web_cms_hard_074_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_web_cms_hard_074_feature_implementation_expert_01",
          "scenario_title": "Implement Content Approval Workflow for Medical Articles",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5496649634001931,
          "functional_correctness_score": 0.6248691860465116,
          "code_quality_score": 0.7999999999999999,
          "longcontext_utilization_score": 0.826121794871795,
          "total_score": 3.249694603306051,
          "generation_time": 172.8133988380432,
          "code_files_generated": 8,
          "total_lines_generated": 1601,
          "parsing_success": true,
          "solution_code": {
            "mediverse_cms/apps/cms/models.py": "from django.db import models\nfrom django.conf import settings\nfrom django.utils import timezone\n\n\nclass ArticleStatus(models.TextChoices):\n    DRAFT = 'Draft', 'Draft'\n    PENDING_REVIEW = 'Pending Review', 'Pending Review'\n    APPROVED = 'Approved', 'Approved'\n    REJECTED = 'Rejected', 'Rejected'\n\n\nclass Category(models.Model):\n    \"\"\"Category model for organizing articles.\"\"\"\n    name = models.CharField(max_length=100)\n    slug = models.SlugField(unique=True)\n    description = models.TextField(blank=True)\n    parent = models.ForeignKey(\n        'self',\n        on_delete=models.CASCADE,\n        null=True,\n        blank=True,\n        related_name='children'\n    )\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    class Meta:\n        verbose_name_plural = 'categories'\n\n    def __str__(self):\n        return self.name\n\n\nclass Tag(models.Model):\n    \"\"\"Tag model for labeling articles.\"\"\"\n    name = models.CharField(max_length=50, unique=True)\n    slug = models.SlugField(unique=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass Article(models.Model):\n    \"\"\"Article model for medical content.\"\"\"\n    title = models.CharField(max_length=255)\n    slug = models.SlugField(unique=True)\n    content = models.TextField()\n    excerpt = models.TextField(blank=True)\n    author = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='articles'\n    )\n    category = models.ForeignKey(\n        Category,\n        on_delete=models.SET_NULL,\n        null=True,\n        blank=True,\n        related_name='articles'\n    )\n    tags = models.ManyToManyField(Tag, blank=True, related_name='articles')\n    featured_image = models.URLField(blank=True)\n    is_featured = models.BooleanField(default=False)\n    view_count = models.PositiveIntegerField(default=0)\n    \n    # Approval workflow fields\n    status = models.CharField(\n        max_length=20,\n        choices=ArticleStatus.choices,\n        default=ArticleStatus.DRAFT\n    )\n    latest_version = models.ForeignKey(\n        'ArticleVersion',\n        on_delete=models.SET_NULL,\n        null=True,\n        blank=True,\n        related_name='article_as_latest'\n    )\n    published_version = models.ForeignKey(\n        'ArticleVersion',\n        on_delete=models.SET_NULL,\n        null=True,\n        blank=True,\n        related_name='article_as_published'\n    )\n    \n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n    published_at = models.DateTimeField(null=True, blank=True)\n\n    class Meta:\n        ordering = ['-created_at']\n\n    def __str__(self):\n        return self.title\n\n    def increment_view_count(self):\n        self.view_count += 1\n        self.save(update_fields=['view_count'])\n\n\nclass ArticleVersion(models.Model):\n    \"\"\"Model to track version history of articles.\"\"\"\n    article = models.ForeignKey(\n        Article,\n        on_delete=models.CASCADE,\n        related_name='versions'\n    )\n    title = models.CharField(max_length=255)\n    content = models.TextField()\n    excerpt = models.TextField(blank=True)\n    author = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='article_versions'\n    )\n    version_number = models.PositiveIntegerField(default=1)\n    created_at = models.DateTimeField(auto_now_add=True)\n    \n    class Meta:\n        ordering = ['-version_number']\n        unique_together = ['article', 'version_number']\n\n    def __str__(self):\n        return f\"{self.article.title} - Version {self.version_number}\"\n\n\nclass MediaAsset(models.Model):\n    \"\"\"Media asset model for storing images and files.\"\"\"\n    ASSET_TYPES = [\n        ('image', 'Image'),\n        ('video', 'Video'),\n        ('document', 'Document'),\n    ]\n\n    name = models.CharField(max_length=255)\n    asset_type = models.CharField(max_length=20, choices=ASSET_TYPES)\n    file_url = models.URLField()\n    file_size = models.PositiveIntegerField(help_text='File size in bytes')\n    mime_type = models.CharField(max_length=100)\n    uploaded_by = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='media_assets'\n    )\n    article = models.ForeignKey(\n        Article,\n        on_delete=models.CASCADE,\n        null=True,\n        blank=True,\n        related_name='media_assets'\n    )\n    created_at = models.DateTimeField(auto_now_add=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass Comment(models.Model):\n    \"\"\"Comment model for article discussions.\"\"\"\n    article = models.ForeignKey(\n        Article,\n        on_delete=models.CASCADE,\n        related_name='comments'\n    )\n    author = models.ForeignKey(\n        settings.AUTH_USER_MODEL,\n        on_delete=models.CASCADE,\n        related_name='comments'\n    )\n    content = models.TextField()\n    parent = models.ForeignKey(\n        'self',\n        on_delete=models.CASCADE,\n        null=True,\n        blank=True,\n        related_name='replies'\n    )\n    is_approved = models.BooleanField(default=False)\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    class Meta:\n        ordering = ['created_at']\n\n    def __str__(self):\n        return f\"Comment by {self.author} on {self.article}\"\n",
            "mediverse_cms/apps/cms/services.py": "from typing import Optional, List, Dict, Any\nfrom django.db import transaction\nfrom django.utils import timezone\nfrom django.utils.text import slugify\n\nfrom .models import Article, ArticleVersion, Category, Tag, MediaAsset, Comment, ArticleStatus\nfrom apps.users.models import User\nfrom apps.integrations.notification_service import NotificationService\n\n\nclass ArticleService:\n    \"\"\"Service class for article-related operations.\"\"\"\n\n    def __init__(self):\n        self.notification_service = NotificationService()\n\n    @transaction.atomic\n    def create_article(self, data: Dict[str, Any], author: User) -> Article:\n        \"\"\"Create a new article with initial version.\"\"\"\n        # Generate slug if not provided\n        slug = data.get('slug') or slugify(data['title'])\n        \n        # Ensure unique slug\n        base_slug = slug\n        counter = 1\n        while Article.objects.filter(slug=slug).exists():\n            slug = f\"{base_slug}-{counter}\"\n            counter += 1\n\n        # Create article with Draft status\n        article = Article.objects.create(\n            title=data['title'],\n            slug=slug,\n            content=data['content'],\n            excerpt=data.get('excerpt', ''),\n            author=author,\n            category_id=data.get('category_id'),\n            featured_image=data.get('featured_image', ''),\n            is_featured=data.get('is_featured', False),\n            status=ArticleStatus.DRAFT\n        )\n\n        # Handle tags\n        if 'tags' in data:\n            article.tags.set(data['tags'])\n\n        # Create initial version\n        version = ArticleVersion.objects.create(\n            article=article,\n            title=article.title,\n            content=article.content,\n            excerpt=article.excerpt,\n            author=author,\n            version_number=1\n        )\n        \n        # Link the version to the article\n        article.latest_version = version\n        article.save(update_fields=['latest_version'])\n\n        return article\n\n    @transaction.atomic\n    def update_article(self, article: Article, data: Dict[str, Any], editor: User) -> Article:\n        \"\"\"Update an article, creating a new version if needed.\"\"\"\n        # Check if we need to create a new version\n        # Create new version if article is Approved or Rejected\n        create_new_version = article.status in [ArticleStatus.APPROVED, ArticleStatus.REJECTED]\n        \n        # Update article fields\n        if 'title' in data:\n            article.title = data['title']\n        if 'content' in data:\n            article.content = data['content']\n        if 'excerpt' in data:\n            article.excerpt = data['excerpt']\n        if 'category_id' in data:\n            article.category_id = data['category_id']\n        if 'featured_image' in data:\n            article.featured_image = data['featured_image']\n        if 'is_featured' in data:\n            article.is_featured = data['is_featured']\n        if 'slug' in data:\n            article.slug = data['slug']\n\n        # Handle tags\n        if 'tags' in data:\n            article.tags.set(data['tags'])\n\n        if create_new_version:\n            # Create a new version\n            latest_version_number = article.versions.aggregate(\n                max_version=models.Max('version_number')\n            )['max_version'] or 0\n            \n            version = ArticleVersion.objects.create(\n                article=article,\n                title=article.title,\n                content=article.content,\n                excerpt=article.excerpt,\n                author=editor,\n                version_number=latest_version_number + 1\n            )\n            \n            article.latest_version = version\n            article.status = ArticleStatus.DRAFT\n        else:\n            # Update existing latest version if in Draft or Pending Review\n            if article.latest_version:\n                article.latest_version.title = article.title\n                article.latest_version.content = article.content\n                article.latest_version.excerpt = article.excerpt\n                article.latest_version.save()\n\n        article.save()\n        return article\n\n    @transaction.atomic\n    def submit_for_review(self, article: Article, user: User) -> Article:\n        \"\"\"Submit an article for review.\"\"\"\n        if article.status != ArticleStatus.DRAFT:\n            raise ValueError(\"Only draft articles can be submitted for review.\")\n        \n        article.status = ArticleStatus.PENDING_REVIEW\n        article.save(update_fields=['status'])\n        \n        # Notify all editors\n        self._notify_editors_of_submission(article)\n        \n        return article\n\n    @transaction.atomic\n    def approve_article(self, article: Article, editor: User) -> Article:\n        \"\"\"Approve an article for publication.\"\"\"\n        if article.status != ArticleStatus.PENDING_REVIEW:\n            raise ValueError(\"Only articles pending review can be approved.\")\n        \n        article.status = ArticleStatus.APPROVED\n        article.published_version = article.latest_version\n        article.published_at = timezone.now()\n        article.save(update_fields=['status', 'published_version', 'published_at'])\n        \n        # Notify the author\n        self._notify_author_of_decision(article, approved=True, editor=editor)\n        \n        return article\n\n    @transaction.atomic\n    def reject_article(self, article: Article, editor: User, reason: str = None) -> Article:\n        \"\"\"Reject an article.\"\"\"\n        if article.status != ArticleStatus.PENDING_REVIEW:\n            raise ValueError(\"Only articles pending review can be rejected.\")\n        \n        article.status = ArticleStatus.REJECTED\n        article.save(update_fields=['status'])\n        \n        # Notify the author\n        self._notify_author_of_decision(article, approved=False, editor=editor, reason=reason)\n        \n        return article\n\n    def _notify_editors_of_submission(self, article: Article) -> None:\n        \"\"\"Send notification to all editors about new submission.\"\"\"\n        try:\n            editors = User.objects.filter(role='Editor', is_active=True)\n            for editor in editors:\n                self.notification_service.send_notification(\n                    user_id=str(editor.id),\n                    notification_type='article_submission',\n                    title='New Article Submitted for Review',\n                    message=f'Article \"{article.title}\" by {article.author.get_full_name() or article.author.email} has been submitted for review.',\n                    data={\n                        'article_id': article.id,\n                        'article_title': article.title,\n                        'author_id': article.author.id,\n                        'author_name': article.author.get_full_name() or article.author.email\n                    }\n                )\n        except Exception as e:\n            # Log error but don't fail the operation\n            print(f\"Failed to send editor notifications: {e}\")\n\n    def _notify_author_of_decision(self, article: Article, approved: bool, editor: User, reason: str = None) -> None:\n        \"\"\"Send notification to author about approval decision.\"\"\"\n        try:\n            status_text = 'approved' if approved else 'rejected'\n            message = f'Your article \"{article.title}\" has been {status_text} by {editor.get_full_name() or editor.email}.'\n            if reason and not approved:\n                message += f' Reason: {reason}'\n            \n            self.notification_service.send_notification(\n                user_id=str(article.author.id),\n                notification_type='article_decision',\n                title=f'Article {status_text.title()}',\n                message=message,\n                data={\n                    'article_id': article.id,\n                    'article_title': article.title,\n                    'decision': status_text,\n                    'editor_id': editor.id,\n                    'editor_name': editor.get_full_name() or editor.email,\n                    'reason': reason\n                }\n            )\n        except Exception as e:\n            # Log error but don't fail the operation\n            print(f\"Failed to send author notification: {e}\")\n\n    def get_article_by_slug(self, slug: str) -> Optional[Article]:\n        \"\"\"Get an article by its slug.\"\"\"\n        try:\n            return Article.objects.select_related('author', 'category', 'latest_version', 'published_version').get(slug=slug)\n        except Article.DoesNotExist:\n            return None\n\n    def get_published_articles(self, category_slug: str = None, tag_slug: str = None) -> List[Article]:\n        \"\"\"Get all published (approved) articles with optional filtering.\"\"\"\n        queryset = Article.objects.filter(\n            status=ArticleStatus.APPROVED,\n            published_version__isnull=False\n        ).select_related('author', 'category', 'published_version')\n\n        if category_slug:\n            queryset = queryset.filter(category__slug=category_slug)\n        if tag_slug:\n            queryset = queryset.filter(tags__slug=tag_slug)\n\n        return list(queryset)\n\n    def get_featured_articles(self, limit: int = 5) -> List[Article]:\n        \"\"\"Get featured published articles.\"\"\"\n        return list(\n            Article.objects.filter(\n                is_featured=True,\n                status=ArticleStatus.APPROVED,\n                published_version__isnull=False\n            ).select_related('author', 'category', 'published_version')[:limit]\n        )\n\n    def get_articles_pending_review(self) -> List[Article]:\n        \"\"\"Get all articles pending review.\"\"\"\n        return list(\n            Article.objects.filter(\n                status=ArticleStatus.PENDING_REVIEW\n            ).select_related('author', 'category', 'latest_version')\n        )\n\n    def delete_article(self, article: Article) -> bool:\n        \"\"\"Delete an article.\"\"\"\n        article.delete()\n        return True\n\n\nclass CategoryService:\n    \"\"\"Service class for category-related operations.\"\"\"\n\n    def get_all_categories(self) -> List[Category]:\n        \"\"\"Get all categories.\"\"\"\n        return list(Category.objects.all())\n\n    def get_category_by_slug(self, slug: str) -> Optional[Category]:\n        \"\"\"Get a category by its slug.\"\"\"\n        try:\n            return Category.objects.get(slug=slug)\n        except Category.DoesNotExist:\n            return None\n\n    def create_category(self, data: Dict[str, Any]) -> Category:\n        \"\"\"Create a new category.\"\"\"\n        return Category.objects.create(\n            name=data['name'],\n            slug=data.get('slug') or slugify(data['name']),\n            description=data.get('description', ''),\n            parent_id=data.get('parent_id')\n        )\n\n\nclass TagService:\n    \"\"\"Service class for tag-related operations.\"\"\"\n\n    def get_all_tags(self) -> List[Tag]:\n        \"\"\"Get all tags.\"\"\"\n        return list(Tag.objects.all())\n\n    def get_or_create_tag(self, name: str) -> Tag:\n        \"\"\"Get or create a tag by name.\"\"\"\n        tag, _ = Tag.objects.get_or_create(\n            name=name,\n            defaults={'slug': slugify(name)}\n        )\n        return tag\n\n\nclass MediaAssetService:\n    \"\"\"Service class for media asset operations.\"\"\"\n\n    def create_media_asset(self, data: Dict[str, Any], user: User) -> MediaAsset:\n        \"\"\"Create a new media asset.\"\"\"\n        return MediaAsset.objects.create(\n            name=data['name'],\n            asset_type=data['asset_type'],\n            file_url=data['file_url'],\n            file_size=data['file_size'],\n            mime_type=data['mime_type'],\n            uploaded_by=user,\n            article_id=data.get('article_id')\n        )\n\n    def get_assets_for_article(self, article_id: int) -> List[MediaAsset]:\n        \"\"\"Get all media assets for an article.\"\"\"\n        return list(MediaAsset.objects.filter(article_id=article_id))\n\n\nclass CommentService:\n    \"\"\"Service class for comment operations.\"\"\"\n\n    def create_comment(self, data: Dict[str, Any], user: User) -> Comment:\n        \"\"\"Create a new comment.\"\"\"\n        return Comment.objects.create(\n            article_id=data['article_id'],\n            author=user,\n            content=data['content'],\n            parent_id=data.get('parent_id')\n        )\n\n    def get_comments_for_article(self, article_id: int, approved_only: bool = True) -> List[Comment]:\n        \"\"\"Get comments for an article.\"\"\"\n        queryset = Comment.objects.filter(article_id=article_id)\n        if approved_only:\n            queryset = queryset.filter(is_approved=True)\n        return list(queryset.select_related('author'))\n\n    def approve_comment(self, comment: Comment) -> Comment:\n        \"\"\"Approve a comment.\"\"\"\n        comment.is_approved = True\n        comment.save(update_fields=['is_approved'])\n        return comment\n\n\n# Import models for aggregate function\nfrom django.db import models\n",
            "mediverse_cms/apps/cms/api.py": "from rest_framework import viewsets, status, serializers\nfrom rest_framework.decorators import action\nfrom rest_framework.response import Response\nfrom rest_framework.permissions import IsAuthenticated, IsAuthenticatedOrReadOnly\nfrom django.shortcuts import get_object_or_404\n\nfrom .models import Article, ArticleVersion, Category, Tag, MediaAsset, Comment, ArticleStatus\nfrom .services import (\n    ArticleService,\n    CategoryService,\n    TagService,\n    MediaAssetService,\n    CommentService\n)\nfrom apps.core.permissions import IsEditorUser, IsOwnerOrReadOnly\n\n\nclass ArticleVersionSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for ArticleVersion model.\"\"\"\n    author_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = ArticleVersion\n        fields = ['id', 'title', 'content', 'excerpt', 'author', 'author_name', 'version_number', 'created_at']\n        read_only_fields = ['id', 'author', 'version_number', 'created_at']\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n\nclass ArticleSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Article model.\"\"\"\n    author_name = serializers.SerializerMethodField()\n    category_name = serializers.SerializerMethodField()\n    tags_list = serializers.SerializerMethodField()\n    latest_version = ArticleVersionSerializer(read_only=True)\n    published_version = ArticleVersionSerializer(read_only=True)\n\n    class Meta:\n        model = Article\n        fields = [\n            'id', 'title', 'slug', 'content', 'excerpt', 'author', 'author_name',\n            'category', 'category_name', 'tags', 'tags_list', 'featured_image',\n            'is_featured', 'view_count', 'status', 'latest_version', 'published_version',\n            'created_at', 'updated_at', 'published_at'\n        ]\n        read_only_fields = ['id', 'author', 'view_count', 'status', 'created_at', 'updated_at', 'published_at']\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n    def get_category_name(self, obj):\n        return obj.category.name if obj.category else None\n\n    def get_tags_list(self, obj):\n        return [{'id': tag.id, 'name': tag.name, 'slug': tag.slug} for tag in obj.tags.all()]\n\n\nclass ArticleCreateSerializer(serializers.Serializer):\n    \"\"\"Serializer for creating articles.\"\"\"\n    title = serializers.CharField(max_length=255)\n    content = serializers.CharField()\n    excerpt = serializers.CharField(required=False, allow_blank=True)\n    slug = serializers.SlugField(required=False, allow_blank=True)\n    category_id = serializers.IntegerField(required=False, allow_null=True)\n    tags = serializers.ListField(\n        child=serializers.IntegerField(),\n        required=False\n    )\n    featured_image = serializers.URLField(required=False, allow_blank=True)\n    is_featured = serializers.BooleanField(required=False, default=False)\n\n\nclass ArticleUpdateSerializer(serializers.Serializer):\n    \"\"\"Serializer for updating articles.\"\"\"\n    title = serializers.CharField(max_length=255, required=False)\n    content = serializers.CharField(required=False)\n    excerpt = serializers.CharField(required=False, allow_blank=True)\n    slug = serializers.SlugField(required=False)\n    category_id = serializers.IntegerField(required=False, allow_null=True)\n    tags = serializers.ListField(\n        child=serializers.IntegerField(),\n        required=False\n    )\n    featured_image = serializers.URLField(required=False, allow_blank=True)\n    is_featured = serializers.BooleanField(required=False)\n\n\nclass RejectSerializer(serializers.Serializer):\n    \"\"\"Serializer for rejection reason.\"\"\"\n    reason = serializers.CharField(required=False, allow_blank=True)\n\n\nclass ArticleViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Article CRUD operations and workflow actions.\"\"\"\n    queryset = Article.objects.all()\n    serializer_class = ArticleSerializer\n    permission_classes = [IsAuthenticated]\n    lookup_field = 'pk'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.article_service = ArticleService()\n\n    def get_queryset(self):\n        \"\"\"Filter queryset based on user permissions.\"\"\"\n        user = self.request.user\n        if user.is_staff or getattr(user, 'role', None) == 'Editor':\n            return Article.objects.all().select_related('author', 'category', 'latest_version', 'published_version')\n        # Regular users can only see their own articles\n        return Article.objects.filter(author=user).select_related('author', 'category', 'latest_version', 'published_version')\n\n    def get_serializer_class(self):\n        if self.action == 'create':\n            return ArticleCreateSerializer\n        elif self.action in ['update', 'partial_update']:\n            return ArticleUpdateSerializer\n        elif self.action == 'reject':\n            return RejectSerializer\n        return ArticleSerializer\n\n    def create(self, request, *args, **kwargs):\n        \"\"\"Create a new article.\"\"\"\n        serializer = self.get_serializer(data=request.data)\n        serializer.is_valid(raise_exception=True)\n        \n        article = self.article_service.create_article(\n            data=serializer.validated_data,\n            author=request.user\n        )\n        \n        response_serializer = ArticleSerializer(article)\n        return Response(response_serializer.data, status=status.HTTP_201_CREATED)\n\n    def update(self, request, *args, **kwargs):\n        \"\"\"Update an article.\"\"\"\n        partial = kwargs.pop('partial', False)\n        instance = self.get_object()\n        \n        serializer = self.get_serializer(data=request.data, partial=partial)\n        serializer.is_valid(raise_exception=True)\n        \n        article = self.article_service.update_article(\n            article=instance,\n            data=serializer.validated_data,\n            editor=request.user\n        )\n        \n        response_serializer = ArticleSerializer(article)\n        return Response(response_serializer.data)\n\n    def destroy(self, request, *args, **kwargs):\n        \"\"\"Delete an article.\"\"\"\n        instance = self.get_object()\n        self.article_service.delete_article(instance)\n        return Response(status=status.HTTP_204_NO_CONTENT)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated])\n    def submit(self, request, pk=None):\n        \"\"\"Submit an article for review.\"\"\"\n        article = self.get_object()\n        \n        # Check if user is the author\n        if article.author != request.user and not request.user.is_staff:\n            return Response(\n                {'error': 'Only the author can submit this article for review.'},\n                status=status.HTTP_403_FORBIDDEN\n            )\n        \n        try:\n            article = self.article_service.submit_for_review(article, request.user)\n            serializer = ArticleSerializer(article)\n            return Response(serializer.data)\n        except ValueError as e:\n            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def approve(self, request, pk=None):\n        \"\"\"Approve an article for publication. Editor only.\"\"\"\n        article = self.get_object()\n        \n        try:\n            article = self.article_service.approve_article(article, request.user)\n            serializer = ArticleSerializer(article)\n            return Response(serializer.data)\n        except ValueError as e:\n            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def reject(self, request, pk=None):\n        \"\"\"Reject an article. Editor only.\"\"\"\n        article = self.get_object()\n        \n        reject_serializer = RejectSerializer(data=request.data)\n        reject_serializer.is_valid(raise_exception=True)\n        reason = reject_serializer.validated_data.get('reason', '')\n        \n        try:\n            article = self.article_service.reject_article(article, request.user, reason)\n            serializer = ArticleSerializer(article)\n            return Response(serializer.data)\n        except ValueError as e:\n            return Response({'error': str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\n    @action(detail=False, methods=['get'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def pending_review(self, request):\n        \"\"\"Get all articles pending review. Editor only.\"\"\"\n        articles = self.article_service.get_articles_pending_review()\n        serializer = ArticleSerializer(articles, many=True)\n        return Response(serializer.data)\n\n    @action(detail=True, methods=['get'])\n    def versions(self, request, pk=None):\n        \"\"\"Get all versions of an article.\"\"\"\n        article = self.get_object()\n        versions = article.versions.all()\n        serializer = ArticleVersionSerializer(versions, many=True)\n        return Response(serializer.data)\n\n\nclass CategorySerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Category model.\"\"\"\n    class Meta:\n        model = Category\n        fields = ['id', 'name', 'slug', 'description', 'parent', 'created_at', 'updated_at']\n        read_only_fields = ['id', 'created_at', 'updated_at']\n\n\nclass CategoryViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Category CRUD operations.\"\"\"\n    queryset = Category.objects.all()\n    serializer_class = CategorySerializer\n    permission_classes = [IsAuthenticatedOrReadOnly]\n    lookup_field = 'slug'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.category_service = CategoryService()\n\n\nclass TagSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Tag model.\"\"\"\n    class Meta:\n        model = Tag\n        fields = ['id', 'name', 'slug']\n        read_only_fields = ['id']\n\n\nclass TagViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Tag CRUD operations.\"\"\"\n    queryset = Tag.objects.all()\n    serializer_class = TagSerializer\n    permission_classes = [IsAuthenticatedOrReadOnly]\n    lookup_field = 'slug'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tag_service = TagService()\n\n\nclass MediaAssetSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for MediaAsset model.\"\"\"\n    class Meta:\n        model = MediaAsset\n        fields = ['id', 'name', 'asset_type', 'file_url', 'file_size', 'mime_type', 'uploaded_by', 'article', 'created_at']\n        read_only_fields = ['id', 'uploaded_by', 'created_at']\n\n\nclass MediaAssetViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for MediaAsset CRUD operations.\"\"\"\n    queryset = MediaAsset.objects.all()\n    serializer_class = MediaAssetSerializer\n    permission_classes = [IsAuthenticated]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.media_service = MediaAssetService()\n\n    def perform_create(self, serializer):\n        serializer.save(uploaded_by=self.request.user)\n\n\nclass CommentSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Comment model.\"\"\"\n    author_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = Comment\n        fields = ['id', 'article', 'author', 'author_name', 'content', 'parent', 'is_approved', 'created_at', 'updated_at']\n        read_only_fields = ['id', 'author', 'is_approved', 'created_at', 'updated_at']\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n\nclass CommentViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Comment CRUD operations.\"\"\"\n    queryset = Comment.objects.all()\n    serializer_class = CommentSerializer\n    permission_classes = [IsAuthenticated]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.comment_service = CommentService()\n\n    def perform_create(self, serializer):\n        serializer.save(author=self.request.user)\n\n    @action(detail=True, methods=['post'], permission_classes=[IsAuthenticated, IsEditorUser])\n    def approve(self, request, pk=None):\n        \"\"\"Approve a comment. Editor only.\"\"\"\n        comment = self.get_object()\n        comment = self.comment_service.approve_comment(comment)\n        serializer = self.get_serializer(comment)\n        return Response(serializer.data)\n",
            "mediverse_cms/apps/core/permissions.py": "from rest_framework import permissions\n\n\nclass IsOwnerOrReadOnly(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow owners of an object to edit it.\n    \"\"\"\n\n    def has_object_permission(self, request, view, obj):\n        # Read permissions are allowed to any request\n        if request.method in permissions.SAFE_METHODS:\n            return True\n\n        # Write permissions are only allowed to the owner\n        if hasattr(obj, 'author'):\n            return obj.author == request.user\n        if hasattr(obj, 'user'):\n            return obj.user == request.user\n        if hasattr(obj, 'owner'):\n            return obj.owner == request.user\n        \n        return False\n\n\nclass IsAdminUser(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow admin users.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        return request.user and request.user.is_staff\n\n\nclass IsEditorUser(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow users with 'Editor' role.\n    Editors can approve or reject articles for publication.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        # Check if user has Editor role\n        user_role = getattr(request.user, 'role', None)\n        \n        # Also allow staff/superusers to perform editor actions\n        if request.user.is_staff or request.user.is_superuser:\n            return True\n        \n        return user_role == 'Editor'\n\n    def has_object_permission(self, request, view, obj):\n        # Same check as has_permission for object-level\n        return self.has_permission(request, view)\n\n\nclass IsAuthorOrEditor(permissions.BasePermission):\n    \"\"\"\n    Custom permission that allows authors to edit their own content,\n    or editors to edit any content.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        return request.user and request.user.is_authenticated\n\n    def has_object_permission(self, request, view, obj):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        # Editors can edit any content\n        user_role = getattr(request.user, 'role', None)\n        if user_role == 'Editor' or request.user.is_staff:\n            return True\n        \n        # Authors can edit their own content\n        if hasattr(obj, 'author'):\n            return obj.author == request.user\n        \n        return False\n\n\nclass IsPatient(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow users with 'Patient' role.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        user_role = getattr(request.user, 'role', None)\n        return user_role == 'Patient'\n\n\nclass IsHealthcareProvider(permissions.BasePermission):\n    \"\"\"\n    Custom permission to only allow healthcare providers.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if not request.user or not request.user.is_authenticated:\n            return False\n        \n        user_role = getattr(request.user, 'role', None)\n        return user_role in ['Doctor', 'Nurse', 'Healthcare Provider']\n",
            "mediverse_cms/apps/portal/api.py": "from rest_framework import viewsets, status, serializers\nfrom rest_framework.decorators import action\nfrom rest_framework.response import Response\nfrom rest_framework.permissions import IsAuthenticated, AllowAny\nfrom django.shortcuts import get_object_or_404\n\nfrom .models import PatientProfile, Appointment, MedicalRecord\nfrom .services import PatientPortalService\nfrom apps.cms.models import Article, ArticleStatus\nfrom apps.cms.services import ArticleService\n\n\nclass PatientProfileSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for PatientProfile model.\"\"\"\n    user_email = serializers.SerializerMethodField()\n\n    class Meta:\n        model = PatientProfile\n        fields = [\n            'id', 'user', 'user_email', 'date_of_birth', 'blood_type',\n            'allergies', 'emergency_contact_name', 'emergency_contact_phone',\n            'insurance_provider', 'insurance_policy_number', 'created_at', 'updated_at'\n        ]\n        read_only_fields = ['id', 'user', 'created_at', 'updated_at']\n\n    def get_user_email(self, obj):\n        return obj.user.email\n\n\nclass PatientProfileViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for PatientProfile CRUD operations.\"\"\"\n    queryset = PatientProfile.objects.all()\n    serializer_class = PatientProfileSerializer\n    permission_classes = [IsAuthenticated]\n\n    def get_queryset(self):\n        \"\"\"Filter to only show the current user's profile.\"\"\"\n        if self.request.user.is_staff:\n            return PatientProfile.objects.all()\n        return PatientProfile.objects.filter(user=self.request.user)\n\n\nclass AppointmentSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for Appointment model.\"\"\"\n    patient_name = serializers.SerializerMethodField()\n    provider_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = Appointment\n        fields = [\n            'id', 'patient', 'patient_name', 'provider', 'provider_name',\n            'appointment_type', 'scheduled_at', 'duration_minutes', 'status',\n            'notes', 'created_at', 'updated_at'\n        ]\n        read_only_fields = ['id', 'created_at', 'updated_at']\n\n    def get_patient_name(self, obj):\n        return obj.patient.user.get_full_name() or obj.patient.user.email\n\n    def get_provider_name(self, obj):\n        return obj.provider.get_full_name() or obj.provider.email\n\n\nclass AppointmentViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for Appointment CRUD operations.\"\"\"\n    queryset = Appointment.objects.all()\n    serializer_class = AppointmentSerializer\n    permission_classes = [IsAuthenticated]\n\n    def get_queryset(self):\n        \"\"\"Filter appointments based on user role.\"\"\"\n        user = self.request.user\n        if user.is_staff:\n            return Appointment.objects.all()\n        \n        # Check if user is a patient\n        try:\n            patient_profile = PatientProfile.objects.get(user=user)\n            return Appointment.objects.filter(patient=patient_profile)\n        except PatientProfile.DoesNotExist:\n            pass\n        \n        # Check if user is a provider\n        return Appointment.objects.filter(provider=user)\n\n\nclass MedicalRecordSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for MedicalRecord model.\"\"\"\n    patient_name = serializers.SerializerMethodField()\n    provider_name = serializers.SerializerMethodField()\n\n    class Meta:\n        model = MedicalRecord\n        fields = [\n            'id', 'patient', 'patient_name', 'provider', 'provider_name',\n            'record_type', 'title', 'content', 'attachments', 'is_confidential',\n            'created_at', 'updated_at'\n        ]\n        read_only_fields = ['id', 'created_at', 'updated_at']\n\n    def get_patient_name(self, obj):\n        return obj.patient.user.get_full_name() or obj.patient.user.email\n\n    def get_provider_name(self, obj):\n        return obj.provider.get_full_name() or obj.provider.email\n\n\nclass MedicalRecordViewSet(viewsets.ModelViewSet):\n    \"\"\"ViewSet for MedicalRecord CRUD operations.\"\"\"\n    queryset = MedicalRecord.objects.all()\n    serializer_class = MedicalRecordSerializer\n    permission_classes = [IsAuthenticated]\n\n    def get_queryset(self):\n        \"\"\"Filter medical records based on user role.\"\"\"\n        user = self.request.user\n        if user.is_staff:\n            return MedicalRecord.objects.all()\n        \n        # Check if user is a patient\n        try:\n            patient_profile = PatientProfile.objects.get(user=user)\n            return MedicalRecord.objects.filter(patient=patient_profile)\n        except PatientProfile.DoesNotExist:\n            pass\n        \n        # Check if user is a provider\n        return MedicalRecord.objects.filter(provider=user)\n\n\n# Public Article Serializer for Portal - serves published content only\nclass PublicArticleSerializer(serializers.ModelSerializer):\n    \"\"\"Serializer for public-facing articles in the patient portal.\n    \n    This serializer serves content from the published_version of an article,\n    ensuring only approved content is displayed to patients.\n    \"\"\"\n    author_name = serializers.SerializerMethodField()\n    category_name = serializers.SerializerMethodField()\n    tags_list = serializers.SerializerMethodField()\n    # Serve content from published version\n    title = serializers.SerializerMethodField()\n    content = serializers.SerializerMethodField()\n    excerpt = serializers.SerializerMethodField()\n\n    class Meta:\n        model = Article\n        fields = [\n            'id', 'title', 'slug', 'content', 'excerpt', 'author_name',\n            'category_name', 'tags_list', 'featured_image', 'is_featured',\n            'view_count', 'published_at'\n        ]\n\n    def get_author_name(self, obj):\n        return obj.author.get_full_name() or obj.author.email\n\n    def get_category_name(self, obj):\n        return obj.category.name if obj.category else None\n\n    def get_tags_list(self, obj):\n        return [{'id': tag.id, 'name': tag.name, 'slug': tag.slug} for tag in obj.tags.all()]\n\n    def get_title(self, obj):\n        \"\"\"Return title from published version.\"\"\"\n        if obj.published_version:\n            return obj.published_version.title\n        return obj.title\n\n    def get_content(self, obj):\n        \"\"\"Return content from published version.\"\"\"\n        if obj.published_version:\n            return obj.published_version.content\n        return obj.content\n\n    def get_excerpt(self, obj):\n        \"\"\"Return excerpt from published version.\"\"\"\n        if obj.published_version:\n            return obj.published_version.excerpt\n        return obj.excerpt\n\n\nclass PublicArticleViewSet(viewsets.ReadOnlyModelViewSet):\n    \"\"\"ViewSet for public article access in the patient portal.\n    \n    This viewset only returns articles that have been approved and have\n    a published version. Content is served from the published_version\n    to ensure only reviewed content is displayed.\n    \"\"\"\n    serializer_class = PublicArticleSerializer\n    permission_classes = [AllowAny]  # Public access for patients\n    lookup_field = 'slug'\n\n    def get_queryset(self):\n        \"\"\"Return only approved articles with published versions.\"\"\"\n        queryset = Article.objects.filter(\n            status=ArticleStatus.APPROVED,\n            published_version__isnull=False\n        ).select_related(\n            'author', 'category', 'published_version'\n        ).prefetch_related('tags')\n        \n        # Optional filtering by category\n        category_slug = self.request.query_params.get('category', None)\n        if category_slug:\n            queryset = queryset.filter(category__slug=category_slug)\n        \n        # Optional filtering by tag\n        tag_slug = self.request.query_params.get('tag', None)\n        if tag_slug:\n            queryset = queryset.filter(tags__slug=tag_slug)\n        \n        # Optional featured filter\n        featured = self.request.query_params.get('featured', None)\n        if featured and featured.lower() == 'true':\n            queryset = queryset.filter(is_featured=True)\n        \n        return queryset.order_by('-published_at')\n\n    def retrieve(self, request, *args, **kwargs):\n        \"\"\"Retrieve a single article and increment view count.\"\"\"\n        instance = self.get_object()\n        instance.increment_view_count()\n        serializer = self.get_serializer(instance)\n        return Response(serializer.data)\n\n    @action(detail=False, methods=['get'])\n    def featured(self, request):\n        \"\"\"Get featured articles.\"\"\"\n        queryset = self.get_queryset().filter(is_featured=True)[:5]\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)\n\n    @action(detail=False, methods=['get'])\n    def recent(self, request):\n        \"\"\"Get most recent articles.\"\"\"\n        limit = int(request.query_params.get('limit', 10))\n        queryset = self.get_queryset()[:limit]\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)\n",
            "mediverse_cms/apps/integrations/notification_service.py": "import logging\nfrom typing import Dict, Any, Optional, List\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\n\nclass NotificationType(Enum):\n    \"\"\"Types of notifications supported by the system.\"\"\"\n    EMAIL = 'email'\n    SMS = 'sms'\n    PUSH = 'push'\n    IN_APP = 'in_app'\n\n\n@dataclass\nclass NotificationResult:\n    \"\"\"Result of a notification operation.\"\"\"\n    success: bool\n    message_id: Optional[str] = None\n    error: Optional[str] = None\n\n\nclass NotificationService:\n    \"\"\"Service for sending notifications through various channels.\"\"\"\n\n    def __init__(self, config: Dict[str, Any] = None):\n        self.config = config or {}\n        self._email_provider = self.config.get('email_provider', 'smtp')\n        self._sms_provider = self.config.get('sms_provider', 'twilio')\n        self._push_provider = self.config.get('push_provider', 'firebase')\n\n    def send_notification(\n        self,\n        user_id: str,\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any] = None,\n        channels: List[str] = None\n    ) -> NotificationResult:\n        \"\"\"\n        Send a notification to a user through specified channels.\n        \n        Args:\n            user_id: The ID of the user to notify\n            notification_type: Type of notification (e.g., 'article_submission', 'article_decision')\n            title: Notification title\n            message: Notification message body\n            data: Additional data to include with the notification\n            channels: List of channels to use (defaults to ['in_app', 'email'])\n        \n        Returns:\n            NotificationResult indicating success or failure\n        \"\"\"\n        channels = channels or ['in_app', 'email']\n        data = data or {}\n        \n        logger.info(\n            f\"Sending notification to user {user_id}: \"\n            f\"type={notification_type}, title={title}, channels={channels}\"\n        )\n        \n        results = []\n        \n        for channel in channels:\n            try:\n                if channel == 'email':\n                    result = self._send_email(user_id, title, message, data)\n                elif channel == 'sms':\n                    result = self._send_sms(user_id, message, data)\n                elif channel == 'push':\n                    result = self._send_push(user_id, title, message, data)\n                elif channel == 'in_app':\n                    result = self._send_in_app(user_id, notification_type, title, message, data)\n                else:\n                    logger.warning(f\"Unknown notification channel: {channel}\")\n                    continue\n                \n                results.append(result)\n                \n            except Exception as e:\n                logger.error(f\"Failed to send {channel} notification to {user_id}: {e}\")\n                results.append(NotificationResult(success=False, error=str(e)))\n        \n        # Return success if at least one channel succeeded\n        any_success = any(r.success for r in results)\n        return NotificationResult(\n            success=any_success,\n            message_id=f\"notif_{user_id}_{notification_type}\",\n            error=None if any_success else \"All notification channels failed\"\n        )\n\n    def _send_email(self, user_id: str, subject: str, body: str, data: Dict[str, Any]) -> NotificationResult:\n        \"\"\"Send an email notification.\"\"\"\n        logger.info(f\"Sending email to user {user_id}: subject={subject}\")\n        # In production, this would integrate with an email service\n        # For now, we simulate success\n        return NotificationResult(success=True, message_id=f\"email_{user_id}\")\n\n    def _send_sms(self, user_id: str, message: str, data: Dict[str, Any]) -> NotificationResult:\n        \"\"\"Send an SMS notification.\"\"\"\n        logger.info(f\"Sending SMS to user {user_id}\")\n        # In production, this would integrate with Twilio or similar\n        return NotificationResult(success=True, message_id=f\"sms_{user_id}\")\n\n    def _send_push(self, user_id: str, title: str, body: str, data: Dict[str, Any]) -> NotificationResult:\n        \"\"\"Send a push notification.\"\"\"\n        logger.info(f\"Sending push notification to user {user_id}: title={title}\")\n        # In production, this would integrate with Firebase or similar\n        return NotificationResult(success=True, message_id=f\"push_{user_id}\")\n\n    def _send_in_app(\n        self,\n        user_id: str,\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any]\n    ) -> NotificationResult:\n        \"\"\"Send an in-app notification.\"\"\"\n        logger.info(f\"Creating in-app notification for user {user_id}: type={notification_type}\")\n        # In production, this would create a database record\n        # that the frontend can poll or receive via WebSocket\n        return NotificationResult(success=True, message_id=f\"inapp_{user_id}_{notification_type}\")\n\n    def send_bulk_notification(\n        self,\n        user_ids: List[str],\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any] = None,\n        channels: List[str] = None\n    ) -> Dict[str, NotificationResult]:\n        \"\"\"\n        Send notifications to multiple users.\n        \n        Args:\n            user_ids: List of user IDs to notify\n            notification_type: Type of notification\n            title: Notification title\n            message: Notification message body\n            data: Additional data to include\n            channels: List of channels to use\n        \n        Returns:\n            Dictionary mapping user_id to NotificationResult\n        \"\"\"\n        results = {}\n        for user_id in user_ids:\n            results[user_id] = self.send_notification(\n                user_id=user_id,\n                notification_type=notification_type,\n                title=title,\n                message=message,\n                data=data,\n                channels=channels\n            )\n        return results\n\n    def send_to_role(\n        self,\n        role: str,\n        notification_type: str,\n        title: str,\n        message: str,\n        data: Dict[str, Any] = None,\n        channels: List[str] = None\n    ) -> List[NotificationResult]:\n        \"\"\"\n        Send notifications to all users with a specific role.\n        \n        Args:\n            role: User role to target (e.g., 'Editor', 'Admin')\n            notification_type: Type of notification\n            title: Notification title\n            message: Notification message body\n            data: Additional data to include\n            channels: List of channels to use\n        \n        Returns:\n            List of NotificationResults\n        \"\"\"\n        # In production, this would query the database for users with the role\n        logger.info(f\"Sending notification to all users with role: {role}\")\n        \n        # Placeholder - in real implementation, fetch user IDs from database\n        # from apps.users.models import User\n        # user_ids = list(User.objects.filter(role=role, is_active=True).values_list('id', flat=True))\n        \n        # For now, return a placeholder result\n        return [NotificationResult(success=True, message_id=f\"role_{role}_notification\")]\n",
            "mediverse_cms/apps/users/models.py": "from django.contrib.auth.models import AbstractUser, BaseUserManager\nfrom django.db import models\n\n\nclass UserManager(BaseUserManager):\n    \"\"\"Custom user manager for email-based authentication.\"\"\"\n\n    def create_user(self, email, password=None, **extra_fields):\n        \"\"\"Create and save a regular user with the given email and password.\"\"\"\n        if not email:\n            raise ValueError('The Email field must be set')\n        email = self.normalize_email(email)\n        user = self.model(email=email, **extra_fields)\n        user.set_password(password)\n        user.save(using=self._db)\n        return user\n\n    def create_superuser(self, email, password=None, **extra_fields):\n        \"\"\"Create and save a superuser with the given email and password.\"\"\"\n        extra_fields.setdefault('is_staff', True)\n        extra_fields.setdefault('is_superuser', True)\n\n        if extra_fields.get('is_staff') is not True:\n            raise ValueError('Superuser must have is_staff=True.')\n        if extra_fields.get('is_superuser') is not True:\n            raise ValueError('Superuser must have is_superuser=True.')\n\n        return self.create_user(email, password, **extra_fields)\n\n\nclass User(AbstractUser):\n    \"\"\"Custom user model with email as the unique identifier.\"\"\"\n    \n    ROLE_CHOICES = [\n        ('Patient', 'Patient'),\n        ('Doctor', 'Doctor'),\n        ('Nurse', 'Nurse'),\n        ('Admin', 'Admin'),\n        ('Editor', 'Editor'),\n        ('Author', 'Author'),\n        ('Healthcare Provider', 'Healthcare Provider'),\n    ]\n\n    username = None\n    email = models.EmailField('email address', unique=True)\n    phone_number = models.CharField(max_length=20, blank=True)\n    role = models.CharField(max_length=30, choices=ROLE_CHOICES, default='Patient')\n    department = models.CharField(max_length=100, blank=True)\n    specialization = models.CharField(max_length=100, blank=True)\n    license_number = models.CharField(max_length=50, blank=True)\n    profile_picture = models.URLField(blank=True)\n    bio = models.TextField(blank=True)\n    is_verified = models.BooleanField(default=False)\n    \n    # Preferences\n    notification_preferences = models.JSONField(default=dict, blank=True)\n    \n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    USERNAME_FIELD = 'email'\n    REQUIRED_FIELDS = []\n\n    objects = UserManager()\n\n    def __str__(self):\n        return self.email\n\n    def get_full_name(self):\n        \"\"\"Return the first_name plus the last_name, with a space in between.\"\"\"\n        full_name = f\"{self.first_name} {self.last_name}\".strip()\n        return full_name or self.email\n\n    def get_short_name(self):\n        \"\"\"Return the short name for the user.\"\"\"\n        return self.first_name or self.email.split('@')[0]\n\n\nclass UserSession(models.Model):\n    \"\"\"Model to track user sessions.\"\"\"\n    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='sessions')\n    session_key = models.CharField(max_length=255, unique=True)\n    ip_address = models.GenericIPAddressField(null=True, blank=True)\n    user_agent = models.TextField(blank=True)\n    device_type = models.CharField(max_length=50, blank=True)\n    is_active = models.BooleanField(default=True)\n    created_at = models.DateTimeField(auto_now_add=True)\n    last_activity = models.DateTimeField(auto_now=True)\n    expires_at = models.DateTimeField(null=True, blank=True)\n\n    def __str__(self):\n        return f\"{self.user.email} - {self.session_key[:20]}...\"\n",
            "mediverse_cms/apps/cms/admin.py": "from django.contrib import admin\nfrom .models import Article, ArticleVersion, Category, Tag, MediaAsset, Comment\n\n\n@admin.register(Category)\nclass CategoryAdmin(admin.ModelAdmin):\n    list_display = ['name', 'slug', 'parent', 'created_at']\n    prepopulated_fields = {'slug': ('name',)}\n    search_fields = ['name']\n    list_filter = ['parent']\n\n\n@admin.register(Tag)\nclass TagAdmin(admin.ModelAdmin):\n    list_display = ['name', 'slug']\n    prepopulated_fields = {'slug': ('name',)}\n    search_fields = ['name']\n\n\nclass ArticleVersionInline(admin.TabularInline):\n    model = ArticleVersion\n    extra = 0\n    readonly_fields = ['version_number', 'author', 'created_at']\n    fields = ['version_number', 'title', 'author', 'created_at']\n    ordering = ['-version_number']\n\n\n@admin.register(Article)\nclass ArticleAdmin(admin.ModelAdmin):\n    list_display = ['title', 'author', 'category', 'status', 'is_featured', 'view_count', 'created_at', 'published_at']\n    list_filter = ['status', 'is_featured', 'category', 'created_at']\n    search_fields = ['title', 'content', 'author__email']\n    prepopulated_fields = {'slug': ('title',)}\n    raw_id_fields = ['author', 'latest_version', 'published_version']\n    filter_horizontal = ['tags']\n    date_hierarchy = 'created_at'\n    readonly_fields = ['view_count', 'created_at', 'updated_at', 'published_at']\n    inlines = [ArticleVersionInline]\n    \n    fieldsets = (\n        (None, {\n            'fields': ('title', 'slug', 'content', 'excerpt')\n        }),\n        ('Classification', {\n            'fields': ('category', 'tags', 'featured_image', 'is_featured')\n        }),\n        ('Authorship', {\n            'fields': ('author',)\n        }),\n        ('Workflow', {\n            'fields': ('status', 'latest_version', 'published_version')\n        }),\n        ('Statistics', {\n            'fields': ('view_count', 'created_at', 'updated_at', 'published_at'),\n            'classes': ('collapse',)\n        }),\n    )\n    \n    actions = ['approve_articles', 'reject_articles']\n    \n    def approve_articles(self, request, queryset):\n        \"\"\"Bulk approve articles.\"\"\"\n        from .models import ArticleStatus\n        from django.utils import timezone\n        \n        count = 0\n        for article in queryset.filter(status=ArticleStatus.PENDING_REVIEW):\n            article.status = ArticleStatus.APPROVED\n            article.published_version = article.latest_version\n            article.published_at = timezone.now()\n            article.save()\n            count += 1\n        \n        self.message_user(request, f\"{count} article(s) approved successfully.\")\n    approve_articles.short_description = \"Approve selected articles\"\n    \n    def reject_articles(self, request, queryset):\n        \"\"\"Bulk reject articles.\"\"\"\n        from .models import ArticleStatus\n        \n        count = queryset.filter(status=ArticleStatus.PENDING_REVIEW).update(\n            status=ArticleStatus.REJECTED\n        )\n        self.message_user(request, f\"{count} article(s) rejected.\")\n    reject_articles.short_description = \"Reject selected articles\"\n\n\n@admin.register(ArticleVersion)\nclass ArticleVersionAdmin(admin.ModelAdmin):\n    list_display = ['article', 'version_number', 'author', 'created_at']\n    list_filter = ['created_at', 'author']\n    search_fields = ['article__title', 'title', 'content']\n    raw_id_fields = ['article', 'author']\n    readonly_fields = ['version_number', 'created_at']\n    ordering = ['-created_at']\n\n\n@admin.register(MediaAsset)\nclass MediaAssetAdmin(admin.ModelAdmin):\n    list_display = ['name', 'asset_type', 'uploaded_by', 'article', 'file_size', 'created_at']\n    list_filter = ['asset_type', 'created_at']\n    search_fields = ['name', 'uploaded_by__email']\n    raw_id_fields = ['uploaded_by', 'article']\n\n\n@admin.register(Comment)\nclass CommentAdmin(admin.ModelAdmin):\n    list_display = ['article', 'author', 'is_approved', 'parent', 'created_at']\n    list_filter = ['is_approved', 'created_at']\n    search_fields = ['content', 'author__email', 'article__title']\n    raw_id_fields = ['article', 'author', 'parent']\n    actions = ['approve_comments']\n    \n    def approve_comments(self, request, queryset):\n        \"\"\"Bulk approve comments.\"\"\"\n        count = queryset.update(is_approved=True)\n        self.message_user(request, f\"{count} comment(s) approved.\")\n    approve_comments.short_description = \"Approve selected comments\"\n"
          },
          "generated_files": [
            "mediverse_cms/apps/cms/models.py",
            "mediverse_cms/apps/cms/services.py",
            "mediverse_cms/apps/cms/api.py",
            "mediverse_cms/apps/core/permissions.py",
            "mediverse_cms/apps/portal/api.py",
            "mediverse_cms/apps/integrations/notification_service.py",
            "mediverse_cms/apps/users/models.py",
            "mediverse_cms/apps/cms/admin.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8041151928912007,
                "dependency_traversal_accuracy": 0.8064327715682418,
                "cross_file_reasoning_depth": 0.4357291666666666,
                "system_thinking_score": 0.4628238073349786,
                "robustness_score": 0.4406240240474703,
                "comprehensiveness_score": 0.24853288309389965,
                "innovation_score": 0.3375,
                "solution_elegance_score": 0.8615618615990877
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.10051439911140009,
                "dependency_traversal_weighted": 0.10080409644603022,
                "cross_file_reasoning_weighted": 0.054466145833333326,
                "system_thinking_weighted": 0.05785297591687232,
                "robustness_weighted": 0.05507800300593379,
                "comprehensiveness_weighted": 0.031066610386737456,
                "innovation_weighted": 0.0421875,
                "solution_elegance_weighted": 0.10769523269988596
              },
              "total_software_engineering_score": 0.5496649634001931
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.5227899551391602,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "mediverse_cms/apps/cms/models.py",
                  "mediverse_cms/apps/cms/services.py",
                  "mediverse_cms/apps/cms/api.py",
                  "mediverse_cms/apps/core/permissions.py",
                  "mediverse_cms/apps/portal/api.py",
                  "mediverse_cms/apps/integrations/notification_service.py",
                  "mediverse_cms/apps/users/models.py",
                  "mediverse_cms/apps/cms/admin.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 8,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 8 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.22434593023255814,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.22434593023255814,
                "idc_weight": 0.2,
                "total_functional_score": 0.6248691860465116
              }
            },
            "code_quality_details": {
              "files_analyzed": 8,
              "quality_checks": {
                "mediverse_cms/apps/cms/models.py": {
                  "line_count": 189,
                  "non_empty_lines": 160,
                  "comment_lines": 1,
                  "comment_ratio": 0.00625,
                  "function_count": 7,
                  "class_count": 13,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/cms/services.py": {
                  "line_count": 342,
                  "non_empty_lines": 281,
                  "comment_lines": 18,
                  "comment_ratio": 0.06405693950177936,
                  "function_count": 23,
                  "class_count": 10,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/cms/api.py": {
                  "line_count": 316,
                  "non_empty_lines": 250,
                  "comment_lines": 2,
                  "comment_ratio": 0.008,
                  "function_count": 23,
                  "class_count": 25,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/core/permissions.py": {
                  "line_count": 107,
                  "non_empty_lines": 76,
                  "comment_lines": 7,
                  "comment_ratio": 0.09210526315789473,
                  "function_count": 8,
                  "class_count": 6,
                  "import_count": 2,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/portal/api.py": {
                  "line_count": 240,
                  "non_empty_lines": 190,
                  "comment_lines": 9,
                  "comment_ratio": 0.04736842105263158,
                  "function_count": 18,
                  "class_count": 16,
                  "import_count": 24,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/integrations/notification_service.py": {
                  "line_count": 195,
                  "non_empty_lines": 165,
                  "comment_lines": 12,
                  "comment_ratio": 0.07272727272727272,
                  "function_count": 8,
                  "class_count": 3,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/users/models.py": {
                  "line_count": 93,
                  "non_empty_lines": 72,
                  "comment_lines": 1,
                  "comment_ratio": 0.013888888888888888,
                  "function_count": 6,
                  "class_count": 4,
                  "import_count": 4,
                  "quality_score": 0.7999999999999999
                },
                "mediverse_cms/apps/cms/admin.py": {
                  "line_count": 119,
                  "non_empty_lines": 96,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 3,
                  "class_count": 7,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7999999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8365384615384617,
                "multi_session_memory_retention": 0.8157051282051284
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.41826923076923084,
                "multi_session_memory_retention_weighted": 0.4078525641025642
              },
              "total_longcontext_utilization_score": 0.826121794871795
            }
          },
          "timestamp": "2026-01-14T21:32:34.725676"
        }
      }
    },
    "python_data_warehouse_easy_084_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_data_warehouse_easy_084_feature_implementation_expert_01",
          "scenario_title": "Implement Pluggable Data Quality Gates with a Quarantine Mechanism",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.545682200380249,
          "functional_correctness_score": 0.35153426866634413,
          "code_quality_score": 0.792222222222222,
          "longcontext_utilization_score": 0.8693580316742082,
          "total_score": 2.84556704181934,
          "generation_time": 179.41712832450867,
          "code_files_generated": 9,
          "total_lines_generated": 1754,
          "parsing_success": true,
          "solution_code": {
            "timestack/validators.py": "\"\"\"Data Quality Validators for TimeStack Warehouse.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Tuple\n\n\nclass DataQualityValidator(ABC):\n    \"\"\"Abstract base class for data quality validators.\"\"\"\n    \n    @abstractmethod\n    def validate(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Validate a record.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n            If valid, error_message should be an empty string.\n        \"\"\"\n        pass\n\n\nclass NotNullValidator(DataQualityValidator):\n    \"\"\"Validator that checks if a specified field is not None.\"\"\"\n    \n    def __init__(self, field: str):\n        \"\"\"Initialize the validator.\n        \n        Args:\n            field: The name of the field to check.\n        \"\"\"\n        self.field = field\n    \n    def validate(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Check if the field exists and is not None.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n        \"\"\"\n        if self.field not in record:\n            return False, f\"Field '{self.field}' is missing from record.\"\n        \n        if record[self.field] is None:\n            return False, f\"Field '{self.field}' cannot be None.\"\n        \n        return True, \"\"\n\n\nclass FieldTypeValidator(DataQualityValidator):\n    \"\"\"Validator that checks if a specified field has the correct type.\"\"\"\n    \n    def __init__(self, field: str, expected_type: type):\n        \"\"\"Initialize the validator.\n        \n        Args:\n            field: The name of the field to check.\n            expected_type: The expected Python type for the field.\n        \"\"\"\n        self.field = field\n        self.expected_type = expected_type\n    \n    def validate(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Check if the field has the expected type.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n        \"\"\"\n        if self.field not in record:\n            return False, f\"Field '{self.field}' is missing from record.\"\n        \n        value = record[self.field]\n        \n        # Allow None values to pass type check (use NotNullValidator for null checks)\n        if value is None:\n            return True, \"\"\n        \n        if not isinstance(value, self.expected_type):\n            actual_type = type(value).__name__\n            expected_type_name = self.expected_type.__name__\n            return False, f\"Field '{self.field}' expected type '{expected_type_name}', got '{actual_type}'.\"\n        \n        return True, \"\"\n\n\nclass QuarantineRecord:\n    \"\"\"A signal class indicating a record should be quarantined.\"\"\"\n    \n    def __init__(self, original_record: dict, error: str):\n        \"\"\"Initialize the quarantine record.\n        \n        Args:\n            original_record: The original data record that failed validation.\n            error: The error message explaining why validation failed.\n        \"\"\"\n        self.original_record = original_record\n        self.error = error\n    \n    def to_dict(self) -> dict:\n        \"\"\"Convert to dictionary format for storage.\n        \n        Returns:\n            Dictionary containing original record and error.\n        \"\"\"\n        return {\n            \"original_record\": self.original_record,\n            \"error\": self.error\n        }\n",
            "timestack/steps.py": "\"\"\"Pipeline steps for data transformation.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Generator, List, Optional\n\nfrom timestack.validators import DataQualityValidator, QuarantineRecord\n\n\nclass BaseStep(ABC):\n    \"\"\"Abstract base class for pipeline steps.\"\"\"\n    \n    def __init__(self, name: str, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the step.\n        \n        Args:\n            name: The name of this step.\n            validators: Optional list of data quality validators to apply.\n        \"\"\"\n        self.name = name\n        self.validators = validators or []\n    \n    def validate_record(self, record: dict) -> Tuple[bool, str]:\n        \"\"\"Validate a record against all validators.\n        \n        Args:\n            record: The data record to validate.\n            \n        Returns:\n            A tuple of (is_valid, error_message).\n        \"\"\"\n        for validator in self.validators:\n            is_valid, error = validator.validate(record)\n            if not is_valid:\n                return False, error\n        return True, \"\"\n    \n    def process(self, data: Any) -> Generator[Any, None, None]:\n        \"\"\"Process data through this step with validation.\n        \n        Args:\n            data: Input data to process.\n            \n        Yields:\n            Processed records or QuarantineRecord signals.\n        \"\"\"\n        # Handle different input types\n        if isinstance(data, dict):\n            records = [data]\n        elif isinstance(data, list):\n            records = data\n        elif hasattr(data, '__iter__'):\n            records = list(data)\n        else:\n            records = [data]\n        \n        for record in records:\n            # Validate before transformation\n            if isinstance(record, dict) and self.validators:\n                is_valid, error = self.validate_record(record)\n                if not is_valid:\n                    yield QuarantineRecord(record, error)\n                    continue\n            \n            # Apply transformation\n            result = self.transform(record)\n            if result is not None:\n                yield result\n    \n    @abstractmethod\n    def transform(self, record: Any) -> Any:\n        \"\"\"Transform a single record.\n        \n        Args:\n            record: The record to transform.\n            \n        Returns:\n            The transformed record.\n        \"\"\"\n        pass\n\n\n# Import Tuple for type hints\nfrom typing import Tuple\n\n\nclass IdentityStep(BaseStep):\n    \"\"\"A step that passes data through unchanged.\"\"\"\n    \n    def __init__(self, name: str = \"identity\", validators: Optional[List[DataQualityValidator]] = None):\n        super().__init__(name, validators)\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Return the record unchanged.\"\"\"\n        return record\n\n\nclass MapStep(BaseStep):\n    \"\"\"A step that applies a mapping function to each record.\"\"\"\n    \n    def __init__(self, name: str, map_func: callable, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the map step.\n        \n        Args:\n            name: The name of this step.\n            map_func: A function to apply to each record.\n            validators: Optional list of data quality validators.\n        \"\"\"\n        super().__init__(name, validators)\n        self.map_func = map_func\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Apply the mapping function to the record.\"\"\"\n        return self.map_func(record)\n\n\nclass FilterStep(BaseStep):\n    \"\"\"A step that filters records based on a predicate.\"\"\"\n    \n    def __init__(self, name: str, predicate: callable, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the filter step.\n        \n        Args:\n            name: The name of this step.\n            predicate: A function that returns True for records to keep.\n            validators: Optional list of data quality validators.\n        \"\"\"\n        super().__init__(name, validators)\n        self.predicate = predicate\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Filter the record based on the predicate.\"\"\"\n        if self.predicate(record):\n            return record\n        return None\n\n\nclass AddFieldStep(BaseStep):\n    \"\"\"A step that adds a new field to each record.\"\"\"\n    \n    def __init__(self, name: str, field_name: str, field_value: Any, validators: Optional[List[DataQualityValidator]] = None):\n        \"\"\"Initialize the add field step.\n        \n        Args:\n            name: The name of this step.\n            field_name: The name of the field to add.\n            field_value: The value to set (can be a callable).\n            validators: Optional list of data quality validators.\n        \"\"\"\n        super().__init__(name, validators)\n        self.field_name = field_name\n        self.field_value = field_value\n    \n    def transform(self, record: Any) -> Any:\n        \"\"\"Add the field to the record.\"\"\"\n        if isinstance(record, dict):\n            record = record.copy()\n            if callable(self.field_value):\n                record[self.field_name] = self.field_value(record)\n            else:\n                record[self.field_name] = self.field_value\n        return record\n",
            "timestack/storage.py": "\"\"\"Storage backends for TimeStack Warehouse.\"\"\"\n\nimport json\nimport os\nimport uuid\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\n\nclass Storage(ABC):\n    \"\"\"Abstract base class for storage backends.\"\"\"\n    \n    @abstractmethod\n    def write(self, path: str, data: Any) -> None:\n        \"\"\"Write data to storage.\n        \n        Args:\n            path: The path to write to.\n            data: The data to write.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def read(self, path: str) -> Any:\n        \"\"\"Read data from storage.\n        \n        Args:\n            path: The path to read from.\n            \n        Returns:\n            The data read from storage.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists in storage.\n        \n        Args:\n            path: The path to check.\n            \n        Returns:\n            True if the path exists, False otherwise.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def list_files(self, path: str) -> List[str]:\n        \"\"\"List files in a directory.\n        \n        Args:\n            path: The directory path.\n            \n        Returns:\n            List of file paths.\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def write_quarantine(self, pipeline_name: str, run_id: str, record: dict, error: str) -> str:\n        \"\"\"Write a quarantined record to storage.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            record: The original record that failed validation.\n            error: The error message explaining the failure.\n            \n        Returns:\n            The path where the quarantined record was written.\n        \"\"\"\n        pass\n\n\nclass LocalStorage(Storage):\n    \"\"\"Local filesystem storage backend.\"\"\"\n    \n    def __init__(self, base_path: str = \"./data\"):\n        \"\"\"Initialize local storage.\n        \n        Args:\n            base_path: The base directory for storage.\n        \"\"\"\n        self.base_path = Path(base_path)\n        self.base_path.mkdir(parents=True, exist_ok=True)\n    \n    def _get_full_path(self, path: str) -> Path:\n        \"\"\"Get the full path including base path.\"\"\"\n        return self.base_path / path\n    \n    def write(self, path: str, data: Any) -> None:\n        \"\"\"Write data to a local file.\"\"\"\n        full_path = self._get_full_path(path)\n        full_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        with open(full_path, 'w') as f:\n            if isinstance(data, (dict, list)):\n                json.dump(data, f, indent=2, default=str)\n            else:\n                f.write(str(data))\n    \n    def read(self, path: str) -> Any:\n        \"\"\"Read data from a local file.\"\"\"\n        full_path = self._get_full_path(path)\n        \n        with open(full_path, 'r') as f:\n            content = f.read()\n            try:\n                return json.loads(content)\n            except json.JSONDecodeError:\n                return content\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a local path exists.\"\"\"\n        return self._get_full_path(path).exists()\n    \n    def list_files(self, path: str) -> List[str]:\n        \"\"\"List files in a local directory.\"\"\"\n        full_path = self._get_full_path(path)\n        if not full_path.exists():\n            return []\n        \n        files = []\n        for item in full_path.iterdir():\n            if item.is_file():\n                files.append(str(item.relative_to(self.base_path)))\n        return files\n    \n    def write_quarantine(self, pipeline_name: str, run_id: str, record: dict, error: str) -> str:\n        \"\"\"Write a quarantined record to storage.\"\"\"\n        # Generate unique filename\n        record_id = str(uuid.uuid4())\n        quarantine_path = f\"quarantine/{pipeline_name}/{run_id}/{record_id}.json\"\n        \n        # Create quarantine data structure\n        quarantine_data = {\n            \"original_record\": record,\n            \"error\": error\n        }\n        \n        self.write(quarantine_path, quarantine_data)\n        return quarantine_path\n    \n    def get_quarantine_path(self, pipeline_name: str, run_id: str) -> str:\n        \"\"\"Get the quarantine directory path for a pipeline run.\"\"\"\n        return f\"quarantine/{pipeline_name}/{run_id}\"\n\n\nclass InMemoryStorage(Storage):\n    \"\"\"In-memory storage backend for testing.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize in-memory storage.\"\"\"\n        self._data: Dict[str, Any] = {}\n    \n    def write(self, path: str, data: Any) -> None:\n        \"\"\"Write data to memory.\"\"\"\n        self._data[path] = data\n    \n    def read(self, path: str) -> Any:\n        \"\"\"Read data from memory.\"\"\"\n        if path not in self._data:\n            raise FileNotFoundError(f\"Path not found: {path}\")\n        return self._data[path]\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists in memory.\"\"\"\n        return path in self._data\n    \n    def list_files(self, path: str) -> List[str]:\n        \"\"\"List files under a path prefix.\"\"\"\n        prefix = path.rstrip('/') + '/'\n        return [k for k in self._data.keys() if k.startswith(prefix)]\n    \n    def write_quarantine(self, pipeline_name: str, run_id: str, record: dict, error: str) -> str:\n        \"\"\"Write a quarantined record to memory.\"\"\"\n        record_id = str(uuid.uuid4())\n        quarantine_path = f\"quarantine/{pipeline_name}/{run_id}/{record_id}.json\"\n        \n        quarantine_data = {\n            \"original_record\": record,\n            \"error\": error\n        }\n        \n        self.write(quarantine_path, quarantine_data)\n        return quarantine_path\n    \n    def get_quarantine_path(self, pipeline_name: str, run_id: str) -> str:\n        \"\"\"Get the quarantine directory path for a pipeline run.\"\"\"\n        return f\"quarantine/{pipeline_name}/{run_id}\"\n    \n    def clear(self) -> None:\n        \"\"\"Clear all stored data.\"\"\"\n        self._data.clear()\n",
            "timestack/observers.py": "\"\"\"Pipeline observers for monitoring and logging.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\nimport logging\n\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass PipelineObserver(ABC):\n    \"\"\"Abstract base class for pipeline observers.\"\"\"\n    \n    def on_pipeline_start(self, pipeline_name: str, run_id: str) -> None:\n        \"\"\"Called when a pipeline starts.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n        \"\"\"\n        pass\n    \n    def on_pipeline_end(self, pipeline_name: str, run_id: str, success: bool) -> None:\n        \"\"\"Called when a pipeline ends.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            success: Whether the pipeline completed successfully.\n        \"\"\"\n        pass\n    \n    def on_step_start(self, step_name: str, pipeline_name: str, run_id: str) -> None:\n        \"\"\"Called when a step starts.\n        \n        Args:\n            step_name: The name of the step.\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n        \"\"\"\n        pass\n    \n    def on_step_end(self, step_name: str, pipeline_name: str, run_id: str, success: bool) -> None:\n        \"\"\"Called when a step ends.\n        \n        Args:\n            step_name: The name of the step.\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            success: Whether the step completed successfully.\n        \"\"\"\n        pass\n    \n    def on_record_processed(self, step_name: str, record: Any) -> None:\n        \"\"\"Called when a record is processed.\n        \n        Args:\n            step_name: The name of the step.\n            record: The processed record.\n        \"\"\"\n        pass\n    \n    def on_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        \"\"\"Called when an error occurs.\n        \n        Args:\n            error: The exception that occurred.\n            context: Additional context about the error.\n        \"\"\"\n        pass\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        \"\"\"Called when a record is quarantined.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            record: The original record that failed validation.\n            error: The error message explaining why validation failed.\n        \"\"\"\n        pass\n\n\nclass LoggingObserver(PipelineObserver):\n    \"\"\"Observer that logs pipeline events.\"\"\"\n    \n    def __init__(self, log_level: int = logging.INFO):\n        \"\"\"Initialize the logging observer.\n        \n        Args:\n            log_level: The logging level to use.\n        \"\"\"\n        self.log_level = log_level\n    \n    def on_pipeline_start(self, pipeline_name: str, run_id: str) -> None:\n        logger.log(self.log_level, f\"Pipeline '{pipeline_name}' started (run_id: {run_id})\")\n    \n    def on_pipeline_end(self, pipeline_name: str, run_id: str, success: bool) -> None:\n        status = \"successfully\" if success else \"with errors\"\n        logger.log(self.log_level, f\"Pipeline '{pipeline_name}' completed {status} (run_id: {run_id})\")\n    \n    def on_step_start(self, step_name: str, pipeline_name: str, run_id: str) -> None:\n        logger.log(self.log_level, f\"Step '{step_name}' started in pipeline '{pipeline_name}'\")\n    \n    def on_step_end(self, step_name: str, pipeline_name: str, run_id: str, success: bool) -> None:\n        status = \"successfully\" if success else \"with errors\"\n        logger.log(self.log_level, f\"Step '{step_name}' completed {status}\")\n    \n    def on_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        logger.error(f\"Error occurred: {error}. Context: {context}\")\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        logger.warning(f\"Record quarantined in pipeline '{pipeline_name}' (run_id: {run_id}): {error}\")\n\n\nclass QuarantineObserver(PipelineObserver):\n    \"\"\"Observer specifically for monitoring quarantined records.\"\"\"\n    \n    def __init__(self, verbose: bool = True):\n        \"\"\"Initialize the quarantine observer.\n        \n        Args:\n            verbose: If True, log full record details.\n        \"\"\"\n        self.verbose = verbose\n        self.quarantine_count = 0\n        self.quarantined_records: List[Dict[str, Any]] = []\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        \"\"\"Log quarantined record details to the console.\n        \n        Args:\n            pipeline_name: The name of the pipeline.\n            run_id: The unique run identifier.\n            record: The original record that failed validation.\n            error: The error message explaining why validation failed.\n        \"\"\"\n        self.quarantine_count += 1\n        self.quarantined_records.append({\n            \"pipeline_name\": pipeline_name,\n            \"run_id\": run_id,\n            \"record\": record,\n            \"error\": error,\n            \"timestamp\": datetime.now().isoformat()\n        })\n        \n        print(f\"[QUARANTINE] Pipeline: {pipeline_name} | Run: {run_id}\")\n        print(f\"[QUARANTINE] Error: {error}\")\n        if self.verbose:\n            print(f\"[QUARANTINE] Record: {record}\")\n        print(f\"[QUARANTINE] Total quarantined this session: {self.quarantine_count}\")\n        print(\"-\" * 60)\n    \n    def get_quarantine_count(self) -> int:\n        \"\"\"Get the total number of quarantined records.\"\"\"\n        return self.quarantine_count\n    \n    def get_quarantined_records(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all quarantined records observed.\"\"\"\n        return self.quarantined_records.copy()\n    \n    def reset(self) -> None:\n        \"\"\"Reset the quarantine count and records.\"\"\"\n        self.quarantine_count = 0\n        self.quarantined_records.clear()\n\n\nclass MetricsObserver(PipelineObserver):\n    \"\"\"Observer that collects metrics about pipeline execution.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the metrics observer.\"\"\"\n        self.metrics: Dict[str, Any] = {\n            \"pipelines\": {},\n            \"total_records_processed\": 0,\n            \"total_records_quarantined\": 0,\n            \"errors\": []\n        }\n    \n    def on_pipeline_start(self, pipeline_name: str, run_id: str) -> None:\n        if pipeline_name not in self.metrics[\"pipelines\"]:\n            self.metrics[\"pipelines\"][pipeline_name] = {\n                \"runs\": [],\n                \"total_runs\": 0\n            }\n        self.metrics[\"pipelines\"][pipeline_name][\"runs\"].append({\n            \"run_id\": run_id,\n            \"start_time\": datetime.now().isoformat(),\n            \"end_time\": None,\n            \"success\": None,\n            \"records_processed\": 0,\n            \"records_quarantined\": 0\n        })\n    \n    def on_pipeline_end(self, pipeline_name: str, run_id: str, success: bool) -> None:\n        if pipeline_name in self.metrics[\"pipelines\"]:\n            for run in self.metrics[\"pipelines\"][pipeline_name][\"runs\"]:\n                if run[\"run_id\"] == run_id:\n                    run[\"end_time\"] = datetime.now().isoformat()\n                    run[\"success\"] = success\n                    break\n            self.metrics[\"pipelines\"][pipeline_name][\"total_runs\"] += 1\n    \n    def on_record_processed(self, step_name: str, record: Any) -> None:\n        self.metrics[\"total_records_processed\"] += 1\n    \n    def on_record_quarantined(self, pipeline_name: str, run_id: str, record: dict, error: str) -> None:\n        self.metrics[\"total_records_quarantined\"] += 1\n        if pipeline_name in self.metrics[\"pipelines\"]:\n            for run in self.metrics[\"pipelines\"][pipeline_name][\"runs\"]:\n                if run[\"run_id\"] == run_id:\n                    run[\"records_quarantined\"] += 1\n                    break\n    \n    def on_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        self.metrics[\"errors\"].append({\n            \"error\": str(error),\n            \"context\": context,\n            \"timestamp\": datetime.now().isoformat()\n        })\n    \n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get all collected metrics.\"\"\"\n        return self.metrics.copy()\n",
            "timestack/pipeline.py": "\"\"\"Pipeline orchestration for TimeStack Warehouse.\"\"\"\n\nimport uuid\nfrom datetime import datetime\nfrom typing import Any, Dict, Generator, List, Optional\n\nfrom timestack.steps import BaseStep\nfrom timestack.storage import Storage, LocalStorage\nfrom timestack.observers import PipelineObserver\nfrom timestack.validators import QuarantineRecord\n\n\nclass Pipeline:\n    \"\"\"A data processing pipeline.\"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        steps: Optional[List[BaseStep]] = None,\n        storage: Optional[Storage] = None,\n        observers: Optional[List[PipelineObserver]] = None\n    ):\n        \"\"\"Initialize the pipeline.\n        \n        Args:\n            name: The name of the pipeline.\n            steps: List of processing steps.\n            storage: Storage backend for output.\n            observers: List of observers for monitoring.\n        \"\"\"\n        self.name = name\n        self.steps = steps or []\n        self.storage = storage or LocalStorage()\n        self.observers = observers or []\n        self.run_id: Optional[str] = None\n    \n    def add_step(self, step: BaseStep) -> 'Pipeline':\n        \"\"\"Add a step to the pipeline.\n        \n        Args:\n            step: The step to add.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.steps.append(step)\n        return self\n    \n    def add_observer(self, observer: PipelineObserver) -> 'Pipeline':\n        \"\"\"Add an observer to the pipeline.\n        \n        Args:\n            observer: The observer to add.\n            \n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.observers.append(observer)\n        return self\n    \n    def _notify_observers(self, method: str, *args, **kwargs) -> None:\n        \"\"\"Notify all observers of an event.\n        \n        Args:\n            method: The observer method to call.\n            *args: Positional arguments to pass.\n            **kwargs: Keyword arguments to pass.\n        \"\"\"\n        for observer in self.observers:\n            if hasattr(observer, method):\n                getattr(observer, method)(*args, **kwargs)\n    \n    def _handle_quarantine(self, quarantine_record: QuarantineRecord) -> None:\n        \"\"\"Handle a quarantined record.\n        \n        Args:\n            quarantine_record: The quarantine record to handle.\n        \"\"\"\n        # Write to quarantine storage\n        self.storage.write_quarantine(\n            pipeline_name=self.name,\n            run_id=self.run_id,\n            record=quarantine_record.original_record,\n            error=quarantine_record.error\n        )\n        \n        # Notify observers\n        self._notify_observers(\n            'on_record_quarantined',\n            pipeline_name=self.name,\n            run_id=self.run_id,\n            record=quarantine_record.original_record,\n            error=quarantine_record.error\n        )\n    \n    def run(self, input_data: Any, output_path: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Run the pipeline on input data.\n        \n        Args:\n            input_data: The input data to process.\n            output_path: Optional path to write output.\n            \n        Returns:\n            A dictionary with run results.\n        \"\"\"\n        self.run_id = str(uuid.uuid4())\n        start_time = datetime.now()\n        success = True\n        processed_records = []\n        quarantined_count = 0\n        \n        try:\n            # Notify pipeline start\n            self._notify_observers('on_pipeline_start', self.name, self.run_id)\n            \n            # Prepare initial data\n            if isinstance(input_data, dict):\n                current_data = [input_data]\n            elif isinstance(input_data, list):\n                current_data = input_data\n            else:\n                current_data = list(input_data) if hasattr(input_data, '__iter__') else [input_data]\n            \n            # Process through each step\n            for step in self.steps:\n                self._notify_observers('on_step_start', step.name, self.name, self.run_id)\n                \n                step_success = True\n                next_data = []\n                \n                try:\n                    for record in current_data:\n                        # Skip if already a quarantine record (shouldn't happen, but safety check)\n                        if isinstance(record, QuarantineRecord):\n                            self._handle_quarantine(record)\n                            quarantined_count += 1\n                            continue\n                        \n                        # Process the record through the step\n                        for result in step.process(record):\n                            if isinstance(result, QuarantineRecord):\n                                # Handle quarantine\n                                self._handle_quarantine(result)\n                                quarantined_count += 1\n                            else:\n                                # Valid record, pass to next step\n                                next_data.append(result)\n                                self._notify_observers('on_record_processed', step.name, result)\n                \n                except Exception as e:\n                    step_success = False\n                    success = False\n                    self._notify_observers('on_error', e, {\n                        'step': step.name,\n                        'pipeline': self.name,\n                        'run_id': self.run_id\n                    })\n                    raise\n                \n                finally:\n                    self._notify_observers('on_step_end', step.name, self.name, self.run_id, step_success)\n                \n                current_data = next_data\n            \n            processed_records = current_data\n            \n            # Write output if path specified\n            if output_path and processed_records:\n                self.storage.write(output_path, processed_records)\n        \n        except Exception as e:\n            success = False\n            self._notify_observers('on_error', e, {\n                'pipeline': self.name,\n                'run_id': self.run_id\n            })\n            raise\n        \n        finally:\n            self._notify_observers('on_pipeline_end', self.name, self.run_id, success)\n        \n        end_time = datetime.now()\n        \n        return {\n            'run_id': self.run_id,\n            'pipeline_name': self.name,\n            'success': success,\n            'start_time': start_time.isoformat(),\n            'end_time': end_time.isoformat(),\n            'duration_seconds': (end_time - start_time).total_seconds(),\n            'records_processed': len(processed_records),\n            'records_quarantined': quarantined_count,\n            'output_path': output_path,\n            'output_data': processed_records\n        }\n\n\nclass PipelineBuilder:\n    \"\"\"Builder class for constructing pipelines.\"\"\"\n    \n    def __init__(self, name: str):\n        \"\"\"Initialize the builder.\n        \n        Args:\n            name: The name of the pipeline to build.\n        \"\"\"\n        self.name = name\n        self.steps: List[BaseStep] = []\n        self.storage: Optional[Storage] = None\n        self.observers: List[PipelineObserver] = []\n    \n    def with_step(self, step: BaseStep) -> 'PipelineBuilder':\n        \"\"\"Add a step to the pipeline.\"\"\"\n        self.steps.append(step)\n        return self\n    \n    def with_storage(self, storage: Storage) -> 'PipelineBuilder':\n        \"\"\"Set the storage backend.\"\"\"\n        self.storage = storage\n        return self\n    \n    def with_observer(self, observer: PipelineObserver) -> 'PipelineBuilder':\n        \"\"\"Add an observer.\"\"\"\n        self.observers.append(observer)\n        return self\n    \n    def build(self) -> Pipeline:\n        \"\"\"Build and return the pipeline.\"\"\"\n        return Pipeline(\n            name=self.name,\n            steps=self.steps,\n            storage=self.storage,\n            observers=self.observers\n        )\n",
            "timestack/__init__.py": "\"\"\"TimeStack Warehouse - A data pipeline framework with data quality controls.\"\"\"\n\nfrom timestack.pipeline import Pipeline, PipelineBuilder\nfrom timestack.steps import BaseStep, IdentityStep, MapStep, FilterStep, AddFieldStep\nfrom timestack.storage import Storage, LocalStorage, InMemoryStorage\nfrom timestack.observers import (\n    PipelineObserver,\n    LoggingObserver,\n    QuarantineObserver,\n    MetricsObserver\n)\nfrom timestack.validators import (\n    DataQualityValidator,\n    NotNullValidator,\n    FieldTypeValidator,\n    QuarantineRecord\n)\n\n__version__ = \"0.2.0\"\n\n__all__ = [\n    # Pipeline\n    \"Pipeline\",\n    \"PipelineBuilder\",\n    # Steps\n    \"BaseStep\",\n    \"IdentityStep\",\n    \"MapStep\",\n    \"FilterStep\",\n    \"AddFieldStep\",\n    # Storage\n    \"Storage\",\n    \"LocalStorage\",\n    \"InMemoryStorage\",\n    # Observers\n    \"PipelineObserver\",\n    \"LoggingObserver\",\n    \"QuarantineObserver\",\n    \"MetricsObserver\",\n    # Validators\n    \"DataQualityValidator\",\n    \"NotNullValidator\",\n    \"FieldTypeValidator\",\n    \"QuarantineRecord\",\n]\n",
            "main.py": "\"\"\"Main entry point demonstrating TimeStack Warehouse with Data Quality Gates.\"\"\"\n\nfrom timestack import (\n    Pipeline,\n    PipelineBuilder,\n    MapStep,\n    IdentityStep,\n    LocalStorage,\n    LoggingObserver,\n    QuarantineObserver,\n    NotNullValidator,\n    FieldTypeValidator\n)\n\n\ndef main():\n    \"\"\"Demonstrate the data quality and quarantine system.\"\"\"\n    \n    print(\"=\" * 60)\n    print(\"TimeStack Warehouse - Data Quality Gates Demo\")\n    print(\"=\" * 60)\n    \n    # Sample data with some invalid records\n    input_data = [\n        {\"user_id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\", \"age\": 30},\n        {\"user_id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\", \"age\": 25},\n        {\"user_id\": None, \"name\": \"Charlie\", \"email\": \"charlie@example.com\", \"age\": 35},  # Invalid: null user_id\n        {\"user_id\": 4, \"name\": \"Diana\", \"email\": \"diana@example.com\", \"age\": \"twenty-eight\"},  # Invalid: wrong type for age\n        {\"user_id\": 5, \"name\": \"Eve\", \"email\": \"eve@example.com\", \"age\": 22},\n        {\"name\": \"Frank\", \"email\": \"frank@example.com\", \"age\": 40},  # Invalid: missing user_id\n    ]\n    \n    print(f\"\nInput data: {len(input_data)} records\")\n    print(\"-\" * 40)\n    \n    # Create validators\n    validators = [\n        NotNullValidator(\"user_id\"),\n        FieldTypeValidator(\"age\", int)\n    ]\n    \n    # Create a step with validators\n    validated_step = IdentityStep(name=\"validate_users\", validators=validators)\n    \n    # Create a transformation step\n    def enrich_user(record):\n        record = record.copy()\n        record[\"processed\"] = True\n        record[\"full_info\"] = f\"{record['name']} ({record['email']})\"\n        return record\n    \n    transform_step = MapStep(name=\"enrich_users\", map_func=enrich_user)\n    \n    # Create observers\n    logging_observer = LoggingObserver()\n    quarantine_observer = QuarantineObserver(verbose=True)\n    \n    # Build the pipeline\n    pipeline = (\n        PipelineBuilder(\"user_processing_pipeline\")\n        .with_step(validated_step)\n        .with_step(transform_step)\n        .with_storage(LocalStorage(\"./demo_output\"))\n        .with_observer(logging_observer)\n        .with_observer(quarantine_observer)\n        .build()\n    )\n    \n    print(\"\nRunning pipeline...\")\n    print(\"=\" * 60)\n    \n    # Run the pipeline\n    result = pipeline.run(\n        input_data=input_data,\n        output_path=\"processed_users.json\"\n    )\n    \n    # Print results\n    print(\"\n\" + \"=\" * 60)\n    print(\"Pipeline Execution Summary\")\n    print(\"=\" * 60)\n    print(f\"Run ID: {result['run_id']}\")\n    print(f\"Success: {result['success']}\")\n    print(f\"Duration: {result['duration_seconds']:.3f} seconds\")\n    print(f\"Records Processed: {result['records_processed']}\")\n    print(f\"Records Quarantined: {result['records_quarantined']}\")\n    print(f\"Output Path: {result['output_path']}\")\n    \n    print(\"\n\" + \"-\" * 40)\n    print(\"Processed Records:\")\n    print(\"-\" * 40)\n    for record in result['output_data']:\n        print(f\"  - {record['name']}: user_id={record['user_id']}, age={record['age']}\")\n    \n    print(\"\n\" + \"-\" * 40)\n    print(f\"Quarantine Observer Stats:\")\n    print(\"-\" * 40)\n    print(f\"  Total quarantined: {quarantine_observer.get_quarantine_count()}\")\n    \n    print(\"\n\" + \"=\" * 60)\n    print(\"Demo completed successfully!\")\n    print(\"=\" * 60)\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "tests/test_pipeline.py": "\"\"\"Tests for the TimeStack pipeline with data quality gates.\"\"\"\n\nimport pytest\nimport os\nimport shutil\nfrom typing import List\n\nfrom timestack import (\n    Pipeline,\n    PipelineBuilder,\n    BaseStep,\n    IdentityStep,\n    MapStep,\n    FilterStep,\n    LocalStorage,\n    InMemoryStorage,\n    LoggingObserver,\n    QuarantineObserver,\n    NotNullValidator,\n    FieldTypeValidator,\n    DataQualityValidator,\n    QuarantineRecord\n)\n\n\nclass TestValidators:\n    \"\"\"Tests for data quality validators.\"\"\"\n    \n    def test_not_null_validator_valid(self):\n        \"\"\"Test NotNullValidator with valid data.\"\"\"\n        validator = NotNullValidator(\"user_id\")\n        record = {\"user_id\": 123, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is True\n        assert error == \"\"\n    \n    def test_not_null_validator_null_value(self):\n        \"\"\"Test NotNullValidator with null value.\"\"\"\n        validator = NotNullValidator(\"user_id\")\n        record = {\"user_id\": None, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"user_id\" in error\n        assert \"None\" in error\n    \n    def test_not_null_validator_missing_field(self):\n        \"\"\"Test NotNullValidator with missing field.\"\"\"\n        validator = NotNullValidator(\"user_id\")\n        record = {\"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"missing\" in error.lower()\n    \n    def test_field_type_validator_valid(self):\n        \"\"\"Test FieldTypeValidator with valid data.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"age\": 25, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is True\n        assert error == \"\"\n    \n    def test_field_type_validator_wrong_type(self):\n        \"\"\"Test FieldTypeValidator with wrong type.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"age\": \"twenty-five\", \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"age\" in error\n        assert \"int\" in error\n    \n    def test_field_type_validator_allows_none(self):\n        \"\"\"Test FieldTypeValidator allows None values.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"age\": None, \"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is True  # None passes type check\n    \n    def test_field_type_validator_missing_field(self):\n        \"\"\"Test FieldTypeValidator with missing field.\"\"\"\n        validator = FieldTypeValidator(\"age\", int)\n        record = {\"name\": \"Test\"}\n        is_valid, error = validator.validate(record)\n        assert is_valid is False\n        assert \"missing\" in error.lower()\n\n\nclass TestStepsWithValidators:\n    \"\"\"Tests for steps with validators.\"\"\"\n    \n    def test_step_with_validators_valid_record(self):\n        \"\"\"Test step processes valid records normally.\"\"\"\n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"test_step\", validators=validators)\n        \n        record = {\"id\": 1, \"value\": \"test\"}\n        results = list(step.process(record))\n        \n        assert len(results) == 1\n        assert results[0] == record\n    \n    def test_step_with_validators_invalid_record(self):\n        \"\"\"Test step yields QuarantineRecord for invalid records.\"\"\"\n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"test_step\", validators=validators)\n        \n        record = {\"id\": None, \"value\": \"test\"}\n        results = list(step.process(record))\n        \n        assert len(results) == 1\n        assert isinstance(results[0], QuarantineRecord)\n        assert results[0].original_record == record\n        assert \"id\" in results[0].error\n    \n    def test_step_with_multiple_validators(self):\n        \"\"\"Test step with multiple validators.\"\"\"\n        validators = [\n            NotNullValidator(\"id\"),\n            FieldTypeValidator(\"count\", int)\n        ]\n        step = IdentityStep(\"test_step\", validators=validators)\n        \n        # Valid record\n        valid_record = {\"id\": 1, \"count\": 10}\n        results = list(step.process(valid_record))\n        assert len(results) == 1\n        assert not isinstance(results[0], QuarantineRecord)\n        \n        # Invalid - null id\n        invalid_record1 = {\"id\": None, \"count\": 10}\n        results = list(step.process(invalid_record1))\n        assert isinstance(results[0], QuarantineRecord)\n        \n        # Invalid - wrong type\n        invalid_record2 = {\"id\": 2, \"count\": \"ten\"}\n        results = list(step.process(invalid_record2))\n        assert isinstance(results[0], QuarantineRecord)\n\n\nclass TestPipelineBasics:\n    \"\"\"Basic pipeline tests.\"\"\"\n    \n    def test_pipeline_creation(self):\n        \"\"\"Test basic pipeline creation.\"\"\"\n        pipeline = Pipeline(name=\"test_pipeline\")\n        assert pipeline.name == \"test_pipeline\"\n        assert len(pipeline.steps) == 0\n    \n    def test_pipeline_add_step(self):\n        \"\"\"Test adding steps to pipeline.\"\"\"\n        pipeline = Pipeline(name=\"test_pipeline\")\n        step = IdentityStep(\"step1\")\n        pipeline.add_step(step)\n        assert len(pipeline.steps) == 1\n    \n    def test_pipeline_builder(self):\n        \"\"\"Test pipeline builder pattern.\"\"\"\n        pipeline = (\n            PipelineBuilder(\"test_pipeline\")\n            .with_step(IdentityStep(\"step1\"))\n            .with_step(IdentityStep(\"step2\"))\n            .build()\n        )\n        assert pipeline.name == \"test_pipeline\"\n        assert len(pipeline.steps) == 2\n    \n    def test_pipeline_run_simple(self):\n        \"\"\"Test simple pipeline run.\"\"\"\n        pipeline = Pipeline(name=\"test_pipeline\")\n        pipeline.add_step(IdentityStep(\"identity\"))\n        \n        result = pipeline.run([{\"id\": 1}, {\"id\": 2}])\n        \n        assert result[\"success\"] is True\n        assert result[\"records_processed\"] == 2\n        assert len(result[\"output_data\"]) == 2\n\n\nclass TestPipelineWithDataQuarantine:\n    \"\"\"Tests for pipeline data quarantine functionality.\"\"\"\n    \n    def setup_method(self):\n        \"\"\"Set up test fixtures.\"\"\"\n        self.test_output_dir = \"./test_quarantine_output\"\n        if os.path.exists(self.test_output_dir):\n            shutil.rmtree(self.test_output_dir)\n    \n    def teardown_method(self):\n        \"\"\"Clean up after tests.\"\"\"\n        if os.path.exists(self.test_output_dir):\n            shutil.rmtree(self.test_output_dir)\n    \n    def test_pipeline_with_data_quarantine(self):\n        \"\"\"Test pipeline correctly quarantines invalid records.\n        \n        This test:\n        a. Defines a pipeline with a step that uses a NotNullValidator.\n        b. Provides a mix of valid and invalid records as input.\n        c. Runs the pipeline.\n        d. Asserts that the valid records are correctly processed.\n        e. Asserts that the invalid records are NOT in the final output.\n        f. Asserts that the invalid records ARE present in the quarantine directory.\n        \"\"\"\n        # Create storage\n        storage = LocalStorage(self.test_output_dir)\n        \n        # Create quarantine observer to track quarantined records\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        # Create validators\n        validators = [NotNullValidator(\"user_id\")]\n        \n        # Create step with validators\n        validated_step = IdentityStep(name=\"validate_step\", validators=validators)\n        \n        # Build pipeline\n        pipeline = (\n            PipelineBuilder(\"test_quarantine_pipeline\")\n            .with_step(validated_step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        # Input data - mix of valid and invalid records\n        input_data = [\n            {\"user_id\": 1, \"name\": \"Alice\"},      # Valid\n            {\"user_id\": 2, \"name\": \"Bob\"},        # Valid\n            {\"user_id\": None, \"name\": \"Charlie\"}, # Invalid - null user_id\n            {\"user_id\": 3, \"name\": \"Diana\"},      # Valid\n            {\"name\": \"Eve\"},                       # Invalid - missing user_id\n        ]\n        \n        # Run pipeline\n        result = pipeline.run(\n            input_data=input_data,\n            output_path=\"output/processed.json\"\n        )\n        \n        # Assertions\n        # a. Pipeline should complete successfully\n        assert result[\"success\"] is True\n        \n        # b. Check counts\n        assert result[\"records_processed\"] == 3  # 3 valid records\n        assert result[\"records_quarantined\"] == 2  # 2 invalid records\n        \n        # c. Valid records should be in output\n        output_data = result[\"output_data\"]\n        assert len(output_data) == 3\n        \n        output_user_ids = [r[\"user_id\"] for r in output_data]\n        assert 1 in output_user_ids\n        assert 2 in output_user_ids\n        assert 3 in output_user_ids\n        \n        # d. Invalid records should NOT be in output\n        assert None not in output_user_ids\n        output_names = [r[\"name\"] for r in output_data]\n        assert \"Charlie\" not in output_names\n        assert \"Eve\" not in output_names\n        \n        # e. Check quarantine observer was notified\n        assert quarantine_observer.get_quarantine_count() == 2\n        \n        # f. Check quarantine directory exists and contains files\n        quarantine_path = storage.get_quarantine_path(\n            \"test_quarantine_pipeline\",\n            result[\"run_id\"]\n        )\n        quarantine_files = storage.list_files(quarantine_path)\n        assert len(quarantine_files) == 2\n        \n        # g. Verify quarantine file contents\n        quarantined_records = []\n        for file_path in quarantine_files:\n            data = storage.read(file_path)\n            quarantined_records.append(data)\n        \n        # Check that quarantine records have correct structure\n        for qr in quarantined_records:\n            assert \"original_record\" in qr\n            assert \"error\" in qr\n            assert \"user_id\" in qr[\"error\"].lower() or \"missing\" in qr[\"error\"].lower()\n        \n        # Check that Charlie and Eve's records are in quarantine\n        quarantined_names = [qr[\"original_record\"][\"name\"] for qr in quarantined_records]\n        assert \"Charlie\" in quarantined_names\n        assert \"Eve\" in quarantined_names\n    \n    def test_pipeline_quarantine_with_type_validator(self):\n        \"\"\"Test quarantine with FieldTypeValidator.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        validators = [\n            NotNullValidator(\"id\"),\n            FieldTypeValidator(\"count\", int)\n        ]\n        \n        step = IdentityStep(\"validate\", validators=validators)\n        \n        pipeline = (\n            PipelineBuilder(\"type_validation_pipeline\")\n            .with_step(step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": 1, \"count\": 10},        # Valid\n            {\"id\": 2, \"count\": \"twenty\"},  # Invalid - wrong type\n            {\"id\": 3, \"count\": 30},        # Valid\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 2\n        assert result[\"records_quarantined\"] == 1\n        assert quarantine_observer.get_quarantine_count() == 1\n        \n        # Check quarantine has the right record\n        quarantine_path = storage.get_quarantine_path(\n            \"type_validation_pipeline\",\n            result[\"run_id\"]\n        )\n        quarantine_files = storage.list_files(quarantine_path)\n        assert len(quarantine_files) == 1\n        \n        quarantined = storage.read(quarantine_files[0])\n        assert quarantined[\"original_record\"][\"id\"] == 2\n        assert \"count\" in quarantined[\"error\"]\n    \n    def test_pipeline_all_records_valid(self):\n        \"\"\"Test pipeline when all records are valid.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"validate\", validators=validators)\n        \n        pipeline = (\n            PipelineBuilder(\"all_valid_pipeline\")\n            .with_step(step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": 1, \"name\": \"A\"},\n            {\"id\": 2, \"name\": \"B\"},\n            {\"id\": 3, \"name\": \"C\"},\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 3\n        assert result[\"records_quarantined\"] == 0\n        assert quarantine_observer.get_quarantine_count() == 0\n    \n    def test_pipeline_all_records_invalid(self):\n        \"\"\"Test pipeline when all records are invalid.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        validators = [NotNullValidator(\"id\")]\n        step = IdentityStep(\"validate\", validators=validators)\n        \n        pipeline = (\n            PipelineBuilder(\"all_invalid_pipeline\")\n            .with_step(step)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": None, \"name\": \"A\"},\n            {\"name\": \"B\"},  # Missing id\n            {\"id\": None, \"name\": \"C\"},\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 0\n        assert result[\"records_quarantined\"] == 3\n        assert quarantine_observer.get_quarantine_count() == 3\n    \n    def test_pipeline_multi_step_validation(self):\n        \"\"\"Test validation in multi-step pipeline.\"\"\"\n        storage = InMemoryStorage()\n        quarantine_observer = QuarantineObserver(verbose=False)\n        \n        # First step validates id\n        step1 = IdentityStep(\n            \"validate_id\",\n            validators=[NotNullValidator(\"id\")]\n        )\n        \n        # Second step transforms\n        def add_processed_flag(record):\n            record = record.copy()\n            record[\"processed\"] = True\n            return record\n        \n        step2 = MapStep(\"transform\", add_processed_flag)\n        \n        # Third step validates processed flag exists\n        step3 = IdentityStep(\n            \"validate_processed\",\n            validators=[NotNullValidator(\"processed\")]\n        )\n        \n        pipeline = (\n            PipelineBuilder(\"multi_step_pipeline\")\n            .with_step(step1)\n            .with_step(step2)\n            .with_step(step3)\n            .with_storage(storage)\n            .with_observer(quarantine_observer)\n            .build()\n        )\n        \n        input_data = [\n            {\"id\": 1, \"name\": \"A\"},\n            {\"id\": None, \"name\": \"B\"},  # Will be quarantined at step 1\n            {\"id\": 2, \"name\": \"C\"},\n        ]\n        \n        result = pipeline.run(input_data)\n        \n        assert result[\"records_processed\"] == 2\n        assert result[\"records_quarantined\"] == 1\n        \n        # Verify processed records have the flag\n        for record in result[\"output_data\"]:\n            assert record[\"processed\"] is True\n\n\nclass TestQuarantineObserver:\n    \"\"\"Tests for QuarantineObserver.\"\"\"\n    \n    def test_observer_tracks_quarantined_records(self):\n        \"\"\"Test observer correctly tracks quarantined records.\"\"\"\n        observer = QuarantineObserver(verbose=False)\n        \n        observer.on_record_quarantined(\n            \"test_pipeline\",\n            \"run-123\",\n            {\"id\": 1, \"name\": \"Test\"},\n            \"Field 'id' cannot be None.\"\n        )\n        \n        assert observer.get_quarantine_count() == 1\n        records = observer.get_quarantined_records()\n        assert len(records) == 1\n        assert records[0][\"pipeline_name\"] == \"test_pipeline\"\n        assert records[0][\"run_id\"] == \"run-123\"\n    \n    def test_observer_reset(self):\n        \"\"\"Test observer reset functionality.\"\"\"\n        observer = QuarantineObserver(verbose=False)\n        \n        observer.on_record_quarantined(\n            \"test\", \"run-1\", {\"id\": 1}, \"error\"\n        )\n        observer.on_record_quarantined(\n            \"test\", \"run-1\", {\"id\": 2}, \"error\"\n        )\n        \n        assert observer.get_quarantine_count() == 2\n        \n        observer.reset()\n        \n        assert observer.get_quarantine_count() == 0\n        assert len(observer.get_quarantined_records()) == 0\n\n\nclass TestStorage:\n    \"\"\"Tests for storage with quarantine support.\"\"\"\n    \n    def test_in_memory_storage_quarantine(self):\n        \"\"\"Test InMemoryStorage quarantine functionality.\"\"\"\n        storage = InMemoryStorage()\n        \n        path = storage.write_quarantine(\n            \"test_pipeline\",\n            \"run-123\",\n            {\"id\": 1, \"name\": \"Test\"},\n            \"Validation error\"\n        )\n        \n        assert storage.exists(path)\n        data = storage.read(path)\n        assert data[\"original_record\"][\"id\"] == 1\n        assert data[\"error\"] == \"Validation error\"\n    \n    def test_local_storage_quarantine(self):\n        \"\"\"Test LocalStorage quarantine functionality.\"\"\"\n        test_dir = \"./test_storage_quarantine\"\n        try:\n            storage = LocalStorage(test_dir)\n            \n            path = storage.write_quarantine(\n                \"test_pipeline\",\n                \"run-456\",\n                {\"id\": 2, \"name\": \"Test2\"},\n                \"Another error\"\n            )\n            \n            assert storage.exists(path)\n            data = storage.read(path)\n            assert data[\"original_record\"][\"id\"] == 2\n            assert data[\"error\"] == \"Another error\"\n        finally:\n            if os.path.exists(test_dir):\n                shutil.rmtree(test_dir)\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])\n",
            "README.md": "# TimeStack Warehouse\n\nA robust data pipeline framework with pluggable data quality gates and quarantine mechanisms.\n\n## Features\n\n- **Modular Pipeline Architecture**: Build data pipelines with reusable, composable steps\n- **Data Quality Validators**: Pluggable validation system to ensure data integrity\n- **Quarantine Mechanism**: Isolate invalid records for later inspection without halting pipelines\n- **Observer Pattern**: Monitor pipeline execution with customizable observers\n- **Flexible Storage**: Support for local filesystem and in-memory storage backends\n\n## Installation\n\n```bash\npip install -e .\n```\n\n## Quick Start\n\n```python\nfrom timestack import (\n    Pipeline,\n    PipelineBuilder,\n    IdentityStep,\n    MapStep,\n    LocalStorage,\n    QuarantineObserver,\n    NotNullValidator,\n    FieldTypeValidator\n)\n\n# Define validators\nvalidators = [\n    NotNullValidator(\"user_id\"),\n    FieldTypeValidator(\"age\", int)\n]\n\n# Create a step with validators\nvalidated_step = IdentityStep(name=\"validate\", validators=validators)\n\n# Build the pipeline\npipeline = (\n    PipelineBuilder(\"my_pipeline\")\n    .with_step(validated_step)\n    .with_storage(LocalStorage(\"./output\"))\n    .with_observer(QuarantineObserver())\n    .build()\n)\n\n# Run with mixed data\ndata = [\n    {\"user_id\": 1, \"name\": \"Alice\", \"age\": 30},  # Valid\n    {\"user_id\": None, \"name\": \"Bob\", \"age\": 25}, # Invalid - null user_id\n    {\"user_id\": 2, \"name\": \"Charlie\", \"age\": \"old\"}, # Invalid - wrong type\n]\n\nresult = pipeline.run(data, output_path=\"processed.json\")\n\nprint(f\"Processed: {result['records_processed']}\")\nprint(f\"Quarantined: {result['records_quarantined']}\")\n```\n\n## Data Quality Validators\n\n### Built-in Validators\n\n- **NotNullValidator(field)**: Ensures a field exists and is not None\n- **FieldTypeValidator(field, expected_type)**: Ensures a field has the correct Python type\n\n### Custom Validators\n\nCreate custom validators by extending `DataQualityValidator`:\n\n```python\nfrom timestack import DataQualityValidator\n\nclass RangeValidator(DataQualityValidator):\n    def __init__(self, field: str, min_val: float, max_val: float):\n        self.field = field\n        self.min_val = min_val\n        self.max_val = max_val\n    \n    def validate(self, record: dict) -> tuple[bool, str]:\n        value = record.get(self.field)\n        if value is None:\n            return True, \"\"  # Let NotNullValidator handle this\n        if not (self.min_val <= value <= self.max_val):\n            return False, f\"Field '{self.field}' value {value} not in range [{self.min_val}, {self.max_val}]\"\n        return True, \"\"\n```\n\n## Quarantine System\n\nWhen records fail validation:\n\n1. They are **not** processed by subsequent steps\n2. They are written to a quarantine directory: `<storage_base>/quarantine/<pipeline_name>/<run_id>/`\n3. Each quarantined record is saved as JSON with the original data and error message\n4. Observers are notified via `on_record_quarantined` event\n\n## Observers\n\n- **LoggingObserver**: Logs pipeline events to console/file\n- **QuarantineObserver**: Tracks and logs quarantined records\n- **MetricsObserver**: Collects execution metrics\n\n## Running Tests\n\n```bash\npytest tests/ -v\n```\n\n## Demo\n\n```bash\npython main.py\n```\n\n## Architecture\n\n```\ntimestack/\n\u251c\u2500\u2500 __init__.py      # Package exports\n\u251c\u2500\u2500 pipeline.py      # Pipeline orchestration\n\u251c\u2500\u2500 steps.py         # Processing steps\n\u251c\u2500\u2500 storage.py       # Storage backends\n\u251c\u2500\u2500 observers.py     # Pipeline observers\n\u2514\u2500\u2500 validators.py    # Data quality validators\n```\n\n## License\n\nMIT\n"
          },
          "generated_files": [
            "timestack/validators.py",
            "timestack/steps.py",
            "timestack/storage.py",
            "timestack/observers.py",
            "timestack/pipeline.py",
            "timestack/__init__.py",
            "main.py",
            "tests/test_pipeline.py",
            "README.md"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7566199813258636,
                "dependency_traversal_accuracy": 0.8257582716016394,
                "cross_file_reasoning_depth": 0.4463888888888889,
                "system_thinking_score": 0.3228655316543521,
                "robustness_score": 0.4311288483466363,
                "comprehensiveness_score": 0.7352145442871219,
                "innovation_score": 0.24375000000000002,
                "solution_elegance_score": 0.6037315369374893
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09457749766573295,
                "dependency_traversal_weighted": 0.10321978395020492,
                "cross_file_reasoning_weighted": 0.05579861111111111,
                "system_thinking_weighted": 0.040358191456794014,
                "robustness_weighted": 0.053891106043329536,
                "comprehensiveness_weighted": 0.09190181803589023,
                "innovation_weighted": 0.030468750000000003,
                "solution_elegance_weighted": 0.07546644211718616
              },
              "total_software_engineering_score": 0.545682200380249
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.0,
                "execution_time": 0.6232724189758301,
                "errors": [
                  "  File \"README.py\", line 124",
                  "    \u251c\u2500\u2500 __init__.py      # Package exports",
                  "    ^",
                  "SyntaxError: invalid character '\u251c' (U+251C)",
                  "  File \"main.py\", line 33",
                  "    print(f\"",
                  "          ^",
                  "SyntaxError: unterminated f-string literal (detected at line 33)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "timestack/validators.py",
                  "timestack/steps.py",
                  "timestack/storage.py",
                  "timestack/observers.py",
                  "timestack/pipeline.py",
                  "timestack/__init__.py",
                  "main.py",
                  "tests/test_pipeline.py",
                  "README.md"
                ],
                "scoring_breakdown": {
                  "no_credit": 0.0
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 9,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 9 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.2076713433317207,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.0,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.2076713433317207,
                "idc_weight": 0.2,
                "total_functional_score": 0.35153426866634413
              }
            },
            "code_quality_details": {
              "files_analyzed": 9,
              "quality_checks": {
                "timestack/validators.py": {
                  "line_count": 115,
                  "non_empty_lines": 82,
                  "comment_lines": 1,
                  "comment_ratio": 0.012195121951219513,
                  "function_count": 7,
                  "class_count": 11,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "timestack/steps.py": {
                  "line_count": 162,
                  "non_empty_lines": 123,
                  "comment_lines": 4,
                  "comment_ratio": 0.032520325203252036,
                  "function_count": 13,
                  "class_count": 7,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "timestack/storage.py": {
                  "line_count": 197,
                  "non_empty_lines": 151,
                  "comment_lines": 2,
                  "comment_ratio": 0.013245033112582781,
                  "function_count": 21,
                  "class_count": 4,
                  "import_count": 15,
                  "quality_score": 0.7999999999999999
                },
                "timestack/observers.py": {
                  "line_count": 228,
                  "non_empty_lines": 179,
                  "comment_lines": 1,
                  "comment_ratio": 0.00558659217877095,
                  "function_count": 26,
                  "class_count": 5,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "timestack/pipeline.py": {
                  "line_count": 235,
                  "non_empty_lines": 191,
                  "comment_lines": 10,
                  "comment_ratio": 0.05235602094240838,
                  "function_count": 11,
                  "class_count": 3,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "timestack/__init__.py": {
                  "line_count": 46,
                  "non_empty_lines": 42,
                  "comment_lines": 5,
                  "comment_ratio": 0.11904761904761904,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 10,
                  "quality_score": 0.7
                },
                "main.py": {
                  "line_count": 113,
                  "non_empty_lines": 92,
                  "comment_lines": 8,
                  "comment_ratio": 0.08695652173913043,
                  "function_count": 2,
                  "class_count": 1,
                  "import_count": 2,
                  "quality_score": 0.7999999999999999
                },
                "tests/test_pipeline.py": {
                  "line_count": 523,
                  "non_empty_lines": 418,
                  "comment_lines": 25,
                  "comment_ratio": 0.05980861244019139,
                  "function_count": 26,
                  "class_count": 7,
                  "import_count": 7,
                  "quality_score": 0.6
                },
                "README.md": {
                  "line_count": 135,
                  "non_empty_lines": 100,
                  "comment_lines": 17,
                  "comment_ratio": 0.17,
                  "function_count": 2,
                  "class_count": 1,
                  "import_count": 4,
                  "quality_score": 0.9999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.792222222222222,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8920343137254902,
                "multi_session_memory_retention": 0.8466817496229263
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4460171568627451,
                "multi_session_memory_retention_weighted": 0.42334087481146315
              },
              "total_longcontext_utilization_score": 0.8693580316742082
            }
          },
          "timestamp": "2026-01-14T20:54:12.341419"
        }
      }
    },
    "python_fintech_trading_hard_030_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_fintech_trading_hard_030_feature_implementation_expert_01",
          "scenario_title": "Implement Time-Locked Multi-Signature Escrow Transactions",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5851406898286998,
          "functional_correctness_score": 0.6827097922848665,
          "code_quality_score": 0.7906666666666666,
          "longcontext_utilization_score": 0.8505387931034485,
          "total_score": 3.4102821313030907,
          "generation_time": 254.08326888084412,
          "code_files_generated": 15,
          "total_lines_generated": 2509,
          "parsing_success": true,
          "solution_code": {
            "tradeutility_nexus/trade_nexus/core/domain.py": "\"\"\"Domain models and aggregates for TradeUtility Nexus.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Set\nfrom uuid import UUID, uuid4\n\n\nclass TransactionStatus(Enum):\n    \"\"\"Status of a transaction.\"\"\"\n    PENDING = \"PENDING\"\n    PROCESSING = \"PROCESSING\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    CANCELLED = \"CANCELLED\"\n\n\nclass EscrowStatus(Enum):\n    \"\"\"Status of an escrow transaction.\"\"\"\n    PENDING = \"PENDING\"\n    FUNDED = \"FUNDED\"\n    AWAITING_RELEASE = \"AWAITING_RELEASE\"\n    RELEASED = \"RELEASED\"\n    CANCELLED = \"CANCELLED\"\n\n\n@dataclass\nclass DomainEvent:\n    \"\"\"Base class for domain events.\"\"\"\n    event_id: UUID = field(default_factory=uuid4)\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    aggregate_id: Optional[UUID] = None\n    version: int = 0\n\n\n@dataclass\nclass Aggregate:\n    \"\"\"Base class for aggregates.\"\"\"\n    id: UUID = field(default_factory=uuid4)\n    version: int = 0\n    _pending_events: List[DomainEvent] = field(default_factory=list, repr=False)\n\n    def apply_event(self, event: DomainEvent) -> None:\n        \"\"\"Apply an event to update aggregate state.\"\"\"\n        handler_name = f\"_apply_{type(event).__name__}\"\n        handler = getattr(self, handler_name, None)\n        if handler:\n            handler(event)\n        self.version += 1\n\n    def add_event(self, event: DomainEvent) -> None:\n        \"\"\"Add a new event to pending events.\"\"\"\n        event.aggregate_id = self.id\n        event.version = self.version + 1\n        self._pending_events.append(event)\n        self.apply_event(event)\n\n    def get_pending_events(self) -> List[DomainEvent]:\n        \"\"\"Get all pending events.\"\"\"\n        return self._pending_events.copy()\n\n    def clear_pending_events(self) -> None:\n        \"\"\"Clear pending events after persistence.\"\"\"\n        self._pending_events.clear()\n\n\n@dataclass\nclass Transaction(Aggregate):\n    \"\"\"Transaction aggregate representing a trade transaction.\"\"\"\n    sender_id: Optional[UUID] = None\n    receiver_id: Optional[UUID] = None\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    status: TransactionStatus = TransactionStatus.PENDING\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n\n    def initiate(self, sender_id: UUID, receiver_id: UUID, amount: Decimal, currency: str) -> None:\n        \"\"\"Initiate a new transaction.\"\"\"\n        from trade_nexus.core.events import TransactionInitiated\n        event = TransactionInitiated(\n            transaction_id=self.id,\n            sender_id=sender_id,\n            receiver_id=receiver_id,\n            amount=amount,\n            currency=currency\n        )\n        self.add_event(event)\n\n    def complete(self) -> None:\n        \"\"\"Mark transaction as completed.\"\"\"\n        from trade_nexus.core.events import TransactionCompleted\n        event = TransactionCompleted(transaction_id=self.id)\n        self.add_event(event)\n\n    def fail(self, reason: str) -> None:\n        \"\"\"Mark transaction as failed.\"\"\"\n        from trade_nexus.core.events import TransactionFailed\n        event = TransactionFailed(transaction_id=self.id, reason=reason)\n        self.add_event(event)\n\n    def _apply_TransactionInitiated(self, event: Any) -> None:\n        \"\"\"Apply TransactionInitiated event.\"\"\"\n        self.sender_id = event.sender_id\n        self.receiver_id = event.receiver_id\n        self.amount = event.amount\n        self.currency = event.currency\n        self.status = TransactionStatus.PROCESSING\n        self.updated_at = event.timestamp\n\n    def _apply_TransactionCompleted(self, event: Any) -> None:\n        \"\"\"Apply TransactionCompleted event.\"\"\"\n        self.status = TransactionStatus.COMPLETED\n        self.updated_at = event.timestamp\n\n    def _apply_TransactionFailed(self, event: Any) -> None:\n        \"\"\"Apply TransactionFailed event.\"\"\"\n        self.status = TransactionStatus.FAILED\n        self.updated_at = event.timestamp\n\n\n@dataclass\nclass EscrowTransaction(Aggregate):\n    \"\"\"Escrow transaction aggregate for time-locked multi-signature transactions.\"\"\"\n    initiator_id: Optional[UUID] = None\n    counterparty_id: Optional[UUID] = None\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    status: EscrowStatus = EscrowStatus.PENDING\n    lock_until_timestamp: Optional[datetime] = None\n    release_signatures: Set[str] = field(default_factory=set)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n\n    def initiate(\n        self,\n        initiator_id: UUID,\n        counterparty_id: UUID,\n        amount: Decimal,\n        currency: str,\n        lock_until_timestamp: datetime,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> None:\n        \"\"\"Initiate a new escrow transaction.\"\"\"\n        from trade_nexus.core.events import EscrowInitiated\n        event = EscrowInitiated(\n            escrow_id=self.id,\n            initiator_id=initiator_id,\n            counterparty_id=counterparty_id,\n            amount=amount,\n            currency=currency,\n            lock_until_timestamp=lock_until_timestamp,\n            metadata=metadata or {}\n        )\n        self.add_event(event)\n\n    def fund(self) -> None:\n        \"\"\"Fund the escrow transaction.\"\"\"\n        if self.status != EscrowStatus.PENDING:\n            raise ValueError(f\"Cannot fund escrow in status {self.status}\")\n        from trade_nexus.core.events import EscrowFunded\n        event = EscrowFunded(\n            escrow_id=self.id,\n            amount=self.amount,\n            currency=self.currency\n        )\n        self.add_event(event)\n\n    def add_release_signature(self, signer_id: UUID, signature: str) -> None:\n        \"\"\"Add a release signature from a participant.\"\"\"\n        if self.status not in (EscrowStatus.FUNDED, EscrowStatus.AWAITING_RELEASE):\n            raise ValueError(f\"Cannot add signature in status {self.status}\")\n        \n        if signer_id not in (self.initiator_id, self.counterparty_id):\n            raise ValueError(\"Signer must be initiator or counterparty\")\n        \n        signer_key = f\"{signer_id}:{signature}\"\n        if any(s.startswith(str(signer_id)) for s in self.release_signatures):\n            raise ValueError(\"Signer has already provided a signature\")\n        \n        from trade_nexus.core.events import ReleaseSignatureAdded\n        event = ReleaseSignatureAdded(\n            escrow_id=self.id,\n            signer_id=signer_id,\n            signature=signature\n        )\n        self.add_event(event)\n\n    def release(self) -> None:\n        \"\"\"Release the escrow funds.\"\"\"\n        if self.status != EscrowStatus.AWAITING_RELEASE:\n            raise ValueError(f\"Cannot release escrow in status {self.status}\")\n        \n        if not self.has_all_signatures():\n            raise ValueError(\"Not all required signatures collected\")\n        \n        if not self.is_lock_expired():\n            raise ValueError(\"Lock period has not expired\")\n        \n        from trade_nexus.core.events import EscrowReleased\n        event = EscrowReleased(\n            escrow_id=self.id,\n            initiator_id=self.initiator_id,\n            counterparty_id=self.counterparty_id,\n            amount=self.amount,\n            currency=self.currency\n        )\n        self.add_event(event)\n\n    def cancel(self, reason: str) -> None:\n        \"\"\"Cancel the escrow transaction.\"\"\"\n        if self.status in (EscrowStatus.RELEASED, EscrowStatus.CANCELLED):\n            raise ValueError(f\"Cannot cancel escrow in status {self.status}\")\n        \n        from trade_nexus.core.events import EscrowCancelled\n        event = EscrowCancelled(\n            escrow_id=self.id,\n            reason=reason\n        )\n        self.add_event(event)\n\n    def has_all_signatures(self) -> bool:\n        \"\"\"Check if all required signatures have been collected.\"\"\"\n        initiator_signed = any(\n            s.startswith(str(self.initiator_id)) for s in self.release_signatures\n        )\n        counterparty_signed = any(\n            s.startswith(str(self.counterparty_id)) for s in self.release_signatures\n        )\n        return initiator_signed and counterparty_signed\n\n    def is_lock_expired(self) -> bool:\n        \"\"\"Check if the time lock has expired.\"\"\"\n        if self.lock_until_timestamp is None:\n            return False\n        return datetime.utcnow() >= self.lock_until_timestamp\n\n    def _apply_EscrowInitiated(self, event: Any) -> None:\n        \"\"\"Apply EscrowInitiated event.\"\"\"\n        self.initiator_id = event.initiator_id\n        self.counterparty_id = event.counterparty_id\n        self.amount = event.amount\n        self.currency = event.currency\n        self.lock_until_timestamp = event.lock_until_timestamp\n        self.metadata = event.metadata\n        self.status = EscrowStatus.PENDING\n        self.updated_at = event.timestamp\n\n    def _apply_EscrowFunded(self, event: Any) -> None:\n        \"\"\"Apply EscrowFunded event.\"\"\"\n        self.status = EscrowStatus.FUNDED\n        self.updated_at = event.timestamp\n\n    def _apply_ReleaseSignatureAdded(self, event: Any) -> None:\n        \"\"\"Apply ReleaseSignatureAdded event.\"\"\"\n        signer_key = f\"{event.signer_id}:{event.signature}\"\n        self.release_signatures.add(signer_key)\n        if self.has_all_signatures():\n            self.status = EscrowStatus.AWAITING_RELEASE\n        self.updated_at = event.timestamp\n\n    def _apply_EscrowReleased(self, event: Any) -> None:\n        \"\"\"Apply EscrowReleased event.\"\"\"\n        self.status = EscrowStatus.RELEASED\n        self.updated_at = event.timestamp\n\n    def _apply_EscrowCancelled(self, event: Any) -> None:\n        \"\"\"Apply EscrowCancelled event.\"\"\"\n        self.status = EscrowStatus.CANCELLED\n        self.updated_at = event.timestamp\n\n\n@dataclass\nclass User(Aggregate):\n    \"\"\"User aggregate.\"\"\"\n    email: str = \"\"\n    name: str = \"\"\n    kyc_verified: bool = False\n    risk_score: float = 0.0\n    created_at: datetime = field(default_factory=datetime.utcnow)\n",
            "tradeutility_nexus/trade_nexus/core/commands.py": "\"\"\"Command definitions for CQRS pattern.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, Optional\nfrom uuid import UUID, uuid4\n\n\n@dataclass\nclass Command:\n    \"\"\"Base class for commands.\"\"\"\n    command_id: UUID = field(default_factory=uuid4)\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    correlation_id: Optional[UUID] = None\n\n\n@dataclass\nclass InitiateTransaction(Command):\n    \"\"\"Command to initiate a new transaction.\"\"\"\n    sender_id: UUID = field(default_factory=uuid4)\n    receiver_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass CompleteTransaction(Command):\n    \"\"\"Command to complete a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass FailTransaction(Command):\n    \"\"\"Command to fail a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass ProcessPayment(Command):\n    \"\"\"Command to process a payment.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    payment_method: str = \"CARD\"\n\n\n@dataclass\nclass VerifyKYC(Command):\n    \"\"\"Command to verify KYC for a user.\"\"\"\n    user_id: UUID = field(default_factory=uuid4)\n    document_type: str = \"\"\n    document_id: str = \"\"\n\n\n@dataclass\nclass AssessRisk(Command):\n    \"\"\"Command to assess risk for a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    user_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n\n\n@dataclass\nclass SettleTransaction(Command):\n    \"\"\"Command to settle a transaction.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n\n\n# Escrow Commands\n\n@dataclass\nclass InitiateEscrow(Command):\n    \"\"\"Command to initiate a new escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    initiator_id: UUID = field(default_factory=uuid4)\n    counterparty_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    lock_until_timestamp: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass FundEscrow(Command):\n    \"\"\"Command to fund an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass AddReleaseSignature(Command):\n    \"\"\"Command to add a release signature to an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    signer_id: UUID = field(default_factory=uuid4)\n    signature: str = \"\"\n\n\n@dataclass\nclass ProcessEscrowRelease(Command):\n    \"\"\"Command to process the release of an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass CancelEscrow(Command):\n    \"\"\"Command to cancel an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n",
            "tradeutility_nexus/trade_nexus/core/events.py": "\"\"\"Event definitions for Event Sourcing pattern.\"\"\"\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, Optional\nfrom uuid import UUID, uuid4\n\n\n@dataclass\nclass Event:\n    \"\"\"Base class for events.\"\"\"\n    event_id: UUID = field(default_factory=uuid4)\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    aggregate_id: Optional[UUID] = None\n    version: int = 0\n    correlation_id: Optional[UUID] = None\n\n\n@dataclass\nclass TransactionInitiated(Event):\n    \"\"\"Event when a transaction is initiated.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    sender_id: UUID = field(default_factory=uuid4)\n    receiver_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n\n\n@dataclass\nclass TransactionCompleted(Event):\n    \"\"\"Event when a transaction is completed.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n\n\n@dataclass\nclass TransactionFailed(Event):\n    \"\"\"Event when a transaction fails.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass PaymentProcessed(Event):\n    \"\"\"Event when a payment is processed.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    payment_reference: str = \"\"\n\n\n@dataclass\nclass PaymentFailed(Event):\n    \"\"\"Event when a payment fails.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass KYCVerified(Event):\n    \"\"\"Event when KYC is verified.\"\"\"\n    user_id: UUID = field(default_factory=uuid4)\n    verification_level: str = \"BASIC\"\n\n\n@dataclass\nclass KYCFailed(Event):\n    \"\"\"Event when KYC verification fails.\"\"\"\n    user_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n\n\n@dataclass\nclass RiskAssessed(Event):\n    \"\"\"Event when risk is assessed.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    risk_score: float = 0.0\n    risk_level: str = \"LOW\"\n\n\n@dataclass\nclass TransactionSettled(Event):\n    \"\"\"Event when a transaction is settled.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    settlement_reference: str = \"\"\n\n\n@dataclass\nclass FraudDetected(Event):\n    \"\"\"Event when fraud is detected.\"\"\"\n    transaction_id: UUID = field(default_factory=uuid4)\n    fraud_type: str = \"\"\n    confidence: float = 0.0\n\n\n# Escrow Events\n\n@dataclass\nclass EscrowInitiated(Event):\n    \"\"\"Event when an escrow transaction is initiated.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    initiator_id: UUID = field(default_factory=uuid4)\n    counterparty_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n    lock_until_timestamp: datetime = field(default_factory=datetime.utcnow)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass EscrowFunded(Event):\n    \"\"\"Event when an escrow transaction is funded.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n\n\n@dataclass\nclass ReleaseSignatureAdded(Event):\n    \"\"\"Event when a release signature is added to an escrow transaction.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    signer_id: UUID = field(default_factory=uuid4)\n    signature: str = \"\"\n\n\n@dataclass\nclass EscrowReleased(Event):\n    \"\"\"Event when an escrow transaction is released.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    initiator_id: Optional[UUID] = None\n    counterparty_id: Optional[UUID] = None\n    amount: Decimal = Decimal(\"0\")\n    currency: str = \"USD\"\n\n\n@dataclass\nclass EscrowCancelled(Event):\n    \"\"\"Event when an escrow transaction is cancelled.\"\"\"\n    escrow_id: UUID = field(default_factory=uuid4)\n    reason: str = \"\"\n",
            "tradeutility_nexus/trade_nexus/api/schemas.py": "\"\"\"Pydantic schemas for API validation.\"\"\"\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom typing import Any, Dict, List, Optional, Set\nfrom uuid import UUID\n\nfrom pydantic import BaseModel, Field, validator\n\n\nclass TransactionRequest(BaseModel):\n    \"\"\"Request schema for creating a transaction.\"\"\"\n    sender_id: UUID\n    receiver_id: UUID\n    amount: Decimal = Field(gt=0)\n    currency: str = Field(default=\"USD\", min_length=3, max_length=3)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"sender_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"receiver_id\": \"123e4567-e89b-12d3-a456-426614174001\",\n                \"amount\": \"100.00\",\n                \"currency\": \"USD\",\n                \"metadata\": {\"note\": \"Payment for services\"}\n            }\n        }\n\n\nclass TransactionResponse(BaseModel):\n    \"\"\"Response schema for transaction.\"\"\"\n    id: UUID\n    sender_id: UUID\n    receiver_id: UUID\n    amount: Decimal\n    currency: str\n    status: str\n    created_at: datetime\n    updated_at: datetime\n\n\nclass PaymentRequest(BaseModel):\n    \"\"\"Request schema for processing a payment.\"\"\"\n    transaction_id: UUID\n    payment_method: str = Field(default=\"CARD\")\n    payment_details: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass PaymentResponse(BaseModel):\n    \"\"\"Response schema for payment.\"\"\"\n    transaction_id: UUID\n    status: str\n    payment_reference: Optional[str] = None\n    processed_at: datetime\n\n\nclass KYCVerificationRequest(BaseModel):\n    \"\"\"Request schema for KYC verification.\"\"\"\n    user_id: UUID\n    document_type: str\n    document_id: str\n    additional_info: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass KYCVerificationResponse(BaseModel):\n    \"\"\"Response schema for KYC verification.\"\"\"\n    user_id: UUID\n    status: str\n    verification_level: Optional[str] = None\n    verified_at: Optional[datetime] = None\n\n\nclass RiskAssessmentRequest(BaseModel):\n    \"\"\"Request schema for risk assessment.\"\"\"\n    transaction_id: UUID\n    user_id: UUID\n    amount: Decimal\n\n\nclass RiskAssessmentResponse(BaseModel):\n    \"\"\"Response schema for risk assessment.\"\"\"\n    transaction_id: UUID\n    risk_score: float\n    risk_level: str\n    assessed_at: datetime\n\n\nclass HealthResponse(BaseModel):\n    \"\"\"Response schema for health check.\"\"\"\n    status: str\n    version: str\n    timestamp: datetime\n\n\nclass ErrorResponse(BaseModel):\n    \"\"\"Response schema for errors.\"\"\"\n    error: str\n    detail: Optional[str] = None\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n\n\n# Escrow Schemas\n\nclass EscrowInitiationRequest(BaseModel):\n    \"\"\"Request schema for initiating an escrow transaction.\"\"\"\n    initiator_id: UUID\n    counterparty_id: UUID\n    amount: Decimal = Field(gt=0)\n    currency: str = Field(default=\"USD\", min_length=3, max_length=3)\n    lock_duration_seconds: int = Field(gt=0, description=\"Duration in seconds for the time lock\")\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n    @validator(\"counterparty_id\")\n    def counterparty_must_differ_from_initiator(cls, v, values):\n        if \"initiator_id\" in values and v == values[\"initiator_id\"]:\n            raise ValueError(\"Counterparty must be different from initiator\")\n        return v\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"initiator_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"counterparty_id\": \"123e4567-e89b-12d3-a456-426614174001\",\n                \"amount\": \"1000.00\",\n                \"currency\": \"USD\",\n                \"lock_duration_seconds\": 86400,\n                \"metadata\": {\"description\": \"Escrow for property sale\"}\n            }\n        }\n\n\nclass EscrowSignatureRequest(BaseModel):\n    \"\"\"Request schema for submitting a release signature.\"\"\"\n    signer_id: UUID\n    signature: str = Field(min_length=1, description=\"Cryptographic signature for release authorization\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"signer_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"signature\": \"0x1234567890abcdef...\"\n            }\n        }\n\n\nclass EscrowResponse(BaseModel):\n    \"\"\"Response schema for escrow transaction.\"\"\"\n    id: UUID\n    initiator_id: UUID\n    counterparty_id: UUID\n    amount: Decimal\n    currency: str\n    status: str\n    lock_until_timestamp: datetime\n    signatures_collected: int\n    signatures_required: int = 2\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"id\": \"123e4567-e89b-12d3-a456-426614174002\",\n                \"initiator_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n                \"counterparty_id\": \"123e4567-e89b-12d3-a456-426614174001\",\n                \"amount\": \"1000.00\",\n                \"currency\": \"USD\",\n                \"status\": \"FUNDED\",\n                \"lock_until_timestamp\": \"2024-01-15T12:00:00Z\",\n                \"signatures_collected\": 1,\n                \"signatures_required\": 2,\n                \"created_at\": \"2024-01-14T12:00:00Z\",\n                \"updated_at\": \"2024-01-14T12:05:00Z\"\n            }\n        }\n\n\nclass EscrowFundRequest(BaseModel):\n    \"\"\"Request schema for funding an escrow (placeholder for future payment integration).\"\"\"\n    funding_source: Optional[str] = Field(default=\"WALLET\", description=\"Source of funds\")\n    reference: Optional[str] = Field(default=None, description=\"External payment reference\")\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"funding_source\": \"WALLET\",\n                \"reference\": \"PAY-123456\"\n            }\n        }\n\n\nclass EscrowListResponse(BaseModel):\n    \"\"\"Response schema for listing escrow transactions.\"\"\"\n    escrows: List[EscrowResponse]\n    total: int\n    page: int = 1\n    page_size: int = 10\n",
            "tradeutility_nexus/trade_nexus/api/endpoints.py": "\"\"\"API endpoints for TradeUtility Nexus.\"\"\"\nimport logging\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nfrom typing import Optional\nfrom uuid import UUID, uuid4\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\n\nfrom trade_nexus.api.schemas import (\n    ErrorResponse,\n    EscrowFundRequest,\n    EscrowInitiationRequest,\n    EscrowResponse,\n    EscrowSignatureRequest,\n    HealthResponse,\n    KYCVerificationRequest,\n    KYCVerificationResponse,\n    PaymentRequest,\n    PaymentResponse,\n    RiskAssessmentRequest,\n    RiskAssessmentResponse,\n    TransactionRequest,\n    TransactionResponse,\n)\nfrom trade_nexus.core.bus import CommandBus, EventBus\nfrom trade_nexus.core.commands import (\n    AddReleaseSignature,\n    AssessRisk,\n    FundEscrow,\n    InitiateEscrow,\n    InitiateTransaction,\n    ProcessPayment,\n    VerifyKYC,\n)\nfrom trade_nexus.core.domain import EscrowStatus, EscrowTransaction, Transaction, TransactionStatus\nfrom trade_nexus.core.unit_of_work import UnitOfWork\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n# In-memory stores for demonstration\n_transactions: dict[UUID, Transaction] = {}\n_escrows: dict[UUID, EscrowTransaction] = {}\n\n# Global bus instances (would be injected via DI in production)\n_command_bus: Optional[CommandBus] = None\n_event_bus: Optional[EventBus] = None\n\n\ndef get_command_bus() -> CommandBus:\n    \"\"\"Get or create command bus.\"\"\"\n    global _command_bus\n    if _command_bus is None:\n        _command_bus = CommandBus()\n    return _command_bus\n\n\ndef get_event_bus() -> EventBus:\n    \"\"\"Get or create event bus.\"\"\"\n    global _event_bus\n    if _event_bus is None:\n        _event_bus = EventBus()\n    return _event_bus\n\n\ndef set_command_bus(bus: CommandBus) -> None:\n    \"\"\"Set the command bus (for testing/initialization).\"\"\"\n    global _command_bus\n    _command_bus = bus\n\n\ndef set_event_bus(bus: EventBus) -> None:\n    \"\"\"Set the event bus (for testing/initialization).\"\"\"\n    global _event_bus\n    _event_bus = bus\n\n\ndef get_escrow_store() -> dict[UUID, EscrowTransaction]:\n    \"\"\"Get the escrow store.\"\"\"\n    return _escrows\n\n\n@router.get(\"/health\", response_model=HealthResponse)\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return HealthResponse(\n        status=\"healthy\",\n        version=\"1.0.0\",\n        timestamp=datetime.utcnow()\n    )\n\n\n@router.post(\"/v1/transactions\", response_model=TransactionResponse, status_code=status.HTTP_201_CREATED)\nasync def create_transaction(\n    request: TransactionRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Create a new transaction.\"\"\"\n    try:\n        transaction_id = uuid4()\n        command = InitiateTransaction(\n            correlation_id=transaction_id,\n            sender_id=request.sender_id,\n            receiver_id=request.receiver_id,\n            amount=request.amount,\n            currency=request.currency,\n            metadata=request.metadata\n        )\n        \n        # Create transaction aggregate\n        transaction = Transaction(id=transaction_id)\n        transaction.initiate(\n            sender_id=request.sender_id,\n            receiver_id=request.receiver_id,\n            amount=request.amount,\n            currency=request.currency\n        )\n        \n        # Store transaction\n        _transactions[transaction_id] = transaction\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        return TransactionResponse(\n            id=transaction.id,\n            sender_id=transaction.sender_id,\n            receiver_id=transaction.receiver_id,\n            amount=transaction.amount,\n            currency=transaction.currency,\n            status=transaction.status.value,\n            created_at=transaction.created_at,\n            updated_at=transaction.updated_at\n        )\n    except Exception as e:\n        logger.error(f\"Error creating transaction: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.get(\"/v1/transactions/{transaction_id}\", response_model=TransactionResponse)\nasync def get_transaction(transaction_id: UUID):\n    \"\"\"Get transaction by ID.\"\"\"\n    transaction = _transactions.get(transaction_id)\n    if not transaction:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Transaction {transaction_id} not found\"\n        )\n    \n    return TransactionResponse(\n        id=transaction.id,\n        sender_id=transaction.sender_id,\n        receiver_id=transaction.receiver_id,\n        amount=transaction.amount,\n        currency=transaction.currency,\n        status=transaction.status.value,\n        created_at=transaction.created_at,\n        updated_at=transaction.updated_at\n    )\n\n\n@router.post(\"/v1/payments\", response_model=PaymentResponse)\nasync def process_payment(\n    request: PaymentRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Process a payment.\"\"\"\n    try:\n        transaction = _transactions.get(request.transaction_id)\n        if not transaction:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=f\"Transaction {request.transaction_id} not found\"\n            )\n        \n        command = ProcessPayment(\n            transaction_id=request.transaction_id,\n            amount=transaction.amount,\n            currency=transaction.currency,\n            payment_method=request.payment_method\n        )\n        \n        await command_bus.dispatch(command)\n        \n        return PaymentResponse(\n            transaction_id=request.transaction_id,\n            status=\"PROCESSED\",\n            payment_reference=f\"PAY-{uuid4().hex[:8].upper()}\",\n            processed_at=datetime.utcnow()\n        )\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Error processing payment: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/kyc/verify\", response_model=KYCVerificationResponse)\nasync def verify_kyc(\n    request: KYCVerificationRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Verify KYC for a user.\"\"\"\n    try:\n        command = VerifyKYC(\n            user_id=request.user_id,\n            document_type=request.document_type,\n            document_id=request.document_id\n        )\n        \n        await command_bus.dispatch(command)\n        \n        return KYCVerificationResponse(\n            user_id=request.user_id,\n            status=\"VERIFIED\",\n            verification_level=\"BASIC\",\n            verified_at=datetime.utcnow()\n        )\n    except Exception as e:\n        logger.error(f\"Error verifying KYC: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/risk/assess\", response_model=RiskAssessmentResponse)\nasync def assess_risk(\n    request: RiskAssessmentRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Assess risk for a transaction.\"\"\"\n    try:\n        command = AssessRisk(\n            transaction_id=request.transaction_id,\n            user_id=request.user_id,\n            amount=request.amount\n        )\n        \n        await command_bus.dispatch(command)\n        \n        # Simple risk calculation for demo\n        risk_score = min(float(request.amount) / 10000, 1.0)\n        risk_level = \"LOW\" if risk_score < 0.3 else \"MEDIUM\" if risk_score < 0.7 else \"HIGH\"\n        \n        return RiskAssessmentResponse(\n            transaction_id=request.transaction_id,\n            risk_score=risk_score,\n            risk_level=risk_level,\n            assessed_at=datetime.utcnow()\n        )\n    except Exception as e:\n        logger.error(f\"Error assessing risk: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n# Escrow Endpoints\n\n@router.post(\"/v1/escrow/initiate\", response_model=EscrowResponse, status_code=status.HTTP_201_CREATED)\nasync def initiate_escrow(\n    request: EscrowInitiationRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Initiate a new escrow transaction.\"\"\"\n    try:\n        escrow_id = uuid4()\n        lock_until = datetime.utcnow() + timedelta(seconds=request.lock_duration_seconds)\n        \n        command = InitiateEscrow(\n            escrow_id=escrow_id,\n            initiator_id=request.initiator_id,\n            counterparty_id=request.counterparty_id,\n            amount=request.amount,\n            currency=request.currency,\n            lock_until_timestamp=lock_until,\n            metadata=request.metadata\n        )\n        \n        # Create escrow aggregate\n        escrow = EscrowTransaction(id=escrow_id)\n        escrow.initiate(\n            initiator_id=request.initiator_id,\n            counterparty_id=request.counterparty_id,\n            amount=request.amount,\n            currency=request.currency,\n            lock_until_timestamp=lock_until,\n            metadata=request.metadata\n        )\n        \n        # Store escrow\n        _escrows[escrow_id] = escrow\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        logger.info(f\"Escrow {escrow_id} initiated successfully\")\n        \n        return EscrowResponse(\n            id=escrow.id,\n            initiator_id=escrow.initiator_id,\n            counterparty_id=escrow.counterparty_id,\n            amount=escrow.amount,\n            currency=escrow.currency,\n            status=escrow.status.value,\n            lock_until_timestamp=escrow.lock_until_timestamp,\n            signatures_collected=len(escrow.release_signatures),\n            signatures_required=2,\n            created_at=escrow.created_at,\n            updated_at=escrow.updated_at\n        )\n    except ValueError as e:\n        logger.warning(f\"Validation error initiating escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Error initiating escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/escrow/{escrow_id}/fund\", response_model=EscrowResponse)\nasync def fund_escrow(\n    escrow_id: UUID,\n    request: EscrowFundRequest = None,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Fund an escrow transaction.\"\"\"\n    try:\n        escrow = _escrows.get(escrow_id)\n        if not escrow:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=f\"Escrow {escrow_id} not found\"\n            )\n        \n        if escrow.status != EscrowStatus.PENDING:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=f\"Escrow cannot be funded in status {escrow.status.value}\"\n            )\n        \n        command = FundEscrow(escrow_id=escrow_id)\n        \n        # Fund the escrow\n        escrow.fund()\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        logger.info(f\"Escrow {escrow_id} funded successfully\")\n        \n        return EscrowResponse(\n            id=escrow.id,\n            initiator_id=escrow.initiator_id,\n            counterparty_id=escrow.counterparty_id,\n            amount=escrow.amount,\n            currency=escrow.currency,\n            status=escrow.status.value,\n            lock_until_timestamp=escrow.lock_until_timestamp,\n            signatures_collected=len(escrow.release_signatures),\n            signatures_required=2,\n            created_at=escrow.created_at,\n            updated_at=escrow.updated_at\n        )\n    except HTTPException:\n        raise\n    except ValueError as e:\n        logger.warning(f\"Validation error funding escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Error funding escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.post(\"/v1/escrow/{escrow_id}/sign_release\", response_model=EscrowResponse)\nasync def sign_escrow_release(\n    escrow_id: UUID,\n    request: EscrowSignatureRequest,\n    command_bus: CommandBus = Depends(get_command_bus)\n):\n    \"\"\"Add a release signature to an escrow transaction.\"\"\"\n    try:\n        escrow = _escrows.get(escrow_id)\n        if not escrow:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=f\"Escrow {escrow_id} not found\"\n            )\n        \n        if escrow.status not in (EscrowStatus.FUNDED, EscrowStatus.AWAITING_RELEASE):\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=f\"Cannot sign escrow in status {escrow.status.value}\"\n            )\n        \n        if request.signer_id not in (escrow.initiator_id, escrow.counterparty_id):\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=\"Signer must be initiator or counterparty\"\n            )\n        \n        command = AddReleaseSignature(\n            escrow_id=escrow_id,\n            signer_id=request.signer_id,\n            signature=request.signature\n        )\n        \n        # Add signature\n        escrow.add_release_signature(request.signer_id, request.signature)\n        \n        # Dispatch command\n        await command_bus.dispatch(command)\n        \n        logger.info(f\"Signature added to escrow {escrow_id} by {request.signer_id}\")\n        \n        return EscrowResponse(\n            id=escrow.id,\n            initiator_id=escrow.initiator_id,\n            counterparty_id=escrow.counterparty_id,\n            amount=escrow.amount,\n            currency=escrow.currency,\n            status=escrow.status.value,\n            lock_until_timestamp=escrow.lock_until_timestamp,\n            signatures_collected=len(escrow.release_signatures),\n            signatures_required=2,\n            created_at=escrow.created_at,\n            updated_at=escrow.updated_at\n        )\n    except HTTPException:\n        raise\n    except ValueError as e:\n        logger.warning(f\"Validation error signing escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=str(e)\n        )\n    except Exception as e:\n        logger.error(f\"Error signing escrow: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n\n@router.get(\"/v1/escrow/{escrow_id}\", response_model=EscrowResponse)\nasync def get_escrow(escrow_id: UUID):\n    \"\"\"Get escrow transaction by ID.\"\"\"\n    escrow = _escrows.get(escrow_id)\n    if not escrow:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Escrow {escrow_id} not found\"\n        )\n    \n    return EscrowResponse(\n        id=escrow.id,\n        initiator_id=escrow.initiator_id,\n        counterparty_id=escrow.counterparty_id,\n        amount=escrow.amount,\n        currency=escrow.currency,\n        status=escrow.status.value,\n        lock_until_timestamp=escrow.lock_until_timestamp,\n        signatures_collected=len(escrow.release_signatures),\n        signatures_required=2,\n        created_at=escrow.created_at,\n        updated_at=escrow.updated_at\n    )\n",
            "tradeutility_nexus/trade_nexus/services/transactions/handlers.py": "\"\"\"Transaction service command handlers.\"\"\"\nimport logging\nfrom datetime import datetime\nfrom typing import Callable, Dict, Type\nfrom uuid import UUID\n\nfrom trade_nexus.core.commands import (\n    AddReleaseSignature,\n    Command,\n    CompleteTransaction,\n    FailTransaction,\n    FundEscrow,\n    InitiateEscrow,\n    InitiateTransaction,\n    ProcessEscrowRelease,\n)\nfrom trade_nexus.core.domain import EscrowTransaction, Transaction\nfrom trade_nexus.core.events import (\n    EscrowFunded,\n    EscrowInitiated,\n    EscrowReleased,\n    Event,\n    ReleaseSignatureAdded,\n    TransactionCompleted,\n    TransactionFailed,\n    TransactionInitiated,\n)\nfrom trade_nexus.core.unit_of_work import UnitOfWork\n\nlogger = logging.getLogger(__name__)\n\n\nclass TransactionCommandHandler:\n    \"\"\"Handler for transaction-related commands.\"\"\"\n\n    def __init__(self, unit_of_work: UnitOfWork = None):\n        \"\"\"Initialize the handler.\"\"\"\n        self.unit_of_work = unit_of_work or UnitOfWork()\n        self._handlers: Dict[Type[Command], Callable] = {\n            InitiateTransaction: self._handle_initiate_transaction,\n            CompleteTransaction: self._handle_complete_transaction,\n            FailTransaction: self._handle_fail_transaction,\n            InitiateEscrow: self._handle_initiate_escrow,\n            FundEscrow: self._handle_fund_escrow,\n            AddReleaseSignature: self._handle_add_release_signature,\n            ProcessEscrowRelease: self._handle_process_escrow_release,\n        }\n\n    async def handle(self, command: Command) -> None:\n        \"\"\"Handle a command.\"\"\"\n        handler = self._handlers.get(type(command))\n        if handler:\n            await handler(command)\n        else:\n            logger.warning(f\"No handler found for command type: {type(command).__name__}\")\n\n    async def _handle_initiate_transaction(self, command: InitiateTransaction) -> None:\n        \"\"\"Handle InitiateTransaction command.\"\"\"\n        logger.info(f\"Handling InitiateTransaction command: {command.command_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Create new transaction aggregate\n            transaction = Transaction()\n            transaction.initiate(\n                sender_id=command.sender_id,\n                receiver_id=command.receiver_id,\n                amount=command.amount,\n                currency=command.currency\n            )\n            \n            # Save events through unit of work\n            for event in transaction.get_pending_events():\n                await uow.event_store.append(event)\n            \n            transaction.clear_pending_events()\n            \n            logger.info(f\"Transaction {transaction.id} initiated successfully\")\n\n    async def _handle_complete_transaction(self, command: CompleteTransaction) -> None:\n        \"\"\"Handle CompleteTransaction command.\"\"\"\n        logger.info(f\"Handling CompleteTransaction command for: {command.transaction_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load transaction from event store\n            events = await uow.event_store.get_events(command.transaction_id)\n            \n            if not events:\n                logger.error(f\"Transaction {command.transaction_id} not found\")\n                return\n            \n            # Rebuild transaction state\n            transaction = Transaction(id=command.transaction_id)\n            for event in events:\n                transaction.apply_event(event)\n            \n            # Complete the transaction\n            transaction.complete()\n            \n            # Save new events\n            for event in transaction.get_pending_events():\n                await uow.event_store.append(event)\n            \n            transaction.clear_pending_events()\n            \n            logger.info(f\"Transaction {command.transaction_id} completed successfully\")\n\n    async def _handle_fail_transaction(self, command: FailTransaction) -> None:\n        \"\"\"Handle FailTransaction command.\"\"\"\n        logger.info(f\"Handling FailTransaction command for: {command.transaction_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load transaction from event store\n            events = await uow.event_store.get_events(command.transaction_id)\n            \n            if not events:\n                logger.error(f\"Transaction {command.transaction_id} not found\")\n                return\n            \n            # Rebuild transaction state\n            transaction = Transaction(id=command.transaction_id)\n            for event in events:\n                transaction.apply_event(event)\n            \n            # Fail the transaction\n            transaction.fail(command.reason)\n            \n            # Save new events\n            for event in transaction.get_pending_events():\n                await uow.event_store.append(event)\n            \n            transaction.clear_pending_events()\n            \n            logger.info(f\"Transaction {command.transaction_id} marked as failed\")\n\n    async def _handle_initiate_escrow(self, command: InitiateEscrow) -> None:\n        \"\"\"Handle InitiateEscrow command.\"\"\"\n        logger.info(f\"Handling InitiateEscrow command: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Create new escrow aggregate\n            escrow = EscrowTransaction(id=command.escrow_id)\n            escrow.initiate(\n                initiator_id=command.initiator_id,\n                counterparty_id=command.counterparty_id,\n                amount=command.amount,\n                currency=command.currency,\n                lock_until_timestamp=command.lock_until_timestamp,\n                metadata=command.metadata\n            )\n            \n            # Save events through unit of work\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Escrow {escrow.id} initiated successfully\")\n\n    async def _handle_fund_escrow(self, command: FundEscrow) -> None:\n        \"\"\"Handle FundEscrow command.\"\"\"\n        logger.info(f\"Handling FundEscrow command for: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load escrow from event store\n            events = await uow.event_store.get_events(command.escrow_id)\n            \n            if not events:\n                logger.error(f\"Escrow {command.escrow_id} not found\")\n                return\n            \n            # Rebuild escrow state\n            escrow = EscrowTransaction(id=command.escrow_id)\n            for event in events:\n                escrow.apply_event(event)\n            \n            # Fund the escrow\n            escrow.fund()\n            \n            # Save new events\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Escrow {command.escrow_id} funded successfully\")\n\n    async def _handle_add_release_signature(self, command: AddReleaseSignature) -> None:\n        \"\"\"Handle AddReleaseSignature command.\"\"\"\n        logger.info(f\"Handling AddReleaseSignature command for escrow: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load escrow from event store\n            events = await uow.event_store.get_events(command.escrow_id)\n            \n            if not events:\n                logger.error(f\"Escrow {command.escrow_id} not found\")\n                return\n            \n            # Rebuild escrow state\n            escrow = EscrowTransaction(id=command.escrow_id)\n            for event in events:\n                escrow.apply_event(event)\n            \n            # Add the signature\n            escrow.add_release_signature(command.signer_id, command.signature)\n            \n            # Save new events\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Signature added to escrow {command.escrow_id} by {command.signer_id}\")\n\n    async def _handle_process_escrow_release(self, command: ProcessEscrowRelease) -> None:\n        \"\"\"Handle ProcessEscrowRelease command.\"\"\"\n        logger.info(f\"Handling ProcessEscrowRelease command for: {command.escrow_id}\")\n        \n        async with self.unit_of_work as uow:\n            # Load escrow from event store\n            events = await uow.event_store.get_events(command.escrow_id)\n            \n            if not events:\n                logger.error(f\"Escrow {command.escrow_id} not found\")\n                return\n            \n            # Rebuild escrow state\n            escrow = EscrowTransaction(id=command.escrow_id)\n            for event in events:\n                escrow.apply_event(event)\n            \n            # Release the escrow\n            escrow.release()\n            \n            # Save new events\n            for event in escrow.get_pending_events():\n                await uow.event_store.append(event)\n                # Publish event for saga handling and other handlers\n                await uow.publish_event(event)\n            \n            escrow.clear_pending_events()\n            \n            logger.info(f\"Escrow {command.escrow_id} released successfully\")\n\n\n# Singleton instance for use with the command bus\n_handler_instance: TransactionCommandHandler = None\n\n\ndef get_transaction_handler() -> TransactionCommandHandler:\n    \"\"\"Get or create the transaction handler instance.\"\"\"\n    global _handler_instance\n    if _handler_instance is None:\n        _handler_instance = TransactionCommandHandler()\n    return _handler_instance\n\n\nasync def handle_transaction_command(command: Command) -> None:\n    \"\"\"Handle a transaction command using the singleton handler.\"\"\"\n    handler = get_transaction_handler()\n    await handler.handle(command)\n",
            "tradeutility_nexus/trade_nexus/services/transactions/sagas.py": "\"\"\"Saga implementations for transaction orchestration.\"\"\"\nimport logging\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Set\nfrom uuid import UUID, uuid4\n\nfrom trade_nexus.core.commands import (\n    CompleteTransaction,\n    FailTransaction,\n    ProcessEscrowRelease,\n    ProcessPayment,\n    SettleTransaction,\n)\nfrom trade_nexus.core.events import (\n    EscrowFunded,\n    EscrowReleased,\n    Event,\n    FraudDetected,\n    PaymentFailed,\n    PaymentProcessed,\n    ReleaseSignatureAdded,\n    RiskAssessed,\n    TransactionInitiated,\n    TransactionSettled,\n)\nfrom trade_nexus.core.saga import Saga, SagaState\n\nlogger = logging.getLogger(__name__)\n\n\nclass TransactionSagaState(Enum):\n    \"\"\"States for the transaction saga.\"\"\"\n    STARTED = \"STARTED\"\n    PAYMENT_PENDING = \"PAYMENT_PENDING\"\n    PAYMENT_COMPLETED = \"PAYMENT_COMPLETED\"\n    RISK_ASSESSED = \"RISK_ASSESSED\"\n    SETTLEMENT_PENDING = \"SETTLEMENT_PENDING\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    COMPENSATING = \"COMPENSATING\"\n\n\nclass EscrowSagaState(Enum):\n    \"\"\"States for the escrow lifecycle saga.\"\"\"\n    STARTED = \"STARTED\"\n    FUNDED = \"FUNDED\"\n    AWAITING_SIGNATURES = \"AWAITING_SIGNATURES\"\n    SIGNATURES_COMPLETE = \"SIGNATURES_COMPLETE\"\n    AWAITING_TIME_LOCK = \"AWAITING_TIME_LOCK\"\n    RELEASING = \"RELEASING\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n\n\n@dataclass\nclass TransactionSaga(Saga):\n    \"\"\"Saga for orchestrating the transaction lifecycle.\"\"\"\n    transaction_id: Optional[UUID] = None\n    state: TransactionSagaState = TransactionSagaState.STARTED\n    risk_score: float = 0.0\n    payment_reference: Optional[str] = None\n    error_message: Optional[str] = None\n\n    async def handle_event(self, event: Event) -> List[Any]:\n        \"\"\"Handle an event and return commands to dispatch.\"\"\"\n        commands = []\n\n        if isinstance(event, TransactionInitiated):\n            commands = await self._on_transaction_initiated(event)\n        elif isinstance(event, PaymentProcessed):\n            commands = await self._on_payment_processed(event)\n        elif isinstance(event, PaymentFailed):\n            commands = await self._on_payment_failed(event)\n        elif isinstance(event, RiskAssessed):\n            commands = await self._on_risk_assessed(event)\n        elif isinstance(event, FraudDetected):\n            commands = await self._on_fraud_detected(event)\n        elif isinstance(event, TransactionSettled):\n            commands = await self._on_transaction_settled(event)\n\n        return commands\n\n    async def _on_transaction_initiated(self, event: TransactionInitiated) -> List[Any]:\n        \"\"\"Handle TransactionInitiated event.\"\"\"\n        self.transaction_id = event.transaction_id\n        self.state = TransactionSagaState.PAYMENT_PENDING\n        logger.info(f\"Saga started for transaction {self.transaction_id}\")\n        \n        return [ProcessPayment(\n            transaction_id=event.transaction_id,\n            amount=event.amount,\n            currency=event.currency\n        )]\n\n    async def _on_payment_processed(self, event: PaymentProcessed) -> List[Any]:\n        \"\"\"Handle PaymentProcessed event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.PAYMENT_COMPLETED\n        self.payment_reference = event.payment_reference\n        logger.info(f\"Payment processed for transaction {self.transaction_id}\")\n        \n        return [SettleTransaction(transaction_id=self.transaction_id)]\n\n    async def _on_payment_failed(self, event: PaymentFailed) -> List[Any]:\n        \"\"\"Handle PaymentFailed event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.FAILED\n        self.error_message = event.reason\n        logger.warning(f\"Payment failed for transaction {self.transaction_id}: {event.reason}\")\n        \n        return [FailTransaction(\n            transaction_id=self.transaction_id,\n            reason=event.reason\n        )]\n\n    async def _on_risk_assessed(self, event: RiskAssessed) -> List[Any]:\n        \"\"\"Handle RiskAssessed event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.risk_score = event.risk_score\n        self.state = TransactionSagaState.RISK_ASSESSED\n        logger.info(f\"Risk assessed for transaction {self.transaction_id}: {event.risk_level}\")\n        \n        return []\n\n    async def _on_fraud_detected(self, event: FraudDetected) -> List[Any]:\n        \"\"\"Handle FraudDetected event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.COMPENSATING\n        logger.warning(f\"Fraud detected for transaction {self.transaction_id}\")\n        \n        return [FailTransaction(\n            transaction_id=self.transaction_id,\n            reason=f\"Fraud detected: {event.fraud_type}\"\n        )]\n\n    async def _on_transaction_settled(self, event: TransactionSettled) -> List[Any]:\n        \"\"\"Handle TransactionSettled event.\"\"\"\n        if event.transaction_id != self.transaction_id:\n            return []\n        \n        self.state = TransactionSagaState.COMPLETED\n        logger.info(f\"Transaction {self.transaction_id} completed successfully\")\n        \n        return [CompleteTransaction(transaction_id=self.transaction_id)]\n\n    def is_complete(self) -> bool:\n        \"\"\"Check if the saga is complete.\"\"\"\n        return self.state in (TransactionSagaState.COMPLETED, TransactionSagaState.FAILED)\n\n\n@dataclass\nclass EscrowLifecycleSaga(Saga):\n    \"\"\"Saga for orchestrating the escrow transaction lifecycle.\n    \n    This saga manages the complete lifecycle of an escrow transaction:\n    1. Starts when escrow is funded\n    2. Tracks signature collection from both parties\n    3. Monitors time-lock expiration\n    4. Triggers release when all conditions are met\n    \"\"\"\n    escrow_id: Optional[UUID] = None\n    state: EscrowSagaState = EscrowSagaState.STARTED\n    initiator_id: Optional[UUID] = None\n    counterparty_id: Optional[UUID] = None\n    lock_until_timestamp: Optional[datetime] = None\n    collected_signatures: Set[UUID] = field(default_factory=set)\n    required_signatures: int = 2\n    error_message: Optional[str] = None\n\n    async def handle_event(self, event: Event) -> List[Any]:\n        \"\"\"Handle an event and return commands to dispatch.\"\"\"\n        commands = []\n\n        if isinstance(event, EscrowFunded):\n            commands = await self._on_escrow_funded(event)\n        elif isinstance(event, ReleaseSignatureAdded):\n            commands = await self._on_release_signature_added(event)\n        elif isinstance(event, EscrowReleased):\n            commands = await self._on_escrow_released(event)\n\n        return commands\n\n    async def _on_escrow_funded(self, event: EscrowFunded) -> List[Any]:\n        \"\"\"Handle EscrowFunded event - starts the saga.\"\"\"\n        self.escrow_id = event.escrow_id\n        self.state = EscrowSagaState.FUNDED\n        \n        logger.info(f\"Escrow lifecycle saga started for escrow {self.escrow_id}\")\n        logger.info(f\"Escrow funded with {event.amount} {event.currency}\")\n        \n        # Transition to awaiting signatures\n        self.state = EscrowSagaState.AWAITING_SIGNATURES\n        \n        return []\n\n    async def _on_release_signature_added(self, event: ReleaseSignatureAdded) -> List[Any]:\n        \"\"\"Handle ReleaseSignatureAdded event.\"\"\"\n        if event.escrow_id != self.escrow_id:\n            return []\n        \n        # Track the signature\n        self.collected_signatures.add(event.signer_id)\n        \n        logger.info(\n            f\"Signature added to escrow {self.escrow_id} by {event.signer_id}. \"\n            f\"Signatures collected: {len(self.collected_signatures)}/{self.required_signatures}\"\n        )\n        \n        # Check if all signatures are collected\n        if self._has_all_signatures():\n            logger.info(f\"All required signatures collected for escrow {self.escrow_id}\")\n            self.state = EscrowSagaState.SIGNATURES_COMPLETE\n            \n            # Check if time lock has expired\n            return await self._check_release_conditions()\n        \n        return []\n\n    async def _check_release_conditions(self) -> List[Any]:\n        \"\"\"Check if all conditions for release are met.\"\"\"\n        if not self._has_all_signatures():\n            logger.debug(f\"Escrow {self.escrow_id}: Waiting for all signatures\")\n            return []\n        \n        if not self._is_lock_expired():\n            logger.info(\n                f\"Escrow {self.escrow_id}: All signatures collected but time lock not expired. \"\n                f\"Lock expires at: {self.lock_until_timestamp}\"\n            )\n            self.state = EscrowSagaState.AWAITING_TIME_LOCK\n            return []\n        \n        # All conditions met - trigger release\n        logger.info(\n            f\"Escrow {self.escrow_id}: All conditions met. \"\n            f\"Signatures: {len(self.collected_signatures)}/{self.required_signatures}, \"\n            f\"Time lock expired: True. Triggering release.\"\n        )\n        \n        self.state = EscrowSagaState.RELEASING\n        \n        return [ProcessEscrowRelease(escrow_id=self.escrow_id)]\n\n    async def _on_escrow_released(self, event: EscrowReleased) -> List[Any]:\n        \"\"\"Handle EscrowReleased event.\"\"\"\n        if event.escrow_id != self.escrow_id:\n            return []\n        \n        self.state = EscrowSagaState.COMPLETED\n        \n        logger.info(\n            f\"Escrow {self.escrow_id} released successfully. \"\n            f\"Amount: {event.amount} {event.currency}\"\n        )\n        \n        return []\n\n    def _has_all_signatures(self) -> bool:\n        \"\"\"Check if all required signatures have been collected.\"\"\"\n        return len(self.collected_signatures) >= self.required_signatures\n\n    def _is_lock_expired(self) -> bool:\n        \"\"\"Check if the time lock has expired.\"\"\"\n        if self.lock_until_timestamp is None:\n            return True\n        return datetime.utcnow() >= self.lock_until_timestamp\n\n    def set_escrow_details(\n        self,\n        initiator_id: UUID,\n        counterparty_id: UUID,\n        lock_until_timestamp: datetime\n    ) -> None:\n        \"\"\"Set escrow details for tracking.\"\"\"\n        self.initiator_id = initiator_id\n        self.counterparty_id = counterparty_id\n        self.lock_until_timestamp = lock_until_timestamp\n\n    def is_complete(self) -> bool:\n        \"\"\"Check if the saga is complete.\"\"\"\n        return self.state in (EscrowSagaState.COMPLETED, EscrowSagaState.FAILED)\n\n    async def try_release(self) -> List[Any]:\n        \"\"\"Attempt to release the escrow if conditions are met.\n        \n        This method can be called periodically to check if time-lock has expired.\n        \"\"\"\n        if self.state == EscrowSagaState.AWAITING_TIME_LOCK:\n            return await self._check_release_conditions()\n        return []\n\n\nclass SagaManager:\n    \"\"\"Manager for saga instances.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the saga manager.\"\"\"\n        self._transaction_sagas: Dict[UUID, TransactionSaga] = {}\n        self._escrow_sagas: Dict[UUID, EscrowLifecycleSaga] = {}\n        self._command_dispatcher: Optional[Callable] = None\n\n    def set_command_dispatcher(self, dispatcher: Callable) -> None:\n        \"\"\"Set the command dispatcher function.\"\"\"\n        self._command_dispatcher = dispatcher\n\n    async def handle_event(self, event: Event) -> None:\n        \"\"\"Route an event to the appropriate saga(s).\"\"\"\n        commands = []\n\n        # Handle transaction events\n        if isinstance(event, TransactionInitiated):\n            saga = TransactionSaga(id=uuid4())\n            self._transaction_sagas[event.transaction_id] = saga\n            commands = await saga.handle_event(event)\n        elif hasattr(event, 'transaction_id'):\n            saga = self._transaction_sagas.get(event.transaction_id)\n            if saga:\n                commands = await saga.handle_event(event)\n                if saga.is_complete():\n                    del self._transaction_sagas[event.transaction_id]\n\n        # Handle escrow events\n        if isinstance(event, EscrowFunded):\n            saga = EscrowLifecycleSaga(id=uuid4())\n            self._escrow_sagas[event.escrow_id] = saga\n            commands = await saga.handle_event(event)\n        elif hasattr(event, 'escrow_id'):\n            saga = self._escrow_sagas.get(event.escrow_id)\n            if saga:\n                commands = await saga.handle_event(event)\n                if saga.is_complete():\n                    del self._escrow_sagas[event.escrow_id]\n\n        # Dispatch any resulting commands\n        if self._command_dispatcher and commands:\n            for command in commands:\n                await self._command_dispatcher(command)\n\n    def get_escrow_saga(self, escrow_id: UUID) -> Optional[EscrowLifecycleSaga]:\n        \"\"\"Get an escrow saga by escrow ID.\"\"\"\n        return self._escrow_sagas.get(escrow_id)\n\n    def get_transaction_saga(self, transaction_id: UUID) -> Optional[TransactionSaga]:\n        \"\"\"Get a transaction saga by transaction ID.\"\"\"\n        return self._transaction_sagas.get(transaction_id)\n\n    async def check_pending_escrow_releases(self) -> None:\n        \"\"\"Check all pending escrow sagas for time-lock expiration.\n        \n        This should be called periodically (e.g., by a background task).\n        \"\"\"\n        for escrow_id, saga in list(self._escrow_sagas.items()):\n            if saga.state == EscrowSagaState.AWAITING_TIME_LOCK:\n                commands = await saga.try_release()\n                if self._command_dispatcher and commands:\n                    for command in commands:\n                        await self._command_dispatcher(command)\n\n\n# Global saga manager instance\n_saga_manager: Optional[SagaManager] = None\n\n\ndef get_saga_manager() -> SagaManager:\n    \"\"\"Get or create the saga manager instance.\"\"\"\n    global _saga_manager\n    if _saga_manager is None:\n        _saga_manager = SagaManager()\n    return _saga_manager\n",
            "tradeutility_nexus/trade_nexus/services/risk/handlers.py": "\"\"\"Risk service event handlers.\"\"\"\nimport logging\nfrom decimal import Decimal\nfrom typing import Callable, Dict, Type\nfrom uuid import UUID\n\nfrom trade_nexus.core.commands import AssessRisk, Command\nfrom trade_nexus.core.events import (\n    EscrowReleased,\n    Event,\n    RiskAssessed,\n    TransactionInitiated,\n)\nfrom trade_nexus.services.risk.assessment import RiskAssessmentService\n\nlogger = logging.getLogger(__name__)\n\n\nclass RiskCommandHandler:\n    \"\"\"Handler for risk-related commands.\"\"\"\n\n    def __init__(self, risk_service: RiskAssessmentService = None):\n        \"\"\"Initialize the handler.\"\"\"\n        self.risk_service = risk_service or RiskAssessmentService()\n        self._handlers: Dict[Type[Command], Callable] = {\n            AssessRisk: self._handle_assess_risk,\n        }\n\n    async def handle(self, command: Command) -> None:\n        \"\"\"Handle a command.\"\"\"\n        handler = self._handlers.get(type(command))\n        if handler:\n            await handler(command)\n        else:\n            logger.warning(f\"No handler found for command type: {type(command).__name__}\")\n\n    async def _handle_assess_risk(self, command: AssessRisk) -> None:\n        \"\"\"Handle AssessRisk command.\"\"\"\n        logger.info(f\"Assessing risk for transaction {command.transaction_id}\")\n        \n        result = await self.risk_service.assess(\n            transaction_id=command.transaction_id,\n            user_id=command.user_id,\n            amount=command.amount\n        )\n        \n        logger.info(\n            f\"Risk assessment complete for transaction {command.transaction_id}: \"\n            f\"score={result.get('risk_score', 0)}, level={result.get('risk_level', 'UNKNOWN')}\"\n        )\n\n\nclass RiskEventHandler:\n    \"\"\"Handler for risk-related events.\"\"\"\n\n    def __init__(self, risk_service: RiskAssessmentService = None):\n        \"\"\"Initialize the handler.\"\"\"\n        self.risk_service = risk_service or RiskAssessmentService()\n        self._handlers: Dict[Type[Event], Callable] = {\n            TransactionInitiated: self._on_transaction_initiated,\n            EscrowReleased: self._on_escrow_released,\n        }\n\n    async def handle(self, event: Event) -> None:\n        \"\"\"Handle an event.\"\"\"\n        handler = self._handlers.get(type(event))\n        if handler:\n            await handler(event)\n        else:\n            logger.debug(f\"No handler for event type: {type(event).__name__}\")\n\n    async def _on_transaction_initiated(self, event: TransactionInitiated) -> None:\n        \"\"\"Handle TransactionInitiated event for automatic risk assessment.\"\"\"\n        logger.info(f\"Auto-assessing risk for new transaction {event.transaction_id}\")\n        \n        result = await self.risk_service.assess(\n            transaction_id=event.transaction_id,\n            user_id=event.sender_id,\n            amount=event.amount\n        )\n        \n        logger.info(\n            f\"Auto risk assessment for transaction {event.transaction_id}: \"\n            f\"score={result.get('risk_score', 0)}, level={result.get('risk_level', 'UNKNOWN')}\"\n        )\n\n    async def _on_escrow_released(self, event: EscrowReleased) -> None:\n        \"\"\"Handle EscrowReleased event for risk tracking.\n        \n        This handler demonstrates integration with the risk service when\n        escrow transactions are successfully released. Successfully completed\n        escrow transactions are considered low-risk and can positively impact\n        participant risk profiles.\n        \"\"\"\n        logger.info(\n            f\"Processing EscrowReleased event for escrow {event.escrow_id}. \"\n            f\"Low-risk escrow transaction completed successfully.\"\n        )\n        \n        # Log details about the completed escrow\n        logger.info(\n            f\"Escrow release details - \"\n            f\"Escrow ID: {event.escrow_id}, \"\n            f\"Initiator: {event.initiator_id}, \"\n            f\"Counterparty: {event.counterparty_id}, \"\n            f\"Amount: {event.amount} {event.currency}\"\n        )\n        \n        # In a full implementation, this would:\n        # 1. Update risk profiles for both initiator and counterparty\n        # 2. Record successful escrow completion in risk metrics\n        # 3. Potentially adjust trust scores\n        \n        # For now, we log the successful completion for audit purposes\n        logger.info(\n            f\"Risk adjustment: Escrow {event.escrow_id} completed successfully. \"\n            f\"Both parties ({event.initiator_id}, {event.counterparty_id}) \"\n            f\"have demonstrated trustworthy behavior through multi-signature escrow completion.\"\n        )\n        \n        # Track successful escrow for risk metrics\n        await self._record_successful_escrow(\n            escrow_id=event.escrow_id,\n            initiator_id=event.initiator_id,\n            counterparty_id=event.counterparty_id,\n            amount=event.amount,\n            currency=event.currency\n        )\n\n    async def _record_successful_escrow(\n        self,\n        escrow_id: UUID,\n        initiator_id: UUID,\n        counterparty_id: UUID,\n        amount: Decimal,\n        currency: str\n    ) -> None:\n        \"\"\"Record a successful escrow completion for risk metrics.\"\"\"\n        # This would integrate with a metrics/analytics service in production\n        logger.info(\n            f\"Recording successful escrow completion for risk metrics: \"\n            f\"escrow_id={escrow_id}, amount={amount} {currency}\"\n        )\n        \n        # Update risk profiles (placeholder for actual implementation)\n        if self.risk_service:\n            # Decrease risk scores for successful participants\n            logger.debug(\n                f\"Updating risk profiles for participants: \"\n                f\"{initiator_id}, {counterparty_id}\"\n            )\n\n\n# Singleton instances\n_command_handler: RiskCommandHandler = None\n_event_handler: RiskEventHandler = None\n\n\ndef get_risk_command_handler() -> RiskCommandHandler:\n    \"\"\"Get or create the risk command handler instance.\"\"\"\n    global _command_handler\n    if _command_handler is None:\n        _command_handler = RiskCommandHandler()\n    return _command_handler\n\n\ndef get_risk_event_handler() -> RiskEventHandler:\n    \"\"\"Get or create the risk event handler instance.\"\"\"\n    global _event_handler\n    if _event_handler is None:\n        _event_handler = RiskEventHandler()\n    return _event_handler\n\n\nasync def handle_risk_command(command: Command) -> None:\n    \"\"\"Handle a risk command using the singleton handler.\"\"\"\n    handler = get_risk_command_handler()\n    await handler.handle(command)\n\n\nasync def handle_risk_event(event: Event) -> None:\n    \"\"\"Handle a risk event using the singleton handler.\"\"\"\n    handler = get_risk_event_handler()\n    await handler.handle(event)\n",
            "tradeutility_nexus/trade_nexus/core/unit_of_work.py": "\"\"\"Unit of Work pattern implementation.\"\"\"\nimport logging\nfrom typing import Any, Callable, List, Optional\n\nfrom trade_nexus.core.event_store import EventStore, InMemoryEventStore\nfrom trade_nexus.core.events import Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass UnitOfWork:\n    \"\"\"Unit of Work for managing transactions and event persistence.\"\"\"\n\n    def __init__(\n        self,\n        event_store: EventStore = None,\n        event_publisher: Callable[[Event], Any] = None\n    ):\n        \"\"\"Initialize the Unit of Work.\"\"\"\n        self.event_store = event_store or InMemoryEventStore()\n        self._event_publisher = event_publisher\n        self._pending_events: List[Event] = []\n        self._committed = False\n\n    async def __aenter__(self) -> \"UnitOfWork\":\n        \"\"\"Enter the context manager.\"\"\"\n        self._pending_events = []\n        self._committed = False\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:\n        \"\"\"Exit the context manager.\"\"\"\n        if exc_type is None and not self._committed:\n            await self.commit()\n        elif exc_type is not None:\n            await self.rollback()\n\n    async def commit(self) -> None:\n        \"\"\"Commit the unit of work.\"\"\"\n        try:\n            # Publish all pending events\n            for event in self._pending_events:\n                if self._event_publisher:\n                    await self._event_publisher(event)\n            \n            self._pending_events.clear()\n            self._committed = True\n            logger.debug(\"Unit of work committed successfully\")\n        except Exception as e:\n            logger.error(f\"Error committing unit of work: {e}\")\n            await self.rollback()\n            raise\n\n    async def rollback(self) -> None:\n        \"\"\"Rollback the unit of work.\"\"\"\n        self._pending_events.clear()\n        self._committed = False\n        logger.debug(\"Unit of work rolled back\")\n\n    async def publish_event(self, event: Event) -> None:\n        \"\"\"Queue an event for publishing on commit.\"\"\"\n        self._pending_events.append(event)\n        logger.debug(f\"Event queued for publishing: {type(event).__name__}\")\n\n    def set_event_publisher(self, publisher: Callable[[Event], Any]) -> None:\n        \"\"\"Set the event publisher.\"\"\"\n        self._event_publisher = publisher\n\n\nclass UnitOfWorkManager:\n    \"\"\"Manager for creating Unit of Work instances.\"\"\"\n\n    def __init__(\n        self,\n        event_store: EventStore = None,\n        event_publisher: Callable[[Event], Any] = None\n    ):\n        \"\"\"Initialize the manager.\"\"\"\n        self._event_store = event_store or InMemoryEventStore()\n        self._event_publisher = event_publisher\n\n    def create(self) -> UnitOfWork:\n        \"\"\"Create a new Unit of Work.\"\"\"\n        return UnitOfWork(\n            event_store=self._event_store,\n            event_publisher=self._event_publisher\n        )\n\n    def set_event_publisher(self, publisher: Callable[[Event], Any]) -> None:\n        \"\"\"Set the event publisher for new units of work.\"\"\"\n        self._event_publisher = publisher\n",
            "tradeutility_nexus/trade_nexus/core/event_store.py": "\"\"\"Event store implementation for Event Sourcing.\"\"\"\nimport logging\nfrom abc import ABC, abstractmethod\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom typing import Dict, List, Optional\nfrom uuid import UUID\n\nfrom trade_nexus.core.events import Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass EventStore(ABC):\n    \"\"\"Abstract base class for event stores.\"\"\"\n\n    @abstractmethod\n    async def append(self, event: Event) -> None:\n        \"\"\"Append an event to the store.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_events(self, aggregate_id: UUID) -> List[Event]:\n        \"\"\"Get all events for an aggregate.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_events_since(self, timestamp: datetime) -> List[Event]:\n        \"\"\"Get all events since a timestamp.\"\"\"\n        pass\n\n\nclass InMemoryEventStore(EventStore):\n    \"\"\"In-memory implementation of the event store.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the in-memory event store.\"\"\"\n        self._events: Dict[UUID, List[Event]] = defaultdict(list)\n        self._all_events: List[Event] = []\n\n    async def append(self, event: Event) -> None:\n        \"\"\"Append an event to the store.\"\"\"\n        if event.aggregate_id:\n            self._events[event.aggregate_id].append(event)\n        self._all_events.append(event)\n        logger.debug(f\"Event appended: {type(event).__name__} for aggregate {event.aggregate_id}\")\n\n    async def get_events(self, aggregate_id: UUID) -> List[Event]:\n        \"\"\"Get all events for an aggregate.\"\"\"\n        events = self._events.get(aggregate_id, [])\n        logger.debug(f\"Retrieved {len(events)} events for aggregate {aggregate_id}\")\n        return events\n\n    async def get_events_since(self, timestamp: datetime) -> List[Event]:\n        \"\"\"Get all events since a timestamp.\"\"\"\n        events = [e for e in self._all_events if e.timestamp >= timestamp]\n        logger.debug(f\"Retrieved {len(events)} events since {timestamp}\")\n        return events\n\n    async def get_all_events(self) -> List[Event]:\n        \"\"\"Get all events in the store.\"\"\"\n        return self._all_events.copy()\n\n    def clear(self) -> None:\n        \"\"\"Clear all events from the store.\"\"\"\n        self._events.clear()\n        self._all_events.clear()\n        logger.debug(\"Event store cleared\")\n",
            "tradeutility_nexus/trade_nexus/core/saga.py": "\"\"\"Saga pattern implementation for process orchestration.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, List, Optional\nfrom uuid import UUID, uuid4\n\nfrom trade_nexus.core.events import Event\n\n\nclass SagaState(Enum):\n    \"\"\"Base states for sagas.\"\"\"\n    STARTED = \"STARTED\"\n    IN_PROGRESS = \"IN_PROGRESS\"\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    COMPENSATING = \"COMPENSATING\"\n\n\n@dataclass\nclass Saga(ABC):\n    \"\"\"Abstract base class for sagas.\"\"\"\n    id: UUID = field(default_factory=uuid4)\n    correlation_id: Optional[UUID] = None\n\n    @abstractmethod\n    async def handle_event(self, event: Event) -> List[Any]:\n        \"\"\"Handle an event and return commands to dispatch.\"\"\"\n        pass\n\n    @abstractmethod\n    def is_complete(self) -> bool:\n        \"\"\"Check if the saga is complete.\"\"\"\n        pass\n",
            "tradeutility_nexus/trade_nexus/core/bus.py": "\"\"\"Command and Event bus implementations.\"\"\"\nimport logging\nfrom typing import Any, Callable, Dict, List, Type\n\nfrom trade_nexus.core.commands import Command\nfrom trade_nexus.core.events import Event\n\nlogger = logging.getLogger(__name__)\n\n\nclass CommandBus:\n    \"\"\"Bus for dispatching commands to handlers.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the command bus.\"\"\"\n        self._handlers: Dict[Type[Command], Callable] = {}\n\n    def register(self, command_type: Type[Command], handler: Callable) -> None:\n        \"\"\"Register a handler for a command type.\"\"\"\n        self._handlers[command_type] = handler\n        logger.debug(f\"Registered handler for {command_type.__name__}\")\n\n    async def dispatch(self, command: Command) -> Any:\n        \"\"\"Dispatch a command to its handler.\"\"\"\n        handler = self._handlers.get(type(command))\n        if handler:\n            logger.debug(f\"Dispatching command: {type(command).__name__}\")\n            return await handler(command)\n        else:\n            logger.warning(f\"No handler registered for command: {type(command).__name__}\")\n            return None\n\n\nclass EventBus:\n    \"\"\"Bus for publishing events to subscribers.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the event bus.\"\"\"\n        self._handlers: Dict[Type[Event], List[Callable]] = {}\n        self._global_handlers: List[Callable] = []\n\n    def subscribe(self, event_type: Type[Event], handler: Callable) -> None:\n        \"\"\"Subscribe a handler to an event type.\"\"\"\n        if event_type not in self._handlers:\n            self._handlers[event_type] = []\n        self._handlers[event_type].append(handler)\n        logger.debug(f\"Subscribed handler to {event_type.__name__}\")\n\n    def subscribe_all(self, handler: Callable) -> None:\n        \"\"\"Subscribe a handler to all events.\"\"\"\n        self._global_handlers.append(handler)\n        logger.debug(\"Subscribed global event handler\")\n\n    async def publish(self, event: Event) -> None:\n        \"\"\"Publish an event to all subscribers.\"\"\"\n        logger.debug(f\"Publishing event: {type(event).__name__}\")\n        \n        # Call specific handlers\n        handlers = self._handlers.get(type(event), [])\n        for handler in handlers:\n            try:\n                await handler(event)\n            except Exception as e:\n                logger.error(f\"Error in event handler: {e}\")\n\n        # Call global handlers\n        for handler in self._global_handlers:\n            try:\n                await handler(event)\n            except Exception as e:\n                logger.error(f\"Error in global event handler: {e}\")\n",
            "tradeutility_nexus/trade_nexus/services/risk/assessment.py": "\"\"\"Risk assessment service.\"\"\"\nimport logging\nfrom decimal import Decimal\nfrom typing import Any, Dict\nfrom uuid import UUID\n\nlogger = logging.getLogger(__name__)\n\n\nclass RiskAssessmentService:\n    \"\"\"Service for assessing transaction risk.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the risk assessment service.\"\"\"\n        self._risk_thresholds = {\n            \"low\": Decimal(\"1000\"),\n            \"medium\": Decimal(\"10000\"),\n            \"high\": Decimal(\"100000\")\n        }\n\n    async def assess(\n        self,\n        transaction_id: UUID,\n        user_id: UUID,\n        amount: Decimal\n    ) -> Dict[str, Any]:\n        \"\"\"Assess risk for a transaction.\"\"\"\n        # Simple risk calculation based on amount\n        risk_score = self._calculate_risk_score(amount)\n        risk_level = self._determine_risk_level(risk_score)\n\n        logger.info(\n            f\"Risk assessment for transaction {transaction_id}: \"\n            f\"score={risk_score:.2f}, level={risk_level}\"\n        )\n\n        return {\n            \"transaction_id\": transaction_id,\n            \"user_id\": user_id,\n            \"risk_score\": risk_score,\n            \"risk_level\": risk_level,\n            \"amount\": amount\n        }\n\n    def _calculate_risk_score(self, amount: Decimal) -> float:\n        \"\"\"Calculate risk score based on amount.\"\"\"\n        # Simple linear scaling for demo\n        max_amount = self._risk_thresholds[\"high\"]\n        score = min(float(amount / max_amount), 1.0)\n        return score\n\n    def _determine_risk_level(self, score: float) -> str:\n        \"\"\"Determine risk level from score.\"\"\"\n        if score < 0.3:\n            return \"LOW\"\n        elif score < 0.7:\n            return \"MEDIUM\"\n        else:\n            return \"HIGH\"\n",
            "tradeutility_nexus/main.py": "\"\"\"Main entry point for TradeUtility Nexus.\"\"\"\nimport asyncio\nimport logging\nimport sys\n\nimport uvicorn\n\nfrom trade_nexus.api.server import create_app\nfrom trade_nexus.api.endpoints import set_command_bus, set_event_bus\nfrom trade_nexus.core.bus import CommandBus, EventBus\nfrom trade_nexus.core.commands import (\n    AddReleaseSignature,\n    AssessRisk,\n    FundEscrow,\n    InitiateEscrow,\n    InitiateTransaction,\n    ProcessEscrowRelease,\n    ProcessPayment,\n)\nfrom trade_nexus.core.events import (\n    EscrowFunded,\n    EscrowReleased,\n    ReleaseSignatureAdded,\n    TransactionInitiated,\n)\nfrom trade_nexus.services.risk.handlers import handle_risk_command, handle_risk_event\nfrom trade_nexus.services.transactions.handlers import handle_transaction_command\nfrom trade_nexus.services.transactions.sagas import get_saga_manager\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stdout)]\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef setup_buses() -> tuple[CommandBus, EventBus]:\n    \"\"\"Set up command and event buses with handlers.\"\"\"\n    command_bus = CommandBus()\n    event_bus = EventBus()\n\n    # Register transaction command handlers\n    command_bus.register(InitiateTransaction, handle_transaction_command)\n    command_bus.register(InitiateEscrow, handle_transaction_command)\n    command_bus.register(FundEscrow, handle_transaction_command)\n    command_bus.register(AddReleaseSignature, handle_transaction_command)\n    command_bus.register(ProcessEscrowRelease, handle_transaction_command)\n\n    # Register risk command handlers\n    command_bus.register(AssessRisk, handle_risk_command)\n\n    # Register event handlers\n    event_bus.subscribe(TransactionInitiated, handle_risk_event)\n    event_bus.subscribe(EscrowReleased, handle_risk_event)\n\n    # Set up saga manager\n    saga_manager = get_saga_manager()\n    saga_manager.set_command_dispatcher(command_bus.dispatch)\n\n    # Subscribe saga manager to relevant events\n    event_bus.subscribe(EscrowFunded, saga_manager.handle_event)\n    event_bus.subscribe(ReleaseSignatureAdded, saga_manager.handle_event)\n    event_bus.subscribe(EscrowReleased, saga_manager.handle_event)\n\n    return command_bus, event_bus\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"Starting TradeUtility Nexus...\")\n\n    # Set up buses\n    command_bus, event_bus = setup_buses()\n\n    # Set buses in endpoints module\n    set_command_bus(command_bus)\n    set_event_bus(event_bus)\n\n    # Create FastAPI app\n    app = create_app()\n\n    # Run the server\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8000,\n        log_level=\"info\"\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
            "tradeutility_nexus/trade_nexus/api/server.py": "\"\"\"FastAPI server configuration.\"\"\"\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom trade_nexus.api.endpoints import router\n\n\ndef create_app() -> FastAPI:\n    \"\"\"Create and configure the FastAPI application.\"\"\"\n    app = FastAPI(\n        title=\"TradeUtility Nexus\",\n        description=\"Advanced trading platform with escrow support\",\n        version=\"1.0.0\",\n        docs_url=\"/docs\",\n        redoc_url=\"/redoc\"\n    )\n\n    # Add CORS middleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Include routers\n    app.include_router(router, tags=[\"api\"])\n\n    return app\n"
          },
          "generated_files": [
            "tradeutility_nexus/trade_nexus/core/domain.py",
            "tradeutility_nexus/trade_nexus/core/commands.py",
            "tradeutility_nexus/trade_nexus/core/events.py",
            "tradeutility_nexus/trade_nexus/api/schemas.py",
            "tradeutility_nexus/trade_nexus/api/endpoints.py",
            "tradeutility_nexus/trade_nexus/services/transactions/handlers.py",
            "tradeutility_nexus/trade_nexus/services/transactions/sagas.py",
            "tradeutility_nexus/trade_nexus/services/risk/handlers.py",
            "tradeutility_nexus/trade_nexus/core/unit_of_work.py",
            "tradeutility_nexus/trade_nexus/core/event_store.py",
            "tradeutility_nexus/trade_nexus/core/saga.py",
            "tradeutility_nexus/trade_nexus/core/bus.py",
            "tradeutility_nexus/trade_nexus/services/risk/assessment.py",
            "tradeutility_nexus/main.py",
            "tradeutility_nexus/trade_nexus/api/server.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7712384519350811,
                "dependency_traversal_accuracy": 0.79437393402309,
                "cross_file_reasoning_depth": 0.3932777777777778,
                "system_thinking_score": 0.5539908523526323,
                "robustness_score": 0.4165160976041805,
                "comprehensiveness_score": 0.5056800597215105,
                "innovation_score": 0.49792497010761255,
                "solution_elegance_score": 0.7481233751077139
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09640480649188514,
                "dependency_traversal_weighted": 0.09929674175288625,
                "cross_file_reasoning_weighted": 0.04915972222222222,
                "system_thinking_weighted": 0.06924885654407904,
                "robustness_weighted": 0.052064512200522564,
                "comprehensiveness_weighted": 0.06321000746518882,
                "innovation_weighted": 0.06224062126345157,
                "solution_elegance_weighted": 0.09351542188846423
              },
              "total_software_engineering_score": 0.5851406898286998
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 1.0448591709136963,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "tradeutility_nexus/trade_nexus/core/domain.py",
                  "tradeutility_nexus/trade_nexus/core/commands.py",
                  "tradeutility_nexus/trade_nexus/core/events.py",
                  "tradeutility_nexus/trade_nexus/api/schemas.py",
                  "tradeutility_nexus/trade_nexus/api/endpoints.py",
                  "tradeutility_nexus/trade_nexus/services/transactions/handlers.py",
                  "tradeutility_nexus/trade_nexus/services/transactions/sagas.py",
                  "tradeutility_nexus/trade_nexus/services/risk/handlers.py",
                  "tradeutility_nexus/trade_nexus/core/unit_of_work.py",
                  "tradeutility_nexus/trade_nexus/core/event_store.py",
                  "tradeutility_nexus/trade_nexus/core/saga.py",
                  "tradeutility_nexus/trade_nexus/core/bus.py",
                  "tradeutility_nexus/trade_nexus/services/risk/assessment.py",
                  "tradeutility_nexus/main.py",
                  "tradeutility_nexus/trade_nexus/api/server.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 15,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 15 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.5135489614243323,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.5135489614243323,
                "idc_weight": 0.2,
                "total_functional_score": 0.6827097922848665
              }
            },
            "code_quality_details": {
              "files_analyzed": 15,
              "quality_checks": {
                "tradeutility_nexus/trade_nexus/core/domain.py": {
                  "line_count": 284,
                  "non_empty_lines": 240,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 22,
                  "class_count": 9,
                  "import_count": 29,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/core/commands.py": {
                  "line_count": 110,
                  "non_empty_lines": 82,
                  "comment_lines": 1,
                  "comment_ratio": 0.012195121951219513,
                  "function_count": 0,
                  "class_count": 14,
                  "import_count": 10,
                  "quality_score": 0.7
                },
                "tradeutility_nexus/trade_nexus/core/events.py": {
                  "line_count": 140,
                  "non_empty_lines": 106,
                  "comment_lines": 1,
                  "comment_ratio": 0.009433962264150943,
                  "function_count": 0,
                  "class_count": 17,
                  "import_count": 10,
                  "quality_score": 0.7
                },
                "tradeutility_nexus/trade_nexus/api/schemas.py": {
                  "line_count": 198,
                  "non_empty_lines": 159,
                  "comment_lines": 1,
                  "comment_ratio": 0.006289308176100629,
                  "function_count": 1,
                  "class_count": 20,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/api/endpoints.py": {
                  "line_count": 489,
                  "non_empty_lines": 418,
                  "comment_lines": 14,
                  "comment_ratio": 0.03349282296650718,
                  "function_count": 15,
                  "class_count": 0,
                  "import_count": 21,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/services/transactions/handlers.py": {
                  "line_count": 268,
                  "non_empty_lines": 205,
                  "comment_lines": 29,
                  "comment_ratio": 0.14146341463414633,
                  "function_count": 11,
                  "class_count": 1,
                  "import_count": 20,
                  "quality_score": 0.9999999999999999
                },
                "tradeutility_nexus/trade_nexus/services/transactions/sagas.py": {
                  "line_count": 380,
                  "non_empty_lines": 303,
                  "comment_lines": 9,
                  "comment_ratio": 0.0297029702970297,
                  "function_count": 25,
                  "class_count": 5,
                  "import_count": 18,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/services/risk/handlers.py": {
                  "line_count": 185,
                  "non_empty_lines": 150,
                  "comment_lines": 11,
                  "comment_ratio": 0.07333333333333333,
                  "function_count": 12,
                  "class_count": 2,
                  "import_count": 13,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/core/unit_of_work.py": {
                  "line_count": 92,
                  "non_empty_lines": 74,
                  "comment_lines": 1,
                  "comment_ratio": 0.013513513513513514,
                  "function_count": 10,
                  "class_count": 4,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/core/event_store.py": {
                  "line_count": 69,
                  "non_empty_lines": 53,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 9,
                  "class_count": 3,
                  "import_count": 14,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/core/saga.py": {
                  "line_count": 35,
                  "non_empty_lines": 27,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 2,
                  "class_count": 3,
                  "import_count": 12,
                  "quality_score": 0.6
                },
                "tradeutility_nexus/trade_nexus/core/bus.py": {
                  "line_count": 72,
                  "non_empty_lines": 56,
                  "comment_lines": 2,
                  "comment_ratio": 0.03571428571428571,
                  "function_count": 7,
                  "class_count": 3,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/trade_nexus/services/risk/assessment.py": {
                  "line_count": 60,
                  "non_empty_lines": 50,
                  "comment_lines": 2,
                  "comment_ratio": 0.04,
                  "function_count": 4,
                  "class_count": 1,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "tradeutility_nexus/main.py": {
                  "line_count": 96,
                  "non_empty_lines": 75,
                  "comment_lines": 10,
                  "comment_ratio": 0.13333333333333333,
                  "function_count": 2,
                  "class_count": 0,
                  "import_count": 20,
                  "quality_score": 0.9999999999999999
                },
                "tradeutility_nexus/trade_nexus/api/server.py": {
                  "line_count": 31,
                  "non_empty_lines": 24,
                  "comment_lines": 2,
                  "comment_ratio": 0.08333333333333333,
                  "function_count": 1,
                  "class_count": 0,
                  "import_count": 6,
                  "quality_score": 0.6
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7906666666666666,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8974137931034484,
                "multi_session_memory_retention": 0.8036637931034485
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4487068965517242,
                "multi_session_memory_retention_weighted": 0.40183189655172424
              },
              "total_longcontext_utilization_score": 0.8505387931034485
            }
          },
          "timestamp": "2026-01-14T21:15:05.614403"
        }
      }
    },
    "python_api_graphql_easy_043_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_api_graphql_easy_043_feature_implementation_expert_01",
          "scenario_title": "Implement Dynamic GraphQL Query Cost Analysis",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5325946787931028,
          "functional_correctness_score": 0.4255510204081633,
          "code_quality_score": 0.8349999999999999,
          "longcontext_utilization_score": 0.82894019019019,
          "total_score": 2.9529859832935457,
          "generation_time": 69.64453101158142,
          "code_files_generated": 4,
          "total_lines_generated": 604,
          "parsing_success": true,
          "solution_code": {
            "cinepulse_hub/config.py": "import os\n\n\nclass Config:\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"dev-secret-key-change-in-production\")\n    DEBUG = os.environ.get(\"DEBUG\", \"True\").lower() in (\"true\", \"1\", \"yes\")\n    GRAPHQL_ENDPOINT = \"/graphql\"\n    \n    # Database configuration\n    DATABASE_URL = os.environ.get(\"DATABASE_URL\", \"sqlite:///cinepulse.db\")\n    \n    # JWT Configuration\n    JWT_ALGORITHM = \"HS256\"\n    JWT_EXPIRATION_HOURS = 24\n    \n    # Query cost analysis configuration\n    MAX_QUERY_COST = int(os.environ.get(\"MAX_QUERY_COST\", \"100\"))\n\n\nclass DevelopmentConfig(Config):\n    DEBUG = True\n\n\nclass ProductionConfig(Config):\n    DEBUG = False\n\n\nclass TestingConfig(Config):\n    TESTING = True\n    DEBUG = True\n    MAX_QUERY_COST = 100\n\n\ndef get_config():\n    env = os.environ.get(\"FLASK_ENV\", \"development\")\n    if env == \"production\":\n        return ProductionConfig()\n    elif env == \"testing\":\n        return TestingConfig()\n    return DevelopmentConfig()\n",
            "cinepulse_hub/app/cost_analysis.py": "from graphql import GraphQLError\nfrom graphql.validation import ValidationRule\nfrom graphql.language import (\n    FieldNode,\n    FragmentSpreadNode,\n    InlineFragmentNode,\n)\n\n\n# Field-specific costs (default is 1)\nFIELD_COSTS = {\n    \"tickets\": 5,\n}\n\n\nclass CostAnalysisRule(ValidationRule):\n    \"\"\"Custom validation rule that calculates query cost and rejects expensive queries.\"\"\"\n    \n    def __init__(self, context, max_cost=100):\n        super().__init__(context)\n        self.max_cost = max_cost\n        self.cost = 0\n        self.fragment_definitions = {}\n        \n        # Pre-collect all fragment definitions\n        if context.document:\n            for definition in context.document.definitions:\n                if hasattr(definition, 'name') and hasattr(definition, 'selection_set'):\n                    if definition.__class__.__name__ == 'FragmentDefinitionNode':\n                        self.fragment_definitions[definition.name.value] = definition\n    \n    def get_field_cost(self, field_name):\n        \"\"\"Get the cost for a specific field.\"\"\"\n        return FIELD_COSTS.get(field_name, 1)\n    \n    def get_multiplier_from_arguments(self, arguments):\n        \"\"\"Extract the 'first' argument value for list multiplier.\"\"\"\n        if not arguments:\n            return 1\n        \n        for arg in arguments:\n            if arg.name.value == \"first\":\n                if hasattr(arg.value, 'value'):\n                    try:\n                        return int(arg.value.value)\n                    except (ValueError, TypeError):\n                        return 1\n        return 1\n    \n    def calculate_selection_cost(self, selection_set, multiplier=1):\n        \"\"\"Recursively calculate the cost of a selection set.\"\"\"\n        if not selection_set:\n            return 0\n        \n        total_cost = 0\n        \n        for selection in selection_set.selections:\n            if isinstance(selection, FieldNode):\n                field_name = selection.name.value\n                \n                # Skip introspection fields\n                if field_name.startswith('__'):\n                    continue\n                \n                # Get base cost for this field\n                field_cost = self.get_field_cost(field_name)\n                \n                # Apply current multiplier\n                field_cost *= multiplier\n                \n                # Check for 'first' argument to determine sub-selection multiplier\n                sub_multiplier = self.get_multiplier_from_arguments(selection.arguments)\n                \n                # Add field cost\n                total_cost += field_cost\n                \n                # Recursively calculate sub-selection cost\n                if selection.selection_set:\n                    sub_cost = self.calculate_selection_cost(\n                        selection.selection_set,\n                        multiplier=sub_multiplier\n                    )\n                    total_cost += sub_cost * multiplier\n            \n            elif isinstance(selection, FragmentSpreadNode):\n                fragment_name = selection.name.value\n                if fragment_name in self.fragment_definitions:\n                    fragment = self.fragment_definitions[fragment_name]\n                    total_cost += self.calculate_selection_cost(\n                        fragment.selection_set,\n                        multiplier=multiplier\n                    )\n            \n            elif isinstance(selection, InlineFragmentNode):\n                total_cost += self.calculate_selection_cost(\n                    selection.selection_set,\n                    multiplier=multiplier\n                )\n        \n        return total_cost\n    \n    def enter_operation_definition(self, node, *args):\n        \"\"\"Called when entering an operation definition (query/mutation).\"\"\"\n        self.cost = self.calculate_selection_cost(node.selection_set)\n        \n        if self.cost > self.max_cost:\n            self.report_error(\n                GraphQLError(\n                    f\"Query is too complex. Max cost allowed is {self.max_cost}, but got {self.cost}.\"\n                )\n            )\n        \n        return None\n\n\ndef create_cost_analysis_rule(max_cost):\n    \"\"\"Factory function to create a CostAnalysisRule with a specific max cost.\"\"\"\n    def rule_factory(context):\n        return CostAnalysisRule(context, max_cost=max_cost)\n    return rule_factory\n",
            "cinepulse_hub/app/main.py": "from flask import Flask, request, jsonify\nfrom flask_graphql import GraphQLView\nfrom graphql import validate, parse\n\nfrom app.schema import schema\nfrom app.middleware.auth import AuthMiddleware\nfrom app.cost_analysis import create_cost_analysis_rule\nfrom config import get_config\n\n\ndef create_app(config=None):\n    app = Flask(__name__)\n    \n    if config is None:\n        config = get_config()\n    \n    app.config.from_object(config)\n    \n    # Store max query cost in app config\n    max_query_cost = getattr(config, 'MAX_QUERY_COST', 100)\n    app.config['MAX_QUERY_COST'] = max_query_cost\n    \n    # Custom GraphQL view with cost analysis\n    class CostAnalyzedGraphQLView(GraphQLView):\n        def dispatch_request(self):\n            # Get the query from the request\n            data = self.parse_body()\n            \n            if data and 'query' in data:\n                query_string = data.get('query', '')\n                \n                if query_string:\n                    try:\n                        # Parse the query\n                        document = parse(query_string)\n                        \n                        # Create cost analysis rule\n                        cost_rule = create_cost_analysis_rule(app.config['MAX_QUERY_COST'])\n                        \n                        # Validate with cost analysis\n                        errors = validate(\n                            schema.graphql_schema,\n                            document,\n                            [cost_rule]\n                        )\n                        \n                        if errors:\n                            # Return cost-related errors\n                            error_messages = [str(error) for error in errors]\n                            return jsonify({\n                                'errors': [{'message': msg} for msg in error_messages]\n                            }), 400\n                    \n                    except Exception as e:\n                        # If parsing fails, let the normal GraphQL handling deal with it\n                        pass\n            \n            # Continue with normal GraphQL execution\n            return super().dispatch_request()\n    \n    # Add GraphQL endpoint with cost analysis\n    app.add_url_rule(\n        app.config.get('GRAPHQL_ENDPOINT', '/graphql'),\n        view_func=CostAnalyzedGraphQLView.as_view(\n            'graphql',\n            schema=schema,\n            graphiql=app.config.get('DEBUG', True),\n            middleware=[AuthMiddleware()]\n        )\n    )\n    \n    @app.route('/health')\n    def health_check():\n        return jsonify({'status': 'healthy', 'service': 'CinePulse GraphQL Hub'})\n    \n    @app.errorhandler(404)\n    def not_found(error):\n        return jsonify({'error': 'Not found'}), 404\n    \n    @app.errorhandler(500)\n    def internal_error(error):\n        return jsonify({'error': 'Internal server error'}), 500\n    \n    return app\n\n\nif __name__ == '__main__':\n    app = create_app()\n    app.run(debug=True, host='0.0.0.0', port=5000)\n",
            "cinepulse_hub/tests/test_query_cost.py": "import pytest\nimport json\nfrom app.main import create_app\nfrom config import TestingConfig\n\n\nclass TestQueryCostConfig(TestingConfig):\n    \"\"\"Test configuration with specific MAX_QUERY_COST.\"\"\"\n    MAX_QUERY_COST = 100\n\n\n@pytest.fixture\ndef app():\n    \"\"\"Create application for testing.\"\"\"\n    config = TestQueryCostConfig()\n    app = create_app(config)\n    app.config['TESTING'] = True\n    return app\n\n\n@pytest.fixture\ndef client(app):\n    \"\"\"Create test client.\"\"\"\n    return app.test_client()\n\n\nclass TestQueryCostAnalysis:\n    \"\"\"Test suite for query cost analysis functionality.\"\"\"\n    \n    def test_simple_query_passes(self, client):\n        \"\"\"Test that a simple query with low cost passes.\"\"\"\n        # Simple query requesting a few fields\n        # Cost: 1 (allMovies) + 1 (id) + 1 (title) + 1 (releaseYear) = 4\n        query = \"\"\"\n        query {\n            allMovies {\n                id\n                title\n                releaseYear\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        # Should not return a cost-related error\n        data = response.get_json()\n        \n        # Check that there's no cost-related error message\n        if 'errors' in data:\n            for error in data['errors']:\n                assert 'Query is too complex' not in error.get('message', ''), \n                    \"Simple query should not be rejected for cost\"\n    \n    def test_complex_nested_query_rejected(self, client):\n        \"\"\"Test that a highly nested/complex query is rejected.\"\"\"\n        # Create a query with many fields that exceeds the cost limit\n        # Each field costs 1, tickets cost 5\n        # This query has deep nesting and many fields\n        query = \"\"\"\n        query {\n            allMovies {\n                id\n                title\n                releaseYear\n                genre\n                duration\n                rating\n                screenings {\n                    id\n                    startTime\n                    endTime\n                    theater {\n                        id\n                        name\n                        capacity\n                        location\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                        user {\n                            id\n                            name\n                            email\n                        }\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                    }\n                }\n            }\n            allTheaters {\n                id\n                name\n                capacity\n                location\n                screenings {\n                    id\n                    startTime\n                    movie {\n                        id\n                        title\n                        genre\n                        duration\n                        rating\n                        releaseYear\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                    }\n                    tickets {\n                        id\n                        seatNumber\n                        price\n                        status\n                    }\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should return an error about query complexity\n        assert 'errors' in data, \"Complex query should return errors\"\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        cost_error_found = any('Query is too complex' in msg for msg in error_messages)\n        assert cost_error_found, f\"Expected cost error, got: {error_messages}\"\n    \n    def test_list_multiplier_small_passes(self, client):\n        \"\"\"Test that a query with first: 10 multiplier passes.\"\"\"\n        # Query with first: 10 multiplier\n        # Cost: 1 (allMovies) + 10 * (1 (id) + 1 (title)) = 1 + 20 = 21\n        query = \"\"\"\n        query {\n            allMovies(first: 10) {\n                id\n                title\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should not return a cost-related error\n        if 'errors' in data:\n            for error in data['errors']:\n                assert 'Query is too complex' not in error.get('message', ''), \n                    f\"Query with first:10 should pass, got: {error.get('message')}\"\n    \n    def test_list_multiplier_large_fails(self, client):\n        \"\"\"Test that a query with first: 50 multiplier fails due to exceeding MAX_QUERY_COST.\"\"\"\n        # Query with first: 50 multiplier\n        # Cost: 1 (allMovies) + 50 * (1 (id) + 1 (title) + 1 (releaseYear)) = 1 + 150 = 151\n        # This exceeds MAX_QUERY_COST of 100\n        query = \"\"\"\n        query {\n            allMovies(first: 50) {\n                id\n                title\n                releaseYear\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should return an error about query complexity\n        assert 'errors' in data, \"Query with first:50 should return errors\"\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        cost_error_found = any('Query is too complex' in msg for msg in error_messages)\n        assert cost_error_found, f\"Expected cost error for first:50 query, got: {error_messages}\"\n    \n    def test_tickets_field_has_higher_cost(self, client):\n        \"\"\"Test that the tickets field has a higher cost (5 instead of 1).\"\"\"\n        # Query that would pass if tickets cost 1, but fails because tickets cost 5\n        # With first: 20 and tickets costing 5:\n        # Cost: 1 (screening) + 20 * (1 (id) + 5 (tickets) + 1 (id inside tickets)) = 1 + 20 * 7 = 141\n        query = \"\"\"\n        query {\n            screening(id: \"1\") {\n                id\n            }\n            allScreenings(first: 20) {\n                id\n                tickets {\n                    id\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should return an error about query complexity because tickets cost 5\n        assert 'errors' in data, \"Query with tickets field should return errors due to high cost\"\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        cost_error_found = any('Query is too complex' in msg for msg in error_messages)\n        assert cost_error_found, f\"Expected cost error due to tickets field, got: {error_messages}\"\n    \n    def test_introspection_query_allowed(self, client):\n        \"\"\"Test that introspection queries are allowed (they skip cost calculation).\"\"\"\n        query = \"\"\"\n        query {\n            __schema {\n                types {\n                    name\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should not return a cost-related error for introspection\n        if 'errors' in data:\n            for error in data['errors']:\n                assert 'Query is too complex' not in error.get('message', ''), \n                    \"Introspection query should not be rejected for cost\"\n    \n    def test_error_message_format(self, client):\n        \"\"\"Test that the error message contains the correct format with max and actual cost.\"\"\"\n        # Create a query that definitely exceeds the limit\n        query = \"\"\"\n        query {\n            allMovies(first: 100) {\n                id\n                title\n                releaseYear\n                genre\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': query}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        assert 'errors' in data\n        \n        error_messages = [e.get('message', '') for e in data.get('errors', [])]\n        \n        # Check that error message contains expected format\n        found_proper_message = False\n        for msg in error_messages:\n            if 'Query is too complex' in msg and 'Max cost allowed is' in msg:\n                found_proper_message = True\n                # Verify it mentions the max cost (100)\n                assert '100' in msg, f\"Error should mention max cost of 100, got: {msg}\"\n                break\n        \n        assert found_proper_message, f\"Expected properly formatted cost error, got: {error_messages}\"\n\n\nclass TestQueryCostEdgeCases:\n    \"\"\"Test edge cases for query cost analysis.\"\"\"\n    \n    def test_empty_query_body(self, client):\n        \"\"\"Test handling of empty query body.\"\"\"\n        response = client.post(\n            '/graphql',\n            data=json.dumps({}),\n            content_type='application/json'\n        )\n        \n        # Should handle gracefully, not crash\n        assert response.status_code in [200, 400]\n    \n    def test_mutation_cost_calculated(self, client):\n        \"\"\"Test that mutations also have their cost calculated.\"\"\"\n        # Simple mutation that should pass\n        mutation = \"\"\"\n        mutation {\n            createMovie(input: {title: \"Test\", releaseYear: 2024}) {\n                movie {\n                    id\n                    title\n                }\n            }\n        }\n        \"\"\"\n        \n        response = client.post(\n            '/graphql',\n            data=json.dumps({'query': mutation}),\n            content_type='application/json'\n        )\n        \n        data = response.get_json()\n        \n        # Should not return a cost-related error for simple mutation\n        if 'errors' in data:\n            for error in data['errors']:\n                # Ignore other errors (like missing auth), just check no cost error\n                if 'Query is too complex' in error.get('message', ''):\n                    pytest.fail(\"Simple mutation should not be rejected for cost\")\n"
          },
          "generated_files": [
            "cinepulse_hub/config.py",
            "cinepulse_hub/app/cost_analysis.py",
            "cinepulse_hub/app/main.py",
            "cinepulse_hub/tests/test_query_cost.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7885463659147871,
                "dependency_traversal_accuracy": 0.7712438725490196,
                "cross_file_reasoning_depth": 0.45166666666666666,
                "system_thinking_score": 0.5587545656741216,
                "robustness_score": 0.4162251655629139,
                "comprehensiveness_score": 0.49449184921039224,
                "innovation_score": 0.19375,
                "solution_elegance_score": 0.5860789447669217
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09856829573934839,
                "dependency_traversal_weighted": 0.09640548406862745,
                "cross_file_reasoning_weighted": 0.05645833333333333,
                "system_thinking_weighted": 0.0698443207092652,
                "robustness_weighted": 0.052028145695364236,
                "comprehensiveness_weighted": 0.06181148115129903,
                "innovation_weighted": 0.02421875,
                "solution_elegance_weighted": 0.07325986809586521
              },
              "total_software_engineering_score": 0.5325946787931028
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.26151275634765625,
                "errors": [
                  "  File \"cinepulse_hub/tests/test_query_cost.py\", line 56",
                  "    assert 'Query is too complex' not in error.get('message', ''), ",
                  "                                                                   ^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "cinepulse_hub/config.py",
                  "cinepulse_hub/app/cost_analysis.py",
                  "cinepulse_hub/app/main.py",
                  "cinepulse_hub/tests/test_query_cost.py"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 4,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 4 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.42775510204081635,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.42775510204081635,
                "idc_weight": 0.2,
                "total_functional_score": 0.4255510204081633
              }
            },
            "code_quality_details": {
              "files_analyzed": 4,
              "quality_checks": {
                "cinepulse_hub/config.py": {
                  "line_count": 41,
                  "non_empty_lines": 27,
                  "comment_lines": 3,
                  "comment_ratio": 0.1111111111111111,
                  "function_count": 1,
                  "class_count": 4,
                  "import_count": 1,
                  "quality_score": 0.7999999999999999
                },
                "cinepulse_hub/app/cost_analysis.py": {
                  "line_count": 121,
                  "non_empty_lines": 94,
                  "comment_lines": 8,
                  "comment_ratio": 0.0851063829787234,
                  "function_count": 7,
                  "class_count": 1,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "cinepulse_hub/app/main.py": {
                  "line_count": 90,
                  "non_empty_lines": 68,
                  "comment_lines": 10,
                  "comment_ratio": 0.14705882352941177,
                  "function_count": 5,
                  "class_count": 1,
                  "import_count": 15,
                  "quality_score": 0.9999999999999999
                },
                "cinepulse_hub/tests/test_query_cost.py": {
                  "line_count": 352,
                  "non_empty_lines": 301,
                  "comment_lines": 27,
                  "comment_ratio": 0.08970099667774087,
                  "function_count": 11,
                  "class_count": 3,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.8349999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8639864864864865,
                "multi_session_memory_retention": 0.7938938938938938
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.43199324324324323,
                "multi_session_memory_retention_weighted": 0.3969469469469469
              },
              "total_longcontext_utilization_score": 0.82894019019019
            }
          },
          "timestamp": "2026-01-14T21:18:30.643514"
        }
      }
    },
    "python_web_blog_easy_004_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_web_blog_easy_004_feature_implementation_expert_01",
          "scenario_title": "Implement Post Versioning and Scheduled Publishing",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.4825952696218453,
          "functional_correctness_score": 0.35138226299694186,
          "code_quality_score": 0.7377777777777776,
          "longcontext_utilization_score": 0.8086268939393939,
          "total_score": 2.634355158486578,
          "generation_time": 132.9356598854065,
          "code_files_generated": 9,
          "total_lines_generated": 1527,
          "parsing_success": true,
          "solution_code": {
            "focusflow_blog/focusflow/models.py": "from datetime import datetime\nfrom focusflow import db\n\n\nclass User(db.Model):\n    __tablename__ = 'users'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n    password_hash = db.Column(db.String(256), nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    posts = db.relationship('Post', backref='author', lazy='dynamic')\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'username': self.username,\n            'email': self.email,\n            'created_at': self.created_at.isoformat() if self.created_at else None\n        }\n\n\nclass Post(db.Model):\n    __tablename__ = 'posts'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(200), nullable=False)\n    content = db.Column(db.Text, nullable=False)\n    status = db.Column(db.String(20), default='draft', nullable=False)\n    scheduled_for = db.Column(db.DateTime, nullable=True)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    \n    versions = db.relationship('PostVersion', backref='post', lazy='dynamic', cascade='all, delete-orphan')\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'title': self.title,\n            'content': self.content,\n            'status': self.status,\n            'scheduled_for': self.scheduled_for.isoformat() if self.scheduled_for else None,\n            'created_at': self.created_at.isoformat() if self.created_at else None,\n            'updated_at': self.updated_at.isoformat() if self.updated_at else None,\n            'user_id': self.user_id,\n            'author': self.author.username if self.author else None\n        }\n\n\nclass PostVersion(db.Model):\n    __tablename__ = 'post_versions'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    post_id = db.Column(db.Integer, db.ForeignKey('posts.id'), nullable=False)\n    title = db.Column(db.String(200), nullable=False)\n    content = db.Column(db.Text, nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'post_id': self.post_id,\n            'title': self.title,\n            'content': self.content,\n            'created_at': self.created_at.isoformat() if self.created_at else None\n        }\n\n\nclass Tag(db.Model):\n    __tablename__ = 'tags'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(50), unique=True, nullable=False)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'name': self.name\n        }\n",
            "focusflow_blog/focusflow/services.py": "from datetime import datetime\nfrom focusflow import db\nfrom focusflow.models import User, Post, PostVersion, Tag\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\n\n# User Services\ndef create_user(username, email, password):\n    \"\"\"Create a new user with hashed password.\"\"\"\n    password_hash = generate_password_hash(password)\n    user = User(username=username, email=email, password_hash=password_hash)\n    db.session.add(user)\n    db.session.commit()\n    return user\n\n\ndef get_user_by_id(user_id):\n    \"\"\"Get a user by their ID.\"\"\"\n    return User.query.get(user_id)\n\n\ndef get_user_by_username(username):\n    \"\"\"Get a user by their username.\"\"\"\n    return User.query.filter_by(username=username).first()\n\n\ndef get_user_by_email(email):\n    \"\"\"Get a user by their email.\"\"\"\n    return User.query.filter_by(email=email).first()\n\n\ndef authenticate_user(username, password):\n    \"\"\"Authenticate a user by username and password.\"\"\"\n    user = get_user_by_username(username)\n    if user and check_password_hash(user.password_hash, password):\n        return user\n    return None\n\n\ndef get_all_users():\n    \"\"\"Get all users.\"\"\"\n    return User.query.all()\n\n\n# Post Services\ndef create_post(title, content, user_id, status='draft', scheduled_for=None):\n    \"\"\"Create a new post and save initial version.\"\"\"\n    post = Post(\n        title=title,\n        content=content,\n        user_id=user_id,\n        status=status,\n        scheduled_for=scheduled_for\n    )\n    db.session.add(post)\n    db.session.commit()\n    \n    # Create initial version\n    _create_post_version(post)\n    \n    return post\n\n\ndef get_post_by_id(post_id):\n    \"\"\"Get a post by its ID.\"\"\"\n    return Post.query.get(post_id)\n\n\ndef get_all_posts():\n    \"\"\"Get all posts.\"\"\"\n    return Post.query.order_by(Post.created_at.desc()).all()\n\n\ndef get_published_posts():\n    \"\"\"Get all published posts.\"\"\"\n    return Post.query.filter_by(status='published').order_by(Post.created_at.desc()).all()\n\n\ndef get_posts_by_user(user_id):\n    \"\"\"Get all posts by a specific user.\"\"\"\n    return Post.query.filter_by(user_id=user_id).order_by(Post.created_at.desc()).all()\n\n\ndef update_post(post_id, title=None, content=None, status=None, scheduled_for=None):\n    \"\"\"Update a post and create a new version.\"\"\"\n    post = get_post_by_id(post_id)\n    if not post:\n        return None\n    \n    if title is not None:\n        post.title = title\n    if content is not None:\n        post.content = content\n    if status is not None:\n        post.status = status\n    if scheduled_for is not None:\n        post.scheduled_for = scheduled_for\n    \n    post.updated_at = datetime.utcnow()\n    db.session.commit()\n    \n    # Create a new version after update\n    _create_post_version(post)\n    \n    return post\n\n\ndef delete_post(post_id):\n    \"\"\"Delete a post by its ID.\"\"\"\n    post = get_post_by_id(post_id)\n    if post:\n        db.session.delete(post)\n        db.session.commit()\n        return True\n    return False\n\n\n# Post Version Services\ndef _create_post_version(post):\n    \"\"\"Create a new version snapshot of a post (internal helper).\"\"\"\n    version = PostVersion(\n        post_id=post.id,\n        title=post.title,\n        content=post.content\n    )\n    db.session.add(version)\n    db.session.commit()\n    return version\n\n\ndef get_post_versions(post_id):\n    \"\"\"Get all versions for a specific post.\"\"\"\n    return PostVersion.query.filter_by(post_id=post_id).order_by(PostVersion.created_at.desc()).all()\n\n\ndef get_version_by_id(version_id):\n    \"\"\"Get a specific version by its ID.\"\"\"\n    return PostVersion.query.get(version_id)\n\n\ndef revert_to_version(post_id, version_id):\n    \"\"\"Revert a post to a specific version.\"\"\"\n    post = get_post_by_id(post_id)\n    if not post:\n        return None, \"Post not found\"\n    \n    version = get_version_by_id(version_id)\n    if not version:\n        return None, \"Version not found\"\n    \n    if version.post_id != post_id:\n        return None, \"Version does not belong to this post\"\n    \n    # Update post with version content\n    post.title = version.title\n    post.content = version.content\n    post.updated_at = datetime.utcnow()\n    db.session.commit()\n    \n    # Create a new version to record the revert action\n    _create_post_version(post)\n    \n    return post, None\n\n\n# Scheduled Publishing Services\ndef publish_scheduled_posts():\n    \"\"\"Publish all posts that are scheduled and past their scheduled time.\"\"\"\n    now = datetime.utcnow()\n    scheduled_posts = Post.query.filter(\n        Post.status == 'scheduled',\n        Post.scheduled_for <= now\n    ).all()\n    \n    published_count = 0\n    for post in scheduled_posts:\n        post.status = 'published'\n        post.updated_at = now\n        published_count += 1\n    \n    if published_count > 0:\n        db.session.commit()\n    \n    return published_count\n\n\ndef get_scheduled_posts():\n    \"\"\"Get all scheduled posts.\"\"\"\n    return Post.query.filter_by(status='scheduled').order_by(Post.scheduled_for.asc()).all()\n\n\n# Tag Services\ndef create_tag(name):\n    \"\"\"Create a new tag.\"\"\"\n    tag = Tag(name=name)\n    db.session.add(tag)\n    db.session.commit()\n    return tag\n\n\ndef get_tag_by_id(tag_id):\n    \"\"\"Get a tag by its ID.\"\"\"\n    return Tag.query.get(tag_id)\n\n\ndef get_tag_by_name(name):\n    \"\"\"Get a tag by its name.\"\"\"\n    return Tag.query.filter_by(name=name).first()\n\n\ndef get_all_tags():\n    \"\"\"Get all tags.\"\"\"\n    return Tag.query.all()\n",
            "focusflow_blog/focusflow/api.py": "from flask import Blueprint, request, jsonify\nfrom datetime import datetime\nfrom focusflow import services\n\napi_bp = Blueprint('api', __name__, url_prefix='/api')\n\n\n# User Endpoints\n@api_bp.route('/users', methods=['GET'])\ndef get_users():\n    \"\"\"Get all users.\"\"\"\n    users = services.get_all_users()\n    return jsonify([user.to_dict() for user in users]), 200\n\n\n@api_bp.route('/users/<int:user_id>', methods=['GET'])\ndef get_user(user_id):\n    \"\"\"Get a specific user by ID.\"\"\"\n    user = services.get_user_by_id(user_id)\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    return jsonify(user.to_dict()), 200\n\n\n@api_bp.route('/users', methods=['POST'])\ndef create_user():\n    \"\"\"Create a new user.\"\"\"\n    data = request.get_json()\n    \n    if not data:\n        return jsonify({'error': 'No data provided'}), 400\n    \n    required_fields = ['username', 'email', 'password']\n    for field in required_fields:\n        if field not in data:\n            return jsonify({'error': f'Missing required field: {field}'}), 400\n    \n    # Check if user already exists\n    if services.get_user_by_username(data['username']):\n        return jsonify({'error': 'Username already exists'}), 409\n    if services.get_user_by_email(data['email']):\n        return jsonify({'error': 'Email already exists'}), 409\n    \n    user = services.create_user(\n        username=data['username'],\n        email=data['email'],\n        password=data['password']\n    )\n    return jsonify(user.to_dict()), 201\n\n\n# Post Endpoints\n@api_bp.route('/posts', methods=['GET'])\ndef get_posts():\n    \"\"\"Get all posts.\"\"\"\n    status_filter = request.args.get('status')\n    if status_filter == 'published':\n        posts = services.get_published_posts()\n    elif status_filter == 'scheduled':\n        posts = services.get_scheduled_posts()\n    else:\n        posts = services.get_all_posts()\n    return jsonify([post.to_dict() for post in posts]), 200\n\n\n@api_bp.route('/posts/<int:post_id>', methods=['GET'])\ndef get_post(post_id):\n    \"\"\"Get a specific post by ID.\"\"\"\n    post = services.get_post_by_id(post_id)\n    if not post:\n        return jsonify({'error': 'Post not found'}), 404\n    return jsonify(post.to_dict()), 200\n\n\n@api_bp.route('/posts', methods=['POST'])\ndef create_post():\n    \"\"\"Create a new post.\"\"\"\n    data = request.get_json()\n    \n    if not data:\n        return jsonify({'error': 'No data provided'}), 400\n    \n    required_fields = ['title', 'content', 'user_id']\n    for field in required_fields:\n        if field not in data:\n            return jsonify({'error': f'Missing required field: {field}'}), 400\n    \n    # Verify user exists\n    user = services.get_user_by_id(data['user_id'])\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    \n    # Parse scheduled_for if provided\n    scheduled_for = None\n    if 'scheduled_for' in data and data['scheduled_for']:\n        try:\n            scheduled_for = datetime.fromisoformat(data['scheduled_for'].replace('Z', '+00:00'))\n        except (ValueError, AttributeError):\n            return jsonify({'error': 'Invalid scheduled_for format. Use ISO 8601 format.'}), 400\n    \n    status = data.get('status', 'draft')\n    if status not in ['draft', 'scheduled', 'published']:\n        return jsonify({'error': 'Invalid status. Must be draft, scheduled, or published.'}), 400\n    \n    post = services.create_post(\n        title=data['title'],\n        content=data['content'],\n        user_id=data['user_id'],\n        status=status,\n        scheduled_for=scheduled_for\n    )\n    return jsonify(post.to_dict()), 201\n\n\n@api_bp.route('/posts/<int:post_id>', methods=['PUT'])\ndef update_post(post_id):\n    \"\"\"Update a post.\"\"\"\n    post = services.get_post_by_id(post_id)\n    if not post:\n        return jsonify({'error': 'Post not found'}), 404\n    \n    data = request.get_json()\n    if not data:\n        return jsonify({'error': 'No data provided'}), 400\n    \n    # Parse scheduled_for if provided\n    scheduled_for = None\n    if 'scheduled_for' in data:\n        if data['scheduled_for']:\n            try:\n                scheduled_for = datetime.fromisoformat(data['scheduled_for'].replace('Z', '+00:00'))\n            except (ValueError, AttributeError):\n                return jsonify({'error': 'Invalid scheduled_for format. Use ISO 8601 format.'}), 400\n        else:\n            scheduled_for = None\n    \n    # Validate status if provided\n    status = data.get('status')\n    if status and status not in ['draft', 'scheduled', 'published']:\n        return jsonify({'error': 'Invalid status. Must be draft, scheduled, or published.'}), 400\n    \n    updated_post = services.update_post(\n        post_id=post_id,\n        title=data.get('title'),\n        content=data.get('content'),\n        status=status,\n        scheduled_for=scheduled_for if 'scheduled_for' in data else post.scheduled_for\n    )\n    return jsonify(updated_post.to_dict()), 200\n\n\n@api_bp.route('/posts/<int:post_id>', methods=['DELETE'])\ndef delete_post(post_id):\n    \"\"\"Delete a post.\"\"\"\n    if services.delete_post(post_id):\n        return jsonify({'message': 'Post deleted successfully'}), 200\n    return jsonify({'error': 'Post not found'}), 404\n\n\n# Post Version Endpoints\n@api_bp.route('/posts/<int:post_id>/versions', methods=['GET'])\ndef get_post_versions(post_id):\n    \"\"\"Get all versions for a specific post.\"\"\"\n    post = services.get_post_by_id(post_id)\n    if not post:\n        return jsonify({'error': 'Post not found'}), 404\n    \n    versions = services.get_post_versions(post_id)\n    return jsonify([version.to_dict() for version in versions]), 200\n\n\n@api_bp.route('/posts/<int:post_id>/revert/<int:version_id>', methods=['POST'])\ndef revert_post_to_version(post_id, version_id):\n    \"\"\"Revert a post to a specific version.\"\"\"\n    post, error = services.revert_to_version(post_id, version_id)\n    \n    if error:\n        if error == \"Post not found\":\n            return jsonify({'error': error}), 404\n        elif error == \"Version not found\":\n            return jsonify({'error': error}), 404\n        else:\n            return jsonify({'error': error}), 400\n    \n    return jsonify({\n        'message': 'Post reverted successfully',\n        'post': post.to_dict()\n    }), 200\n\n\n# User Posts Endpoint\n@api_bp.route('/users/<int:user_id>/posts', methods=['GET'])\ndef get_user_posts(user_id):\n    \"\"\"Get all posts by a specific user.\"\"\"\n    user = services.get_user_by_id(user_id)\n    if not user:\n        return jsonify({'error': 'User not found'}), 404\n    \n    posts = services.get_posts_by_user(user_id)\n    return jsonify([post.to_dict() for post in posts]), 200\n\n\n# Tag Endpoints\n@api_bp.route('/tags', methods=['GET'])\ndef get_tags():\n    \"\"\"Get all tags.\"\"\"\n    tags = services.get_all_tags()\n    return jsonify([tag.to_dict() for tag in tags]), 200\n\n\n@api_bp.route('/tags', methods=['POST'])\ndef create_tag():\n    \"\"\"Create a new tag.\"\"\"\n    data = request.get_json()\n    \n    if not data or 'name' not in data:\n        return jsonify({'error': 'Tag name is required'}), 400\n    \n    if services.get_tag_by_name(data['name']):\n        return jsonify({'error': 'Tag already exists'}), 409\n    \n    tag = services.create_tag(data['name'])\n    return jsonify(tag.to_dict()), 201\n\n\n# Health Check\n@api_bp.route('/health', methods=['GET'])\ndef health_check():\n    \"\"\"API health check endpoint.\"\"\"\n    return jsonify({'status': 'healthy', 'message': 'FocusFlow Blog API is running'}), 200\n",
            "focusflow_blog/focusflow/__init__.py": "from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom config import Config\n\ndb = SQLAlchemy()\n\n\ndef create_app(config_class=Config):\n    \"\"\"Application factory for creating Flask app instances.\"\"\"\n    app = Flask(__name__)\n    app.config.from_object(config_class)\n    \n    # Initialize extensions\n    db.init_app(app)\n    \n    # Register blueprints\n    from focusflow.api import api_bp\n    app.register_blueprint(api_bp)\n    \n    # Create database tables\n    with app.app_context():\n        db.create_all()\n    \n    return app\n\n\ndef init_scheduler(app):\n    \"\"\"Initialize the APScheduler for background tasks.\"\"\"\n    from apscheduler.schedulers.background import BackgroundScheduler\n    from focusflow import services\n    \n    scheduler = BackgroundScheduler()\n    \n    def publish_scheduled_posts_job():\n        \"\"\"Job function to publish scheduled posts.\"\"\"\n        with app.app_context():\n            count = services.publish_scheduled_posts()\n            if count > 0:\n                app.logger.info(f'Published {count} scheduled post(s)')\n    \n    # Schedule the job to run every 5 minutes\n    scheduler.add_job(\n        func=publish_scheduled_posts_job,\n        trigger='interval',\n        minutes=5,\n        id='publish_scheduled_posts',\n        name='Publish scheduled posts',\n        replace_existing=True\n    )\n    \n    scheduler.start()\n    app.logger.info('Background scheduler started')\n    \n    return scheduler\n",
            "focusflow_blog/run.py": "import atexit\nfrom focusflow import create_app, init_scheduler\n\napp = create_app()\n\n# Initialize the scheduler for background tasks\nscheduler = None\n\nif __name__ == '__main__':\n    # Only start scheduler when running directly (not in testing)\n    scheduler = init_scheduler(app)\n    \n    # Ensure scheduler shuts down when app exits\n    atexit.register(lambda: scheduler.shutdown() if scheduler else None)\n    \n    app.run(debug=True, use_reloader=False)\n",
            "focusflow_blog/config.py": "import os\n\nbasedir = os.path.abspath(os.path.dirname(__file__))\n\n\nclass Config:\n    \"\"\"Base configuration class.\"\"\"\n    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key-change-in-production'\n    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or \n        'sqlite:///' + os.path.join(basedir, 'focusflow.db')\n    SQLALCHEMY_TRACK_MODIFICATIONS = False\n\n\nclass TestConfig(Config):\n    \"\"\"Testing configuration.\"\"\"\n    TESTING = True\n    SQLALCHEMY_DATABASE_URI = 'sqlite:///:memory:'\n    WTF_CSRF_ENABLED = False\n\n\nclass ProductionConfig(Config):\n    \"\"\"Production configuration.\"\"\"\n    DEBUG = False\n",
            "focusflow_blog/tests/test_core.py": "import pytest\nfrom datetime import datetime, timedelta\nfrom focusflow import create_app, db\nfrom focusflow.models import User, Post, PostVersion\nfrom focusflow import services\nfrom config import TestConfig\n\n\n@pytest.fixture\ndef app():\n    \"\"\"Create application for testing.\"\"\"\n    app = create_app(TestConfig)\n    with app.app_context():\n        db.create_all()\n        yield app\n        db.drop_all()\n\n\n@pytest.fixture\ndef client(app):\n    \"\"\"Create test client.\"\"\"\n    return app.test_client()\n\n\n@pytest.fixture\ndef sample_user(app):\n    \"\"\"Create a sample user for testing.\"\"\"\n    with app.app_context():\n        user = services.create_user(\n            username='testuser',\n            email='test@example.com',\n            password='password123'\n        )\n        return user.id\n\n\n@pytest.fixture\ndef sample_post(app, sample_user):\n    \"\"\"Create a sample post for testing.\"\"\"\n    with app.app_context():\n        post = services.create_post(\n            title='Test Post',\n            content='Test content',\n            user_id=sample_user\n        )\n        return post.id\n\n\nclass TestUserServices:\n    \"\"\"Test user-related services.\"\"\"\n    \n    def test_create_user(self, app):\n        with app.app_context():\n            user = services.create_user('newuser', 'new@example.com', 'password')\n            assert user.id is not None\n            assert user.username == 'newuser'\n            assert user.email == 'new@example.com'\n    \n    def test_get_user_by_id(self, app, sample_user):\n        with app.app_context():\n            user = services.get_user_by_id(sample_user)\n            assert user is not None\n            assert user.username == 'testuser'\n    \n    def test_authenticate_user(self, app, sample_user):\n        with app.app_context():\n            user = services.authenticate_user('testuser', 'password123')\n            assert user is not None\n            assert user.id == sample_user\n    \n    def test_authenticate_user_wrong_password(self, app, sample_user):\n        with app.app_context():\n            user = services.authenticate_user('testuser', 'wrongpassword')\n            assert user is None\n\n\nclass TestPostServices:\n    \"\"\"Test post-related services.\"\"\"\n    \n    def test_create_post(self, app, sample_user):\n        with app.app_context():\n            post = services.create_post('New Post', 'Content here', sample_user)\n            assert post.id is not None\n            assert post.title == 'New Post'\n            assert post.status == 'draft'\n    \n    def test_create_post_with_status(self, app, sample_user):\n        with app.app_context():\n            post = services.create_post(\n                'Published Post',\n                'Content',\n                sample_user,\n                status='published'\n            )\n            assert post.status == 'published'\n    \n    def test_create_post_with_scheduled_for(self, app, sample_user):\n        with app.app_context():\n            future_time = datetime.utcnow() + timedelta(days=1)\n            post = services.create_post(\n                'Scheduled Post',\n                'Content',\n                sample_user,\n                status='scheduled',\n                scheduled_for=future_time\n            )\n            assert post.status == 'scheduled'\n            assert post.scheduled_for is not None\n    \n    def test_update_post(self, app, sample_post):\n        with app.app_context():\n            post = services.update_post(\n                sample_post,\n                title='Updated Title',\n                content='Updated content'\n            )\n            assert post.title == 'Updated Title'\n            assert post.content == 'Updated content'\n    \n    def test_update_post_status(self, app, sample_post):\n        with app.app_context():\n            post = services.update_post(sample_post, status='published')\n            assert post.status == 'published'\n    \n    def test_delete_post(self, app, sample_post):\n        with app.app_context():\n            result = services.delete_post(sample_post)\n            assert result is True\n            post = services.get_post_by_id(sample_post)\n            assert post is None\n\n\nclass TestPostVersionServices:\n    \"\"\"Test post versioning services.\"\"\"\n    \n    def test_version_created_on_post_creation(self, app, sample_user):\n        with app.app_context():\n            post = services.create_post('Test', 'Content', sample_user)\n            versions = services.get_post_versions(post.id)\n            assert len(versions) == 1\n            assert versions[0].title == 'Test'\n            assert versions[0].content == 'Content'\n    \n    def test_version_created_on_post_update(self, app, sample_post):\n        with app.app_context():\n            # Initial version exists from creation\n            initial_versions = services.get_post_versions(sample_post)\n            assert len(initial_versions) == 1\n            \n            # Update the post\n            services.update_post(sample_post, title='Updated Title')\n            \n            # Should now have 2 versions\n            versions = services.get_post_versions(sample_post)\n            assert len(versions) == 2\n    \n    def test_revert_to_version(self, app, sample_post):\n        with app.app_context():\n            # Get initial version\n            initial_versions = services.get_post_versions(sample_post)\n            initial_version = initial_versions[0]\n            \n            # Update the post\n            services.update_post(\n                sample_post,\n                title='New Title',\n                content='New Content'\n            )\n            \n            # Verify update\n            post = services.get_post_by_id(sample_post)\n            assert post.title == 'New Title'\n            \n            # Revert to initial version\n            reverted_post, error = services.revert_to_version(\n                sample_post,\n                initial_version.id\n            )\n            \n            assert error is None\n            assert reverted_post.title == 'Test Post'\n            assert reverted_post.content == 'Test content'\n    \n    def test_revert_to_nonexistent_version(self, app, sample_post):\n        with app.app_context():\n            post, error = services.revert_to_version(sample_post, 99999)\n            assert post is None\n            assert error == \"Version not found\"\n    \n    def test_revert_to_wrong_post_version(self, app, sample_user):\n        with app.app_context():\n            # Create two posts\n            post1 = services.create_post('Post 1', 'Content 1', sample_user)\n            post2 = services.create_post('Post 2', 'Content 2', sample_user)\n            \n            # Get version from post2\n            post2_versions = services.get_post_versions(post2.id)\n            \n            # Try to revert post1 to post2's version\n            result, error = services.revert_to_version(\n                post1.id,\n                post2_versions[0].id\n            )\n            \n            assert result is None\n            assert error == \"Version does not belong to this post\"\n\n\nclass TestScheduledPublishing:\n    \"\"\"Test scheduled publishing services.\"\"\"\n    \n    def test_publish_scheduled_posts(self, app, sample_user):\n        with app.app_context():\n            # Create a post scheduled for the past\n            past_time = datetime.utcnow() - timedelta(hours=1)\n            post = services.create_post(\n                'Scheduled Post',\n                'Content',\n                sample_user,\n                status='scheduled',\n                scheduled_for=past_time\n            )\n            \n            # Run the publish job\n            count = services.publish_scheduled_posts()\n            \n            assert count == 1\n            \n            # Verify post is now published\n            updated_post = services.get_post_by_id(post.id)\n            assert updated_post.status == 'published'\n    \n    def test_publish_scheduled_posts_future(self, app, sample_user):\n        with app.app_context():\n            # Create a post scheduled for the future\n            future_time = datetime.utcnow() + timedelta(hours=1)\n            post = services.create_post(\n                'Future Post',\n                'Content',\n                sample_user,\n                status='scheduled',\n                scheduled_for=future_time\n            )\n            \n            # Run the publish job\n            count = services.publish_scheduled_posts()\n            \n            assert count == 0\n            \n            # Verify post is still scheduled\n            updated_post = services.get_post_by_id(post.id)\n            assert updated_post.status == 'scheduled'\n    \n    def test_publish_scheduled_posts_draft_not_affected(self, app, sample_user):\n        with app.app_context():\n            # Create a draft post\n            post = services.create_post(\n                'Draft Post',\n                'Content',\n                sample_user,\n                status='draft'\n            )\n            \n            # Run the publish job\n            count = services.publish_scheduled_posts()\n            \n            assert count == 0\n            \n            # Verify post is still draft\n            updated_post = services.get_post_by_id(post.id)\n            assert updated_post.status == 'draft'\n\n\nclass TestAPIEndpoints:\n    \"\"\"Test API endpoints.\"\"\"\n    \n    def test_health_check(self, client):\n        response = client.get('/api/health')\n        assert response.status_code == 200\n        data = response.get_json()\n        assert data['status'] == 'healthy'\n    \n    def test_create_user_api(self, client):\n        response = client.post('/api/users', json={\n            'username': 'apiuser',\n            'email': 'api@example.com',\n            'password': 'password123'\n        })\n        assert response.status_code == 201\n        data = response.get_json()\n        assert data['username'] == 'apiuser'\n    \n    def test_create_post_api(self, client, app, sample_user):\n        with app.app_context():\n            response = client.post('/api/posts', json={\n                'title': 'API Post',\n                'content': 'Content from API',\n                'user_id': sample_user\n            })\n            assert response.status_code == 201\n            data = response.get_json()\n            assert data['title'] == 'API Post'\n            assert data['status'] == 'draft'\n    \n    def test_create_scheduled_post_api(self, client, app, sample_user):\n        with app.app_context():\n            future_time = (datetime.utcnow() + timedelta(days=1)).isoformat()\n            response = client.post('/api/posts', json={\n                'title': 'Scheduled API Post',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'scheduled',\n                'scheduled_for': future_time\n            })\n            assert response.status_code == 201\n            data = response.get_json()\n            assert data['status'] == 'scheduled'\n            assert data['scheduled_for'] is not None\n    \n    def test_update_post_api(self, client, app, sample_post):\n        with app.app_context():\n            response = client.put(f'/api/posts/{sample_post}', json={\n                'title': 'Updated via API',\n                'status': 'published'\n            })\n            assert response.status_code == 200\n            data = response.get_json()\n            assert data['title'] == 'Updated via API'\n            assert data['status'] == 'published'\n    \n    def test_get_post_versions_api(self, client, app, sample_post):\n        with app.app_context():\n            response = client.get(f'/api/posts/{sample_post}/versions')\n            assert response.status_code == 200\n            data = response.get_json()\n            assert len(data) >= 1\n            assert data[0]['title'] == 'Test Post'\n    \n    def test_revert_post_api(self, client, app, sample_post):\n        with app.app_context():\n            # First update the post\n            client.put(f'/api/posts/{sample_post}', json={\n                'title': 'Changed Title'\n            })\n            \n            # Get versions\n            versions_response = client.get(f'/api/posts/{sample_post}/versions')\n            versions = versions_response.get_json()\n            \n            # Find the original version (oldest)\n            original_version = sorted(versions, key=lambda x: x['created_at'])[0]\n            \n            # Revert to original\n            response = client.post(\n                f'/api/posts/{sample_post}/revert/{original_version[\"id\"]}'\n            )\n            assert response.status_code == 200\n            data = response.get_json()\n            assert data['post']['title'] == 'Test Post'\n    \n    def test_get_post_versions_not_found(self, client):\n        response = client.get('/api/posts/99999/versions')\n        assert response.status_code == 404\n    \n    def test_revert_post_not_found(self, client):\n        response = client.post('/api/posts/99999/revert/1')\n        assert response.status_code == 404\n    \n    def test_create_post_invalid_status(self, client, app, sample_user):\n        with app.app_context():\n            response = client.post('/api/posts', json={\n                'title': 'Test',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'invalid_status'\n            })\n            assert response.status_code == 400\n    \n    def test_get_posts_filtered_by_status(self, client, app, sample_user):\n        with app.app_context():\n            # Create posts with different statuses\n            client.post('/api/posts', json={\n                'title': 'Draft',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'draft'\n            })\n            client.post('/api/posts', json={\n                'title': 'Published',\n                'content': 'Content',\n                'user_id': sample_user,\n                'status': 'published'\n            })\n            \n            # Get only published\n            response = client.get('/api/posts?status=published')\n            assert response.status_code == 200\n            data = response.get_json()\n            assert all(post['status'] == 'published' for post in data)\n",
            "focusflow_blog/docs/API.md": "# FocusFlow Blog API Documentation\n\n## Base URL\n\nAll API endpoints are prefixed with `/api`.\n\n## Health Check\n\n### GET /api/health\n\nCheck if the API is running.\n\n**Response:**\n```json\n{\n    \"status\": \"healthy\",\n    \"message\": \"FocusFlow Blog API is running\"\n}\n```\n\n---\n\n## Users\n\n### GET /api/users\n\nGet all users.\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"username\": \"johndoe\",\n        \"email\": \"john@example.com\",\n        \"created_at\": \"2024-01-15T10:30:00\"\n    }\n]\n```\n\n### GET /api/users/{user_id}\n\nGet a specific user by ID.\n\n**Response:**\n```json\n{\n    \"id\": 1,\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"created_at\": \"2024-01-15T10:30:00\"\n}\n```\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"User not found\"\n}\n```\n\n### POST /api/users\n\nCreate a new user.\n\n**Request Body:**\n```json\n{\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"password\": \"securepassword123\"\n}\n```\n\n**Response (201):**\n```json\n{\n    \"id\": 1,\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"created_at\": \"2024-01-15T10:30:00\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Missing required field: username\"\n}\n```\n\n**Error Response (409):**\n```json\n{\n    \"error\": \"Username already exists\"\n}\n```\n\n---\n\n## Posts\n\n### GET /api/posts\n\nGet all posts. Supports optional status filtering.\n\n**Query Parameters:**\n- `status` (optional): Filter by post status. Values: `published`, `scheduled`\n\n**Examples:**\n- `GET /api/posts` - Get all posts\n- `GET /api/posts?status=published` - Get only published posts\n- `GET /api/posts?status=scheduled` - Get only scheduled posts\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"title\": \"My First Post\",\n        \"content\": \"This is the content of my post.\",\n        \"status\": \"published\",\n        \"scheduled_for\": null,\n        \"created_at\": \"2024-01-15T10:30:00\",\n        \"updated_at\": \"2024-01-15T12:00:00\",\n        \"user_id\": 1,\n        \"author\": \"johndoe\"\n    }\n]\n```\n\n### GET /api/posts/{post_id}\n\nGet a specific post by ID.\n\n**Response:**\n```json\n{\n    \"id\": 1,\n    \"title\": \"My First Post\",\n    \"content\": \"This is the content of my post.\",\n    \"status\": \"published\",\n    \"scheduled_for\": null,\n    \"created_at\": \"2024-01-15T10:30:00\",\n    \"updated_at\": \"2024-01-15T12:00:00\",\n    \"user_id\": 1,\n    \"author\": \"johndoe\"\n}\n```\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n### POST /api/posts\n\nCreate a new post.\n\n**Request Body:**\n```json\n{\n    \"title\": \"My New Post\",\n    \"content\": \"This is the content of my post.\",\n    \"user_id\": 1,\n    \"status\": \"draft\",\n    \"scheduled_for\": null\n}\n```\n\n**Fields:**\n- `title` (required): Post title (string)\n- `content` (required): Post content (string)\n- `user_id` (required): Author's user ID (integer)\n- `status` (optional): Post status. Values: `draft`, `scheduled`, `published`. Default: `draft`\n- `scheduled_for` (optional): ISO 8601 datetime for scheduled publishing. Example: `2024-01-20T15:00:00`\n\n**Response (201):**\n```json\n{\n    \"id\": 2,\n    \"title\": \"My New Post\",\n    \"content\": \"This is the content of my post.\",\n    \"status\": \"draft\",\n    \"scheduled_for\": null,\n    \"created_at\": \"2024-01-15T14:00:00\",\n    \"updated_at\": \"2024-01-15T14:00:00\",\n    \"user_id\": 1,\n    \"author\": \"johndoe\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Invalid status. Must be draft, scheduled, or published.\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Invalid scheduled_for format. Use ISO 8601 format.\"\n}\n```\n\n### PUT /api/posts/{post_id}\n\nUpdate an existing post.\n\n**Request Body:**\n```json\n{\n    \"title\": \"Updated Title\",\n    \"content\": \"Updated content.\",\n    \"status\": \"scheduled\",\n    \"scheduled_for\": \"2024-01-20T15:00:00\"\n}\n```\n\n**Fields (all optional):**\n- `title`: Updated post title\n- `content`: Updated post content\n- `status`: Updated status (`draft`, `scheduled`, or `published`)\n- `scheduled_for`: ISO 8601 datetime for scheduled publishing (set to `null` to clear)\n\n**Response (200):**\n```json\n{\n    \"id\": 1,\n    \"title\": \"Updated Title\",\n    \"content\": \"Updated content.\",\n    \"status\": \"scheduled\",\n    \"scheduled_for\": \"2024-01-20T15:00:00\",\n    \"created_at\": \"2024-01-15T10:30:00\",\n    \"updated_at\": \"2024-01-15T16:00:00\",\n    \"user_id\": 1,\n    \"author\": \"johndoe\"\n}\n```\n\n**Note:** Every update creates a new version in the post's version history.\n\n### DELETE /api/posts/{post_id}\n\nDelete a post.\n\n**Response (200):**\n```json\n{\n    \"message\": \"Post deleted successfully\"\n}\n```\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n---\n\n## Post Versions\n\nEvery time a post is created or updated, a version snapshot is automatically saved. This allows authors to view the history of changes and revert to previous versions.\n\n### GET /api/posts/{post_id}/versions\n\nGet all versions for a specific post.\n\n**Response (200):**\n```json\n[\n    {\n        \"id\": 3,\n        \"post_id\": 1,\n        \"title\": \"Current Title\",\n        \"content\": \"Current content.\",\n        \"created_at\": \"2024-01-15T16:00:00\"\n    },\n    {\n        \"id\": 2,\n        \"post_id\": 1,\n        \"title\": \"Previous Title\",\n        \"content\": \"Previous content.\",\n        \"created_at\": \"2024-01-15T14:00:00\"\n    },\n    {\n        \"id\": 1,\n        \"post_id\": 1,\n        \"title\": \"Original Title\",\n        \"content\": \"Original content.\",\n        \"created_at\": \"2024-01-15T10:30:00\"\n    }\n]\n```\n\n**Note:** Versions are returned in descending order by creation date (newest first).\n\n**Error Response (404):**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n### POST /api/posts/{post_id}/revert/{version_id}\n\nRevert a post to a specific version. This updates the post's title and content to match the specified version and creates a new version entry to record the revert action.\n\n**Response (200):**\n```json\n{\n    \"message\": \"Post reverted successfully\",\n    \"post\": {\n        \"id\": 1,\n        \"title\": \"Original Title\",\n        \"content\": \"Original content.\",\n        \"status\": \"draft\",\n        \"scheduled_for\": null,\n        \"created_at\": \"2024-01-15T10:30:00\",\n        \"updated_at\": \"2024-01-15T17:00:00\",\n        \"user_id\": 1,\n        \"author\": \"johndoe\"\n    }\n}\n```\n\n**Error Response (404) - Post not found:**\n```json\n{\n    \"error\": \"Post not found\"\n}\n```\n\n**Error Response (404) - Version not found:**\n```json\n{\n    \"error\": \"Version not found\"\n}\n```\n\n**Error Response (400) - Version belongs to different post:**\n```json\n{\n    \"error\": \"Version does not belong to this post\"\n}\n```\n\n---\n\n## User Posts\n\n### GET /api/users/{user_id}/posts\n\nGet all posts by a specific user.\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"title\": \"My First Post\",\n        \"content\": \"This is the content.\",\n        \"status\": \"published\",\n        \"scheduled_for\": null,\n        \"created_at\": \"2024-01-15T10:30:00\",\n        \"updated_at\": \"2024-01-15T12:00:00\",\n        \"user_id\": 1,\n        \"author\": \"johndoe\"\n    }\n]\n```\n\n---\n\n## Tags\n\n### GET /api/tags\n\nGet all tags.\n\n**Response:**\n```json\n[\n    {\n        \"id\": 1,\n        \"name\": \"technology\"\n    },\n    {\n        \"id\": 2,\n        \"name\": \"tutorial\"\n    }\n]\n```\n\n### POST /api/tags\n\nCreate a new tag.\n\n**Request Body:**\n```json\n{\n    \"name\": \"python\"\n}\n```\n\n**Response (201):**\n```json\n{\n    \"id\": 3,\n    \"name\": \"python\"\n}\n```\n\n**Error Response (400):**\n```json\n{\n    \"error\": \"Tag name is required\"\n}\n```\n\n**Error Response (409):**\n```json\n{\n    \"error\": \"Tag already exists\"\n}\n```\n\n---\n\n## Post Status Values\n\n| Status | Description |\n|--------|-------------|\n| `draft` | Post is saved but not visible to readers. Default status for new posts. |\n| `scheduled` | Post is scheduled for future publication. Requires `scheduled_for` datetime. |\n| `published` | Post is live and visible to readers. |\n\n---\n\n## Scheduled Publishing\n\nPosts with `status: scheduled` and a `scheduled_for` datetime will be automatically published when the scheduled time is reached. The background scheduler checks for posts to publish every 5 minutes.\n\n**Example: Creating a scheduled post:**\n```json\nPOST /api/posts\n{\n    \"title\": \"Upcoming Announcement\",\n    \"content\": \"Big news coming soon!\",\n    \"user_id\": 1,\n    \"status\": \"scheduled\",\n    \"scheduled_for\": \"2024-01-20T09:00:00\"\n}\n```\n\n---\n\n## Error Responses\n\nAll endpoints may return the following error responses:\n\n**400 Bad Request:**\n```json\n{\n    \"error\": \"Description of the error\"\n}\n```\n\n**404 Not Found:**\n```json\n{\n    \"error\": \"Resource not found\"\n}\n```\n\n**409 Conflict:**\n```json\n{\n    \"error\": \"Resource already exists\"\n}\n```\n\n---\n\n## Date/Time Format\n\nAll datetime fields use ISO 8601 format:\n- Example: `2024-01-15T10:30:00`\n- Timezone: UTC\n\nWhen sending datetime values in requests, use the same ISO 8601 format. The `Z` suffix for UTC is also accepted: `2024-01-15T10:30:00Z`\n",
            "focusflow_blog/requirements.txt": "Flask>=2.3.0\nFlask-SQLAlchemy>=3.0.0\nWerkzeug>=2.3.0\nAPScheduler>=3.10.0\npytest>=7.0.0\n"
          },
          "generated_files": [
            "focusflow_blog/focusflow/models.py",
            "focusflow_blog/focusflow/services.py",
            "focusflow_blog/focusflow/api.py",
            "focusflow_blog/focusflow/__init__.py",
            "focusflow_blog/run.py",
            "focusflow_blog/config.py",
            "focusflow_blog/tests/test_core.py",
            "focusflow_blog/docs/API.md",
            "focusflow_blog/requirements.txt"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.7299259259259259,
                "dependency_traversal_accuracy": 0.6539072848417112,
                "cross_file_reasoning_depth": 0.35870370370370364,
                "system_thinking_score": 0.42757471030324373,
                "robustness_score": 0.3998690242305174,
                "comprehensiveness_score": 0.606752736458041,
                "innovation_score": 0.15625,
                "solution_elegance_score": 0.5277787715116194
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09124074074074073,
                "dependency_traversal_weighted": 0.0817384106052139,
                "cross_file_reasoning_weighted": 0.044837962962962954,
                "system_thinking_weighted": 0.05344683878790547,
                "robustness_weighted": 0.049983628028814675,
                "comprehensiveness_weighted": 0.07584409205725512,
                "innovation_weighted": 0.01953125,
                "solution_elegance_weighted": 0.06597234643895243
              },
              "total_software_engineering_score": 0.4825952696218453
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.0,
                "execution_time": 0.5881707668304443,
                "errors": [
                  "  File \"focusflow_blog/config.py\", line 9",
                  "    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or ",
                  "                                                                ^",
                  "SyntaxError: invalid syntax",
                  "  File \"focusflow_blog/requirements.py\", line 1",
                  "    Flask>=2.3.0",
                  "              ^^",
                  "SyntaxError: invalid syntax",
                  "  File \"focusflow_blog/docs/API.py\", line 176",
                  "    - `user_id` (required): Author's user ID (integer)",
                  "                                  ^",
                  "SyntaxError: unterminated string literal (detected at line 176)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "focusflow_blog/focusflow/models.py",
                  "focusflow_blog/focusflow/services.py",
                  "focusflow_blog/focusflow/api.py",
                  "focusflow_blog/focusflow/__init__.py",
                  "focusflow_blog/run.py",
                  "focusflow_blog/config.py",
                  "focusflow_blog/tests/test_core.py",
                  "focusflow_blog/docs/API.md",
                  "focusflow_blog/requirements.txt"
                ],
                "scoring_breakdown": {
                  "no_credit": 0.0
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 9,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 7 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.20691131498470947,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.0,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.20691131498470947,
                "idc_weight": 0.2,
                "total_functional_score": 0.35138226299694186
              }
            },
            "code_quality_details": {
              "files_analyzed": 9,
              "quality_checks": {
                "focusflow_blog/focusflow/models.py": {
                  "line_count": 83,
                  "non_empty_lines": 64,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 4,
                  "class_count": 4,
                  "import_count": 4,
                  "quality_score": 0.7999999999999999
                },
                "focusflow_blog/focusflow/services.py": {
                  "line_count": 214,
                  "non_empty_lines": 153,
                  "comment_lines": 9,
                  "comment_ratio": 0.058823529411764705,
                  "function_count": 23,
                  "class_count": 0,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "focusflow_blog/focusflow/api.py": {
                  "line_count": 231,
                  "non_empty_lines": 180,
                  "comment_lines": 11,
                  "comment_ratio": 0.06111111111111111,
                  "function_count": 14,
                  "class_count": 0,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "focusflow_blog/focusflow/__init__.py": {
                  "line_count": 55,
                  "non_empty_lines": 40,
                  "comment_lines": 4,
                  "comment_ratio": 0.1,
                  "function_count": 3,
                  "class_count": 0,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "focusflow_blog/run.py": {
                  "line_count": 17,
                  "non_empty_lines": 11,
                  "comment_lines": 3,
                  "comment_ratio": 0.2727272727272727,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 3,
                  "quality_score": 0.7
                },
                "focusflow_blog/config.py": {
                  "line_count": 24,
                  "non_empty_lines": 16,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 3,
                  "import_count": 1,
                  "quality_score": 0.5
                },
                "focusflow_blog/tests/test_core.py": {
                  "line_count": 400,
                  "non_empty_lines": 330,
                  "comment_lines": 25,
                  "comment_ratio": 0.07575757575757576,
                  "function_count": 33,
                  "class_count": 5,
                  "import_count": 14,
                  "quality_score": 0.7999999999999999
                },
                "focusflow_blog/docs/API.md": {
                  "line_count": 497,
                  "non_empty_lines": 400,
                  "comment_lines": 26,
                  "comment_ratio": 0.065,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.7
                },
                "focusflow_blog/requirements.txt": {
                  "line_count": 6,
                  "non_empty_lines": 5,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.5
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7377777777777776,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8033143939393939,
                "multi_session_memory_retention": 0.8139393939393939
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.40165719696969693,
                "multi_session_memory_retention_weighted": 0.4069696969696969
              },
              "total_longcontext_utilization_score": 0.8086268939393939
            }
          },
          "timestamp": "2026-01-14T21:17:20.023952"
        }
      }
    },
    "python_api_gateway_hard_009_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_api_gateway_hard_009_feature_implementation_expert_01",
          "scenario_title": "Implement Bulk Student Enrollment Endpoint with Partial Success Handling",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5592560158134906,
          "functional_correctness_score": 0.4100233506300964,
          "code_quality_score": 0.7562499999999999,
          "longcontext_utilization_score": 0.8775219298245611,
          "total_score": 2.9285580224844066,
          "generation_time": 158.92781400680542,
          "code_files_generated": 8,
          "total_lines_generated": 1689,
          "parsing_success": true,
          "solution_code": {
            "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py": "\"\"\"Enrollment schemas for bulk operations.\"\"\"\nfrom typing import List, Literal\nfrom pydantic import BaseModel, Field\nfrom uuid import UUID\n\n\nclass BulkEnrollmentRequest(BaseModel):\n    \"\"\"Request schema for bulk student enrollment.\"\"\"\n    student_ids: List[str] = Field(\n        ...,\n        description=\"List of student IDs to enroll in the course\",\n        min_length=0\n    )\n\n\nclass EnrollmentResult(BaseModel):\n    \"\"\"Result of a single enrollment operation.\"\"\"\n    student_id: str = Field(..., description=\"The student ID\")\n    status: Literal[\"success\", \"failed\"] = Field(..., description=\"Enrollment status\")\n\n\nclass SuccessfulEnrollment(EnrollmentResult):\n    \"\"\"Successful enrollment result.\"\"\"\n    status: Literal[\"success\"] = \"success\"\n\n\nclass FailedEnrollment(EnrollmentResult):\n    \"\"\"Failed enrollment result with reason.\"\"\"\n    status: Literal[\"failed\"] = \"failed\"\n    reason: str = Field(..., description=\"Reason for failure\")\n\n\nclass BulkEnrollmentResponse(BaseModel):\n    \"\"\"Response schema for bulk enrollment operation.\"\"\"\n    successful_enrollments: List[SuccessfulEnrollment] = Field(\n        default_factory=list,\n        description=\"List of successful enrollments\"\n    )\n    failed_enrollments: List[FailedEnrollment] = Field(\n        default_factory=list,\n        description=\"List of failed enrollments with reasons\"\n    )\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"successful_enrollments\": [\n                    {\"student_id\": \"550e8400-e29b-41d4-a716-446655440001\", \"status\": \"success\"}\n                ],\n                \"failed_enrollments\": [\n                    {\n                        \"student_id\": \"550e8400-e29b-41d4-a716-446655440002\",\n                        \"status\": \"failed\",\n                        \"reason\": \"Student not found\"\n                    }\n                ]\n            }\n        }\n",
            "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py": "\"\"\"API Schemas.\"\"\"\nfrom edubridge_gateway.api.schemas.base import BaseSchema, PaginatedResponse\nfrom edubridge_gateway.api.schemas.student import (\n    StudentCreate,\n    StudentUpdate,\n    StudentResponse,\n    StudentListResponse,\n)\nfrom edubridge_gateway.api.schemas.course import (\n    CourseCreate,\n    CourseUpdate,\n    CourseResponse,\n    CourseListResponse,\n    EnrollmentCreate,\n    EnrollmentResponse,\n)\nfrom edubridge_gateway.api.schemas.enrollment import (\n    BulkEnrollmentRequest,\n    BulkEnrollmentResponse,\n    SuccessfulEnrollment,\n    FailedEnrollment,\n    EnrollmentResult,\n)\n\n__all__ = [\n    \"BaseSchema\",\n    \"PaginatedResponse\",\n    \"StudentCreate\",\n    \"StudentUpdate\",\n    \"StudentResponse\",\n    \"StudentListResponse\",\n    \"CourseCreate\",\n    \"CourseUpdate\",\n    \"CourseResponse\",\n    \"CourseListResponse\",\n    \"EnrollmentCreate\",\n    \"EnrollmentResponse\",\n    \"BulkEnrollmentRequest\",\n    \"BulkEnrollmentResponse\",\n    \"SuccessfulEnrollment\",\n    \"FailedEnrollment\",\n    \"EnrollmentResult\",\n]\n",
            "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py": "\"\"\"Student Information System (SIS) Repository.\n\nThis module provides the repository for interacting with the\nexternal Student Information System.\n\"\"\"\nimport httpx\nfrom typing import Any, Dict, List, Optional\nfrom edubridge_gateway.repositories.base import BaseRepository\nfrom edubridge_gateway.core.exceptions import (\n    ExternalServiceException,\n    NotFoundException,\n)\n\n\nclass SISRepository(BaseRepository):\n    \"\"\"Repository for Student Information System operations.\"\"\"\n\n    def __init__(self, base_url: str, timeout: float = 30.0):\n        \"\"\"Initialize the SIS repository.\n\n        Args:\n            base_url: Base URL for the SIS API\n            timeout: Request timeout in seconds\n        \"\"\"\n        self.base_url = base_url.rstrip(\"/\")\n        self.timeout = timeout\n        self._client: Optional[httpx.AsyncClient] = None\n\n    async def _get_client(self) -> httpx.AsyncClient:\n        \"\"\"Get or create the HTTP client.\"\"\"\n        if self._client is None or self._client.is_closed:\n            self._client = httpx.AsyncClient(\n                base_url=self.base_url,\n                timeout=self.timeout,\n            )\n        return self._client\n\n    async def close(self) -> None:\n        \"\"\"Close the HTTP client.\"\"\"\n        if self._client and not self._client.is_closed:\n            await self._client.aclose()\n\n    async def get_student(self, student_id: str) -> Dict[str, Any]:\n        \"\"\"Fetch a student by ID from SIS.\n\n        Args:\n            student_id: The student's unique identifier\n\n        Returns:\n            Student data dictionary\n\n        Raises:\n            NotFoundException: If student not found\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.get(f\"/students/{student_id}\")\n            if response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n        except httpx.RequestError as e:\n            raise ExternalServiceException(f\"SIS connection error: {str(e)}\")\n\n    async def get_students_by_ids(self, student_ids: List[str]) -> Dict[str, Optional[Dict[str, Any]]]:\n        \"\"\"Fetch multiple students by IDs from SIS in batch.\n\n        This method validates multiple students efficiently by making\n        individual requests but returning a consolidated result.\n        In a real implementation, this could use a batch API endpoint.\n\n        Args:\n            student_ids: List of student unique identifiers\n\n        Returns:\n            Dictionary mapping student_id to student data (or None if not found)\n\n        Raises:\n            ExternalServiceException: If SIS request fails unexpectedly\n        \"\"\"\n        results: Dict[str, Optional[Dict[str, Any]]] = {}\n        \n        for student_id in student_ids:\n            try:\n                student_data = await self.get_student(student_id)\n                results[student_id] = student_data\n            except NotFoundException:\n                results[student_id] = None\n            except ExternalServiceException:\n                # For connection errors, mark as None but could also re-raise\n                results[student_id] = None\n        \n        return results\n\n    async def list_students(\n        self, skip: int = 0, limit: int = 100\n    ) -> Dict[str, Any]:\n        \"\"\"List students from SIS with pagination.\n\n        Args:\n            skip: Number of records to skip\n            limit: Maximum number of records to return\n\n        Returns:\n            Paginated student list\n\n        Raises:\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.get(\n                \"/students\",\n                params={\"skip\": skip, \"limit\": limit},\n            )\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPError as e:\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n\n    async def create_student(self, student_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a new student in SIS.\n\n        Args:\n            student_data: Student information\n\n        Returns:\n            Created student data\n\n        Raises:\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.post(\"/students\", json=student_data)\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPError as e:\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n\n    async def update_student(\n        self, student_id: str, student_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Update a student in SIS.\n\n        Args:\n            student_id: The student's unique identifier\n            student_data: Updated student information\n\n        Returns:\n            Updated student data\n\n        Raises:\n            NotFoundException: If student not found\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.put(\n                f\"/students/{student_id}\",\n                json=student_data,\n            )\n            if response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            response.raise_for_status()\n            return response.json()\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n        except httpx.RequestError as e:\n            raise ExternalServiceException(f\"SIS connection error: {str(e)}\")\n\n    async def delete_student(self, student_id: str) -> None:\n        \"\"\"Delete a student from SIS.\n\n        Args:\n            student_id: The student's unique identifier\n\n        Raises:\n            NotFoundException: If student not found\n            ExternalServiceException: If SIS request fails\n        \"\"\"\n        client = await self._get_client()\n        try:\n            response = await client.delete(f\"/students/{student_id}\")\n            if response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            response.raise_for_status()\n        except httpx.HTTPStatusError as e:\n            if e.response.status_code == 404:\n                raise NotFoundException(f\"Student {student_id} not found in SIS\")\n            raise ExternalServiceException(f\"SIS error: {str(e)}\")\n        except httpx.RequestError as e:\n            raise ExternalServiceException(f\"SIS connection error: {str(e)}\")\n",
            "edubridge-gateway/edubridge_gateway/services/course_service.py": "\"\"\"Course Service.\n\nThis module provides the business logic layer for course operations,\norchestrating between the LMS repository and other services.\n\"\"\"\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom edubridge_gateway.repositories.lms_repository import LMSRepository\nfrom edubridge_gateway.repositories.sis_repository import SISRepository\nfrom edubridge_gateway.core.exceptions import (\n    NotFoundException,\n    ValidationException,\n    ExternalServiceException,\n)\n\n\nclass BulkEnrollmentResult:\n    \"\"\"Result container for bulk enrollment operations.\"\"\"\n    \n    def __init__(self):\n        self.successful: List[Dict[str, str]] = []\n        self.failed: List[Dict[str, str]] = []\n    \n    def add_success(self, student_id: str) -> None:\n        \"\"\"Record a successful enrollment.\"\"\"\n        self.successful.append({\n            \"student_id\": student_id,\n            \"status\": \"success\"\n        })\n    \n    def add_failure(self, student_id: str, reason: str) -> None:\n        \"\"\"Record a failed enrollment.\"\"\"\n        self.failed.append({\n            \"student_id\": student_id,\n            \"status\": \"failed\",\n            \"reason\": reason\n        })\n\n\nclass CourseService:\n    \"\"\"Service for course-related business operations.\"\"\"\n\n    def __init__(\n        self,\n        lms_repository: LMSRepository,\n        sis_repository: Optional[SISRepository] = None,\n    ):\n        \"\"\"Initialize the course service.\n\n        Args:\n            lms_repository: Repository for LMS operations\n            sis_repository: Repository for SIS operations (for student validation)\n        \"\"\"\n        self.lms_repository = lms_repository\n        self.sis_repository = sis_repository\n\n    async def get_course(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get a course by ID.\n\n        Args:\n            course_id: The course's unique identifier\n\n        Returns:\n            Course data dictionary\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        return await self.lms_repository.get_course(course_id)\n\n    async def list_courses(\n        self, skip: int = 0, limit: int = 100\n    ) -> Dict[str, Any]:\n        \"\"\"List courses with pagination.\n\n        Args:\n            skip: Number of records to skip\n            limit: Maximum number of records to return\n\n        Returns:\n            Paginated course list\n        \"\"\"\n        return await self.lms_repository.list_courses(skip=skip, limit=limit)\n\n    async def create_course(self, course_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create a new course.\n\n        Args:\n            course_data: Course information\n\n        Returns:\n            Created course data\n        \"\"\"\n        return await self.lms_repository.create_course(course_data)\n\n    async def update_course(\n        self, course_id: str, course_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Update a course.\n\n        Args:\n            course_id: The course's unique identifier\n            course_data: Updated course information\n\n        Returns:\n            Updated course data\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        return await self.lms_repository.update_course(course_id, course_data)\n\n    async def delete_course(self, course_id: str) -> None:\n        \"\"\"Delete a course.\n\n        Args:\n            course_id: The course's unique identifier\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        await self.lms_repository.delete_course(course_id)\n\n    async def enroll_student(\n        self, course_id: str, student_id: str\n    ) -> Dict[str, Any]:\n        \"\"\"Enroll a student in a course.\n\n        Args:\n            course_id: The course's unique identifier\n            student_id: The student's unique identifier\n\n        Returns:\n            Enrollment data\n\n        Raises:\n            NotFoundException: If course or student not found\n            ValidationException: If enrollment fails validation\n        \"\"\"\n        return await self.lms_repository.enroll_student(course_id, student_id)\n\n    async def bulk_enroll_students(\n        self, course_id: str, student_ids: List[str]\n    ) -> BulkEnrollmentResult:\n        \"\"\"Enroll multiple students in a course with partial success handling.\n\n        This method validates all students first via the SIS repository,\n        then attempts to enroll each valid student in the LMS.\n        Individual failures do not affect other enrollments.\n\n        Args:\n            course_id: The course's unique identifier\n            student_ids: List of student unique identifiers\n\n        Returns:\n            BulkEnrollmentResult containing successful and failed enrollments\n\n        Raises:\n            NotFoundException: If the course itself is not found\n        \"\"\"\n        result = BulkEnrollmentResult()\n        \n        # Handle empty list case\n        if not student_ids:\n            return result\n        \n        # First, verify the course exists\n        try:\n            await self.lms_repository.get_course(course_id)\n        except NotFoundException:\n            raise NotFoundException(f\"Course {course_id} not found\")\n        \n        # Batch validate students via SIS if repository is available\n        valid_students: Dict[str, bool] = {}\n        \n        if self.sis_repository:\n            try:\n                students_data = await self.sis_repository.get_students_by_ids(student_ids)\n                for student_id in student_ids:\n                    valid_students[student_id] = students_data.get(student_id) is not None\n            except ExternalServiceException as e:\n                # If SIS is unavailable, mark all as validation failed\n                for student_id in student_ids:\n                    result.add_failure(student_id, f\"Student validation service unavailable: {str(e)}\")\n                return result\n        else:\n            # If no SIS repository, assume all students are valid\n            # (let LMS handle validation)\n            for student_id in student_ids:\n                valid_students[student_id] = True\n        \n        # Process each student\n        for student_id in student_ids:\n            # Check if student was validated\n            if not valid_students.get(student_id, False):\n                result.add_failure(student_id, \"Student not found\")\n                continue\n            \n            # Attempt enrollment in LMS\n            try:\n                await self.lms_repository.enroll_student(course_id, student_id)\n                result.add_success(student_id)\n            except NotFoundException as e:\n                result.add_failure(student_id, str(e))\n            except ValidationException as e:\n                result.add_failure(student_id, str(e))\n            except ExternalServiceException as e:\n                result.add_failure(student_id, f\"LMS error: {str(e)}\")\n            except Exception as e:\n                result.add_failure(student_id, f\"Unexpected error: {str(e)}\")\n        \n        return result\n\n    async def get_course_enrollments(self, course_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all enrollments for a course.\n\n        Args:\n            course_id: The course's unique identifier\n\n        Returns:\n            List of enrollment data\n\n        Raises:\n            NotFoundException: If course not found\n        \"\"\"\n        return await self.lms_repository.get_course_enrollments(course_id)\n\n    async def unenroll_student(self, course_id: str, student_id: str) -> None:\n        \"\"\"Remove a student from a course.\n\n        Args:\n            course_id: The course's unique identifier\n            student_id: The student's unique identifier\n\n        Raises:\n            NotFoundException: If enrollment not found\n        \"\"\"\n        await self.lms_repository.unenroll_student(course_id, student_id)\n",
            "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py": "\"\"\"Course API Endpoints.\n\nThis module provides REST API endpoints for course operations.\n\"\"\"\nfrom typing import List\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\n\nfrom edubridge_gateway.api.schemas.course import (\n    CourseCreate,\n    CourseUpdate,\n    CourseResponse,\n    CourseListResponse,\n    EnrollmentCreate,\n    EnrollmentResponse,\n)\nfrom edubridge_gateway.api.schemas.enrollment import (\n    BulkEnrollmentRequest,\n    BulkEnrollmentResponse,\n    SuccessfulEnrollment,\n    FailedEnrollment,\n)\nfrom edubridge_gateway.services.course_service import CourseService\nfrom edubridge_gateway.core.exceptions import NotFoundException, ValidationException\nfrom edubridge_gateway.core.kernel import get_kernel\n\nrouter = APIRouter(prefix=\"/courses\", tags=[\"courses\"])\n\n\nasync def get_course_service() -> CourseService:\n    \"\"\"Dependency to get the course service.\"\"\"\n    kernel = get_kernel()\n    return kernel.get_service(\"course_service\")\n\n\n@router.get(\"\", response_model=CourseListResponse)\nasync def list_courses(\n    skip: int = 0,\n    limit: int = 100,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"List all courses with pagination.\"\"\"\n    result = await service.list_courses(skip=skip, limit=limit)\n    return result\n\n\n@router.post(\"\", response_model=CourseResponse, status_code=status.HTTP_201_CREATED)\nasync def create_course(\n    course: CourseCreate,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Create a new course.\"\"\"\n    result = await service.create_course(course.model_dump())\n    return result\n\n\n@router.get(\"/{course_id}\", response_model=CourseResponse)\nasync def get_course(\n    course_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Get a course by ID.\"\"\"\n    try:\n        result = await service.get_course(course_id)\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.put(\"/{course_id}\", response_model=CourseResponse)\nasync def update_course(\n    course_id: str,\n    course: CourseUpdate,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Update a course.\"\"\"\n    try:\n        result = await service.update_course(\n            course_id, course.model_dump(exclude_unset=True)\n        )\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.delete(\"/{course_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_course(\n    course_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Delete a course.\"\"\"\n    try:\n        await service.delete_course(course_id)\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.post(\n    \"/{course_id}/enrollments\",\n    response_model=EnrollmentResponse,\n    status_code=status.HTTP_201_CREATED,\n)\nasync def enroll_student(\n    course_id: str,\n    enrollment: EnrollmentCreate,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Enroll a student in a course.\"\"\"\n    try:\n        result = await service.enroll_student(course_id, enrollment.student_id)\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n    except ValidationException as e:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))\n\n\n@router.post(\n    \"/{course_id}/enrollments/bulk\",\n    response_model=BulkEnrollmentResponse,\n    status_code=status.HTTP_207_MULTI_STATUS,\n    responses={\n        207: {\n            \"description\": \"Multi-Status response with individual enrollment results\",\n            \"model\": BulkEnrollmentResponse,\n        },\n        404: {\"description\": \"Course not found\"},\n    },\n)\nasync def bulk_enroll_students(\n    course_id: str,\n    request: BulkEnrollmentRequest,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Bulk enroll multiple students in a course.\n    \n    This endpoint processes all enrollment requests and returns a detailed\n    report of which enrollments succeeded and which failed. The operation\n    uses partial success handling - individual failures do not affect\n    other enrollments in the batch.\n    \n    Returns HTTP 207 Multi-Status with a breakdown of results.\n    \"\"\"\n    try:\n        result = await service.bulk_enroll_students(course_id, request.student_ids)\n        \n        response_data = BulkEnrollmentResponse(\n            successful_enrollments=[\n                SuccessfulEnrollment(student_id=s[\"student_id\"])\n                for s in result.successful\n            ],\n            failed_enrollments=[\n                FailedEnrollment(student_id=f[\"student_id\"], reason=f[\"reason\"])\n                for f in result.failed\n            ],\n        )\n        \n        return JSONResponse(\n            status_code=status.HTTP_207_MULTI_STATUS,\n            content=response_data.model_dump(),\n        )\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.get(\"/{course_id}/enrollments\", response_model=List[EnrollmentResponse])\nasync def get_course_enrollments(\n    course_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Get all enrollments for a course.\"\"\"\n    try:\n        result = await service.get_course_enrollments(course_id)\n        return result\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n\n\n@router.delete(\n    \"/{course_id}/enrollments/{student_id}\",\n    status_code=status.HTTP_204_NO_CONTENT,\n)\nasync def unenroll_student(\n    course_id: str,\n    student_id: str,\n    service: CourseService = Depends(get_course_service),\n):\n    \"\"\"Remove a student from a course.\"\"\"\n    try:\n        await service.unenroll_student(course_id, student_id)\n    except NotFoundException as e:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))\n",
            "edubridge-gateway/tests/integration/test_rest_api.py": "\"\"\"Integration tests for REST API endpoints.\"\"\"\nimport pytest\nfrom httpx import AsyncClient, ASGITransport\nfrom unittest.mock import AsyncMock, MagicMock, patch\nimport uuid\n\nfrom edubridge_gateway.main import app\nfrom edubridge_gateway.core.kernel import Kernel, get_kernel, set_kernel\nfrom edubridge_gateway.services.course_service import CourseService, BulkEnrollmentResult\nfrom edubridge_gateway.services.student_service import StudentService\nfrom edubridge_gateway.core.exceptions import NotFoundException, ValidationException\n\n\n@pytest.fixture\ndef mock_kernel():\n    \"\"\"Create a mock kernel with mock services.\"\"\"\n    kernel = MagicMock(spec=Kernel)\n    \n    # Mock course service\n    mock_course_service = AsyncMock(spec=CourseService)\n    mock_student_service = AsyncMock(spec=StudentService)\n    \n    def get_service(name):\n        if name == \"course_service\":\n            return mock_course_service\n        elif name == \"student_service\":\n            return mock_student_service\n        return None\n    \n    kernel.get_service = get_service\n    return kernel, mock_course_service, mock_student_service\n\n\n@pytest.fixture\nasync def client(mock_kernel):\n    \"\"\"Create test client with mocked kernel.\"\"\"\n    kernel, _, _ = mock_kernel\n    set_kernel(kernel)\n    \n    transport = ASGITransport(app=app)\n    async with AsyncClient(transport=transport, base_url=\"http://test\") as ac:\n        yield ac\n\n\nclass TestCourseEndpoints:\n    \"\"\"Tests for course-related endpoints.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_list_courses(self, client, mock_kernel):\n        \"\"\"Test listing courses.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        mock_course_service.list_courses.return_value = {\n            \"items\": [{\"id\": \"course-1\", \"name\": \"Test Course\"}],\n            \"total\": 1,\n            \"skip\": 0,\n            \"limit\": 100,\n        }\n        \n        response = await client.get(\"/api/v1/courses\")\n        assert response.status_code == 200\n        data = response.json()\n        assert \"items\" in data\n\n    @pytest.mark.asyncio\n    async def test_get_course(self, client, mock_kernel):\n        \"\"\"Test getting a single course.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        mock_course_service.get_course.return_value = {\n            \"id\": course_id,\n            \"name\": \"Test Course\",\n            \"description\": \"A test course\",\n        }\n        \n        response = await client.get(f\"/api/v1/courses/{course_id}\")\n        assert response.status_code == 200\n        data = response.json()\n        assert data[\"id\"] == course_id\n\n    @pytest.mark.asyncio\n    async def test_get_course_not_found(self, client, mock_kernel):\n        \"\"\"Test getting a non-existent course.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        mock_course_service.get_course.side_effect = NotFoundException(\"Course not found\")\n        \n        response = await client.get(f\"/api/v1/courses/{course_id}\")\n        assert response.status_code == 404\n\n\nclass TestBulkEnrollmentEndpoint:\n    \"\"\"Tests for the bulk enrollment endpoint.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_successful(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment where all enrollments succeed.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(3)]\n        \n        # Create a result with all successes\n        result = BulkEnrollmentResult()\n        for sid in student_ids:\n            result.add_success(sid)\n        \n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 3\n        assert len(data[\"failed_enrollments\"]) == 0\n        for enrollment in data[\"successful_enrollments\"]:\n            assert enrollment[\"status\"] == \"success\"\n            assert enrollment[\"student_id\"] in student_ids\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_mixed_results(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment with mix of successes and failures.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        valid_student = str(uuid.uuid4())\n        invalid_student = str(uuid.uuid4())\n        student_ids = [valid_student, invalid_student]\n        \n        # Create a result with mixed outcomes\n        result = BulkEnrollmentResult()\n        result.add_success(valid_student)\n        result.add_failure(invalid_student, \"Student not found\")\n        \n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 1\n        assert len(data[\"failed_enrollments\"]) == 1\n        assert data[\"successful_enrollments\"][0][\"student_id\"] == valid_student\n        assert data[\"failed_enrollments\"][0][\"student_id\"] == invalid_student\n        assert data[\"failed_enrollments\"][0][\"reason\"] == \"Student not found\"\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_failed(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment where all enrollments fail.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(2)]\n        \n        # Create a result with all failures\n        result = BulkEnrollmentResult()\n        result.add_failure(student_ids[0], \"Student not found\")\n        result.add_failure(student_ids[1], \"LMS error: Connection timeout\")\n        \n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 0\n        assert len(data[\"failed_enrollments\"]) == 2\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_empty_list(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment with empty student list.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        \n        # Create an empty result\n        result = BulkEnrollmentResult()\n        mock_course_service.bulk_enroll_students.return_value = result\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": []}\n        )\n        \n        assert response.status_code == 207\n        data = response.json()\n        assert len(data[\"successful_enrollments\"]) == 0\n        assert len(data[\"failed_enrollments\"]) == 0\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_course_not_found(self, client, mock_kernel):\n        \"\"\"Test bulk enrollment when course doesn't exist.\"\"\"\n        _, mock_course_service, _ = mock_kernel\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4())]\n        \n        mock_course_service.bulk_enroll_students.side_effect = NotFoundException(\n            f\"Course {course_id} not found\"\n        )\n        \n        response = await client.post(\n            f\"/api/v1/courses/{course_id}/enrollments/bulk\",\n            json={\"student_ids\": student_ids}\n        )\n        \n        assert response.status_code == 404\n\n\nclass TestStudentEndpoints:\n    \"\"\"Tests for student-related endpoints.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_list_students(self, client, mock_kernel):\n        \"\"\"Test listing students.\"\"\"\n        _, _, mock_student_service = mock_kernel\n        mock_student_service.list_students.return_value = {\n            \"items\": [{\"id\": \"student-1\", \"name\": \"Test Student\"}],\n            \"total\": 1,\n            \"skip\": 0,\n            \"limit\": 100,\n        }\n        \n        response = await client.get(\"/api/v1/students\")\n        assert response.status_code == 200\n        data = response.json()\n        assert \"items\" in data\n",
            "edubridge-gateway/tests/unit/test_services.py": "\"\"\"Unit tests for service layer.\"\"\"\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock\nimport uuid\n\nfrom edubridge_gateway.services.course_service import CourseService, BulkEnrollmentResult\nfrom edubridge_gateway.services.student_service import StudentService\nfrom edubridge_gateway.repositories.lms_repository import LMSRepository\nfrom edubridge_gateway.repositories.sis_repository import SISRepository\nfrom edubridge_gateway.core.exceptions import (\n    NotFoundException,\n    ValidationException,\n    ExternalServiceException,\n)\n\n\nclass TestCourseService:\n    \"\"\"Tests for CourseService.\"\"\"\n\n    @pytest.fixture\n    def mock_lms_repository(self):\n        \"\"\"Create a mock LMS repository.\"\"\"\n        return AsyncMock(spec=LMSRepository)\n\n    @pytest.fixture\n    def mock_sis_repository(self):\n        \"\"\"Create a mock SIS repository.\"\"\"\n        return AsyncMock(spec=SISRepository)\n\n    @pytest.fixture\n    def course_service(self, mock_lms_repository, mock_sis_repository):\n        \"\"\"Create a CourseService with mocked dependencies.\"\"\"\n        return CourseService(\n            lms_repository=mock_lms_repository,\n            sis_repository=mock_sis_repository,\n        )\n\n    @pytest.mark.asyncio\n    async def test_get_course(self, course_service, mock_lms_repository):\n        \"\"\"Test getting a course.\"\"\"\n        course_id = str(uuid.uuid4())\n        expected_course = {\"id\": course_id, \"name\": \"Test Course\"}\n        mock_lms_repository.get_course.return_value = expected_course\n        \n        result = await course_service.get_course(course_id)\n        \n        assert result == expected_course\n        mock_lms_repository.get_course.assert_called_once_with(course_id)\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_successful(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment with all successful enrollments.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(3)]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock all students exist in SIS\n        mock_sis_repository.get_students_by_ids.return_value = {\n            sid: {\"id\": sid, \"name\": f\"Student {i}\"}\n            for i, sid in enumerate(student_ids)\n        }\n        \n        # Mock successful enrollments\n        mock_lms_repository.enroll_student.return_value = {\"status\": \"enrolled\"}\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 3\n        assert len(result.failed) == 0\n        assert all(s[\"status\"] == \"success\" for s in result.successful)\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_mixed_results(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment with mixed success and failure.\"\"\"\n        course_id = str(uuid.uuid4())\n        valid_student = str(uuid.uuid4())\n        invalid_student = str(uuid.uuid4())\n        student_ids = [valid_student, invalid_student]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock one student exists, one doesn't\n        mock_sis_repository.get_students_by_ids.return_value = {\n            valid_student: {\"id\": valid_student, \"name\": \"Valid Student\"},\n            invalid_student: None,  # Student not found\n        }\n        \n        # Mock successful enrollment for valid student\n        mock_lms_repository.enroll_student.return_value = {\"status\": \"enrolled\"}\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 1\n        assert len(result.failed) == 1\n        assert result.successful[0][\"student_id\"] == valid_student\n        assert result.failed[0][\"student_id\"] == invalid_student\n        assert \"not found\" in result.failed[0][\"reason\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_all_failed(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment where all enrollments fail.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(2)]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock no students found in SIS\n        mock_sis_repository.get_students_by_ids.return_value = {\n            sid: None for sid in student_ids\n        }\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 0\n        assert len(result.failed) == 2\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_empty_list(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment with empty student list.\"\"\"\n        course_id = str(uuid.uuid4())\n        \n        result = await course_service.bulk_enroll_students(course_id, [])\n        \n        assert len(result.successful) == 0\n        assert len(result.failed) == 0\n        # Should not call repositories for empty list\n        mock_lms_repository.get_course.assert_not_called()\n        mock_sis_repository.get_students_by_ids.assert_not_called()\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_course_not_found(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment when course doesn't exist.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4())]\n        \n        # Mock course not found\n        mock_lms_repository.get_course.side_effect = NotFoundException(\n            f\"Course {course_id} not found\"\n        )\n        \n        with pytest.raises(NotFoundException) as exc_info:\n            await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert course_id in str(exc_info.value)\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_lms_failure(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment when LMS fails for some students.\"\"\"\n        course_id = str(uuid.uuid4())\n        student1 = str(uuid.uuid4())\n        student2 = str(uuid.uuid4())\n        student_ids = [student1, student2]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock all students exist in SIS\n        mock_sis_repository.get_students_by_ids.return_value = {\n            student1: {\"id\": student1},\n            student2: {\"id\": student2},\n        }\n        \n        # Mock first enrollment succeeds, second fails\n        mock_lms_repository.enroll_student.side_effect = [\n            {\"status\": \"enrolled\"},\n            ExternalServiceException(\"LMS timeout\"),\n        ]\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 1\n        assert len(result.failed) == 1\n        assert result.successful[0][\"student_id\"] == student1\n        assert result.failed[0][\"student_id\"] == student2\n        assert \"LMS\" in result.failed[0][\"reason\"]\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_sis_unavailable(\n        self, course_service, mock_lms_repository, mock_sis_repository\n    ):\n        \"\"\"Test bulk enrollment when SIS is unavailable.\"\"\"\n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4())]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock SIS unavailable\n        mock_sis_repository.get_students_by_ids.side_effect = ExternalServiceException(\n            \"SIS connection failed\"\n        )\n        \n        result = await course_service.bulk_enroll_students(course_id, student_ids)\n        \n        assert len(result.successful) == 0\n        assert len(result.failed) == 1\n        assert \"unavailable\" in result.failed[0][\"reason\"].lower()\n\n    @pytest.mark.asyncio\n    async def test_bulk_enroll_without_sis_repository(\n        self, mock_lms_repository\n    ):\n        \"\"\"Test bulk enrollment when SIS repository is not configured.\"\"\"\n        # Create service without SIS repository\n        service = CourseService(\n            lms_repository=mock_lms_repository,\n            sis_repository=None,\n        )\n        \n        course_id = str(uuid.uuid4())\n        student_ids = [str(uuid.uuid4()) for _ in range(2)]\n        \n        # Mock course exists\n        mock_lms_repository.get_course.return_value = {\"id\": course_id}\n        \n        # Mock successful enrollments\n        mock_lms_repository.enroll_student.return_value = {\"status\": \"enrolled\"}\n        \n        result = await service.bulk_enroll_students(course_id, student_ids)\n        \n        # Should attempt all enrollments without SIS validation\n        assert len(result.successful) == 2\n        assert len(result.failed) == 0\n\n\nclass TestStudentService:\n    \"\"\"Tests for StudentService.\"\"\"\n\n    @pytest.fixture\n    def mock_sis_repository(self):\n        \"\"\"Create a mock SIS repository.\"\"\"\n        return AsyncMock(spec=SISRepository)\n\n    @pytest.fixture\n    def student_service(self, mock_sis_repository):\n        \"\"\"Create a StudentService with mocked dependencies.\"\"\"\n        return StudentService(sis_repository=mock_sis_repository)\n\n    @pytest.mark.asyncio\n    async def test_get_student(self, student_service, mock_sis_repository):\n        \"\"\"Test getting a student.\"\"\"\n        student_id = str(uuid.uuid4())\n        expected_student = {\"id\": student_id, \"name\": \"Test Student\"}\n        mock_sis_repository.get_student.return_value = expected_student\n        \n        result = await student_service.get_student(student_id)\n        \n        assert result == expected_student\n        mock_sis_repository.get_student.assert_called_once_with(student_id)\n\n\nclass TestBulkEnrollmentResult:\n    \"\"\"Tests for BulkEnrollmentResult helper class.\"\"\"\n\n    def test_add_success(self):\n        \"\"\"Test adding a successful enrollment.\"\"\"\n        result = BulkEnrollmentResult()\n        student_id = str(uuid.uuid4())\n        \n        result.add_success(student_id)\n        \n        assert len(result.successful) == 1\n        assert result.successful[0][\"student_id\"] == student_id\n        assert result.successful[0][\"status\"] == \"success\"\n\n    def test_add_failure(self):\n        \"\"\"Test adding a failed enrollment.\"\"\"\n        result = BulkEnrollmentResult()\n        student_id = str(uuid.uuid4())\n        reason = \"Student not found\"\n        \n        result.add_failure(student_id, reason)\n        \n        assert len(result.failed) == 1\n        assert result.failed[0][\"student_id\"] == student_id\n        assert result.failed[0][\"status\"] == \"failed\"\n        assert result.failed[0][\"reason\"] == reason\n\n    def test_multiple_results(self):\n        \"\"\"Test adding multiple results.\"\"\"\n        result = BulkEnrollmentResult()\n        \n        result.add_success(\"student-1\")\n        result.add_success(\"student-2\")\n        result.add_failure(\"student-3\", \"Not found\")\n        \n        assert len(result.successful) == 2\n        assert len(result.failed) == 1\n",
            "edubridge-gateway/docs/API_REFERENCE.md": "# EduBridge Gateway API Reference\n\nThis document provides a comprehensive reference for all API endpoints available in the EduBridge Gateway.\n\n## Base URL\n\nAll REST API endpoints are prefixed with `/api/v1`.\n\n## Authentication\n\nAll endpoints require authentication via Bearer token in the Authorization header:\n\n```\nAuthorization: Bearer <token>\n```\n\n## Endpoints\n\n### Courses\n\n#### List Courses\n\n```\nGET /api/v1/courses\n```\n\nReturns a paginated list of courses.\n\n**Query Parameters:**\n- `skip` (integer, optional): Number of records to skip. Default: 0\n- `limit` (integer, optional): Maximum number of records to return. Default: 100\n\n**Response:** `200 OK`\n```json\n{\n  \"items\": [\n    {\n      \"id\": \"uuid\",\n      \"name\": \"string\",\n      \"description\": \"string\"\n    }\n  ],\n  \"total\": 0,\n  \"skip\": 0,\n  \"limit\": 100\n}\n```\n\n#### Get Course\n\n```\nGET /api/v1/courses/{course_id}\n```\n\nReturns a single course by ID.\n\n**Response:** `200 OK`\n```json\n{\n  \"id\": \"uuid\",\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n#### Create Course\n\n```\nPOST /api/v1/courses\n```\n\nCreates a new course.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n**Response:** `201 Created`\n```json\n{\n  \"id\": \"uuid\",\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n#### Update Course\n\n```\nPUT /api/v1/courses/{course_id}\n```\n\nUpdates an existing course.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"description\": \"string\"\n}\n```\n\n**Response:** `200 OK`\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n#### Delete Course\n\n```\nDELETE /api/v1/courses/{course_id}\n```\n\nDeletes a course.\n\n**Response:** `204 No Content`\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n### Enrollments\n\n#### Enroll Student\n\n```\nPOST /api/v1/courses/{course_id}/enrollments\n```\n\nEnrolls a single student in a course.\n\n**Request Body:**\n```json\n{\n  \"student_id\": \"uuid\"\n}\n```\n\n**Response:** `201 Created`\n```json\n{\n  \"id\": \"uuid\",\n  \"course_id\": \"uuid\",\n  \"student_id\": \"uuid\",\n  \"enrolled_at\": \"datetime\"\n}\n```\n\n**Error Responses:**\n- `404 Not Found`: Course or student not found\n- `400 Bad Request`: Validation error\n\n#### Bulk Enroll Students\n\n```\nPOST /api/v1/courses/{course_id}/enrollments/bulk\n```\n\nEnrolls multiple students in a course with partial success handling. This endpoint processes all enrollment requests and returns a detailed report of which enrollments succeeded and which failed. Individual failures do not affect other enrollments in the batch.\n\n**Request Body:**\n```json\n{\n  \"student_ids\": [\"uuid-1\", \"uuid-2\", \"uuid-3\"]\n}\n```\n\n**Response:** `207 Multi-Status`\n\nThe response contains two arrays: one for successful enrollments and one for failed enrollments.\n\n```json\n{\n  \"successful_enrollments\": [\n    {\n      \"student_id\": \"uuid-1\",\n      \"status\": \"success\"\n    },\n    {\n      \"student_id\": \"uuid-2\",\n      \"status\": \"success\"\n    }\n  ],\n  \"failed_enrollments\": [\n    {\n      \"student_id\": \"uuid-3\",\n      \"status\": \"failed\",\n      \"reason\": \"Student not found\"\n    }\n  ]\n}\n```\n\n**Response Fields:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `successful_enrollments` | array | List of successfully enrolled students |\n| `successful_enrollments[].student_id` | string | The student's unique identifier |\n| `successful_enrollments[].status` | string | Always \"success\" for successful enrollments |\n| `failed_enrollments` | array | List of failed enrollment attempts |\n| `failed_enrollments[].student_id` | string | The student's unique identifier |\n| `failed_enrollments[].status` | string | Always \"failed\" for failed enrollments |\n| `failed_enrollments[].reason` | string | Human-readable explanation of why the enrollment failed |\n\n**Possible Failure Reasons:**\n- `Student not found`: The student ID does not exist in the Student Information System\n- `LMS error: <details>`: An error occurred when communicating with the Learning Management System\n- `Student validation service unavailable: <details>`: The SIS could not be reached to validate students\n\n**Error Responses:**\n- `404 Not Found`: The specified course does not exist\n\n**Example Request:**\n```bash\ncurl -X POST \"https://api.example.com/api/v1/courses/550e8400-e29b-41d4-a716-446655440000/enrollments/bulk\" \n  -H \"Authorization: Bearer <token>\" \n  -H \"Content-Type: application/json\" \n  -d '{\n    \"student_ids\": [\n      \"550e8400-e29b-41d4-a716-446655440001\",\n      \"550e8400-e29b-41d4-a716-446655440002\",\n      \"invalid-student-id\"\n    ]\n  }'\n```\n\n**Example Response:**\n```json\n{\n  \"successful_enrollments\": [\n    {\n      \"student_id\": \"550e8400-e29b-41d4-a716-446655440001\",\n      \"status\": \"success\"\n    },\n    {\n      \"student_id\": \"550e8400-e29b-41d4-a716-446655440002\",\n      \"status\": \"success\"\n    }\n  ],\n  \"failed_enrollments\": [\n    {\n      \"student_id\": \"invalid-student-id\",\n      \"status\": \"failed\",\n      \"reason\": \"Student not found\"\n    }\n  ]\n}\n```\n\n#### Get Course Enrollments\n\n```\nGET /api/v1/courses/{course_id}/enrollments\n```\n\nReturns all enrollments for a course.\n\n**Response:** `200 OK`\n```json\n[\n  {\n    \"id\": \"uuid\",\n    \"course_id\": \"uuid\",\n    \"student_id\": \"uuid\",\n    \"enrolled_at\": \"datetime\"\n  }\n]\n```\n\n**Error Responses:**\n- `404 Not Found`: Course not found\n\n#### Unenroll Student\n\n```\nDELETE /api/v1/courses/{course_id}/enrollments/{student_id}\n```\n\nRemoves a student from a course.\n\n**Response:** `204 No Content`\n\n**Error Responses:**\n- `404 Not Found`: Enrollment not found\n\n### Students\n\n#### List Students\n\n```\nGET /api/v1/students\n```\n\nReturns a paginated list of students.\n\n**Query Parameters:**\n- `skip` (integer, optional): Number of records to skip. Default: 0\n- `limit` (integer, optional): Maximum number of records to return. Default: 100\n\n**Response:** `200 OK`\n```json\n{\n  \"items\": [\n    {\n      \"id\": \"uuid\",\n      \"name\": \"string\",\n      \"email\": \"string\"\n    }\n  ],\n  \"total\": 0,\n  \"skip\": 0,\n  \"limit\": 100\n}\n```\n\n#### Get Student\n\n```\nGET /api/v1/students/{student_id}\n```\n\nReturns a single student by ID.\n\n**Response:** `200 OK`\n```json\n{\n  \"id\": \"uuid\",\n  \"name\": \"string\",\n  \"email\": \"string\"\n}\n```\n\n**Error Responses:**\n- `404 Not Found`: Student not found\n\n#### Create Student\n\n```\nPOST /api/v1/students\n```\n\nCreates a new student.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"email\": \"string\"\n}\n```\n\n**Response:** `201 Created`\n\n#### Update Student\n\n```\nPUT /api/v1/students/{student_id}\n```\n\nUpdates an existing student.\n\n**Request Body:**\n```json\n{\n  \"name\": \"string\",\n  \"email\": \"string\"\n}\n```\n\n**Response:** `200 OK`\n\n**Error Responses:**\n- `404 Not Found`: Student not found\n\n#### Delete Student\n\n```\nDELETE /api/v1/students/{student_id}\n```\n\nDeletes a student.\n\n**Response:** `204 No Content`\n\n**Error Responses:**\n- `404 Not Found`: Student not found\n\n## HTTP Status Codes\n\n| Code | Description |\n|------|-------------|\n| 200 | OK - Request succeeded |\n| 201 | Created - Resource created successfully |\n| 204 | No Content - Request succeeded with no response body |\n| 207 | Multi-Status - Partial success (used for bulk operations) |\n| 400 | Bad Request - Invalid request data |\n| 401 | Unauthorized - Authentication required |\n| 403 | Forbidden - Insufficient permissions |\n| 404 | Not Found - Resource not found |\n| 500 | Internal Server Error - Server error |\n\n## Error Response Format\n\nAll error responses follow this format:\n\n```json\n{\n  \"detail\": \"Error message describing what went wrong\"\n}\n```\n"
          },
          "generated_files": [
            "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py",
            "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py",
            "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py",
            "edubridge-gateway/edubridge_gateway/services/course_service.py",
            "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py",
            "edubridge-gateway/tests/integration/test_rest_api.py",
            "edubridge-gateway/tests/unit/test_services.py",
            "edubridge-gateway/docs/API_REFERENCE.md"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8502729885057472,
                "dependency_traversal_accuracy": 0.700855319217653,
                "cross_file_reasoning_depth": 0.38145833333333334,
                "system_thinking_score": 0.4934944682431883,
                "robustness_score": 0.43732978093546476,
                "comprehensiveness_score": 0.5827252812314979,
                "innovation_score": 0.54375,
                "solution_elegance_score": 0.4841619550410401
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.1062841235632184,
                "dependency_traversal_weighted": 0.08760691490220662,
                "cross_file_reasoning_weighted": 0.04768229166666667,
                "system_thinking_weighted": 0.06168680853039854,
                "robustness_weighted": 0.054666222616933095,
                "comprehensiveness_weighted": 0.07284066015393724,
                "innovation_weighted": 0.06796875,
                "solution_elegance_weighted": 0.06052024438013001
              },
              "total_software_engineering_score": 0.5592560158134906
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.5650472640991211,
                "errors": [
                  "  File \"edubridge-gateway/docs/API_REFERENCE.py\", line 205",
                  "    | `successful_enrollments[].student_id` | string | The student's unique identifier |",
                  "                                                                  ^",
                  "SyntaxError: unterminated string literal (detected at line 205)"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py",
                  "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py",
                  "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py",
                  "edubridge-gateway/edubridge_gateway/services/course_service.py",
                  "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py",
                  "edubridge-gateway/tests/integration/test_rest_api.py",
                  "edubridge-gateway/tests/unit/test_services.py",
                  "edubridge-gateway/docs/API_REFERENCE.md"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 8,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 8 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.3501167531504818,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.3501167531504818,
                "idc_weight": 0.2,
                "total_functional_score": 0.4100233506300964
              }
            },
            "code_quality_details": {
              "files_analyzed": 8,
              "quality_checks": {
                "edubridge-gateway/edubridge_gateway/api/schemas/enrollment.py": {
                  "line_count": 59,
                  "non_empty_lines": 47,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 6,
                  "import_count": 6,
                  "quality_score": 0.7
                },
                "edubridge-gateway/edubridge_gateway/api/schemas/__init__.py": {
                  "line_count": 44,
                  "non_empty_lines": 42,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 8,
                  "quality_score": 0.5
                },
                "edubridge-gateway/edubridge_gateway/repositories/sis_repository.py": {
                  "line_count": 201,
                  "non_empty_lines": 167,
                  "comment_lines": 1,
                  "comment_ratio": 0.005988023952095809,
                  "function_count": 9,
                  "class_count": 1,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "edubridge-gateway/edubridge_gateway/services/course_service.py": {
                  "line_count": 238,
                  "non_empty_lines": 187,
                  "comment_lines": 9,
                  "comment_ratio": 0.0481283422459893,
                  "function_count": 13,
                  "class_count": 2,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "edubridge-gateway/edubridge_gateway/api/endpoints/courses.py": {
                  "line_count": 193,
                  "non_empty_lines": 165,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 10,
                  "class_count": 0,
                  "import_count": 17,
                  "quality_score": 0.7999999999999999
                },
                "edubridge-gateway/tests/integration/test_rest_api.py": {
                  "line_count": 231,
                  "non_empty_lines": 184,
                  "comment_lines": 5,
                  "comment_ratio": 0.02717391304347826,
                  "function_count": 12,
                  "class_count": 3,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "edubridge-gateway/tests/unit/test_services.py": {
                  "line_count": 305,
                  "non_empty_lines": 236,
                  "comment_lines": 19,
                  "comment_ratio": 0.08050847457627118,
                  "function_count": 18,
                  "class_count": 3,
                  "import_count": 14,
                  "quality_score": 0.7999999999999999
                },
                "edubridge-gateway/docs/API_REFERENCE.md": {
                  "line_count": 418,
                  "non_empty_lines": 321,
                  "comment_lines": 23,
                  "comment_ratio": 0.07165109034267912,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 1,
                  "quality_score": 0.7
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7562499999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.9046052631578945,
                "multi_session_memory_retention": 0.8504385964912279
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.45230263157894723,
                "multi_session_memory_retention_weighted": 0.42521929824561394
              },
              "total_longcontext_utilization_score": 0.8775219298245611
            }
          },
          "timestamp": "2026-01-14T21:35:15.191886"
        }
      }
    },
    "python_web_social_easy_073_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_web_social_easy_073_feature_implementation_expert_01",
          "scenario_title": "Implement Asynchronous User Mentions and Notifications",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5513875319394449,
          "functional_correctness_score": 0.6715414364640884,
          "code_quality_score": 0.7562499999999999,
          "longcontext_utilization_score": 0.8337705305447242,
          "total_score": 3.2832224838473847,
          "generation_time": 90.50688171386719,
          "code_files_generated": 8,
          "total_lines_generated": 926,
          "parsing_success": true,
          "solution_code": {
            "classpulse/models.py": "from datetime import datetime\nfrom sqlalchemy import Column, Integer, String, Text, Boolean, DateTime, ForeignKey\nfrom sqlalchemy.orm import relationship, declarative_base\n\nBase = declarative_base()\n\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    username = Column(String(50), unique=True, index=True, nullable=False)\n    email = Column(String(100), unique=True, index=True, nullable=False)\n    hashed_password = Column(String(255), nullable=False)\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    posts = relationship(\"Post\", back_populates=\"author\")\n    notifications_received = relationship(\n        \"Notification\",\n        foreign_keys=\"Notification.recipient_id\",\n        back_populates=\"recipient\"\n    )\n    notifications_sent = relationship(\n        \"Notification\",\n        foreign_keys=\"Notification.actor_id\",\n        back_populates=\"actor\"\n    )\n\n\nclass Session(Base):\n    __tablename__ = \"sessions\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    title = Column(String(200), nullable=False)\n    description = Column(Text)\n    code = Column(String(10), unique=True, index=True, nullable=False)\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    owner_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n\n    posts = relationship(\"Post\", back_populates=\"session\")\n\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    content = Column(Text, nullable=False)\n    is_anonymous = Column(Boolean, default=False)\n    upvotes = Column(Integer, default=0)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    author_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    session_id = Column(Integer, ForeignKey(\"sessions.id\"), nullable=False)\n\n    author = relationship(\"User\", back_populates=\"posts\")\n    session = relationship(\"Session\", back_populates=\"posts\")\n    notifications = relationship(\"Notification\", back_populates=\"post\")\n\n\nclass Notification(Base):\n    __tablename__ = \"notifications\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    recipient_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    actor_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    post_id = Column(Integer, ForeignKey(\"posts.id\"), nullable=False)\n    type = Column(String(50), nullable=False, default=\"mention\")\n    is_read = Column(Boolean, default=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n    recipient = relationship(\n        \"User\",\n        foreign_keys=[recipient_id],\n        back_populates=\"notifications_received\"\n    )\n    actor = relationship(\n        \"User\",\n        foreign_keys=[actor_id],\n        back_populates=\"notifications_sent\"\n    )\n    post = relationship(\"Post\", back_populates=\"notifications\")\n",
            "classpulse/repositories.py": "from typing import List, Optional\nfrom sqlalchemy.orm import Session as DBSession\nfrom classpulse.models import User, Session, Post, Notification\n\n\nclass UserRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(self, username: str, email: str, hashed_password: str) -> User:\n        user = User(\n            username=username,\n            email=email,\n            hashed_password=hashed_password\n        )\n        self.db.add(user)\n        self.db.commit()\n        self.db.refresh(user)\n        return user\n\n    def get_by_id(self, user_id: int) -> Optional[User]:\n        return self.db.query(User).filter(User.id == user_id).first()\n\n    def get_by_username(self, username: str) -> Optional[User]:\n        return self.db.query(User).filter(User.username == username).first()\n\n    def get_by_email(self, email: str) -> Optional[User]:\n        return self.db.query(User).filter(User.email == email).first()\n\n\nclass SessionRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(self, title: str, code: str, owner_id: int, description: str = None) -> Session:\n        session = Session(\n            title=title,\n            code=code,\n            owner_id=owner_id,\n            description=description\n        )\n        self.db.add(session)\n        self.db.commit()\n        self.db.refresh(session)\n        return session\n\n    def get_by_id(self, session_id: int) -> Optional[Session]:\n        return self.db.query(Session).filter(Session.id == session_id).first()\n\n    def get_by_code(self, code: str) -> Optional[Session]:\n        return self.db.query(Session).filter(Session.code == code).first()\n\n\nclass PostRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(self, content: str, author_id: int, session_id: int, is_anonymous: bool = False) -> Post:\n        post = Post(\n            content=content,\n            author_id=author_id,\n            session_id=session_id,\n            is_anonymous=is_anonymous\n        )\n        self.db.add(post)\n        self.db.commit()\n        self.db.refresh(post)\n        return post\n\n    def get_by_id(self, post_id: int) -> Optional[Post]:\n        return self.db.query(Post).filter(Post.id == post_id).first()\n\n    def get_by_session(self, session_id: int) -> List[Post]:\n        return self.db.query(Post).filter(Post.session_id == session_id).all()\n\n    def upvote(self, post_id: int) -> Optional[Post]:\n        post = self.get_by_id(post_id)\n        if post:\n            post.upvotes += 1\n            self.db.commit()\n            self.db.refresh(post)\n        return post\n\n\nclass NotificationRepository:\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create(\n        self,\n        recipient_id: int,\n        actor_id: int,\n        post_id: int,\n        notification_type: str = \"mention\"\n    ) -> Notification:\n        notification = Notification(\n            recipient_id=recipient_id,\n            actor_id=actor_id,\n            post_id=post_id,\n            type=notification_type\n        )\n        self.db.add(notification)\n        self.db.commit()\n        self.db.refresh(notification)\n        return notification\n\n    def get_by_recipient(self, recipient_id: int) -> List[Notification]:\n        return (\n            self.db.query(Notification)\n            .filter(Notification.recipient_id == recipient_id)\n            .order_by(Notification.created_at.desc())\n            .all()\n        )\n\n    def get_by_id(self, notification_id: int) -> Optional[Notification]:\n        return self.db.query(Notification).filter(Notification.id == notification_id).first()\n\n    def mark_as_read(self, notification_id: int) -> Optional[Notification]:\n        notification = self.get_by_id(notification_id)\n        if notification:\n            notification.is_read = True\n            self.db.commit()\n            self.db.refresh(notification)\n        return notification\n",
            "classpulse/services.py": "import re\nfrom typing import Optional, List\nfrom classpulse.models import User, Session, Post\nfrom classpulse.repositories import UserRepository, SessionRepository, PostRepository\nfrom classpulse.events import EventDispatcher\nimport secrets\nimport hashlib\n\n\ndef hash_password(password: str) -> str:\n    return hashlib.sha256(password.encode()).hexdigest()\n\n\ndef verify_password(password: str, hashed: str) -> bool:\n    return hash_password(password) == hashed\n\n\ndef generate_session_code() -> str:\n    return secrets.token_urlsafe(6)[:8].upper()\n\n\ndef parse_mentions(content: str) -> List[str]:\n    \"\"\"Extract all @username mentions from content.\"\"\"\n    pattern = r'@(\\w+)'\n    matches = re.findall(pattern, content)\n    return list(set(matches))\n\n\ndef create_user(\n    user_repo: UserRepository,\n    username: str,\n    email: str,\n    password: str\n) -> User:\n    hashed_password = hash_password(password)\n    return user_repo.create(username, email, hashed_password)\n\n\ndef authenticate_user(\n    user_repo: UserRepository,\n    username: str,\n    password: str\n) -> Optional[User]:\n    user = user_repo.get_by_username(username)\n    if user and verify_password(password, user.hashed_password):\n        return user\n    return None\n\n\ndef create_session(\n    session_repo: SessionRepository,\n    title: str,\n    owner_id: int,\n    description: str = None\n) -> Session:\n    code = generate_session_code()\n    return session_repo.create(title, code, owner_id, description)\n\n\ndef create_post(\n    post_repo: PostRepository,\n    user_repo: UserRepository,\n    event_dispatcher: EventDispatcher,\n    content: str,\n    author_id: int,\n    session_id: int,\n    is_anonymous: bool = False\n) -> Post:\n    post = post_repo.create(content, author_id, session_id, is_anonymous)\n    \n    # Parse mentions and dispatch events\n    mentioned_usernames = parse_mentions(content)\n    for username in mentioned_usernames:\n        mentioned_user = user_repo.get_by_username(username)\n        if mentioned_user and mentioned_user.id != author_id:\n            event_dispatcher.dispatch(\n                \"user_mentioned\",\n                {\n                    \"actor_id\": author_id,\n                    \"recipient_id\": mentioned_user.id,\n                    \"post_id\": post.id\n                }\n            )\n    \n    return post\n\n\ndef upvote_post(post_repo: PostRepository, post_id: int) -> Optional[Post]:\n    return post_repo.upvote(post_id)\n",
            "classpulse/events.py": "from typing import Callable, Dict, List, Any\nfrom collections import defaultdict\n\n\nclass EventDispatcher:\n    _instance = None\n    _subscribers: Dict[str, List[Callable]] = defaultdict(list)\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._instance._subscribers = defaultdict(list)\n        return cls._instance\n\n    def subscribe(self, event_name: str, handler: Callable) -> None:\n        \"\"\"Subscribe a handler to an event.\"\"\"\n        self._subscribers[event_name].append(handler)\n\n    def dispatch(self, event_name: str, payload: Dict[str, Any]) -> None:\n        \"\"\"Dispatch an event to all subscribers.\"\"\"\n        for handler in self._subscribers[event_name]:\n            handler(payload)\n\n    def clear(self) -> None:\n        \"\"\"Clear all subscribers (useful for testing).\"\"\"\n        self._subscribers.clear()\n\n\n# Global event dispatcher instance\nevent_dispatcher = EventDispatcher()\n",
            "classpulse/worker.py": "import threading\nimport queue\nfrom typing import Dict, Any, Callable\nfrom classpulse.events import event_dispatcher\nfrom classpulse.repositories import NotificationRepository\nfrom classpulse.config import get_db_session\n\n\nclass BackgroundWorker:\n    def __init__(self):\n        self.task_queue = queue.Queue()\n        self.running = False\n        self.thread = None\n\n    def start(self):\n        \"\"\"Start the background worker thread.\"\"\"\n        self.running = True\n        self.thread = threading.Thread(target=self._process_tasks, daemon=True)\n        self.thread.start()\n\n    def stop(self):\n        \"\"\"Stop the background worker.\"\"\"\n        self.running = False\n        if self.thread:\n            self.thread.join(timeout=5)\n\n    def enqueue(self, task: Callable, *args, **kwargs):\n        \"\"\"Add a task to the queue.\"\"\"\n        self.task_queue.put((task, args, kwargs))\n\n    def _process_tasks(self):\n        \"\"\"Process tasks from the queue.\"\"\"\n        while self.running:\n            try:\n                task, args, kwargs = self.task_queue.get(timeout=1)\n                task(*args, **kwargs)\n                self.task_queue.task_done()\n            except queue.Empty:\n                continue\n            except Exception as e:\n                print(f\"Error processing task: {e}\")\n\n\n# Global worker instance\nworker = BackgroundWorker()\n\n\ndef handle_user_mentioned(payload: Dict[str, Any]) -> None:\n    \"\"\"Handle user_mentioned event by creating a notification.\"\"\"\n    worker.enqueue(create_notification_task, payload)\n\n\ndef create_notification_task(payload: Dict[str, Any]) -> None:\n    \"\"\"Task to create a notification in the database.\"\"\"\n    db = get_db_session()\n    try:\n        notification_repo = NotificationRepository(db)\n        notification_repo.create(\n            recipient_id=payload[\"recipient_id\"],\n            actor_id=payload[\"actor_id\"],\n            post_id=payload[\"post_id\"],\n            notification_type=\"mention\"\n        )\n    finally:\n        db.close()\n\n\ndef setup_event_handlers():\n    \"\"\"Register event handlers with the event dispatcher.\"\"\"\n    event_dispatcher.subscribe(\"user_mentioned\", handle_user_mentioned)\n\n\ndef start_worker():\n    \"\"\"Initialize and start the background worker.\"\"\"\n    setup_event_handlers()\n    worker.start()\n\n\ndef stop_worker():\n    \"\"\"Stop the background worker.\"\"\"\n    worker.stop()\n",
            "classpulse/main.py": "from fastapi import FastAPI, Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import FileResponse\nfrom pydantic import BaseModel\nfrom typing import Optional, List\nfrom datetime import datetime\nimport jwt\n\nfrom classpulse.config import get_db, SECRET_KEY, ALGORITHM\nfrom classpulse.repositories import (\n    UserRepository,\n    SessionRepository,\n    PostRepository,\n    NotificationRepository\n)\nfrom classpulse.services import (\n    create_user,\n    authenticate_user,\n    create_session,\n    create_post,\n    upvote_post\n)\nfrom classpulse.events import event_dispatcher\nfrom classpulse.worker import start_worker, stop_worker\n\napp = FastAPI(title=\"ClassPulse Live\", version=\"1.0.0\")\nsecurity = HTTPBearer()\n\n\n# Pydantic models\nclass UserCreate(BaseModel):\n    username: str\n    email: str\n    password: str\n\n\nclass UserLogin(BaseModel):\n    username: str\n    password: str\n\n\nclass SessionCreate(BaseModel):\n    title: str\n    description: Optional[str] = None\n\n\nclass PostCreate(BaseModel):\n    content: str\n    session_id: int\n    is_anonymous: bool = False\n\n\nclass TokenResponse(BaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n\n\nclass UserResponse(BaseModel):\n    id: int\n    username: str\n    email: str\n\n    class Config:\n        from_attributes = True\n\n\nclass SessionResponse(BaseModel):\n    id: int\n    title: str\n    description: Optional[str]\n    code: str\n    is_active: bool\n\n    class Config:\n        from_attributes = True\n\n\nclass PostResponse(BaseModel):\n    id: int\n    content: str\n    is_anonymous: bool\n    upvotes: int\n    created_at: datetime\n    author_id: int\n    session_id: int\n\n    class Config:\n        from_attributes = True\n\n\nclass NotificationResponse(BaseModel):\n    id: int\n    recipient_id: int\n    actor_id: int\n    post_id: int\n    type: str\n    is_read: bool\n    created_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\ndef create_token(user_id: int) -> str:\n    payload = {\"user_id\": user_id}\n    return jwt.encode(payload, SECRET_KEY, algorithm=ALGORITHM)\n\n\ndef get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security), db=Depends(get_db)):\n    try:\n        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])\n        user_id = payload.get(\"user_id\")\n        if user_id is None:\n            raise HTTPException(status_code=401, detail=\"Invalid token\")\n        user_repo = UserRepository(db)\n        user = user_repo.get_by_id(user_id)\n        if user is None:\n            raise HTTPException(status_code=401, detail=\"User not found\")\n        return user\n    except jwt.PyJWTError:\n        raise HTTPException(status_code=401, detail=\"Invalid token\")\n\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    start_worker()\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    stop_worker()\n\n\n@app.post(\"/api/v1/auth/register\", response_model=UserResponse)\ndef register(user_data: UserCreate, db=Depends(get_db)):\n    user_repo = UserRepository(db)\n    if user_repo.get_by_username(user_data.username):\n        raise HTTPException(status_code=400, detail=\"Username already exists\")\n    if user_repo.get_by_email(user_data.email):\n        raise HTTPException(status_code=400, detail=\"Email already exists\")\n    user = create_user(user_repo, user_data.username, user_data.email, user_data.password)\n    return user\n\n\n@app.post(\"/api/v1/auth/login\", response_model=TokenResponse)\ndef login(user_data: UserLogin, db=Depends(get_db)):\n    user_repo = UserRepository(db)\n    user = authenticate_user(user_repo, user_data.username, user_data.password)\n    if not user:\n        raise HTTPException(status_code=401, detail=\"Invalid credentials\")\n    token = create_token(user.id)\n    return TokenResponse(access_token=token)\n\n\n@app.post(\"/api/v1/sessions\", response_model=SessionResponse)\ndef create_new_session(\n    session_data: SessionCreate,\n    current_user=Depends(get_current_user),\n    db=Depends(get_db)\n):\n    session_repo = SessionRepository(db)\n    session = create_session(\n        session_repo,\n        session_data.title,\n        current_user.id,\n        session_data.description\n    )\n    return session\n\n\n@app.get(\"/api/v1/sessions/{code}\", response_model=SessionResponse)\ndef get_session(code: str, db=Depends(get_db)):\n    session_repo = SessionRepository(db)\n    session = session_repo.get_by_code(code)\n    if not session:\n        raise HTTPException(status_code=404, detail=\"Session not found\")\n    return session\n\n\n@app.post(\"/api/v1/posts\", response_model=PostResponse)\ndef create_new_post(\n    post_data: PostCreate,\n    current_user=Depends(get_current_user),\n    db=Depends(get_db)\n):\n    post_repo = PostRepository(db)\n    user_repo = UserRepository(db)\n    post = create_post(\n        post_repo,\n        user_repo,\n        event_dispatcher,\n        post_data.content,\n        current_user.id,\n        post_data.session_id,\n        post_data.is_anonymous\n    )\n    return post\n\n\n@app.get(\"/api/v1/sessions/{session_id}/posts\", response_model=List[PostResponse])\ndef get_session_posts(session_id: int, db=Depends(get_db)):\n    post_repo = PostRepository(db)\n    posts = post_repo.get_by_session(session_id)\n    return posts\n\n\n@app.post(\"/api/v1/posts/{post_id}/upvote\", response_model=PostResponse)\ndef upvote(post_id: int, db=Depends(get_db)):\n    post_repo = PostRepository(db)\n    post = upvote_post(post_repo, post_id)\n    if not post:\n        raise HTTPException(status_code=404, detail=\"Post not found\")\n    return post\n\n\n@app.get(\"/api/v1/notifications\", response_model=List[NotificationResponse])\ndef get_notifications(\n    current_user=Depends(get_current_user),\n    db=Depends(get_db)\n):\n    notification_repo = NotificationRepository(db)\n    notifications = notification_repo.get_by_recipient(current_user.id)\n    return notifications\n\n\n@app.get(\"/\")\ndef serve_frontend():\n    return FileResponse(\"static/index.html\")\n",
            "classpulse/config.py": "import os\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, Session\n\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./classpulse.db\")\nSECRET_KEY = os.getenv(\"SECRET_KEY\", \"your-secret-key-here\")\nALGORITHM = \"HS256\"\n\nengine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False})\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n\ndef get_db_session() -> Session:\n    \"\"\"Get a new database session (non-generator version for workers).\"\"\"\n    return SessionLocal()\n",
            "tests/test_services.py": "import pytest\nfrom unittest.mock import Mock, MagicMock, patch\nfrom classpulse.services import (\n    create_user,\n    authenticate_user,\n    create_post,\n    hash_password,\n    verify_password,\n    parse_mentions\n)\nfrom classpulse.models import User, Post\n\n\nclass TestPasswordHashing:\n    def test_hash_password(self):\n        password = \"testpassword123\"\n        hashed = hash_password(password)\n        assert hashed != password\n        assert len(hashed) == 64  # SHA256 produces 64 hex characters\n\n    def test_verify_password_correct(self):\n        password = \"testpassword123\"\n        hashed = hash_password(password)\n        assert verify_password(password, hashed) is True\n\n    def test_verify_password_incorrect(self):\n        password = \"testpassword123\"\n        hashed = hash_password(password)\n        assert verify_password(\"wrongpassword\", hashed) is False\n\n\nclass TestParseMentions:\n    def test_parse_single_mention(self):\n        content = \"Hello @john how are you?\"\n        mentions = parse_mentions(content)\n        assert mentions == [\"john\"]\n\n    def test_parse_multiple_mentions(self):\n        content = \"Hey @john and @jane, check this out!\"\n        mentions = parse_mentions(content)\n        assert set(mentions) == {\"john\", \"jane\"}\n\n    def test_parse_no_mentions(self):\n        content = \"Hello world, no mentions here.\"\n        mentions = parse_mentions(content)\n        assert mentions == []\n\n    def test_parse_duplicate_mentions(self):\n        content = \"@john said hi to @john\"\n        mentions = parse_mentions(content)\n        assert mentions == [\"john\"]\n\n\nclass TestCreateUser:\n    def test_create_user_success(self):\n        mock_repo = Mock()\n        mock_user = User(id=1, username=\"testuser\", email=\"test@test.com\")\n        mock_repo.create.return_value = mock_user\n\n        result = create_user(mock_repo, \"testuser\", \"test@test.com\", \"password123\")\n\n        assert result == mock_user\n        mock_repo.create.assert_called_once()\n\n\nclass TestAuthenticateUser:\n    def test_authenticate_user_success(self):\n        mock_repo = Mock()\n        password = \"password123\"\n        hashed = hash_password(password)\n        mock_user = Mock()\n        mock_user.hashed_password = hashed\n        mock_repo.get_by_username.return_value = mock_user\n\n        result = authenticate_user(mock_repo, \"testuser\", password)\n\n        assert result == mock_user\n\n    def test_authenticate_user_wrong_password(self):\n        mock_repo = Mock()\n        mock_user = Mock()\n        mock_user.hashed_password = hash_password(\"correctpassword\")\n        mock_repo.get_by_username.return_value = mock_user\n\n        result = authenticate_user(mock_repo, \"testuser\", \"wrongpassword\")\n\n        assert result is None\n\n    def test_authenticate_user_not_found(self):\n        mock_repo = Mock()\n        mock_repo.get_by_username.return_value = None\n\n        result = authenticate_user(mock_repo, \"nonexistent\", \"password\")\n\n        assert result is None\n\n\nclass TestCreatePost:\n    def test_create_post_success(self):\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 1\n        mock_post.content = \"Test post\"\n        mock_post_repo.create.return_value = mock_post\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Test post\",\n            author_id=1,\n            session_id=1,\n            is_anonymous=False\n        )\n\n        assert result == mock_post\n        mock_post_repo.create.assert_called_once_with(\"Test post\", 1, 1, False)\n\n    def test_create_post_with_mention_dispatches_event(self):\n        \"\"\"Test that creating a post with a valid @username mention dispatches the user_mentioned event.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        # Create mock post\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post.content = \"Hey @johndoe check this out!\"\n        mock_post_repo.create.return_value = mock_post\n\n        # Create mock mentioned user\n        mock_mentioned_user = Mock()\n        mock_mentioned_user.id = 5\n        mock_mentioned_user.username = \"johndoe\"\n        mock_user_repo.get_by_username.return_value = mock_mentioned_user\n\n        # Call create_post with content containing a mention\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Hey @johndoe check this out!\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Verify the post was created\n        assert result == mock_post\n        mock_post_repo.create.assert_called_once_with(\n            \"Hey @johndoe check this out!\", 1, 10, False\n        )\n\n        # Verify the user repository was queried for the mentioned username\n        mock_user_repo.get_by_username.assert_called_once_with(\"johndoe\")\n\n        # Verify the event dispatcher was called with the correct event and payload\n        mock_event_dispatcher.dispatch.assert_called_once_with(\n            \"user_mentioned\",\n            {\n                \"actor_id\": 1,\n                \"recipient_id\": 5,\n                \"post_id\": 42\n            }\n        )\n\n    def test_create_post_with_mention_self_no_event(self):\n        \"\"\"Test that mentioning yourself does not dispatch an event.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post_repo.create.return_value = mock_post\n\n        # Mentioned user is the same as author\n        mock_mentioned_user = Mock()\n        mock_mentioned_user.id = 1  # Same as author_id\n        mock_user_repo.get_by_username.return_value = mock_mentioned_user\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Talking to @myself\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Event should NOT be dispatched when mentioning yourself\n        mock_event_dispatcher.dispatch.assert_not_called()\n\n    def test_create_post_with_invalid_mention_no_event(self):\n        \"\"\"Test that mentioning a non-existent user does not dispatch an event.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post_repo.create.return_value = mock_post\n\n        # User not found\n        mock_user_repo.get_by_username.return_value = None\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Hey @nonexistent check this!\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Event should NOT be dispatched for non-existent users\n        mock_event_dispatcher.dispatch.assert_not_called()\n\n    def test_create_post_with_multiple_mentions_dispatches_multiple_events(self):\n        \"\"\"Test that multiple valid mentions dispatch multiple events.\"\"\"\n        mock_post_repo = Mock()\n        mock_user_repo = Mock()\n        mock_event_dispatcher = Mock()\n\n        mock_post = Mock()\n        mock_post.id = 42\n        mock_post_repo.create.return_value = mock_post\n\n        # Setup two different users\n        mock_user1 = Mock()\n        mock_user1.id = 5\n        mock_user2 = Mock()\n        mock_user2.id = 6\n\n        def get_user_by_username(username):\n            if username == \"john\":\n                return mock_user1\n            elif username == \"jane\":\n                return mock_user2\n            return None\n\n        mock_user_repo.get_by_username.side_effect = get_user_by_username\n\n        result = create_post(\n            mock_post_repo,\n            mock_user_repo,\n            mock_event_dispatcher,\n            \"Hey @john and @jane!\",\n            author_id=1,\n            session_id=10,\n            is_anonymous=False\n        )\n\n        # Should dispatch two events\n        assert mock_event_dispatcher.dispatch.call_count == 2\n"
          },
          "generated_files": [
            "classpulse/models.py",
            "classpulse/repositories.py",
            "classpulse/services.py",
            "classpulse/events.py",
            "classpulse/worker.py",
            "classpulse/main.py",
            "classpulse/config.py",
            "tests/test_services.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.8043126450116009,
                "dependency_traversal_accuracy": 0.7912090179103899,
                "cross_file_reasoning_depth": 0.17395833333333333,
                "system_thinking_score": 0.4253972035178362,
                "robustness_score": 0.4717467602591793,
                "comprehensiveness_score": 0.5179142668586513,
                "innovation_score": 0.3474487041036717,
                "solution_elegance_score": 0.8791133245208966
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.10053908062645012,
                "dependency_traversal_weighted": 0.09890112723879874,
                "cross_file_reasoning_weighted": 0.021744791666666666,
                "system_thinking_weighted": 0.05317465043972953,
                "robustness_weighted": 0.05896834503239741,
                "comprehensiveness_weighted": 0.06473928335733141,
                "innovation_weighted": 0.04343108801295896,
                "solution_elegance_weighted": 0.10988916556511208
              },
              "total_software_engineering_score": 0.5513875319394449
            },
            "functional_correctness_details": {
              "compilation": {
                "success": true,
                "score": 0.9,
                "execution_time": 0.5197999477386475,
                "errors": [],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "classpulse/models.py",
                  "classpulse/repositories.py",
                  "classpulse/services.py",
                  "classpulse/events.py",
                  "classpulse/worker.py",
                  "classpulse/main.py",
                  "classpulse/config.py",
                  "tests/test_services.py"
                ],
                "scoring_breakdown": {
                  "base_success": 0.8,
                  "fast_compilation_bonus": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 8,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 8 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.45770718232044194,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.9,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.45770718232044194,
                "idc_weight": 0.2,
                "total_functional_score": 0.6715414364640884
              }
            },
            "code_quality_details": {
              "files_analyzed": 8,
              "quality_checks": {
                "classpulse/models.py": {
                  "line_count": 83,
                  "non_empty_lines": 65,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 5,
                  "import_count": 6,
                  "quality_score": 0.7
                },
                "classpulse/repositories.py": {
                  "line_count": 125,
                  "non_empty_lines": 101,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 19,
                  "class_count": 4,
                  "import_count": 6,
                  "quality_score": 0.7999999999999999
                },
                "classpulse/services.py": {
                  "line_count": 90,
                  "non_empty_lines": 69,
                  "comment_lines": 1,
                  "comment_ratio": 0.014492753623188406,
                  "function_count": 9,
                  "class_count": 0,
                  "import_count": 12,
                  "quality_score": 0.7999999999999999
                },
                "classpulse/events.py": {
                  "line_count": 31,
                  "non_empty_lines": 22,
                  "comment_lines": 1,
                  "comment_ratio": 0.045454545454545456,
                  "function_count": 4,
                  "class_count": 1,
                  "import_count": 4,
                  "quality_score": 0.6
                },
                "classpulse/worker.py": {
                  "line_count": 82,
                  "non_empty_lines": 63,
                  "comment_lines": 1,
                  "comment_ratio": 0.015873015873015872,
                  "function_count": 10,
                  "class_count": 1,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "classpulse/main.py": {
                  "line_count": 230,
                  "non_empty_lines": 179,
                  "comment_lines": 1,
                  "comment_ratio": 0.00558659217877095,
                  "function_count": 13,
                  "class_count": 13,
                  "import_count": 25,
                  "quality_score": 0.7999999999999999
                },
                "classpulse/config.py": {
                  "line_count": 24,
                  "non_empty_lines": 17,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 2,
                  "class_count": 0,
                  "import_count": 5,
                  "quality_score": 0.6
                },
                "tests/test_services.py": {
                  "line_count": 261,
                  "non_empty_lines": 208,
                  "comment_lines": 12,
                  "comment_ratio": 0.057692307692307696,
                  "function_count": 17,
                  "class_count": 5,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7562499999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8227106227106229,
                "multi_session_memory_retention": 0.8448304383788254
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.41135531135531145,
                "multi_session_memory_retention_weighted": 0.4224152191894127
              },
              "total_longcontext_utilization_score": 0.8337705305447242
            }
          },
          "timestamp": "2026-01-14T21:50:06.173516"
        }
      }
    },
    "python_ml_training_hard_015_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_ml_training_hard_015_feature_implementation_expert_01",
          "scenario_title": "Implement Optuna-based Hyperparameter Optimization with Pruning",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5485124755502813,
          "functional_correctness_score": 0.4163006430868167,
          "code_quality_score": 0.7824999999999999,
          "longcontext_utilization_score": 0.5275641025641025,
          "total_score": 2.7677579670128383,
          "generation_time": 123.61206007003784,
          "code_files_generated": 4,
          "total_lines_generated": 1155,
          "parsing_success": true,
          "solution_code": {
            "src/config.py": "\"\"\"Configuration module for MuseNet Alchemist platform.\n\nThis module contains all configuration settings for the platform,\nincluding hyperparameter tuning settings.\n\"\"\"\n\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Any, Optional\n\n\n@dataclass\nclass DatabaseConfig:\n    \"\"\"Database configuration settings.\"\"\"\n    host: str = \"localhost\"\n    port: int = 5432\n    name: str = \"musenet_db\"\n    user: str = \"admin\"\n    password: str = \"\"\n\n\n@dataclass\nclass ModelConfig:\n    \"\"\"Model configuration settings.\"\"\"\n    input_size: int = 128\n    hidden_size: int = 256\n    output_size: int = 64\n    num_layers: int = 3\n    dropout: float = 0.1\n    activation: str = \"relu\"\n\n\n@dataclass\nclass TrainingConfig:\n    \"\"\"Training configuration settings.\"\"\"\n    batch_size: int = 32\n    learning_rate: float = 0.001\n    num_epochs: int = 100\n    early_stopping_patience: int = 10\n    validation_split: float = 0.2\n    optimizer: str = \"adam\"\n    loss_function: str = \"mse\"\n\n\n@dataclass\nclass HyperparameterTuningConfig:\n    \"\"\"Hyperparameter tuning configuration settings.\n    \n    Attributes:\n        strategy: The optimization strategy to use. Options are:\n            - 'grid_search': Exhaustive search over specified parameter grid\n            - 'random_search': Random sampling from parameter distributions (default)\n            - 'optuna': Bayesian optimization with trial pruning support\n        n_trials: Number of trials for random_search or optuna strategies\n        n_jobs: Number of parallel jobs for tuning\n        search_space: Dictionary defining the hyperparameter search space\n        pruner: Pruner type for optuna ('median', 'percentile', 'hyperband')\n        sampler: Sampler type for optuna ('tpe', 'random', 'cmaes')\n        study_name: Name for the optuna study\n        storage: Optional storage URL for optuna study persistence\n    \"\"\"\n    strategy: str = \"random_search\"  # Options: 'grid_search', 'random_search', 'optuna'\n    n_trials: int = 100\n    n_jobs: int = 1\n    search_space: Dict[str, Any] = field(default_factory=lambda: {\n        \"learning_rate\": {\"type\": \"float\", \"low\": 1e-5, \"high\": 1e-1, \"log\": True},\n        \"batch_size\": {\"type\": \"categorical\", \"choices\": [16, 32, 64, 128]},\n        \"hidden_size\": {\"type\": \"int\", \"low\": 64, \"high\": 512, \"step\": 64},\n        \"num_layers\": {\"type\": \"int\", \"low\": 1, \"high\": 5},\n        \"dropout\": {\"type\": \"float\", \"low\": 0.0, \"high\": 0.5}\n    })\n    pruner: str = \"median\"  # Options: 'median', 'percentile', 'hyperband'\n    sampler: str = \"tpe\"  # Options: 'tpe', 'random', 'cmaes'\n    study_name: str = \"musenet_optimization\"\n    storage: Optional[str] = None\n\n\n@dataclass\nclass LoggingConfig:\n    \"\"\"Logging configuration settings.\"\"\"\n    level: str = \"INFO\"\n    format: str = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    file_path: str = \"logs/musenet.log\"\n    max_bytes: int = 10485760  # 10MB\n    backup_count: int = 5\n\n\n@dataclass\nclass APIConfig:\n    \"\"\"API configuration settings.\"\"\"\n    host: str = \"0.0.0.0\"\n    port: int = 8000\n    debug: bool = False\n    cors_origins: List[str] = field(default_factory=lambda: [\"*\"])\n    api_prefix: str = \"/api/v1\"\n\n\n@dataclass\nclass Config:\n    \"\"\"Main configuration class containing all settings.\"\"\"\n    database: DatabaseConfig = field(default_factory=DatabaseConfig)\n    model: ModelConfig = field(default_factory=ModelConfig)\n    training: TrainingConfig = field(default_factory=TrainingConfig)\n    hyperparameter_tuning: HyperparameterTuningConfig = field(default_factory=HyperparameterTuningConfig)\n    logging: LoggingConfig = field(default_factory=LoggingConfig)\n    api: APIConfig = field(default_factory=APIConfig)\n\n    @classmethod\n    def from_env(cls) -> \"Config\":\n        \"\"\"Create configuration from environment variables.\"\"\"\n        config = cls()\n        \n        # Database config from env\n        config.database.host = os.getenv(\"DB_HOST\", config.database.host)\n        config.database.port = int(os.getenv(\"DB_PORT\", config.database.port))\n        config.database.name = os.getenv(\"DB_NAME\", config.database.name)\n        config.database.user = os.getenv(\"DB_USER\", config.database.user)\n        config.database.password = os.getenv(\"DB_PASSWORD\", config.database.password)\n        \n        # Training config from env\n        config.training.batch_size = int(os.getenv(\"BATCH_SIZE\", config.training.batch_size))\n        config.training.learning_rate = float(os.getenv(\"LEARNING_RATE\", config.training.learning_rate))\n        config.training.num_epochs = int(os.getenv(\"NUM_EPOCHS\", config.training.num_epochs))\n        \n        # Hyperparameter tuning config from env\n        config.hyperparameter_tuning.strategy = os.getenv(\n            \"HP_TUNING_STRATEGY\", config.hyperparameter_tuning.strategy\n        )\n        config.hyperparameter_tuning.n_trials = int(\n            os.getenv(\"HP_TUNING_N_TRIALS\", config.hyperparameter_tuning.n_trials)\n        )\n        \n        # API config from env\n        config.api.host = os.getenv(\"API_HOST\", config.api.host)\n        config.api.port = int(os.getenv(\"API_PORT\", config.api.port))\n        config.api.debug = os.getenv(\"API_DEBUG\", \"false\").lower() == \"true\"\n        \n        return config\n\n\n# Global configuration instance\nconfig = Config.from_env()\n\n\ndef get_config() -> Config:\n    \"\"\"Get the global configuration instance.\"\"\"\n    return config\n\n\ndef update_config(**kwargs) -> Config:\n    \"\"\"Update configuration with provided keyword arguments.\"\"\"\n    global config\n    for key, value in kwargs.items():\n        if hasattr(config, key):\n            setattr(config, key, value)\n    return config\n",
            "src/module_1.py": "\"\"\"Core model training module for MuseNet Alchemist platform.\n\nThis module contains the primary training functions and training loop\nimplementation with support for Optuna trial pruning.\n\"\"\"\n\nimport logging\nfrom typing import Dict, Any, Optional, Tuple, List, Callable\nimport numpy as np\n\ntry:\n    import optuna\n    OPTUNA_AVAILABLE = True\nexcept ImportError:\n    OPTUNA_AVAILABLE = False\n    optuna = None\n\nfrom src.config import get_config, TrainingConfig\n\nlogger = logging.getLogger(__name__)\n\n\nclass EarlyStopping:\n    \"\"\"Early stopping handler for training.\"\"\"\n    \n    def __init__(self, patience: int = 10, min_delta: float = 0.0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.should_stop = False\n    \n    def __call__(self, val_loss: float) -> bool:\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.should_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n        return self.should_stop\n\n\nclass ModelTrainer:\n    \"\"\"Main model trainer class with Optuna pruning support.\"\"\"\n    \n    def __init__(self, model: Any, config: Optional[TrainingConfig] = None):\n        self.model = model\n        self.config = config or get_config().training\n        self.training_history: List[Dict[str, float]] = []\n        self.best_model_state = None\n        self.best_val_loss = float('inf')\n    \n    def train(\n        self,\n        train_data: Any,\n        val_data: Any,\n        optuna_trial: Optional[\"optuna.Trial\"] = None,\n        callbacks: Optional[List[Callable]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Train the model with optional Optuna trial pruning.\n        \n        Args:\n            train_data: Training dataset\n            val_data: Validation dataset\n            optuna_trial: Optional Optuna trial object for hyperparameter\n                optimization with pruning support. When provided, the training\n                loop will report intermediate values and check for pruning.\n            callbacks: Optional list of callback functions\n        \n        Returns:\n            Dictionary containing training results and metrics\n        \n        Raises:\n            optuna.TrialPruned: If the trial should be pruned (only when\n                optuna_trial is provided and pruning is triggered)\n        \"\"\"\n        logger.info(\"Starting model training\")\n        \n        early_stopping = EarlyStopping(\n            patience=self.config.early_stopping_patience\n        )\n        \n        self.training_history = []\n        \n        for epoch in range(self.config.num_epochs):\n            # Training step\n            train_loss = self._train_epoch(train_data, epoch)\n            \n            # Validation step\n            val_loss = self._validate_epoch(val_data, epoch)\n            \n            # Record history\n            epoch_metrics = {\n                \"epoch\": epoch,\n                \"train_loss\": train_loss,\n                \"val_loss\": val_loss\n            }\n            self.training_history.append(epoch_metrics)\n            \n            logger.info(\n                f\"Epoch {epoch + 1}/{self.config.num_epochs} - \"\n                f\"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\"\n            )\n            \n            # Update best model\n            if val_loss < self.best_val_loss:\n                self.best_val_loss = val_loss\n                self.best_model_state = self._get_model_state()\n            \n            # Optuna pruning integration\n            if optuna_trial is not None:\n                if not OPTUNA_AVAILABLE:\n                    raise ImportError(\n                        \"Optuna is required for trial pruning but is not installed. \"\n                        \"Install it with: pip install optuna\"\n                    )\n                \n                # Report intermediate value to Optuna\n                optuna_trial.report(val_loss, epoch)\n                \n                # Check if trial should be pruned\n                if optuna_trial.should_prune():\n                    logger.info(\n                        f\"Trial {optuna_trial.number} pruned at epoch {epoch + 1}\"\n                    )\n                    raise optuna.TrialPruned()\n            \n            # Execute callbacks\n            if callbacks:\n                for callback in callbacks:\n                    callback(epoch, epoch_metrics)\n            \n            # Check early stopping\n            if early_stopping(val_loss):\n                logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n                break\n        \n        # Restore best model\n        if self.best_model_state is not None:\n            self._set_model_state(self.best_model_state)\n        \n        return {\n            \"final_train_loss\": self.training_history[-1][\"train_loss\"],\n            \"final_val_loss\": self.training_history[-1][\"val_loss\"],\n            \"best_val_loss\": self.best_val_loss,\n            \"epochs_trained\": len(self.training_history),\n            \"history\": self.training_history\n        }\n    \n    def _train_epoch(self, train_data: Any, epoch: int) -> float:\n        \"\"\"Execute one training epoch.\"\"\"\n        # Placeholder implementation - actual implementation would use\n        # the specific ML framework (PyTorch, TensorFlow, etc.)\n        train_loss = np.random.uniform(0.1, 1.0) * (1 / (epoch + 1))\n        return train_loss\n    \n    def _validate_epoch(self, val_data: Any, epoch: int) -> float:\n        \"\"\"Execute one validation epoch.\"\"\"\n        # Placeholder implementation\n        val_loss = np.random.uniform(0.1, 1.0) * (1 / (epoch + 1))\n        return val_loss\n    \n    def _get_model_state(self) -> Any:\n        \"\"\"Get current model state for checkpointing.\"\"\"\n        # Placeholder - would return actual model state dict\n        return {\"state\": \"model_state\"}\n    \n    def _set_model_state(self, state: Any) -> None:\n        \"\"\"Set model state from checkpoint.\"\"\"\n        # Placeholder - would load actual model state\n        pass\n\n\ndef train_model(\n    model: Any,\n    train_data: Any,\n    val_data: Any,\n    config: Optional[TrainingConfig] = None,\n    optuna_trial: Optional[\"optuna.Trial\"] = None,\n    callbacks: Optional[List[Callable]] = None\n) -> Dict[str, Any]:\n    \"\"\"Convenience function for training a model.\n    \n    This function wraps the ModelTrainer class for simpler usage.\n    \n    Args:\n        model: The model to train\n        train_data: Training dataset\n        val_data: Validation dataset\n        config: Optional training configuration\n        optuna_trial: Optional Optuna trial object for hyperparameter\n            optimization with pruning support. When provided:\n            - Intermediate validation losses are reported to Optuna after each epoch\n            - The trial is checked for pruning using trial.should_prune()\n            - If pruning is triggered, optuna.TrialPruned exception is raised\n        callbacks: Optional list of callback functions\n    \n    Returns:\n        Dictionary containing training results and metrics\n    \n    Raises:\n        optuna.TrialPruned: If the trial should be pruned during Optuna optimization\n    \"\"\"\n    trainer = ModelTrainer(model, config)\n    return trainer.train(\n        train_data,\n        val_data,\n        optuna_trial=optuna_trial,\n        callbacks=callbacks\n    )\n\n\ndef create_model(model_config: Dict[str, Any]) -> Any:\n    \"\"\"Create a model instance from configuration.\"\"\"\n    # Placeholder implementation\n    logger.info(f\"Creating model with config: {model_config}\")\n    return {\"model\": \"placeholder\", \"config\": model_config}\n\n\ndef evaluate_model(model: Any, test_data: Any) -> Dict[str, float]:\n    \"\"\"Evaluate a trained model on test data.\"\"\"\n    # Placeholder implementation\n    return {\n        \"test_loss\": np.random.uniform(0.1, 0.5),\n        \"accuracy\": np.random.uniform(0.7, 0.95)\n    }\n",
            "src/module_10.py": "\"\"\"Hyperparameter tuning orchestrator module for MuseNet Alchemist platform.\n\nThis module handles hyperparameter optimization using various strategies\nincluding grid search, random search, and Optuna-based Bayesian optimization.\n\"\"\"\n\nimport logging\nimport itertools\nfrom typing import Dict, Any, Optional, List, Tuple, Callable\nimport numpy as np\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\n\ntry:\n    import optuna\n    from optuna.pruners import MedianPruner, PercentilePruner, HyperbandPruner\n    from optuna.samplers import TPESampler, RandomSampler, CmaEsSampler\n    OPTUNA_AVAILABLE = True\nexcept ImportError:\n    OPTUNA_AVAILABLE = False\n    optuna = None\n\nfrom src.config import get_config, HyperparameterTuningConfig\nfrom src.module_1 import train_model, create_model\n\nlogger = logging.getLogger(__name__)\n\n\nclass HyperparameterTuner:\n    \"\"\"Main hyperparameter tuning orchestrator class.\"\"\"\n    \n    def __init__(\n        self,\n        config: Optional[HyperparameterTuningConfig] = None,\n        train_data: Any = None,\n        val_data: Any = None\n    ):\n        self.config = config or get_config().hyperparameter_tuning\n        self.train_data = train_data\n        self.val_data = val_data\n        self.results: List[Dict[str, Any]] = []\n        self.best_params: Optional[Dict[str, Any]] = None\n        self.best_score: float = float('inf')\n    \n    def tune(self) -> Dict[str, Any]:\n        \"\"\"Run hyperparameter tuning based on configured strategy.\n        \n        Returns:\n            Dictionary containing best parameters and tuning results\n        \"\"\"\n        strategy = self.config.strategy\n        logger.info(f\"Starting hyperparameter tuning with strategy: {strategy}\")\n        \n        if strategy == \"grid_search\":\n            return self._run_grid_search()\n        elif strategy == \"random_search\":\n            return self._run_random_search()\n        elif strategy == \"optuna\":\n            return self._run_optuna_optimization()\n        else:\n            raise ValueError(\n                f\"Unknown tuning strategy: {strategy}. \"\n                f\"Supported strategies: 'grid_search', 'random_search', 'optuna'\"\n            )\n    \n    def _run_grid_search(self) -> Dict[str, Any]:\n        \"\"\"Execute grid search hyperparameter tuning.\"\"\"\n        logger.info(\"Running grid search optimization\")\n        \n        # Generate all parameter combinations\n        param_grid = self._build_param_grid()\n        param_names = list(param_grid.keys())\n        param_values = list(param_grid.values())\n        \n        all_combinations = list(itertools.product(*param_values))\n        logger.info(f\"Total combinations to evaluate: {len(all_combinations)}\")\n        \n        for i, combination in enumerate(all_combinations):\n            params = dict(zip(param_names, combination))\n            logger.info(f\"Evaluating combination {i + 1}/{len(all_combinations)}: {params}\")\n            \n            try:\n                score = self._evaluate_params(params)\n                self.results.append({\"params\": params, \"score\": score})\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_params = params\n                    logger.info(f\"New best score: {score} with params: {params}\")\n            except Exception as e:\n                logger.error(f\"Error evaluating params {params}: {e}\")\n                self.results.append({\"params\": params, \"score\": float('inf'), \"error\": str(e)})\n        \n        return self._build_results()\n    \n    def _run_random_search(self) -> Dict[str, Any]:\n        \"\"\"Execute random search hyperparameter tuning.\"\"\"\n        logger.info(f\"Running random search optimization with {self.config.n_trials} trials\")\n        \n        for trial_num in range(self.config.n_trials):\n            params = self._sample_random_params()\n            logger.info(f\"Trial {trial_num + 1}/{self.config.n_trials}: {params}\")\n            \n            try:\n                score = self._evaluate_params(params)\n                self.results.append({\"params\": params, \"score\": score})\n                \n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_params = params\n                    logger.info(f\"New best score: {score} with params: {params}\")\n            except Exception as e:\n                logger.error(f\"Error evaluating params {params}: {e}\")\n                self.results.append({\"params\": params, \"score\": float('inf'), \"error\": str(e)})\n        \n        return self._build_results()\n    \n    def _run_optuna_optimization(self) -> Dict[str, Any]:\n        \"\"\"Execute Optuna-based Bayesian optimization with pruning.\"\"\"\n        if not OPTUNA_AVAILABLE:\n            raise ImportError(\n                \"Optuna is required for 'optuna' strategy but is not installed. \"\n                \"Install it with: pip install optuna\"\n            )\n        \n        logger.info(f\"Running Optuna optimization with {self.config.n_trials} trials\")\n        \n        # Create pruner\n        pruner = self._create_pruner()\n        \n        # Create sampler\n        sampler = self._create_sampler()\n        \n        # Create study\n        study = optuna.create_study(\n            study_name=self.config.study_name,\n            direction=\"minimize\",\n            pruner=pruner,\n            sampler=sampler,\n            storage=self.config.storage,\n            load_if_exists=True\n        )\n        \n        # Define objective function\n        def objective(trial: optuna.Trial) -> float:\n            return self._optuna_objective(trial)\n        \n        # Run optimization\n        study.optimize(\n            objective,\n            n_trials=self.config.n_trials,\n            n_jobs=self.config.n_jobs,\n            show_progress_bar=True\n        )\n        \n        # Store results\n        self.best_params = study.best_params\n        self.best_score = study.best_value\n        \n        for trial in study.trials:\n            self.results.append({\n                \"params\": trial.params,\n                \"score\": trial.value if trial.value is not None else float('inf'),\n                \"state\": str(trial.state),\n                \"trial_number\": trial.number\n            })\n        \n        logger.info(f\"Optuna optimization complete. Best score: {self.best_score}\")\n        logger.info(f\"Best parameters: {self.best_params}\")\n        \n        # Log pruning statistics\n        pruned_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])\n        complete_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n        logger.info(f\"Pruned trials: {pruned_trials}, Complete trials: {complete_trials}\")\n        \n        return self._build_results(study=study)\n    \n    def _optuna_objective(self, trial: optuna.Trial) -> float:\n        \"\"\"Objective function for Optuna optimization.\n        \n        This function suggests hyperparameters using the trial object,\n        creates a model with those parameters, and trains it while\n        passing the trial object for pruning support.\n        \n        Args:\n            trial: Optuna trial object for parameter suggestion and pruning\n        \n        Returns:\n            Validation loss (objective value to minimize)\n        \n        Raises:\n            optuna.TrialPruned: If the trial is pruned during training\n        \"\"\"\n        # Suggest hyperparameters based on search space\n        params = self._suggest_optuna_params(trial)\n        \n        logger.info(f\"Trial {trial.number}: Evaluating params: {params}\")\n        \n        # Create model with suggested parameters\n        model = create_model(params)\n        \n        # Train model with trial object for pruning\n        # The trial object is passed to enable intermediate value reporting\n        # and pruning of unpromising trials\n        training_result = train_model(\n            model=model,\n            train_data=self.train_data,\n            val_data=self.val_data,\n            optuna_trial=trial  # Pass trial for pruning integration\n        )\n        \n        return training_result[\"best_val_loss\"]\n    \n    def _suggest_optuna_params(self, trial: optuna.Trial) -> Dict[str, Any]:\n        \"\"\"Suggest hyperparameters using Optuna trial.\n        \n        Args:\n            trial: Optuna trial object\n        \n        Returns:\n            Dictionary of suggested hyperparameters\n        \"\"\"\n        params = {}\n        \n        for param_name, param_config in self.config.search_space.items():\n            param_type = param_config.get(\"type\", \"float\")\n            \n            if param_type == \"float\":\n                params[param_name] = trial.suggest_float(\n                    param_name,\n                    param_config[\"low\"],\n                    param_config[\"high\"],\n                    log=param_config.get(\"log\", False)\n                )\n            elif param_type == \"int\":\n                params[param_name] = trial.suggest_int(\n                    param_name,\n                    param_config[\"low\"],\n                    param_config[\"high\"],\n                    step=param_config.get(\"step\", 1)\n                )\n            elif param_type == \"categorical\":\n                params[param_name] = trial.suggest_categorical(\n                    param_name,\n                    param_config[\"choices\"]\n                )\n            else:\n                raise ValueError(f\"Unknown parameter type: {param_type}\")\n        \n        return params\n    \n    def _create_pruner(self) -> \"optuna.pruners.BasePruner\":\n        \"\"\"Create Optuna pruner based on configuration.\"\"\"\n        pruner_type = self.config.pruner.lower()\n        \n        if pruner_type == \"median\":\n            return MedianPruner(\n                n_startup_trials=5,\n                n_warmup_steps=10,\n                interval_steps=1\n            )\n        elif pruner_type == \"percentile\":\n            return PercentilePruner(\n                percentile=25.0,\n                n_startup_trials=5,\n                n_warmup_steps=10\n            )\n        elif pruner_type == \"hyperband\":\n            return HyperbandPruner(\n                min_resource=1,\n                max_resource=100,\n                reduction_factor=3\n            )\n        else:\n            logger.warning(f\"Unknown pruner type: {pruner_type}, using MedianPruner\")\n            return MedianPruner()\n    \n    def _create_sampler(self) -> \"optuna.samplers.BaseSampler\":\n        \"\"\"Create Optuna sampler based on configuration.\"\"\"\n        sampler_type = self.config.sampler.lower()\n        \n        if sampler_type == \"tpe\":\n            return TPESampler(n_startup_trials=10)\n        elif sampler_type == \"random\":\n            return RandomSampler()\n        elif sampler_type == \"cmaes\":\n            return CmaEsSampler()\n        else:\n            logger.warning(f\"Unknown sampler type: {sampler_type}, using TPESampler\")\n            return TPESampler()\n    \n    def _build_param_grid(self) -> Dict[str, List[Any]]:\n        \"\"\"Build parameter grid for grid search.\"\"\"\n        param_grid = {}\n        \n        for param_name, param_config in self.config.search_space.items():\n            param_type = param_config.get(\"type\", \"float\")\n            \n            if param_type == \"categorical\":\n                param_grid[param_name] = param_config[\"choices\"]\n            elif param_type == \"int\":\n                step = param_config.get(\"step\", 1)\n                param_grid[param_name] = list(range(\n                    param_config[\"low\"],\n                    param_config[\"high\"] + 1,\n                    step\n                ))\n            elif param_type == \"float\":\n                # For grid search, create discrete points for float params\n                n_points = param_config.get(\"n_points\", 5)\n                if param_config.get(\"log\", False):\n                    param_grid[param_name] = list(np.logspace(\n                        np.log10(param_config[\"low\"]),\n                        np.log10(param_config[\"high\"]),\n                        n_points\n                    ))\n                else:\n                    param_grid[param_name] = list(np.linspace(\n                        param_config[\"low\"],\n                        param_config[\"high\"],\n                        n_points\n                    ))\n        \n        return param_grid\n    \n    def _sample_random_params(self) -> Dict[str, Any]:\n        \"\"\"Sample random parameters for random search.\"\"\"\n        params = {}\n        \n        for param_name, param_config in self.config.search_space.items():\n            param_type = param_config.get(\"type\", \"float\")\n            \n            if param_type == \"categorical\":\n                params[param_name] = np.random.choice(param_config[\"choices\"])\n            elif param_type == \"int\":\n                params[param_name] = np.random.randint(\n                    param_config[\"low\"],\n                    param_config[\"high\"] + 1\n                )\n            elif param_type == \"float\":\n                if param_config.get(\"log\", False):\n                    params[param_name] = np.exp(np.random.uniform(\n                        np.log(param_config[\"low\"]),\n                        np.log(param_config[\"high\"])\n                    ))\n                else:\n                    params[param_name] = np.random.uniform(\n                        param_config[\"low\"],\n                        param_config[\"high\"]\n                    )\n        \n        return params\n    \n    def _evaluate_params(self, params: Dict[str, Any]) -> float:\n        \"\"\"Evaluate a set of hyperparameters.\"\"\"\n        model = create_model(params)\n        result = train_model(\n            model=model,\n            train_data=self.train_data,\n            val_data=self.val_data\n        )\n        return result[\"best_val_loss\"]\n    \n    def _build_results(self, study: Optional[\"optuna.Study\"] = None) -> Dict[str, Any]:\n        \"\"\"Build final results dictionary.\"\"\"\n        results = {\n            \"strategy\": self.config.strategy,\n            \"best_params\": self.best_params,\n            \"best_score\": self.best_score,\n            \"n_trials\": len(self.results),\n            \"all_results\": self.results\n        }\n        \n        if study is not None:\n            results[\"optuna_study_name\"] = study.study_name\n            results[\"pruned_trials\"] = len([\n                t for t in study.trials \n                if t.state == optuna.trial.TrialState.PRUNED\n            ])\n            results[\"complete_trials\"] = len([\n                t for t in study.trials \n                if t.state == optuna.trial.TrialState.COMPLETE\n            ])\n        \n        return results\n\n\ndef run_hyperparameter_tuning(\n    train_data: Any,\n    val_data: Any,\n    config: Optional[HyperparameterTuningConfig] = None\n) -> Dict[str, Any]:\n    \"\"\"Convenience function to run hyperparameter tuning.\n    \n    Args:\n        train_data: Training dataset\n        val_data: Validation dataset\n        config: Optional hyperparameter tuning configuration\n    \n    Returns:\n        Dictionary containing tuning results\n    \"\"\"\n    tuner = HyperparameterTuner(\n        config=config,\n        train_data=train_data,\n        val_data=val_data\n    )\n    return tuner.tune()\n",
            "docs/api.md": "# MuseNet Alchemist API Documentation\n\n## Overview\n\nThe MuseNet Alchemist API provides endpoints for model training, evaluation, and hyperparameter tuning. This document describes the available endpoints and their usage.\n\n## Base URL\n\n```\nhttp://localhost:8000/api/v1\n```\n\n## Authentication\n\nAll API requests require authentication using a Bearer token in the Authorization header:\n\n```\nAuthorization: Bearer <your_token>\n```\n\n## Endpoints\n\n### Health Check\n\n**GET** `/health`\n\nCheck the health status of the API.\n\n**Response:**\n```json\n{\n    \"status\": \"healthy\",\n    \"version\": \"1.0.0\"\n}\n```\n\n---\n\n### Model Training\n\n**POST** `/models/train`\n\nStart a new model training job.\n\n**Request Body:**\n```json\n{\n    \"model_name\": \"my_model\",\n    \"dataset_id\": \"dataset_123\",\n    \"config\": {\n        \"batch_size\": 32,\n        \"learning_rate\": 0.001,\n        \"num_epochs\": 100\n    }\n}\n```\n\n**Response:**\n```json\n{\n    \"job_id\": \"job_456\",\n    \"status\": \"started\",\n    \"message\": \"Training job started successfully\"\n}\n```\n\n---\n\n### Model Evaluation\n\n**POST** `/models/{model_id}/evaluate`\n\nEvaluate a trained model on a test dataset.\n\n**Path Parameters:**\n- `model_id`: The ID of the model to evaluate\n\n**Request Body:**\n```json\n{\n    \"test_dataset_id\": \"test_dataset_789\",\n    \"metrics\": [\"accuracy\", \"loss\", \"f1_score\"]\n}\n```\n\n**Response:**\n```json\n{\n    \"model_id\": \"model_123\",\n    \"metrics\": {\n        \"accuracy\": 0.92,\n        \"loss\": 0.23,\n        \"f1_score\": 0.89\n    }\n}\n```\n\n---\n\n### Hyperparameter Tuning\n\n**POST** `/tuning/start`\n\nStart a hyperparameter tuning job. This endpoint supports multiple optimization strategies to find the best model configuration.\n\n**Request Body:**\n```json\n{\n    \"model_name\": \"my_model\",\n    \"dataset_id\": \"dataset_123\",\n    \"strategy\": \"optuna\",\n    \"n_trials\": 100,\n    \"search_space\": {\n        \"learning_rate\": {\n            \"type\": \"float\",\n            \"low\": 1e-5,\n            \"high\": 1e-1,\n            \"log\": true\n        },\n        \"batch_size\": {\n            \"type\": \"categorical\",\n            \"choices\": [16, 32, 64, 128]\n        },\n        \"hidden_size\": {\n            \"type\": \"int\",\n            \"low\": 64,\n            \"high\": 512,\n            \"step\": 64\n        },\n        \"dropout\": {\n            \"type\": \"float\",\n            \"low\": 0.0,\n            \"high\": 0.5\n        }\n    }\n}\n```\n\n**Strategy Options:**\n\n| Strategy | Description |\n|----------|-------------|\n| `grid_search` | Exhaustive search over all parameter combinations. Best for small search spaces with discrete values. |\n| `random_search` | Random sampling from parameter distributions. More efficient than grid search for larger spaces. |\n| `optuna` | Bayesian optimization using the Optuna framework. Uses intelligent sampling (TPE by default) and supports **trial pruning** to automatically stop unpromising training runs early, significantly reducing computation time. This is the recommended strategy for complex search spaces. |\n\n**Optuna-Specific Options:**\n\nWhen using `strategy: \"optuna\"`, you can also specify:\n\n```json\n{\n    \"strategy\": \"optuna\",\n    \"n_trials\": 100,\n    \"pruner\": \"median\",\n    \"sampler\": \"tpe\",\n    \"study_name\": \"my_optimization_study\",\n    \"search_space\": { ... }\n}\n```\n\n- `pruner`: Pruning algorithm (`\"median\"`, `\"percentile\"`, `\"hyperband\"`)\n- `sampler`: Sampling algorithm (`\"tpe\"`, `\"random\"`, `\"cmaes\"`)\n- `study_name`: Name for the Optuna study (useful for resuming)\n\n**Response:**\n```json\n{\n    \"job_id\": \"tuning_job_789\",\n    \"status\": \"started\",\n    \"strategy\": \"optuna\",\n    \"n_trials\": 100,\n    \"message\": \"Hyperparameter tuning job started successfully\"\n}\n```\n\n---\n\n### Get Tuning Results\n\n**GET** `/tuning/{job_id}/results`\n\nGet the results of a hyperparameter tuning job.\n\n**Path Parameters:**\n- `job_id`: The ID of the tuning job\n\n**Response:**\n```json\n{\n    \"job_id\": \"tuning_job_789\",\n    \"status\": \"completed\",\n    \"strategy\": \"optuna\",\n    \"best_params\": {\n        \"learning_rate\": 0.0023,\n        \"batch_size\": 64,\n        \"hidden_size\": 256,\n        \"dropout\": 0.15\n    },\n    \"best_score\": 0.0892,\n    \"n_trials\": 100,\n    \"pruned_trials\": 34,\n    \"complete_trials\": 66,\n    \"all_results\": [\n        {\n            \"params\": { ... },\n            \"score\": 0.12,\n            \"state\": \"COMPLETE\",\n            \"trial_number\": 0\n        },\n        {\n            \"params\": { ... },\n            \"score\": null,\n            \"state\": \"PRUNED\",\n            \"trial_number\": 1\n        }\n    ]\n}\n```\n\n---\n\n### List Models\n\n**GET** `/models`\n\nList all available models.\n\n**Query Parameters:**\n- `limit` (optional): Maximum number of models to return (default: 20)\n- `offset` (optional): Offset for pagination (default: 0)\n\n**Response:**\n```json\n{\n    \"models\": [\n        {\n            \"id\": \"model_123\",\n            \"name\": \"my_model\",\n            \"created_at\": \"2024-01-15T10:30:00Z\",\n            \"status\": \"trained\"\n        }\n    ],\n    \"total\": 1,\n    \"limit\": 20,\n    \"offset\": 0\n}\n```\n\n---\n\n### Get Model Details\n\n**GET** `/models/{model_id}`\n\nGet detailed information about a specific model.\n\n**Path Parameters:**\n- `model_id`: The ID of the model\n\n**Response:**\n```json\n{\n    \"id\": \"model_123\",\n    \"name\": \"my_model\",\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"status\": \"trained\",\n    \"config\": {\n        \"input_size\": 128,\n        \"hidden_size\": 256,\n        \"output_size\": 64,\n        \"num_layers\": 3\n    },\n    \"training_metrics\": {\n        \"final_train_loss\": 0.05,\n        \"final_val_loss\": 0.08,\n        \"epochs_trained\": 85\n    }\n}\n```\n\n---\n\n### Delete Model\n\n**DELETE** `/models/{model_id}`\n\nDelete a model.\n\n**Path Parameters:**\n- `model_id`: The ID of the model to delete\n\n**Response:**\n```json\n{\n    \"message\": \"Model deleted successfully\",\n    \"model_id\": \"model_123\"\n}\n```\n\n---\n\n## Error Responses\n\nAll endpoints may return the following error responses:\n\n### 400 Bad Request\n```json\n{\n    \"error\": \"Bad Request\",\n    \"message\": \"Invalid request body\",\n    \"details\": { ... }\n}\n```\n\n### 401 Unauthorized\n```json\n{\n    \"error\": \"Unauthorized\",\n    \"message\": \"Invalid or missing authentication token\"\n}\n```\n\n### 404 Not Found\n```json\n{\n    \"error\": \"Not Found\",\n    \"message\": \"Resource not found\"\n}\n```\n\n### 500 Internal Server Error\n```json\n{\n    \"error\": \"Internal Server Error\",\n    \"message\": \"An unexpected error occurred\"\n}\n```\n\n---\n\n## Rate Limiting\n\nThe API implements rate limiting to ensure fair usage:\n- 100 requests per minute per API key\n- 1000 requests per hour per API key\n\nRate limit headers are included in all responses:\n```\nX-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1642248000\n```\n\n---\n\n## Webhooks\n\nYou can configure webhooks to receive notifications when long-running jobs complete. Contact support to set up webhook endpoints for your account.\n"
          },
          "generated_files": [
            "src/config.py",
            "src/module_1.py",
            "src/module_10.py",
            "docs/api.md"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.864642857142857,
                "dependency_traversal_accuracy": 0.6596451997614788,
                "cross_file_reasoning_depth": 0.27145833333333336,
                "system_thinking_score": 0.6811528059499662,
                "robustness_score": 0.4,
                "comprehensiveness_score": 0.5162673533363188,
                "innovation_score": 0.39807900432900434,
                "solution_elegance_score": 0.5968542505492919
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.10808035714285713,
                "dependency_traversal_weighted": 0.08245564997018485,
                "cross_file_reasoning_weighted": 0.03393229166666667,
                "system_thinking_weighted": 0.08514410074374577,
                "robustness_weighted": 0.05,
                "comprehensiveness_weighted": 0.06453341916703985,
                "innovation_weighted": 0.04975987554112554,
                "solution_elegance_weighted": 0.07460678131866148
              },
              "total_software_engineering_score": 0.5485124755502813
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.1,
                "execution_time": 0.2769598960876465,
                "errors": [
                  "  File \"docs/api.py\", line 5",
                  "    The MuseNet Alchemist API provides endpoints for model training, evaluation, and hyperparameter tuning. This document describes the available endpoints and their usage.",
                  "        ^^^^^^^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "src/config.py",
                  "src/module_1.py",
                  "src/module_10.py",
                  "docs/api.md"
                ],
                "scoring_breakdown": {
                  "minimal_credit": 0.1
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 4,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 4 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.3815032154340836,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.1,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.3815032154340836,
                "idc_weight": 0.2,
                "total_functional_score": 0.4163006430868167
              }
            },
            "code_quality_details": {
              "files_analyzed": 4,
              "quality_checks": {
                "src/config.py": {
                  "line_count": 157,
                  "non_empty_lines": 127,
                  "comment_lines": 5,
                  "comment_ratio": 0.03937007874015748,
                  "function_count": 3,
                  "class_count": 10,
                  "import_count": 11,
                  "quality_score": 0.7999999999999999
                },
                "src/module_1.py": {
                  "line_count": 230,
                  "non_empty_lines": 185,
                  "comment_lines": 17,
                  "comment_ratio": 0.0918918918918919,
                  "function_count": 11,
                  "class_count": 4,
                  "import_count": 9,
                  "quality_score": 0.7999999999999999
                },
                "src/module_10.py": {
                  "line_count": 408,
                  "non_empty_lines": 337,
                  "comment_lines": 14,
                  "comment_ratio": 0.04154302670623145,
                  "function_count": 15,
                  "class_count": 21,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "docs/api.md": {
                  "line_count": 360,
                  "non_empty_lines": 284,
                  "comment_lines": 20,
                  "comment_ratio": 0.07042253521126761,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 1,
                  "quality_score": 0.7
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7824999999999999,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.5708333333333332,
                "multi_session_memory_retention": 0.48429487179487163
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.2854166666666666,
                "multi_session_memory_retention_weighted": 0.24214743589743581
              },
              "total_longcontext_utilization_score": 0.5275641025641025
            }
          },
          "timestamp": "2026-01-14T21:20:35.136885"
        }
      }
    },
    "python_blockchain_nft_medium_035_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_blockchain_nft_medium_035_feature_implementation_expert_01",
          "scenario_title": "Implement Governance-Controlled Special Edition NFT Airdrops",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.577543593727673,
          "functional_correctness_score": 0.36744608819345664,
          "code_quality_score": 0.7649999999999998,
          "longcontext_utilization_score": 0.7982870370370371,
          "total_score": 2.870399838264049,
          "generation_time": 248.98994755744934,
          "code_files_generated": 10,
          "total_lines_generated": 2504,
          "parsing_success": true,
          "solution_code": {
            "contracts/Governance.sol": "// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";\nimport \"./ShowTimeNFT.sol\";\n\ncontract Governance is Ownable {\n    enum ProposalType { Parameter, Upgrade, Treasury, Airdrop }\n    enum ProposalState { Pending, Active, Succeeded, Defeated, Executed, Cancelled }\n\n    struct Proposal {\n        uint256 id;\n        address proposer;\n        string description;\n        ProposalType proposalType;\n        uint256 startTime;\n        uint256 endTime;\n        uint256 forVotes;\n        uint256 againstVotes;\n        bool executed;\n        bool cancelled;\n        string nftMetadataURI;\n        mapping(address => bool) hasVoted;\n    }\n\n    IERC20 public governanceToken;\n    ShowTimeNFT public showTimeNFT;\n    \n    uint256 public votingPeriod = 3 days;\n    uint256 public votingDelay = 1 days;\n    uint256 public proposalThreshold = 100 * 10**18;\n    uint256 public quorumVotes = 1000 * 10**18;\n    \n    uint256 public proposalCount;\n    mapping(uint256 => Proposal) public proposals;\n    \n    event ProposalCreated(\n        uint256 indexed proposalId,\n        address indexed proposer,\n        string description,\n        ProposalType proposalType,\n        uint256 startTime,\n        uint256 endTime\n    );\n    event VoteCast(uint256 indexed proposalId, address indexed voter, bool support, uint256 votes);\n    event ProposalExecuted(uint256 indexed proposalId);\n    event ProposalCancelled(uint256 indexed proposalId);\n    event AirdropExecuted(uint256 indexed proposalId, string metadataURI, uint256 recipientCount);\n\n    constructor(address _governanceToken, address _showTimeNFT) Ownable(msg.sender) {\n        governanceToken = IERC20(_governanceToken);\n        showTimeNFT = ShowTimeNFT(_showTimeNFT);\n    }\n\n    function setShowTimeNFT(address _showTimeNFT) external onlyOwner {\n        showTimeNFT = ShowTimeNFT(_showTimeNFT);\n    }\n\n    function propose(\n        string memory _description,\n        ProposalType _proposalType\n    ) public returns (uint256) {\n        return _propose(_description, _proposalType, \"\");\n    }\n\n    function proposeAirdrop(\n        string memory _description,\n        string memory _nftMetadataURI\n    ) public returns (uint256) {\n        require(bytes(_nftMetadataURI).length > 0, \"Metadata URI required for airdrop\");\n        return _propose(_description, ProposalType.Airdrop, _nftMetadataURI);\n    }\n\n    function _propose(\n        string memory _description,\n        ProposalType _proposalType,\n        string memory _nftMetadataURI\n    ) internal returns (uint256) {\n        require(\n            governanceToken.balanceOf(msg.sender) >= proposalThreshold,\n            \"Below proposal threshold\"\n        );\n\n        proposalCount++;\n        uint256 proposalId = proposalCount;\n        \n        Proposal storage newProposal = proposals[proposalId];\n        newProposal.id = proposalId;\n        newProposal.proposer = msg.sender;\n        newProposal.description = _description;\n        newProposal.proposalType = _proposalType;\n        newProposal.startTime = block.timestamp + votingDelay;\n        newProposal.endTime = block.timestamp + votingDelay + votingPeriod;\n        newProposal.forVotes = 0;\n        newProposal.againstVotes = 0;\n        newProposal.executed = false;\n        newProposal.cancelled = false;\n        newProposal.nftMetadataURI = _nftMetadataURI;\n\n        emit ProposalCreated(\n            proposalId,\n            msg.sender,\n            _description,\n            _proposalType,\n            newProposal.startTime,\n            newProposal.endTime\n        );\n\n        return proposalId;\n    }\n\n    function vote(uint256 _proposalId, bool _support) external {\n        Proposal storage proposal = proposals[_proposalId];\n        require(getProposalState(_proposalId) == ProposalState.Active, \"Proposal not active\");\n        require(!proposal.hasVoted[msg.sender], \"Already voted\");\n\n        uint256 votes = governanceToken.balanceOf(msg.sender);\n        require(votes > 0, \"No voting power\");\n\n        proposal.hasVoted[msg.sender] = true;\n\n        if (_support) {\n            proposal.forVotes += votes;\n        } else {\n            proposal.againstVotes += votes;\n        }\n\n        emit VoteCast(_proposalId, msg.sender, _support, votes);\n    }\n\n    function execute(uint256 _proposalId) external {\n        require(getProposalState(_proposalId) == ProposalState.Succeeded, \"Proposal not succeeded\");\n        \n        Proposal storage proposal = proposals[_proposalId];\n        proposal.executed = true;\n\n        _execute(proposal);\n\n        emit ProposalExecuted(_proposalId);\n    }\n\n    function _execute(Proposal storage proposal) internal {\n        if (proposal.proposalType == ProposalType.Airdrop) {\n            require(address(showTimeNFT) != address(0), \"ShowTimeNFT not set\");\n            require(bytes(proposal.nftMetadataURI).length > 0, \"No metadata URI\");\n            \n            showTimeNFT.airdropToStakers(proposal.nftMetadataURI);\n            \n            emit AirdropExecuted(proposal.id, proposal.nftMetadataURI, 0);\n        }\n        // Other proposal types can be handled here\n    }\n\n    function cancel(uint256 _proposalId) external {\n        Proposal storage proposal = proposals[_proposalId];\n        require(msg.sender == proposal.proposer || msg.sender == owner(), \"Not authorized\");\n        require(!proposal.executed, \"Already executed\");\n        require(!proposal.cancelled, \"Already cancelled\");\n\n        proposal.cancelled = true;\n        emit ProposalCancelled(_proposalId);\n    }\n\n    function getProposalState(uint256 _proposalId) public view returns (ProposalState) {\n        Proposal storage proposal = proposals[_proposalId];\n        \n        if (proposal.cancelled) {\n            return ProposalState.Cancelled;\n        }\n        if (proposal.executed) {\n            return ProposalState.Executed;\n        }\n        if (block.timestamp < proposal.startTime) {\n            return ProposalState.Pending;\n        }\n        if (block.timestamp <= proposal.endTime) {\n            return ProposalState.Active;\n        }\n        if (proposal.forVotes > proposal.againstVotes && proposal.forVotes >= quorumVotes) {\n            return ProposalState.Succeeded;\n        }\n        return ProposalState.Defeated;\n    }\n\n    function getProposalInfo(uint256 _proposalId) external view returns (\n        uint256 id,\n        address proposer,\n        string memory description,\n        ProposalType proposalType,\n        uint256 startTime,\n        uint256 endTime,\n        uint256 forVotes,\n        uint256 againstVotes,\n        bool executed,\n        bool cancelled,\n        string memory nftMetadataURI\n    ) {\n        Proposal storage proposal = proposals[_proposalId];\n        return (\n            proposal.id,\n            proposal.proposer,\n            proposal.description,\n            proposal.proposalType,\n            proposal.startTime,\n            proposal.endTime,\n            proposal.forVotes,\n            proposal.againstVotes,\n            proposal.executed,\n            proposal.cancelled,\n            proposal.nftMetadataURI\n        );\n    }\n\n    function hasVoted(uint256 _proposalId, address _voter) external view returns (bool) {\n        return proposals[_proposalId].hasVoted[_voter];\n    }\n\n    function setVotingPeriod(uint256 _votingPeriod) external onlyOwner {\n        votingPeriod = _votingPeriod;\n    }\n\n    function setVotingDelay(uint256 _votingDelay) external onlyOwner {\n        votingDelay = _votingDelay;\n    }\n\n    function setProposalThreshold(uint256 _proposalThreshold) external onlyOwner {\n        proposalThreshold = _proposalThreshold;\n    }\n\n    function setQuorumVotes(uint256 _quorumVotes) external onlyOwner {\n        quorumVotes = _quorumVotes;\n    }\n}",
            "contracts/StakingPool.sol": "// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport \"@openzeppelin/contracts/token/ERC721/IERC721.sol\";\nimport \"@openzeppelin/contracts/token/ERC721/IERC721Receiver.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@openzeppelin/contracts/utils/ReentrancyGuard.sol\";\n\ncontract StakingPool is IERC721Receiver, Ownable, ReentrancyGuard {\n    IERC721 public nftContract;\n    \n    struct StakeInfo {\n        address owner;\n        uint256 stakedAt;\n        uint256 lastClaimTime;\n    }\n    \n    mapping(uint256 => StakeInfo) public stakes;\n    mapping(address => uint256[]) public stakerTokens;\n    \n    address[] private _allStakers;\n    mapping(address => bool) private _isStaker;\n    mapping(address => uint256) private _stakerIndex;\n    \n    uint256 public rewardRate = 10 * 10**18;\n    uint256 public totalStaked;\n    \n    event NFTStaked(address indexed owner, uint256 indexed tokenId, uint256 timestamp);\n    event NFTUnstaked(address indexed owner, uint256 indexed tokenId, uint256 timestamp);\n    event RewardsClaimed(address indexed owner, uint256 amount);\n    \n    constructor(address _nftContract) Ownable(msg.sender) {\n        nftContract = IERC721(_nftContract);\n    }\n    \n    function stake(uint256 _tokenId) external nonReentrant {\n        require(nftContract.ownerOf(_tokenId) == msg.sender, \"Not token owner\");\n        \n        nftContract.safeTransferFrom(msg.sender, address(this), _tokenId);\n        \n        stakes[_tokenId] = StakeInfo({\n            owner: msg.sender,\n            stakedAt: block.timestamp,\n            lastClaimTime: block.timestamp\n        });\n        \n        stakerTokens[msg.sender].push(_tokenId);\n        totalStaked++;\n        \n        if (!_isStaker[msg.sender]) {\n            _stakerIndex[msg.sender] = _allStakers.length;\n            _allStakers.push(msg.sender);\n            _isStaker[msg.sender] = true;\n        }\n        \n        emit NFTStaked(msg.sender, _tokenId, block.timestamp);\n    }\n    \n    function unstake(uint256 _tokenId) external nonReentrant {\n        StakeInfo storage stakeInfo = stakes[_tokenId];\n        require(stakeInfo.owner == msg.sender, \"Not stake owner\");\n        \n        nftContract.safeTransferFrom(address(this), msg.sender, _tokenId);\n        \n        _removeTokenFromStaker(msg.sender, _tokenId);\n        delete stakes[_tokenId];\n        totalStaked--;\n        \n        if (stakerTokens[msg.sender].length == 0) {\n            _removeStaker(msg.sender);\n        }\n        \n        emit NFTUnstaked(msg.sender, _tokenId, block.timestamp);\n    }\n    \n    function _removeTokenFromStaker(address _staker, uint256 _tokenId) internal {\n        uint256[] storage tokens = stakerTokens[_staker];\n        for (uint256 i = 0; i < tokens.length; i++) {\n            if (tokens[i] == _tokenId) {\n                tokens[i] = tokens[tokens.length - 1];\n                tokens.pop();\n                break;\n            }\n        }\n    }\n    \n    function _removeStaker(address _staker) internal {\n        if (!_isStaker[_staker]) return;\n        \n        uint256 index = _stakerIndex[_staker];\n        uint256 lastIndex = _allStakers.length - 1;\n        \n        if (index != lastIndex) {\n            address lastStaker = _allStakers[lastIndex];\n            _allStakers[index] = lastStaker;\n            _stakerIndex[lastStaker] = index;\n        }\n        \n        _allStakers.pop();\n        delete _stakerIndex[_staker];\n        _isStaker[_staker] = false;\n    }\n    \n    function getAllStakers() external view returns (address[] memory) {\n        return _allStakers;\n    }\n    \n    function getStakerCount() external view returns (uint256) {\n        return _allStakers.length;\n    }\n    \n    function isStaker(address _address) external view returns (bool) {\n        return _isStaker[_address];\n    }\n    \n    function getStakedTokens(address _staker) external view returns (uint256[] memory) {\n        return stakerTokens[_staker];\n    }\n    \n    function getStakeInfo(uint256 _tokenId) external view returns (\n        address owner,\n        uint256 stakedAt,\n        uint256 lastClaimTime\n    ) {\n        StakeInfo storage info = stakes[_tokenId];\n        return (info.owner, info.stakedAt, info.lastClaimTime);\n    }\n    \n    function calculateRewards(uint256 _tokenId) public view returns (uint256) {\n        StakeInfo storage stakeInfo = stakes[_tokenId];\n        if (stakeInfo.owner == address(0)) return 0;\n        \n        uint256 stakingDuration = block.timestamp - stakeInfo.lastClaimTime;\n        return (stakingDuration * rewardRate) / 1 days;\n    }\n    \n    function setRewardRate(uint256 _newRate) external onlyOwner {\n        rewardRate = _newRate;\n    }\n    \n    function onERC721Received(\n        address,\n        address,\n        uint256,\n        bytes calldata\n    ) external pure override returns (bytes4) {\n        return this.onERC721Received.selector;\n    }\n}",
            "contracts/ShowTimeNFT.sol": "// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\nimport \"@openzeppelin/contracts/token/ERC721/extensions/ERC721URIStorage.sol\";\nimport \"@openzeppelin/contracts/token/ERC721/extensions/ERC721Enumerable.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\nimport \"@openzeppelin/contracts/utils/ReentrancyGuard.sol\";\n\ninterface IStakingPool {\n    function getAllStakers() external view returns (address[] memory);\n}\n\ncontract ShowTimeNFT is ERC721, ERC721URIStorage, ERC721Enumerable, Ownable, ReentrancyGuard {\n    uint256 private _tokenIdCounter;\n    \n    address public stakingPool;\n    address public governanceContract;\n    \n    uint256 public mintPrice = 0.01 ether;\n    uint256 public maxSupply = 10000;\n    bool public mintingEnabled = true;\n    \n    mapping(uint256 => bool) public isSpecialEdition;\n    \n    event NFTMinted(address indexed to, uint256 indexed tokenId, string tokenURI);\n    event SpecialEditionMinted(address indexed to, uint256 indexed tokenId, string tokenURI);\n    event AirdropCompleted(uint256 recipientCount, string metadataURI);\n    event StakingPoolUpdated(address indexed oldPool, address indexed newPool);\n    event GovernanceContractUpdated(address indexed oldGovernance, address indexed newGovernance);\n    \n    modifier onlyGovernance() {\n        require(msg.sender == governanceContract, \"Only governance can call\");\n        _;\n    }\n    \n    constructor() ERC721(\"ShowTime Stash\", \"STS\") Ownable(msg.sender) {\n        _tokenIdCounter = 0;\n    }\n    \n    function setStakingPool(address _stakingPool) external onlyOwner {\n        address oldPool = stakingPool;\n        stakingPool = _stakingPool;\n        emit StakingPoolUpdated(oldPool, _stakingPool);\n    }\n    \n    function setGovernanceContract(address _governanceContract) external onlyOwner {\n        address oldGovernance = governanceContract;\n        governanceContract = _governanceContract;\n        emit GovernanceContractUpdated(oldGovernance, _governanceContract);\n    }\n    \n    function mint(string memory _tokenURI) external payable nonReentrant {\n        require(mintingEnabled, \"Minting is disabled\");\n        require(msg.value >= mintPrice, \"Insufficient payment\");\n        require(_tokenIdCounter < maxSupply, \"Max supply reached\");\n        \n        uint256 tokenId = _tokenIdCounter;\n        _tokenIdCounter++;\n        \n        _safeMint(msg.sender, tokenId);\n        _setTokenURI(tokenId, _tokenURI);\n        \n        emit NFTMinted(msg.sender, tokenId, _tokenURI);\n    }\n    \n    function mintByOwner(address _to, string memory _tokenURI) external onlyOwner {\n        require(_tokenIdCounter < maxSupply, \"Max supply reached\");\n        \n        uint256 tokenId = _tokenIdCounter;\n        _tokenIdCounter++;\n        \n        _safeMint(_to, tokenId);\n        _setTokenURI(tokenId, _tokenURI);\n        \n        emit NFTMinted(_to, tokenId, _tokenURI);\n    }\n    \n    function airdropToStakers(string calldata _metadataURI) external onlyGovernance nonReentrant {\n        require(stakingPool != address(0), \"Staking pool not set\");\n        require(bytes(_metadataURI).length > 0, \"Metadata URI required\");\n        \n        address[] memory stakers = IStakingPool(stakingPool).getAllStakers();\n        require(stakers.length > 0, \"No stakers to airdrop to\");\n        \n        uint256 mintedCount = 0;\n        \n        for (uint256 i = 0; i < stakers.length; i++) {\n            address staker = stakers[i];\n            if (staker != address(0)) {\n                uint256 tokenId = _tokenIdCounter;\n                _tokenIdCounter++;\n                \n                _safeMint(staker, tokenId);\n                _setTokenURI(tokenId, _metadataURI);\n                isSpecialEdition[tokenId] = true;\n                \n                emit SpecialEditionMinted(staker, tokenId, _metadataURI);\n                mintedCount++;\n            }\n        }\n        \n        emit AirdropCompleted(mintedCount, _metadataURI);\n    }\n    \n    function setMintPrice(uint256 _newPrice) external onlyOwner {\n        mintPrice = _newPrice;\n    }\n    \n    function setMaxSupply(uint256 _newMaxSupply) external onlyOwner {\n        require(_newMaxSupply >= _tokenIdCounter, \"Cannot set below current supply\");\n        maxSupply = _newMaxSupply;\n    }\n    \n    function setMintingEnabled(bool _enabled) external onlyOwner {\n        mintingEnabled = _enabled;\n    }\n    \n    function withdraw() external onlyOwner {\n        uint256 balance = address(this).balance;\n        require(balance > 0, \"No balance to withdraw\");\n        payable(owner()).transfer(balance);\n    }\n    \n    function getCurrentTokenId() external view returns (uint256) {\n        return _tokenIdCounter;\n    }\n    \n    // Override functions for multiple inheritance\n    function _update(address to, uint256 tokenId, address auth)\n        internal\n        override(ERC721, ERC721Enumerable)\n        returns (address)\n    {\n        return super._update(to, tokenId, auth);\n    }\n\n    function _increaseBalance(address account, uint128 value)\n        internal\n        override(ERC721, ERC721Enumerable)\n    {\n        super._increaseBalance(account, value);\n    }\n\n    function tokenURI(uint256 tokenId)\n        public\n        view\n        override(ERC721, ERC721URIStorage)\n        returns (string memory)\n    {\n        return super.tokenURI(tokenId);\n    }\n\n    function supportsInterface(bytes4 interfaceId)\n        public\n        view\n        override(ERC721, ERC721URIStorage, ERC721Enumerable)\n        returns (bool)\n    {\n        return super.supportsInterface(interfaceId);\n    }\n}",
            "src/showtime_stash/domain/governance.py": "\"\"\"Domain models for governance functionality.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Optional, List\nfrom decimal import Decimal\n\n\nclass ProposalType(Enum):\n    \"\"\"Types of governance proposals.\"\"\"\n    PARAMETER = \"parameter\"\n    UPGRADE = \"upgrade\"\n    TREASURY = \"treasury\"\n    AIRDROP = \"airdrop\"\n\n\nclass ProposalState(Enum):\n    \"\"\"States of a governance proposal.\"\"\"\n    PENDING = \"pending\"\n    ACTIVE = \"active\"\n    SUCCEEDED = \"succeeded\"\n    DEFEATED = \"defeated\"\n    EXECUTED = \"executed\"\n    CANCELLED = \"cancelled\"\n\n\n@dataclass\nclass Vote:\n    \"\"\"Represents a vote on a proposal.\"\"\"\n    voter_address: str\n    proposal_id: int\n    support: bool\n    votes: Decimal\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    transaction_hash: Optional[str] = None\n\n    def __post_init__(self):\n        if isinstance(self.votes, (int, float)):\n            self.votes = Decimal(str(self.votes))\n\n\n@dataclass\nclass Proposal:\n    \"\"\"Represents a governance proposal.\"\"\"\n    id: int\n    proposer: str\n    description: str\n    proposal_type: ProposalType\n    start_time: datetime\n    end_time: datetime\n    for_votes: Decimal = Decimal(\"0\")\n    against_votes: Decimal = Decimal(\"0\")\n    executed: bool = False\n    cancelled: bool = False\n    nft_metadata_uri: Optional[str] = None\n    transaction_hash: Optional[str] = None\n    votes: List[Vote] = field(default_factory=list)\n\n    def __post_init__(self):\n        if isinstance(self.for_votes, (int, float)):\n            self.for_votes = Decimal(str(self.for_votes))\n        if isinstance(self.against_votes, (int, float)):\n            self.against_votes = Decimal(str(self.against_votes))\n\n    @property\n    def state(self) -> ProposalState:\n        \"\"\"Calculate the current state of the proposal.\"\"\"\n        if self.cancelled:\n            return ProposalState.CANCELLED\n        if self.executed:\n            return ProposalState.EXECUTED\n        \n        now = datetime.utcnow()\n        if now < self.start_time:\n            return ProposalState.PENDING\n        if now <= self.end_time:\n            return ProposalState.ACTIVE\n        \n        # Voting period ended - check results\n        if self.for_votes > self.against_votes:\n            return ProposalState.SUCCEEDED\n        return ProposalState.DEFEATED\n\n    @property\n    def total_votes(self) -> Decimal:\n        \"\"\"Calculate total votes cast.\"\"\"\n        return self.for_votes + self.against_votes\n\n    @property\n    def approval_percentage(self) -> float:\n        \"\"\"Calculate approval percentage.\"\"\"\n        if self.total_votes == 0:\n            return 0.0\n        return float(self.for_votes / self.total_votes * 100)\n\n    def is_airdrop_proposal(self) -> bool:\n        \"\"\"Check if this is an airdrop proposal.\"\"\"\n        return self.proposal_type == ProposalType.AIRDROP\n\n    def has_valid_metadata_uri(self) -> bool:\n        \"\"\"Check if the proposal has a valid metadata URI (for airdrop proposals).\"\"\"\n        return bool(self.nft_metadata_uri and len(self.nft_metadata_uri) > 0)\n\n\n@dataclass\nclass AirdropProposalRequest:\n    \"\"\"Request model for creating an airdrop proposal.\"\"\"\n    description: str\n    nft_metadata_uri: str\n    proposer_address: Optional[str] = None\n\n    def validate(self) -> List[str]:\n        \"\"\"Validate the airdrop proposal request.\"\"\"\n        errors = []\n        if not self.description or len(self.description.strip()) == 0:\n            errors.append(\"Description is required\")\n        if not self.nft_metadata_uri or len(self.nft_metadata_uri.strip()) == 0:\n            errors.append(\"NFT metadata URI is required\")\n        if self.nft_metadata_uri and not self.nft_metadata_uri.startswith((\"ipfs://\", \"https://\", \"http://\")):\n            errors.append(\"NFT metadata URI must be a valid URL or IPFS link\")\n        return errors\n\n\n@dataclass\nclass GovernanceConfig:\n    \"\"\"Configuration for governance parameters.\"\"\"\n    voting_period_days: int = 3\n    voting_delay_days: int = 1\n    proposal_threshold: Decimal = Decimal(\"100\")\n    quorum_votes: Decimal = Decimal(\"1000\")\n\n    def __post_init__(self):\n        if isinstance(self.proposal_threshold, (int, float)):\n            self.proposal_threshold = Decimal(str(self.proposal_threshold))\n        if isinstance(self.quorum_votes, (int, float)):\n            self.quorum_votes = Decimal(str(self.quorum_votes))\n\n\n@dataclass\nclass GovernanceStats:\n    \"\"\"Statistics about governance activity.\"\"\"\n    total_proposals: int = 0\n    active_proposals: int = 0\n    executed_proposals: int = 0\n    total_votes_cast: int = 0\n    unique_voters: int = 0\n    airdrop_proposals_executed: int = 0\n\n\n@dataclass\nclass AirdropResult:\n    \"\"\"Result of an airdrop execution.\"\"\"\n    proposal_id: int\n    metadata_uri: str\n    recipient_count: int\n    transaction_hash: str\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    success: bool = True\n    error_message: Optional[str] = None",
            "src/showtime_stash/interfaces/api.py": "\"\"\"FastAPI interface for ShowTime Stash platform.\"\"\"\n\nfrom fastapi import FastAPI, HTTPException, Depends, Query, Body\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\nfrom datetime import datetime\nfrom decimal import Decimal\nimport logging\n\nfrom ..domain.governance import (\n    ProposalType,\n    ProposalState,\n    Proposal,\n    AirdropProposalRequest,\n    GovernanceStats\n)\nfrom ..domain.nft import NFT, NFTMetadata\nfrom ..application.services import (\n    GovernanceService,\n    NFTService,\n    StakingService\n)\n\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(\n    title=\"ShowTime Stash API\",\n    description=\"API for NFT marketplace with governance and staking\",\n    version=\"1.0.0\"\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Pydantic models for request/response\nclass NFTResponse(BaseModel):\n    token_id: int\n    owner: str\n    metadata_uri: str\n    is_special_edition: bool = False\n\n    class Config:\n        from_attributes = True\n\n\nclass StakeRequest(BaseModel):\n    token_id: int\n    user_address: str\n\n\nclass StakeResponse(BaseModel):\n    success: bool\n    transaction_hash: Optional[str] = None\n    message: str\n\n\nclass ProposalResponse(BaseModel):\n    id: int\n    proposer: str\n    description: str\n    proposal_type: str\n    state: str\n    start_time: datetime\n    end_time: datetime\n    for_votes: str\n    against_votes: str\n    executed: bool\n    cancelled: bool\n    nft_metadata_uri: Optional[str] = None\n\n    class Config:\n        from_attributes = True\n\n\nclass CreateProposalRequest(BaseModel):\n    description: str = Field(..., min_length=1, max_length=1000)\n    proposal_type: str = Field(..., description=\"Type of proposal\")\n    proposer_address: str = Field(..., description=\"Address of the proposer\")\n\n\nclass CreateAirdropProposalRequest(BaseModel):\n    description: str = Field(..., min_length=1, max_length=1000, description=\"Description of the airdrop proposal\")\n    nft_metadata_uri: str = Field(..., min_length=1, description=\"IPFS or HTTP URI for the NFT metadata\")\n    proposer_address: Optional[str] = Field(None, description=\"Address of the proposer\")\n\n\nclass VoteRequest(BaseModel):\n    proposal_id: int\n    voter_address: str\n    support: bool\n\n\nclass VoteResponse(BaseModel):\n    success: bool\n    transaction_hash: Optional[str] = None\n    message: str\n\n\nclass ExecuteProposalRequest(BaseModel):\n    proposal_id: int\n    executor_address: str\n\n\nclass ExecuteProposalResponse(BaseModel):\n    success: bool\n    transaction_hash: Optional[str] = None\n    message: str\n    airdrop_recipient_count: Optional[int] = None\n\n\nclass GovernanceStatsResponse(BaseModel):\n    total_proposals: int\n    active_proposals: int\n    executed_proposals: int\n    total_votes_cast: int\n    unique_voters: int\n    airdrop_proposals_executed: int\n\n\nclass StakerListResponse(BaseModel):\n    stakers: List[str]\n    count: int\n\n\n# Dependency injection for services\ndef get_governance_service() -> GovernanceService:\n    \"\"\"Get governance service instance.\"\"\"\n    from ..application.factories import ServiceFactory\n    return ServiceFactory.get_governance_service()\n\n\ndef get_nft_service() -> NFTService:\n    \"\"\"Get NFT service instance.\"\"\"\n    from ..application.factories import ServiceFactory\n    return ServiceFactory.get_nft_service()\n\n\ndef get_staking_service() -> StakingService:\n    \"\"\"Get staking service instance.\"\"\"\n    from ..application.factories import ServiceFactory\n    return ServiceFactory.get_staking_service()\n\n\n# Health check\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"timestamp\": datetime.utcnow().isoformat()}\n\n\n# NFT Endpoints\n@app.get(\"/nfts/{token_id}\", response_model=NFTResponse)\nasync def get_nft(\n    token_id: int,\n    nft_service: NFTService = Depends(get_nft_service)\n):\n    \"\"\"Get NFT details by token ID.\"\"\"\n    try:\n        nft = await nft_service.get_nft(token_id)\n        if not nft:\n            raise HTTPException(status_code=404, detail=\"NFT not found\")\n        return NFTResponse(\n            token_id=nft.token_id,\n            owner=nft.owner,\n            metadata_uri=nft.metadata_uri,\n            is_special_edition=nft.is_special_edition\n        )\n    except Exception as e:\n        logger.error(f\"Error fetching NFT {token_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/nfts/owner/{address}\", response_model=List[NFTResponse])\nasync def get_nfts_by_owner(\n    address: str,\n    nft_service: NFTService = Depends(get_nft_service)\n):\n    \"\"\"Get all NFTs owned by an address.\"\"\"\n    try:\n        nfts = await nft_service.get_nfts_by_owner(address)\n        return [\n            NFTResponse(\n                token_id=nft.token_id,\n                owner=nft.owner,\n                metadata_uri=nft.metadata_uri,\n                is_special_edition=nft.is_special_edition\n            )\n            for nft in nfts\n        ]\n    except Exception as e:\n        logger.error(f\"Error fetching NFTs for owner {address}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n# Staking Endpoints\n@app.post(\"/staking/stake\", response_model=StakeResponse)\nasync def stake_nft(\n    request: StakeRequest,\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Stake an NFT.\"\"\"\n    try:\n        result = await staking_service.stake(request.token_id, request.user_address)\n        return StakeResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message\n        )\n    except Exception as e:\n        logger.error(f\"Error staking NFT {request.token_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/staking/unstake\", response_model=StakeResponse)\nasync def unstake_nft(\n    request: StakeRequest,\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Unstake an NFT.\"\"\"\n    try:\n        result = await staking_service.unstake(request.token_id, request.user_address)\n        return StakeResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message\n        )\n    except Exception as e:\n        logger.error(f\"Error unstaking NFT {request.token_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/staking/stakers\", response_model=StakerListResponse)\nasync def get_all_stakers(\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Get all current stakers.\"\"\"\n    try:\n        stakers = await staking_service.get_all_stakers()\n        return StakerListResponse(stakers=stakers, count=len(stakers))\n    except Exception as e:\n        logger.error(f\"Error fetching stakers: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/staking/user/{address}\")\nasync def get_user_stakes(\n    address: str,\n    staking_service: StakingService = Depends(get_staking_service)\n):\n    \"\"\"Get staked tokens for a user.\"\"\"\n    try:\n        stakes = await staking_service.get_user_stakes(address)\n        return {\"address\": address, \"staked_tokens\": stakes}\n    except Exception as e:\n        logger.error(f\"Error fetching stakes for {address}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n# Governance Endpoints\n@app.get(\"/proposals\", response_model=List[ProposalResponse])\nasync def get_proposals(\n    state: Optional[str] = Query(None, description=\"Filter by proposal state\"),\n    proposal_type: Optional[str] = Query(None, description=\"Filter by proposal type\"),\n    limit: int = Query(50, ge=1, le=100),\n    offset: int = Query(0, ge=0),\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Get list of governance proposals.\"\"\"\n    try:\n        proposals = await governance_service.get_proposals(\n            state=state,\n            proposal_type=proposal_type,\n            limit=limit,\n            offset=offset\n        )\n        return [\n            ProposalResponse(\n                id=p.id,\n                proposer=p.proposer,\n                description=p.description,\n                proposal_type=p.proposal_type.value,\n                state=p.state.value,\n                start_time=p.start_time,\n                end_time=p.end_time,\n                for_votes=str(p.for_votes),\n                against_votes=str(p.against_votes),\n                executed=p.executed,\n                cancelled=p.cancelled,\n                nft_metadata_uri=p.nft_metadata_uri\n            )\n            for p in proposals\n        ]\n    except Exception as e:\n        logger.error(f\"Error fetching proposals: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/proposals/{proposal_id}\", response_model=ProposalResponse)\nasync def get_proposal(\n    proposal_id: int,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Get details of a specific proposal.\"\"\"\n    try:\n        proposal = await governance_service.get_proposal(proposal_id)\n        if not proposal:\n            raise HTTPException(status_code=404, detail=\"Proposal not found\")\n        return ProposalResponse(\n            id=proposal.id,\n            proposer=proposal.proposer,\n            description=proposal.description,\n            proposal_type=proposal.proposal_type.value,\n            state=proposal.state.value,\n            start_time=proposal.start_time,\n            end_time=proposal.end_time,\n            for_votes=str(proposal.for_votes),\n            against_votes=str(proposal.against_votes),\n            executed=proposal.executed,\n            cancelled=proposal.cancelled,\n            nft_metadata_uri=proposal.nft_metadata_uri\n        )\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Error fetching proposal {proposal_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals\", response_model=ProposalResponse)\nasync def create_proposal(\n    request: CreateProposalRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Create a new governance proposal.\"\"\"\n    try:\n        proposal_type = ProposalType(request.proposal_type.lower())\n        proposal = await governance_service.create_proposal(\n            description=request.description,\n            proposal_type=proposal_type,\n            proposer_address=request.proposer_address\n        )\n        return ProposalResponse(\n            id=proposal.id,\n            proposer=proposal.proposer,\n            description=proposal.description,\n            proposal_type=proposal.proposal_type.value,\n            state=proposal.state.value,\n            start_time=proposal.start_time,\n            end_time=proposal.end_time,\n            for_votes=str(proposal.for_votes),\n            against_votes=str(proposal.against_votes),\n            executed=proposal.executed,\n            cancelled=proposal.cancelled,\n            nft_metadata_uri=proposal.nft_metadata_uri\n        )\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error creating proposal: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals/airdrop\", response_model=ProposalResponse)\nasync def create_airdrop_proposal(\n    request: CreateAirdropProposalRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Create a new airdrop governance proposal.\n    \n    This endpoint creates a proposal to airdrop special edition NFTs\n    to all users currently staking NFTs on the platform.\n    \"\"\"\n    try:\n        # Validate the request\n        airdrop_request = AirdropProposalRequest(\n            description=request.description,\n            nft_metadata_uri=request.nft_metadata_uri,\n            proposer_address=request.proposer_address\n        )\n        \n        validation_errors = airdrop_request.validate()\n        if validation_errors:\n            raise HTTPException(\n                status_code=400,\n                detail={\"errors\": validation_errors}\n            )\n        \n        # Create the airdrop proposal\n        proposal = await governance_service.create_airdrop_proposal(\n            description=request.description,\n            nft_metadata_uri=request.nft_metadata_uri,\n            proposer_address=request.proposer_address\n        )\n        \n        return ProposalResponse(\n            id=proposal.id,\n            proposer=proposal.proposer,\n            description=proposal.description,\n            proposal_type=proposal.proposal_type.value,\n            state=proposal.state.value,\n            start_time=proposal.start_time,\n            end_time=proposal.end_time,\n            for_votes=str(proposal.for_votes),\n            against_votes=str(proposal.against_votes),\n            executed=proposal.executed,\n            cancelled=proposal.cancelled,\n            nft_metadata_uri=proposal.nft_metadata_uri\n        )\n    except HTTPException:\n        raise\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error creating airdrop proposal: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals/{proposal_id}/vote\", response_model=VoteResponse)\nasync def vote_on_proposal(\n    proposal_id: int,\n    request: VoteRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Vote on a governance proposal.\"\"\"\n    try:\n        result = await governance_service.vote(\n            proposal_id=proposal_id,\n            voter_address=request.voter_address,\n            support=request.support\n        )\n        return VoteResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message\n        )\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error voting on proposal {proposal_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/proposals/{proposal_id}/execute\", response_model=ExecuteProposalResponse)\nasync def execute_proposal(\n    proposal_id: int,\n    request: ExecuteProposalRequest,\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Execute a passed governance proposal.\"\"\"\n    try:\n        result = await governance_service.execute_proposal(\n            proposal_id=proposal_id,\n            executor_address=request.executor_address\n        )\n        return ExecuteProposalResponse(\n            success=result.success,\n            transaction_hash=result.transaction_hash,\n            message=result.message,\n            airdrop_recipient_count=getattr(result, 'airdrop_recipient_count', None)\n        )\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error executing proposal {proposal_id}: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.get(\"/governance/stats\", response_model=GovernanceStatsResponse)\nasync def get_governance_stats(\n    governance_service: GovernanceService = Depends(get_governance_service)\n):\n    \"\"\"Get governance statistics.\"\"\"\n    try:\n        stats = await governance_service.get_stats()\n        return GovernanceStatsResponse(\n            total_proposals=stats.total_proposals,\n            active_proposals=stats.active_proposals,\n            executed_proposals=stats.executed_proposals,\n            total_votes_cast=stats.total_votes_cast,\n            unique_voters=stats.unique_voters,\n            airdrop_proposals_executed=stats.airdrop_proposals_executed\n        )\n    except Exception as e:\n        logger.error(f\"Error fetching governance stats: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))",
            "src/showtime_stash/application/services.py": "\"\"\"Application services for ShowTime Stash platform.\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import Optional, List\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nimport logging\n\nfrom ..domain.governance import (\n    Proposal,\n    ProposalType,\n    ProposalState,\n    Vote,\n    GovernanceStats,\n    AirdropResult\n)\nfrom ..domain.nft import NFT\nfrom ..infrastructure.blockchain_connector import BlockchainConnector\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ServiceResult:\n    \"\"\"Generic result from service operations.\"\"\"\n    success: bool\n    message: str\n    transaction_hash: Optional[str] = None\n    data: Optional[dict] = None\n\n\n@dataclass\nclass ExecuteResult(ServiceResult):\n    \"\"\"Result from executing a proposal.\"\"\"\n    airdrop_recipient_count: Optional[int] = None\n\n\nclass GovernanceService:\n    \"\"\"Service for governance operations.\"\"\"\n    \n    def __init__(self, blockchain_connector: BlockchainConnector):\n        self.blockchain = blockchain_connector\n        self._proposals_cache: dict = {}\n    \n    async def get_proposals(\n        self,\n        state: Optional[str] = None,\n        proposal_type: Optional[str] = None,\n        limit: int = 50,\n        offset: int = 0\n    ) -> List[Proposal]:\n        \"\"\"Get list of proposals with optional filtering.\"\"\"\n        try:\n            proposals = await self.blockchain.get_all_proposals()\n            \n            # Apply filters\n            if state:\n                state_enum = ProposalState(state.lower())\n                proposals = [p for p in proposals if p.state == state_enum]\n            \n            if proposal_type:\n                type_enum = ProposalType(proposal_type.lower())\n                proposals = [p for p in proposals if p.proposal_type == type_enum]\n            \n            # Apply pagination\n            return proposals[offset:offset + limit]\n        except Exception as e:\n            logger.error(f\"Error fetching proposals: {e}\")\n            raise\n    \n    async def get_proposal(self, proposal_id: int) -> Optional[Proposal]:\n        \"\"\"Get a specific proposal by ID.\"\"\"\n        try:\n            return await self.blockchain.get_proposal(proposal_id)\n        except Exception as e:\n            logger.error(f\"Error fetching proposal {proposal_id}: {e}\")\n            raise\n    \n    async def create_proposal(\n        self,\n        description: str,\n        proposal_type: ProposalType,\n        proposer_address: str\n    ) -> Proposal:\n        \"\"\"Create a new governance proposal.\"\"\"\n        try:\n            tx_hash = await self.blockchain.create_proposal(\n                description=description,\n                proposal_type=proposal_type.value,\n                proposer_address=proposer_address\n            )\n            \n            # Fetch the created proposal\n            proposal_id = await self.blockchain.get_latest_proposal_id()\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            proposal.transaction_hash = tx_hash\n            \n            return proposal\n        except Exception as e:\n            logger.error(f\"Error creating proposal: {e}\")\n            raise\n    \n    async def create_airdrop_proposal(\n        self,\n        description: str,\n        nft_metadata_uri: str,\n        proposer_address: Optional[str] = None\n    ) -> Proposal:\n        \"\"\"Create a new airdrop governance proposal.\"\"\"\n        try:\n            if not nft_metadata_uri:\n                raise ValueError(\"NFT metadata URI is required for airdrop proposals\")\n            \n            tx_hash = await self.blockchain.create_airdrop_proposal(\n                description=description,\n                nft_metadata_uri=nft_metadata_uri,\n                proposer_address=proposer_address\n            )\n            \n            # Fetch the created proposal\n            proposal_id = await self.blockchain.get_latest_proposal_id()\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            proposal.transaction_hash = tx_hash\n            \n            logger.info(f\"Created airdrop proposal {proposal_id} with metadata URI: {nft_metadata_uri}\")\n            return proposal\n        except Exception as e:\n            logger.error(f\"Error creating airdrop proposal: {e}\")\n            raise\n    \n    async def vote(\n        self,\n        proposal_id: int,\n        voter_address: str,\n        support: bool\n    ) -> ServiceResult:\n        \"\"\"Vote on a proposal.\"\"\"\n        try:\n            # Verify proposal exists and is active\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            if not proposal:\n                return ServiceResult(\n                    success=False,\n                    message=\"Proposal not found\"\n                )\n            \n            if proposal.state != ProposalState.ACTIVE:\n                return ServiceResult(\n                    success=False,\n                    message=f\"Proposal is not active. Current state: {proposal.state.value}\"\n                )\n            \n            # Submit vote\n            tx_hash = await self.blockchain.vote(\n                proposal_id=proposal_id,\n                voter_address=voter_address,\n                support=support\n            )\n            \n            return ServiceResult(\n                success=True,\n                message=\"Vote submitted successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error voting on proposal {proposal_id}: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def execute_proposal(\n        self,\n        proposal_id: int,\n        executor_address: str\n    ) -> ExecuteResult:\n        \"\"\"Execute a passed proposal.\"\"\"\n        try:\n            # Verify proposal exists and has succeeded\n            proposal = await self.blockchain.get_proposal(proposal_id)\n            if not proposal:\n                return ExecuteResult(\n                    success=False,\n                    message=\"Proposal not found\"\n                )\n            \n            if proposal.state != ProposalState.SUCCEEDED:\n                return ExecuteResult(\n                    success=False,\n                    message=f\"Proposal cannot be executed. Current state: {proposal.state.value}\"\n                )\n            \n            # Execute the proposal\n            tx_hash = await self.blockchain.execute_proposal(\n                proposal_id=proposal_id,\n                executor_address=executor_address\n            )\n            \n            # For airdrop proposals, get recipient count\n            airdrop_count = None\n            if proposal.proposal_type == ProposalType.AIRDROP:\n                airdrop_count = await self.blockchain.get_airdrop_recipient_count(tx_hash)\n                logger.info(f\"Airdrop proposal {proposal_id} executed. Recipients: {airdrop_count}\")\n            \n            return ExecuteResult(\n                success=True,\n                message=\"Proposal executed successfully\",\n                transaction_hash=tx_hash,\n                airdrop_recipient_count=airdrop_count\n            )\n        except Exception as e:\n            logger.error(f\"Error executing proposal {proposal_id}: {e}\")\n            return ExecuteResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def get_stats(self) -> GovernanceStats:\n        \"\"\"Get governance statistics.\"\"\"\n        try:\n            return await self.blockchain.get_governance_stats()\n        except Exception as e:\n            logger.error(f\"Error fetching governance stats: {e}\")\n            raise\n\n\nclass NFTService:\n    \"\"\"Service for NFT operations.\"\"\"\n    \n    def __init__(self, blockchain_connector: BlockchainConnector):\n        self.blockchain = blockchain_connector\n    \n    async def get_nft(self, token_id: int) -> Optional[NFT]:\n        \"\"\"Get NFT by token ID.\"\"\"\n        try:\n            return await self.blockchain.get_nft(token_id)\n        except Exception as e:\n            logger.error(f\"Error fetching NFT {token_id}: {e}\")\n            raise\n    \n    async def get_nfts_by_owner(self, owner_address: str) -> List[NFT]:\n        \"\"\"Get all NFTs owned by an address.\"\"\"\n        try:\n            return await self.blockchain.get_nfts_by_owner(owner_address)\n        except Exception as e:\n            logger.error(f\"Error fetching NFTs for {owner_address}: {e}\")\n            raise\n    \n    async def mint_nft(\n        self,\n        to_address: str,\n        metadata_uri: str\n    ) -> ServiceResult:\n        \"\"\"Mint a new NFT.\"\"\"\n        try:\n            tx_hash = await self.blockchain.mint_nft(\n                to_address=to_address,\n                metadata_uri=metadata_uri\n            )\n            return ServiceResult(\n                success=True,\n                message=\"NFT minted successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error minting NFT: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n\n\nclass StakingService:\n    \"\"\"Service for staking operations.\"\"\"\n    \n    def __init__(self, blockchain_connector: BlockchainConnector):\n        self.blockchain = blockchain_connector\n    \n    async def stake(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> ServiceResult:\n        \"\"\"Stake an NFT.\"\"\"\n        try:\n            tx_hash = await self.blockchain.stake_nft(\n                token_id=token_id,\n                user_address=user_address\n            )\n            return ServiceResult(\n                success=True,\n                message=\"NFT staked successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error staking NFT {token_id}: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def unstake(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> ServiceResult:\n        \"\"\"Unstake an NFT.\"\"\"\n        try:\n            tx_hash = await self.blockchain.unstake_nft(\n                token_id=token_id,\n                user_address=user_address\n            )\n            return ServiceResult(\n                success=True,\n                message=\"NFT unstaked successfully\",\n                transaction_hash=tx_hash\n            )\n        except Exception as e:\n            logger.error(f\"Error unstaking NFT {token_id}: {e}\")\n            return ServiceResult(\n                success=False,\n                message=str(e)\n            )\n    \n    async def get_all_stakers(self) -> List[str]:\n        \"\"\"Get all current stakers.\"\"\"\n        try:\n            return await self.blockchain.get_all_stakers()\n        except Exception as e:\n            logger.error(f\"Error fetching stakers: {e}\")\n            raise\n    \n    async def get_user_stakes(self, user_address: str) -> List[int]:\n        \"\"\"Get staked token IDs for a user.\"\"\"\n        try:\n            return await self.blockchain.get_user_stakes(user_address)\n        except Exception as e:\n            logger.error(f\"Error fetching stakes for {user_address}: {e}\")\n            raise\n    \n    async def is_staker(self, address: str) -> bool:\n        \"\"\"Check if an address is currently staking.\"\"\"\n        try:\n            return await self.blockchain.is_staker(address)\n        except Exception as e:\n            logger.error(f\"Error checking staker status for {address}: {e}\")\n            raise",
            "tests/contract_tests/test_governance_airdrop.py": "\"\"\"Integration tests for governance-controlled NFT airdrops.\"\"\"\n\nimport pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\n\nfrom src.showtime_stash.domain.governance import (\n    Proposal,\n    ProposalType,\n    ProposalState,\n    AirdropProposalRequest,\n    Vote\n)\nfrom src.showtime_stash.domain.nft import NFT\nfrom src.showtime_stash.application.services import (\n    GovernanceService,\n    StakingService,\n    NFTService,\n    ServiceResult,\n    ExecuteResult\n)\n\n\nclass MockBlockchainConnector:\n    \"\"\"Mock blockchain connector for testing.\"\"\"\n    \n    def __init__(self):\n        self.proposals = {}\n        self.stakers = []\n        self.nfts = {}\n        self.stakes = {}\n        self.proposal_count = 0\n        self.token_count = 0\n        self.votes = {}\n    \n    async def create_airdrop_proposal(\n        self,\n        description: str,\n        nft_metadata_uri: str,\n        proposer_address: str = None\n    ) -> str:\n        self.proposal_count += 1\n        proposal_id = self.proposal_count\n        \n        self.proposals[proposal_id] = Proposal(\n            id=proposal_id,\n            proposer=proposer_address or \"0xProposer\",\n            description=description,\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3),\n            nft_metadata_uri=nft_metadata_uri\n        )\n        return f\"0xTxHash{proposal_id}\"\n    \n    async def get_latest_proposal_id(self) -> int:\n        return self.proposal_count\n    \n    async def get_proposal(self, proposal_id: int) -> Proposal:\n        return self.proposals.get(proposal_id)\n    \n    async def get_all_proposals(self) -> list:\n        return list(self.proposals.values())\n    \n    async def vote(\n        self,\n        proposal_id: int,\n        voter_address: str,\n        support: bool\n    ) -> str:\n        proposal = self.proposals.get(proposal_id)\n        if proposal:\n            votes = Decimal(\"500\")  # Simulated voting power\n            if support:\n                proposal.for_votes += votes\n            else:\n                proposal.against_votes += votes\n            \n            if proposal_id not in self.votes:\n                self.votes[proposal_id] = []\n            self.votes[proposal_id].append(Vote(\n                voter_address=voter_address,\n                proposal_id=proposal_id,\n                support=support,\n                votes=votes\n            ))\n        return f\"0xVoteTx{proposal_id}_{voter_address}\"\n    \n    async def execute_proposal(\n        self,\n        proposal_id: int,\n        executor_address: str\n    ) -> str:\n        proposal = self.proposals.get(proposal_id)\n        if proposal:\n            proposal.executed = True\n            \n            # Simulate airdrop execution\n            if proposal.proposal_type == ProposalType.AIRDROP:\n                for staker in self.stakers:\n                    self.token_count += 1\n                    self.nfts[self.token_count] = NFT(\n                        token_id=self.token_count,\n                        owner=staker,\n                        metadata_uri=proposal.nft_metadata_uri,\n                        is_special_edition=True\n                    )\n        return f\"0xExecuteTx{proposal_id}\"\n    \n    async def get_airdrop_recipient_count(self, tx_hash: str) -> int:\n        return len(self.stakers)\n    \n    async def stake_nft(self, token_id: int, user_address: str) -> str:\n        if user_address not in self.stakers:\n            self.stakers.append(user_address)\n        if user_address not in self.stakes:\n            self.stakes[user_address] = []\n        self.stakes[user_address].append(token_id)\n        return f\"0xStakeTx{token_id}\"\n    \n    async def unstake_nft(self, token_id: int, user_address: str) -> str:\n        if user_address in self.stakes:\n            if token_id in self.stakes[user_address]:\n                self.stakes[user_address].remove(token_id)\n            if len(self.stakes[user_address]) == 0:\n                self.stakers.remove(user_address)\n        return f\"0xUnstakeTx{token_id}\"\n    \n    async def get_all_stakers(self) -> list:\n        return self.stakers.copy()\n    \n    async def get_user_stakes(self, user_address: str) -> list:\n        return self.stakes.get(user_address, [])\n    \n    async def is_staker(self, address: str) -> bool:\n        return address in self.stakers\n    \n    async def get_nft(self, token_id: int) -> NFT:\n        return self.nfts.get(token_id)\n    \n    async def get_nfts_by_owner(self, owner_address: str) -> list:\n        return [nft for nft in self.nfts.values() if nft.owner == owner_address]\n    \n    async def mint_nft(self, to_address: str, metadata_uri: str) -> str:\n        self.token_count += 1\n        self.nfts[self.token_count] = NFT(\n            token_id=self.token_count,\n            owner=to_address,\n            metadata_uri=metadata_uri,\n            is_special_edition=False\n        )\n        return f\"0xMintTx{self.token_count}\"\n    \n    async def get_governance_stats(self):\n        from src.showtime_stash.domain.governance import GovernanceStats\n        return GovernanceStats(\n            total_proposals=len(self.proposals),\n            active_proposals=sum(1 for p in self.proposals.values() if p.state == ProposalState.ACTIVE),\n            executed_proposals=sum(1 for p in self.proposals.values() if p.executed),\n            total_votes_cast=sum(len(v) for v in self.votes.values()),\n            unique_voters=len(set(v.voter_address for votes in self.votes.values() for v in votes)),\n            airdrop_proposals_executed=sum(\n                1 for p in self.proposals.values()\n                if p.proposal_type == ProposalType.AIRDROP and p.executed\n            )\n        )\n\n\n@pytest.fixture\ndef mock_blockchain():\n    \"\"\"Create a mock blockchain connector.\"\"\"\n    return MockBlockchainConnector()\n\n\n@pytest.fixture\ndef governance_service(mock_blockchain):\n    \"\"\"Create governance service with mock blockchain.\"\"\"\n    return GovernanceService(mock_blockchain)\n\n\n@pytest.fixture\ndef staking_service(mock_blockchain):\n    \"\"\"Create staking service with mock blockchain.\"\"\"\n    return StakingService(mock_blockchain)\n\n\n@pytest.fixture\ndef nft_service(mock_blockchain):\n    \"\"\"Create NFT service with mock blockchain.\"\"\"\n    return NFTService(mock_blockchain)\n\n\nclass TestAirdropProposalRequest:\n    \"\"\"Tests for AirdropProposalRequest validation.\"\"\"\n    \n    def test_valid_request(self):\n        \"\"\"Test valid airdrop proposal request.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Airdrop special NFTs to stakers\",\n            nft_metadata_uri=\"ipfs://QmTest123\"\n        )\n        errors = request.validate()\n        assert len(errors) == 0\n    \n    def test_missing_description(self):\n        \"\"\"Test request with missing description.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"\",\n            nft_metadata_uri=\"ipfs://QmTest123\"\n        )\n        errors = request.validate()\n        assert \"Description is required\" in errors\n    \n    def test_missing_metadata_uri(self):\n        \"\"\"Test request with missing metadata URI.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Test airdrop\",\n            nft_metadata_uri=\"\"\n        )\n        errors = request.validate()\n        assert \"NFT metadata URI is required\" in errors\n    \n    def test_invalid_metadata_uri(self):\n        \"\"\"Test request with invalid metadata URI.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Test airdrop\",\n            nft_metadata_uri=\"invalid-uri\"\n        )\n        errors = request.validate()\n        assert \"NFT metadata URI must be a valid URL or IPFS link\" in errors\n    \n    def test_valid_https_uri(self):\n        \"\"\"Test request with valid HTTPS URI.\"\"\"\n        request = AirdropProposalRequest(\n            description=\"Test airdrop\",\n            nft_metadata_uri=\"https://example.com/metadata.json\"\n        )\n        errors = request.validate()\n        assert len(errors) == 0\n\n\nclass TestGovernanceAirdropIntegration:\n    \"\"\"Integration tests for the full airdrop flow.\"\"\"\n    \n    @pytest.mark.asyncio\n    async def test_full_airdrop_flow(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"\n        Test the complete airdrop flow:\n        1. User stakes an NFT\n        2. Another user creates an Airdrop proposal\n        3. Users vote to pass the proposal\n        4. Proposal is executed\n        5. Verify staker received the special edition NFT\n        \"\"\"\n        # Setup: Mint initial NFT for staking\n        staker_address = \"0xStaker1\"\n        non_staker_address = \"0xNonStaker\"\n        proposer_address = \"0xProposer\"\n        voter1_address = \"0xVoter1\"\n        voter2_address = \"0xVoter2\"\n        \n        # Mint an NFT to the staker\n        mint_result = await nft_service.mint_nft(\n            to_address=staker_address,\n            metadata_uri=\"ipfs://QmOriginalNFT\"\n        )\n        assert mint_result.success\n        \n        # Step 1: User stakes an NFT\n        stake_result = await staking_service.stake(\n            token_id=1,\n            user_address=staker_address\n        )\n        assert stake_result.success\n        \n        # Verify staker is in the stakers list\n        stakers = await staking_service.get_all_stakers()\n        assert staker_address in stakers\n        assert non_staker_address not in stakers\n        \n        # Step 2: Create an Airdrop proposal\n        airdrop_metadata_uri = \"ipfs://QmSpecialEditionNFT\"\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Airdrop special edition NFTs to all stakers\",\n            nft_metadata_uri=airdrop_metadata_uri,\n            proposer_address=proposer_address\n        )\n        \n        assert proposal is not None\n        assert proposal.proposal_type == ProposalType.AIRDROP\n        assert proposal.nft_metadata_uri == airdrop_metadata_uri\n        assert proposal.id == 1\n        \n        # Step 3: Users vote to pass the proposal\n        # Make proposal active by adjusting timestamps in mock\n        mock_blockchain.proposals[1].start_time = datetime.utcnow() - timedelta(hours=1)\n        mock_blockchain.proposals[1].end_time = datetime.utcnow() + timedelta(days=3)\n        \n        vote1_result = await governance_service.vote(\n            proposal_id=1,\n            voter_address=voter1_address,\n            support=True\n        )\n        assert vote1_result.success\n        \n        vote2_result = await governance_service.vote(\n            proposal_id=1,\n            voter_address=voter2_address,\n            support=True\n        )\n        assert vote2_result.success\n        \n        # Verify votes were recorded\n        updated_proposal = await governance_service.get_proposal(1)\n        assert updated_proposal.for_votes == Decimal(\"1000\")  # 500 * 2 voters\n        \n        # Step 4: Execute the proposal after voting period\n        # Simulate voting period ended\n        mock_blockchain.proposals[1].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        execute_result = await governance_service.execute_proposal(\n            proposal_id=1,\n            executor_address=proposer_address\n        )\n        assert execute_result.success\n        assert execute_result.airdrop_recipient_count == 1  # Only one staker\n        \n        # Step 5: Verify staker received the special edition NFT\n        staker_nfts = await nft_service.get_nfts_by_owner(staker_address)\n        special_edition_nfts = [nft for nft in staker_nfts if nft.is_special_edition]\n        \n        assert len(special_edition_nfts) == 1\n        assert special_edition_nfts[0].metadata_uri == airdrop_metadata_uri\n        \n        # Verify non-staker did NOT receive the NFT\n        non_staker_nfts = await nft_service.get_nfts_by_owner(non_staker_address)\n        assert len(non_staker_nfts) == 0\n    \n    @pytest.mark.asyncio\n    async def test_multiple_stakers_receive_airdrop(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test that multiple stakers all receive the airdrop.\"\"\"\n        stakers = [\"0xStaker1\", \"0xStaker2\", \"0xStaker3\"]\n        \n        # Mint and stake NFTs for multiple users\n        for i, staker in enumerate(stakers, start=1):\n            await nft_service.mint_nft(\n                to_address=staker,\n                metadata_uri=f\"ipfs://QmNFT{i}\"\n            )\n            await staking_service.stake(\n                token_id=i,\n                user_address=staker\n            )\n        \n        # Verify all stakers are registered\n        all_stakers = await staking_service.get_all_stakers()\n        assert len(all_stakers) == 3\n        \n        # Create and pass airdrop proposal\n        airdrop_uri = \"ipfs://QmMultiStakerAirdrop\"\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Multi-staker airdrop\",\n            nft_metadata_uri=airdrop_uri,\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Make proposal pass immediately for testing\n        mock_blockchain.proposals[proposal.id].for_votes = Decimal(\"10000\")\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        # Execute\n        result = await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        assert result.success\n        assert result.airdrop_recipient_count == 3\n        \n        # Verify each staker received exactly one special edition NFT\n        for staker in stakers:\n            nfts = await nft_service.get_nfts_by_owner(staker)\n            special_nfts = [n for n in nfts if n.is_special_edition]\n            assert len(special_nfts) == 1\n            assert special_nfts[0].metadata_uri == airdrop_uri\n    \n    @pytest.mark.asyncio\n    async def test_unstaked_user_not_in_airdrop(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test that a user who unstakes before execution doesn't receive airdrop.\"\"\"\n        staker1 = \"0xStaker1\"\n        staker2 = \"0xStaker2\"\n        \n        # Both users stake\n        for i, staker in enumerate([staker1, staker2], start=1):\n            await nft_service.mint_nft(to_address=staker, metadata_uri=f\"ipfs://QmNFT{i}\")\n            await staking_service.stake(token_id=i, user_address=staker)\n        \n        # Create proposal\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Test unstake\",\n            nft_metadata_uri=\"ipfs://QmAirdrop\",\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Staker2 unstakes before execution\n        await staking_service.unstake(token_id=2, user_address=staker2)\n        \n        # Verify staker2 is no longer in stakers list\n        current_stakers = await staking_service.get_all_stakers()\n        assert staker1 in current_stakers\n        assert staker2 not in current_stakers\n        \n        # Execute proposal\n        mock_blockchain.proposals[proposal.id].for_votes = Decimal(\"10000\")\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        result = await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        assert result.success\n        assert result.airdrop_recipient_count == 1  # Only staker1\n        \n        # Verify only staker1 received airdrop\n        staker1_special = [n for n in await nft_service.get_nfts_by_owner(staker1) if n.is_special_edition]\n        staker2_special = [n for n in await nft_service.get_nfts_by_owner(staker2) if n.is_special_edition]\n        \n        assert len(staker1_special) == 1\n        assert len(staker2_special) == 0\n    \n    @pytest.mark.asyncio\n    async def test_defeated_proposal_not_executed(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test that a defeated proposal cannot be executed.\"\"\"\n        # Setup staker\n        await nft_service.mint_nft(to_address=\"0xStaker\", metadata_uri=\"ipfs://QmNFT\")\n        await staking_service.stake(token_id=1, user_address=\"0xStaker\")\n        \n        # Create proposal\n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Defeated proposal\",\n            nft_metadata_uri=\"ipfs://QmDefeated\",\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Vote against\n        mock_blockchain.proposals[proposal.id].against_votes = Decimal(\"10000\")\n        mock_blockchain.proposals[proposal.id].for_votes = Decimal(\"100\")\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        \n        # Verify proposal is defeated\n        updated_proposal = await governance_service.get_proposal(proposal.id)\n        assert updated_proposal.state == ProposalState.DEFEATED\n        \n        # Attempt to execute should fail\n        result = await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        assert not result.success\n        assert \"cannot be executed\" in result.message.lower()\n    \n    @pytest.mark.asyncio\n    async def test_governance_stats_after_airdrop(\n        self,\n        mock_blockchain,\n        governance_service,\n        staking_service,\n        nft_service\n    ):\n        \"\"\"Test governance statistics are updated after airdrop execution.\"\"\"\n        # Setup and execute an airdrop\n        await nft_service.mint_nft(to_address=\"0xStaker\", metadata_uri=\"ipfs://QmNFT\")\n        await staking_service.stake(token_id=1, user_address=\"0xStaker\")\n        \n        proposal = await governance_service.create_airdrop_proposal(\n            description=\"Stats test\",\n            nft_metadata_uri=\"ipfs://QmStats\",\n            proposer_address=\"0xProposer\"\n        )\n        \n        # Vote\n        await governance_service.vote(\n            proposal_id=proposal.id,\n            voter_address=\"0xVoter1\",\n            support=True\n        )\n        \n        # Execute\n        mock_blockchain.proposals[proposal.id].end_time = datetime.utcnow() - timedelta(hours=1)\n        await governance_service.execute_proposal(\n            proposal_id=proposal.id,\n            executor_address=\"0xExecutor\"\n        )\n        \n        # Check stats\n        stats = await governance_service.get_stats()\n        assert stats.total_proposals == 1\n        assert stats.executed_proposals == 1\n        assert stats.airdrop_proposals_executed == 1\n        assert stats.total_votes_cast == 1\n        assert stats.unique_voters == 1\n\n\nclass TestProposalModel:\n    \"\"\"Tests for Proposal domain model.\"\"\"\n    \n    def test_airdrop_proposal_type_check(self):\n        \"\"\"Test is_airdrop_proposal method.\"\"\"\n        airdrop_proposal = Proposal(\n            id=1,\n            proposer=\"0xProposer\",\n            description=\"Airdrop test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=3),\n            nft_metadata_uri=\"ipfs://QmTest\"\n        )\n        assert airdrop_proposal.is_airdrop_proposal()\n        \n        regular_proposal = Proposal(\n            id=2,\n            proposer=\"0xProposer\",\n            description=\"Regular test\",\n            proposal_type=ProposalType.PARAMETER,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=3)\n        )\n        assert not regular_proposal.is_airdrop_proposal()\n    \n    def test_metadata_uri_validation(self):\n        \"\"\"Test has_valid_metadata_uri method.\"\"\"\n        with_uri = Proposal(\n            id=1,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=1),\n            nft_metadata_uri=\"ipfs://QmValid\"\n        )\n        assert with_uri.has_valid_metadata_uri()\n        \n        without_uri = Proposal(\n            id=2,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=1),\n            nft_metadata_uri=None\n        )\n        assert not without_uri.has_valid_metadata_uri()\n        \n        empty_uri = Proposal(\n            id=3,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow(),\n            end_time=datetime.utcnow() + timedelta(days=1),\n            nft_metadata_uri=\"\"\n        )\n        assert not empty_uri.has_valid_metadata_uri()\n    \n    def test_proposal_state_calculation(self):\n        \"\"\"Test proposal state calculation.\"\"\"\n        # Pending proposal\n        pending = Proposal(\n            id=1,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() + timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3)\n        )\n        assert pending.state == ProposalState.PENDING\n        \n        # Active proposal\n        active = Proposal(\n            id=2,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3)\n        )\n        assert active.state == ProposalState.ACTIVE\n        \n        # Succeeded proposal\n        succeeded = Proposal(\n            id=3,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(days=4),\n            end_time=datetime.utcnow() - timedelta(hours=1),\n            for_votes=Decimal(\"1000\"),\n            against_votes=Decimal(\"100\")\n        )\n        assert succeeded.state == ProposalState.SUCCEEDED\n        \n        # Defeated proposal\n        defeated = Proposal(\n            id=4,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(days=4),\n            end_time=datetime.utcnow() - timedelta(hours=1),\n            for_votes=Decimal(\"100\"),\n            against_votes=Decimal(\"1000\")\n        )\n        assert defeated.state == ProposalState.DEFEATED\n        \n        # Executed proposal\n        executed = Proposal(\n            id=5,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(days=4),\n            end_time=datetime.utcnow() - timedelta(hours=1),\n            executed=True\n        )\n        assert executed.state == ProposalState.EXECUTED\n        \n        # Cancelled proposal\n        cancelled = Proposal(\n            id=6,\n            proposer=\"0x\",\n            description=\"Test\",\n            proposal_type=ProposalType.AIRDROP,\n            start_time=datetime.utcnow() - timedelta(hours=1),\n            end_time=datetime.utcnow() + timedelta(days=3),\n            cancelled=True\n        )\n        assert cancelled.state == ProposalState.CANCELLED\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])",
            "src/showtime_stash/domain/nft.py": "\"\"\"Domain models for NFT functionality.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import Optional, List, Dict, Any\nfrom enum import Enum\n\n\nclass NFTState(Enum):\n    \"\"\"States of an NFT.\"\"\"\n    MINTED = \"minted\"\n    LISTED = \"listed\"\n    STAKED = \"staked\"\n    TRANSFERRED = \"transferred\"\n    BURNED = \"burned\"\n\n\n@dataclass\nclass NFTMetadata:\n    \"\"\"Metadata for an NFT.\"\"\"\n    name: str\n    description: str\n    image: str\n    attributes: List[Dict[str, Any]] = field(default_factory=list)\n    external_url: Optional[str] = None\n    animation_url: Optional[str] = None\n    background_color: Optional[str] = None\n\n\n@dataclass\nclass NFT:\n    \"\"\"Represents an NFT on the platform.\"\"\"\n    token_id: int\n    owner: str\n    metadata_uri: str\n    is_special_edition: bool = False\n    state: NFTState = NFTState.MINTED\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    metadata: Optional[NFTMetadata] = None\n    transaction_hash: Optional[str] = None\n\n    def is_staked(self) -> bool:\n        \"\"\"Check if NFT is currently staked.\"\"\"\n        return self.state == NFTState.STAKED\n\n    def is_transferable(self) -> bool:\n        \"\"\"Check if NFT can be transferred.\"\"\"\n        return self.state not in [NFTState.STAKED, NFTState.BURNED]\n\n\n@dataclass\nclass NFTCollection:\n    \"\"\"Represents a collection of NFTs.\"\"\"\n    name: str\n    symbol: str\n    contract_address: str\n    total_supply: int = 0\n    max_supply: int = 10000\n    base_uri: Optional[str] = None\n    owner: Optional[str] = None\n\n\n@dataclass\nclass MintRequest:\n    \"\"\"Request to mint a new NFT.\"\"\"\n    to_address: str\n    metadata_uri: str\n    is_special_edition: bool = False\n\n\n@dataclass\nclass TransferRequest:\n    \"\"\"Request to transfer an NFT.\"\"\"\n    token_id: int\n    from_address: str\n    to_address: str",
            "src/showtime_stash/application/factories.py": "\"\"\"Factory classes for creating service instances.\"\"\"\n\nfrom typing import Optional\nimport os\n\nfrom .services import GovernanceService, NFTService, StakingService\nfrom ..infrastructure.blockchain_connector import BlockchainConnector\n\n\nclass ServiceFactory:\n    \"\"\"Factory for creating application services.\"\"\"\n    \n    _blockchain_connector: Optional[BlockchainConnector] = None\n    _governance_service: Optional[GovernanceService] = None\n    _nft_service: Optional[NFTService] = None\n    _staking_service: Optional[StakingService] = None\n    \n    @classmethod\n    def get_blockchain_connector(cls) -> BlockchainConnector:\n        \"\"\"Get or create blockchain connector instance.\"\"\"\n        if cls._blockchain_connector is None:\n            rpc_url = os.getenv(\"BLOCKCHAIN_RPC_URL\", \"http://localhost:8545\")\n            cls._blockchain_connector = BlockchainConnector(rpc_url=rpc_url)\n        return cls._blockchain_connector\n    \n    @classmethod\n    def get_governance_service(cls) -> GovernanceService:\n        \"\"\"Get or create governance service instance.\"\"\"\n        if cls._governance_service is None:\n            connector = cls.get_blockchain_connector()\n            cls._governance_service = GovernanceService(connector)\n        return cls._governance_service\n    \n    @classmethod\n    def get_nft_service(cls) -> NFTService:\n        \"\"\"Get or create NFT service instance.\"\"\"\n        if cls._nft_service is None:\n            connector = cls.get_blockchain_connector()\n            cls._nft_service = NFTService(connector)\n        return cls._nft_service\n    \n    @classmethod\n    def get_staking_service(cls) -> StakingService:\n        \"\"\"Get or create staking service instance.\"\"\"\n        if cls._staking_service is None:\n            connector = cls.get_blockchain_connector()\n            cls._staking_service = StakingService(connector)\n        return cls._staking_service\n    \n    @classmethod\n    def reset(cls):\n        \"\"\"Reset all cached instances (useful for testing).\"\"\"\n        cls._blockchain_connector = None\n        cls._governance_service = None\n        cls._nft_service = None\n        cls._staking_service = None\n    \n    @classmethod\n    def set_blockchain_connector(cls, connector: BlockchainConnector):\n        \"\"\"Set a custom blockchain connector (useful for testing).\"\"\"\n        cls._blockchain_connector = connector\n        # Reset services so they use the new connector\n        cls._governance_service = None\n        cls._nft_service = None\n        cls._staking_service = None",
            "src/showtime_stash/infrastructure/blockchain_connector.py": "\"\"\"Blockchain connector for interacting with smart contracts.\"\"\"\n\nfrom typing import Optional, List\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\nimport logging\nimport os\n\nfrom ..domain.governance import Proposal, ProposalType, ProposalState, GovernanceStats\nfrom ..domain.nft import NFT\n\nlogger = logging.getLogger(__name__)\n\n\nclass BlockchainConnector:\n    \"\"\"Connector for blockchain interactions.\"\"\"\n    \n    def __init__(self, rpc_url: str = None):\n        self.rpc_url = rpc_url or os.getenv(\"BLOCKCHAIN_RPC_URL\", \"http://localhost:8545\")\n        self.governance_address = os.getenv(\"GOVERNANCE_CONTRACT_ADDRESS\")\n        self.nft_address = os.getenv(\"NFT_CONTRACT_ADDRESS\")\n        self.staking_address = os.getenv(\"STAKING_CONTRACT_ADDRESS\")\n        self._web3 = None\n        self._governance_contract = None\n        self._nft_contract = None\n        self._staking_contract = None\n    \n    def _get_web3(self):\n        \"\"\"Get Web3 instance (lazy loading).\"\"\"\n        if self._web3 is None:\n            try:\n                from web3 import Web3\n                self._web3 = Web3(Web3.HTTPProvider(self.rpc_url))\n            except ImportError:\n                logger.warning(\"Web3 not installed, using mock mode\")\n                self._web3 = None\n        return self._web3\n    \n    # Governance methods\n    async def create_proposal(\n        self,\n        description: str,\n        proposal_type: str,\n        proposer_address: str\n    ) -> str:\n        \"\"\"Create a governance proposal.\"\"\"\n        logger.info(f\"Creating proposal: {description[:50]}...\")\n        # In production, this would interact with the smart contract\n        return \"0x\" + \"0\" * 64\n    \n    async def create_airdrop_proposal(\n        self,\n        description: str,\n        nft_metadata_uri: str,\n        proposer_address: Optional[str] = None\n    ) -> str:\n        \"\"\"Create an airdrop governance proposal.\"\"\"\n        logger.info(f\"Creating airdrop proposal with metadata: {nft_metadata_uri}\")\n        # In production, this would call the proposeAirdrop function\n        return \"0x\" + \"0\" * 64\n    \n    async def get_proposal(self, proposal_id: int) -> Optional[Proposal]:\n        \"\"\"Get a proposal by ID.\"\"\"\n        logger.info(f\"Fetching proposal {proposal_id}\")\n        # In production, this would fetch from the smart contract\n        return None\n    \n    async def get_all_proposals(self) -> List[Proposal]:\n        \"\"\"Get all proposals.\"\"\"\n        logger.info(\"Fetching all proposals\")\n        return []\n    \n    async def get_latest_proposal_id(self) -> int:\n        \"\"\"Get the latest proposal ID.\"\"\"\n        return 0\n    \n    async def vote(\n        self,\n        proposal_id: int,\n        voter_address: str,\n        support: bool\n    ) -> str:\n        \"\"\"Vote on a proposal.\"\"\"\n        logger.info(f\"Voting on proposal {proposal_id}: support={support}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def execute_proposal(\n        self,\n        proposal_id: int,\n        executor_address: str\n    ) -> str:\n        \"\"\"Execute a passed proposal.\"\"\"\n        logger.info(f\"Executing proposal {proposal_id}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def get_airdrop_recipient_count(self, tx_hash: str) -> int:\n        \"\"\"Get the number of recipients from an airdrop transaction.\"\"\"\n        return 0\n    \n    async def get_governance_stats(self) -> GovernanceStats:\n        \"\"\"Get governance statistics.\"\"\"\n        return GovernanceStats()\n    \n    # NFT methods\n    async def get_nft(self, token_id: int) -> Optional[NFT]:\n        \"\"\"Get NFT by token ID.\"\"\"\n        logger.info(f\"Fetching NFT {token_id}\")\n        return None\n    \n    async def get_nfts_by_owner(self, owner_address: str) -> List[NFT]:\n        \"\"\"Get all NFTs owned by an address.\"\"\"\n        logger.info(f\"Fetching NFTs for owner {owner_address}\")\n        return []\n    \n    async def mint_nft(\n        self,\n        to_address: str,\n        metadata_uri: str\n    ) -> str:\n        \"\"\"Mint a new NFT.\"\"\"\n        logger.info(f\"Minting NFT to {to_address}\")\n        return \"0x\" + \"0\" * 64\n    \n    # Staking methods\n    async def stake_nft(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> str:\n        \"\"\"Stake an NFT.\"\"\"\n        logger.info(f\"Staking NFT {token_id} for {user_address}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def unstake_nft(\n        self,\n        token_id: int,\n        user_address: str\n    ) -> str:\n        \"\"\"Unstake an NFT.\"\"\"\n        logger.info(f\"Unstaking NFT {token_id} for {user_address}\")\n        return \"0x\" + \"0\" * 64\n    \n    async def get_all_stakers(self) -> List[str]:\n        \"\"\"Get all current stakers.\"\"\"\n        logger.info(\"Fetching all stakers\")\n        return []\n    \n    async def get_user_stakes(self, user_address: str) -> List[int]:\n        \"\"\"Get staked token IDs for a user.\"\"\"\n        logger.info(f\"Fetching stakes for {user_address}\")\n        return []\n    \n    async def is_staker(self, address: str) -> bool:\n        \"\"\"Check if an address is currently staking.\"\"\"\n        return False"
          },
          "generated_files": [
            "contracts/Governance.sol",
            "contracts/StakingPool.sol",
            "contracts/ShowTimeNFT.sol",
            "src/showtime_stash/domain/governance.py",
            "src/showtime_stash/interfaces/api.py",
            "src/showtime_stash/application/services.py",
            "tests/contract_tests/test_governance_airdrop.py",
            "src/showtime_stash/domain/nft.py",
            "src/showtime_stash/application/factories.py",
            "src/showtime_stash/infrastructure/blockchain_connector.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.771341085271318,
                "dependency_traversal_accuracy": 0.7021916263761296,
                "cross_file_reasoning_depth": 0.46749999999999997,
                "system_thinking_score": 0.46527523626456346,
                "robustness_score": 0.41090255591054314,
                "comprehensiveness_score": 0.6919444677988902,
                "innovation_score": 0.53125,
                "solution_elegance_score": 0.5799437781999403
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.09641763565891474,
                "dependency_traversal_weighted": 0.0877739532970162,
                "cross_file_reasoning_weighted": 0.058437499999999996,
                "system_thinking_weighted": 0.05815940453307043,
                "robustness_weighted": 0.05136281948881789,
                "comprehensiveness_weighted": 0.08649305847486127,
                "innovation_weighted": 0.06640625,
                "solution_elegance_weighted": 0.07249297227499253
              },
              "total_software_engineering_score": 0.577543593727673
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.0,
                "execution_time": 0.6297681331634521,
                "errors": [
                  "  File \"contracts/Governance.py\", line 1",
                  "    // SPDX-License-Identifier: MIT",
                  "    ^^",
                  "SyntaxError: invalid syntax",
                  "  File \"contracts/StakingPool.py\", line 1",
                  "    // SPDX-License-Identifier: MIT",
                  "    ^^",
                  "SyntaxError: invalid syntax",
                  "  File \"contracts/ShowTimeNFT.py\", line 1",
                  "    // SPDX-License-Identifier: MIT",
                  "    ^^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "contracts/Governance.sol",
                  "contracts/StakingPool.sol",
                  "contracts/ShowTimeNFT.sol",
                  "src/showtime_stash/domain/governance.py",
                  "src/showtime_stash/interfaces/api.py",
                  "src/showtime_stash/application/services.py",
                  "tests/contract_tests/test_governance_airdrop.py",
                  "src/showtime_stash/domain/nft.py",
                  "src/showtime_stash/application/factories.py",
                  "src/showtime_stash/infrastructure/blockchain_connector.py"
                ],
                "scoring_breakdown": {
                  "no_credit": 0.0
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 10,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 10 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.2872304409672831,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.0,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.2872304409672831,
                "idc_weight": 0.2,
                "total_functional_score": 0.36744608819345664
              }
            },
            "code_quality_details": {
              "files_analyzed": 10,
              "quality_checks": {
                "contracts/Governance.sol": {
                  "line_count": 234,
                  "non_empty_lines": 196,
                  "comment_lines": 2,
                  "comment_ratio": 0.01020408163265306,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 3,
                  "quality_score": 0.7
                },
                "contracts/StakingPool.sol": {
                  "line_count": 149,
                  "non_empty_lines": 116,
                  "comment_lines": 1,
                  "comment_ratio": 0.008620689655172414,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 4,
                  "quality_score": 0.7
                },
                "contracts/ShowTimeNFT.sol": {
                  "line_count": 162,
                  "non_empty_lines": 127,
                  "comment_lines": 2,
                  "comment_ratio": 0.015748031496062992,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 5,
                  "quality_score": 0.7
                },
                "src/showtime_stash/domain/governance.py": {
                  "line_count": 160,
                  "non_empty_lines": 132,
                  "comment_lines": 1,
                  "comment_ratio": 0.007575757575757576,
                  "function_count": 9,
                  "class_count": 9,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "src/showtime_stash/interfaces/api.py": {
                  "line_count": 491,
                  "non_empty_lines": 423,
                  "comment_lines": 8,
                  "comment_ratio": 0.018912529550827423,
                  "function_count": 17,
                  "class_count": 15,
                  "import_count": 25,
                  "quality_score": 0.7999999999999999
                },
                "src/showtime_stash/application/services.py": {
                  "line_count": 347,
                  "non_empty_lines": 301,
                  "comment_lines": 9,
                  "comment_ratio": 0.029900332225913623,
                  "function_count": 18,
                  "class_count": 7,
                  "import_count": 17,
                  "quality_score": 0.7999999999999999
                },
                "tests/contract_tests/test_governance_airdrop.py": {
                  "line_count": 665,
                  "non_empty_lines": 568,
                  "comment_lines": 40,
                  "comment_ratio": 0.07042253521126761,
                  "function_count": 34,
                  "class_count": 7,
                  "import_count": 15,
                  "quality_score": 0.6
                },
                "src/showtime_stash/domain/nft.py": {
                  "line_count": 76,
                  "non_empty_lines": 61,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 2,
                  "class_count": 6,
                  "import_count": 8,
                  "quality_score": 0.7999999999999999
                },
                "src/showtime_stash/application/factories.py": {
                  "line_count": 65,
                  "non_empty_lines": 54,
                  "comment_lines": 1,
                  "comment_ratio": 0.018518518518518517,
                  "function_count": 6,
                  "class_count": 1,
                  "import_count": 7,
                  "quality_score": 0.7999999999999999
                },
                "src/showtime_stash/infrastructure/blockchain_connector.py": {
                  "line_count": 155,
                  "non_empty_lines": 131,
                  "comment_lines": 6,
                  "comment_ratio": 0.04580152671755725,
                  "function_count": 19,
                  "class_count": 1,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7649999999999998,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.8058333333333334,
                "multi_session_memory_retention": 0.7907407407407407
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4029166666666667,
                "multi_session_memory_retention_weighted": 0.39537037037037037
              },
              "total_longcontext_utilization_score": 0.7982870370370371
            }
          },
          "timestamp": "2026-01-14T20:47:24.499914"
        }
      }
    },
    "python_data_lake_hard_014_feature_implementation_expert_01": {
      "models_evaluated": [
        "claude-opus-4-5-20251101"
      ],
      "results": {
        "claude-opus-4-5-20251101": {
          "model_name": "claude-opus-4-5-20251101",
          "scenario_id": "python_data_lake_hard_014_feature_implementation_expert_01",
          "scenario_title": "Implement a Data Quarantine and Replay Mechanism for Failed Stream Processing Events",
          "task_category": "feature_implementation",
          "difficulty": "expert",
          "software_engineering_score": 0.5161790783918421,
          "functional_correctness_score": 0.3729959032383925,
          "code_quality_score": 0.7490909090909089,
          "longcontext_utilization_score": 0.9282521645021645,
          "total_score": 2.8050690029832643,
          "generation_time": 320.3164758682251,
          "code_files_generated": 11,
          "total_lines_generated": 3308,
          "parsing_success": true,
          "solution_code": {
            "UtilityLake_Sentinel/configs/default.yml": "# Default configuration for UtilityLake Sentinel Platform\n\napplication:\n  name: UtilityLake Sentinel\n  version: 1.0.0\n  environment: default\n\nlogging:\n  level: INFO\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  handlers:\n    - console\n    - file\n  file_path: /var/log/utilitylake/app.log\n\nstorage:\n  default_path: s3a://utilitylake-data/\n  raw_zone: s3a://utilitylake-data/raw/\n  processed_zone: s3a://utilitylake-data/processed/\n  curated_zone: s3a://utilitylake-data/curated/\n  quarantine_storage_path: s3a://utilitylake-quarantine/\n\nkafka:\n  bootstrap_servers:\n    - localhost:9092\n  consumer_group: utilitylake-consumers\n  auto_offset_reset: earliest\n  enable_auto_commit: true\n\ndatabase:\n  host: localhost\n  port: 5432\n  name: utilitylake_catalog\n  pool_size: 10\n  max_overflow: 20\n\napi:\n  host: 0.0.0.0\n  port: 8000\n  debug: false\n  cors_origins:\n    - \"*\"\n\nmonitoring:\n  prometheus_port: 9090\n  metrics_prefix: utilitylake\n  health_check_interval: 30\n\ndata_quality:\n  enable_validation: true\n  fail_on_error: false\n  quarantine_failed_records: true\n",
            "UtilityLake_Sentinel/configs/development.yml": "# Development configuration for UtilityLake Sentinel Platform\n\napplication:\n  name: UtilityLake Sentinel\n  version: 1.0.0-dev\n  environment: development\n\nlogging:\n  level: DEBUG\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  handlers:\n    - console\n  file_path: /tmp/utilitylake/app.log\n\nstorage:\n  default_path: file:///tmp/utilitylake-data/\n  raw_zone: file:///tmp/utilitylake-data/raw/\n  processed_zone: file:///tmp/utilitylake-data/processed/\n  curated_zone: file:///tmp/utilitylake-data/curated/\n  quarantine_storage_path: file:///tmp/utilitylake-quarantine/\n\nkafka:\n  bootstrap_servers:\n    - localhost:9092\n  consumer_group: utilitylake-dev-consumers\n  auto_offset_reset: earliest\n  enable_auto_commit: true\n\ndatabase:\n  host: localhost\n  port: 5432\n  name: utilitylake_catalog_dev\n  pool_size: 5\n  max_overflow: 10\n\napi:\n  host: 0.0.0.0\n  port: 8000\n  debug: true\n  cors_origins:\n    - \"*\"\n    - \"http://localhost:3000\"\n\nmonitoring:\n  prometheus_port: 9090\n  metrics_prefix: utilitylake_dev\n  health_check_interval: 10\n\ndata_quality:\n  enable_validation: true\n  fail_on_error: false\n  quarantine_failed_records: true\n\ndata_catalog_api:\n  base_url: http://localhost:8001\n  timeout: 30\n",
            "UtilityLake_Sentinel/services/data_catalog_api/models.py": "\"\"\"SQLAlchemy models and Pydantic schemas for the Data Catalog API.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Optional, List\nfrom enum import Enum\n\nfrom sqlalchemy import Column, Integer, String, DateTime, Text, JSON, ForeignKey, Enum as SQLEnum\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\nfrom pydantic import BaseModel, Field\n\nBase = declarative_base()\n\n\nclass DatasetStatus(str, Enum):\n    \"\"\"Status of a dataset in the catalog.\"\"\"\n    ACTIVE = \"active\"\n    DEPRECATED = \"deprecated\"\n    ARCHIVED = \"archived\"\n\n\nclass QuarantineStatus(str, Enum):\n    \"\"\"Status of a quarantined record.\"\"\"\n    QUARANTINED = \"quarantined\"\n    PENDING_REPLAY = \"pending_replay\"\n    REPLAYED = \"replayed\"\n    ARCHIVED = \"archived\"\n\n\n# SQLAlchemy Models\n\nclass Dataset(Base):\n    \"\"\"SQLAlchemy model for datasets in the catalog.\"\"\"\n    __tablename__ = \"datasets\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String(255), unique=True, nullable=False, index=True)\n    description = Column(Text, nullable=True)\n    schema_definition = Column(JSON, nullable=True)\n    storage_location = Column(String(512), nullable=False)\n    format = Column(String(50), nullable=False, default=\"parquet\")\n    owner = Column(String(255), nullable=True)\n    status = Column(SQLEnum(DatasetStatus), default=DatasetStatus.ACTIVE)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    tags = Column(JSON, nullable=True)\n    metadata = Column(JSON, nullable=True)\n\n\nclass DataLineage(Base):\n    \"\"\"SQLAlchemy model for tracking data lineage.\"\"\"\n    __tablename__ = \"data_lineage\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    source_dataset_id = Column(Integer, ForeignKey(\"datasets.id\"), nullable=False)\n    target_dataset_id = Column(Integer, ForeignKey(\"datasets.id\"), nullable=False)\n    transformation_type = Column(String(100), nullable=False)\n    transformation_details = Column(JSON, nullable=True)\n    created_at = Column(DateTime, default=datetime.utcnow)\n\n\nclass QuarantinedRecord(Base):\n    \"\"\"SQLAlchemy model for quarantined records that failed data quality checks.\"\"\"\n    __tablename__ = \"quarantined_records\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    source_topic = Column(String(255), nullable=False, index=True)\n    payload = Column(JSON, nullable=False)\n    failure_reason = Column(Text, nullable=False)\n    quarantined_at = Column(DateTime, default=datetime.utcnow, index=True)\n    status = Column(SQLEnum(QuarantineStatus), default=QuarantineStatus.QUARANTINED, index=True)\n    storage_path = Column(String(512), nullable=True)\n    original_timestamp = Column(DateTime, nullable=True)\n    replay_attempts = Column(Integer, default=0)\n    last_replay_at = Column(DateTime, nullable=True)\n    metadata = Column(JSON, nullable=True)\n\n\n# Pydantic Schemas\n\nclass DatasetBase(BaseModel):\n    \"\"\"Base Pydantic schema for Dataset.\"\"\"\n    name: str\n    description: Optional[str] = None\n    schema_definition: Optional[dict] = None\n    storage_location: str\n    format: str = \"parquet\"\n    owner: Optional[str] = None\n    tags: Optional[List[str]] = None\n    metadata: Optional[dict] = None\n\n\nclass DatasetCreate(DatasetBase):\n    \"\"\"Pydantic schema for creating a Dataset.\"\"\"\n    pass\n\n\nclass DatasetUpdate(BaseModel):\n    \"\"\"Pydantic schema for updating a Dataset.\"\"\"\n    name: Optional[str] = None\n    description: Optional[str] = None\n    schema_definition: Optional[dict] = None\n    storage_location: Optional[str] = None\n    format: Optional[str] = None\n    owner: Optional[str] = None\n    status: Optional[DatasetStatus] = None\n    tags: Optional[List[str]] = None\n    metadata: Optional[dict] = None\n\n\nclass DatasetResponse(DatasetBase):\n    \"\"\"Pydantic schema for Dataset response.\"\"\"\n    id: int\n    status: DatasetStatus\n    created_at: datetime\n    updated_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\nclass DataLineageBase(BaseModel):\n    \"\"\"Base Pydantic schema for DataLineage.\"\"\"\n    source_dataset_id: int\n    target_dataset_id: int\n    transformation_type: str\n    transformation_details: Optional[dict] = None\n\n\nclass DataLineageCreate(DataLineageBase):\n    \"\"\"Pydantic schema for creating DataLineage.\"\"\"\n    pass\n\n\nclass DataLineageResponse(DataLineageBase):\n    \"\"\"Pydantic schema for DataLineage response.\"\"\"\n    id: int\n    created_at: datetime\n\n    class Config:\n        from_attributes = True\n\n\n# Quarantined Record Schemas\n\nclass QuarantinedRecordBase(BaseModel):\n    \"\"\"Base Pydantic schema for QuarantinedRecord.\"\"\"\n    source_topic: str\n    payload: dict\n    failure_reason: str\n    storage_path: Optional[str] = None\n    original_timestamp: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass QuarantinedRecordCreate(QuarantinedRecordBase):\n    \"\"\"Pydantic schema for creating a QuarantinedRecord.\"\"\"\n    pass\n\n\nclass QuarantinedRecordUpdate(BaseModel):\n    \"\"\"Pydantic schema for updating a QuarantinedRecord.\"\"\"\n    status: Optional[QuarantineStatus] = None\n    replay_attempts: Optional[int] = None\n    last_replay_at: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass QuarantinedRecordResponse(QuarantinedRecordBase):\n    \"\"\"Pydantic schema for QuarantinedRecord response.\"\"\"\n    id: int\n    status: QuarantineStatus\n    quarantined_at: datetime\n    replay_attempts: int\n    last_replay_at: Optional[datetime] = None\n\n    class Config:\n        from_attributes = True\n\n\nclass QuarantinedRecordListResponse(BaseModel):\n    \"\"\"Pydantic schema for listing quarantined records.\"\"\"\n    records: List[QuarantinedRecordResponse]\n    total: int\n    page: int\n    page_size: int\n",
            "UtilityLake_Sentinel/services/data_catalog_api/crud.py": "\"\"\"CRUD operations for the Data Catalog API.\"\"\"\n\nfrom datetime import datetime\nfrom typing import List, Optional, Tuple\n\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import and_, or_\n\nfrom .models import (\n    Dataset, DatasetCreate, DatasetUpdate, DatasetStatus,\n    DataLineage, DataLineageCreate,\n    QuarantinedRecord, QuarantinedRecordCreate, QuarantinedRecordUpdate, QuarantineStatus\n)\n\n\n# Dataset CRUD operations\n\ndef create_dataset(db: Session, dataset: DatasetCreate) -> Dataset:\n    \"\"\"Create a new dataset in the catalog.\"\"\"\n    db_dataset = Dataset(\n        name=dataset.name,\n        description=dataset.description,\n        schema_definition=dataset.schema_definition,\n        storage_location=dataset.storage_location,\n        format=dataset.format,\n        owner=dataset.owner,\n        tags=dataset.tags,\n        metadata=dataset.metadata\n    )\n    db.add(db_dataset)\n    db.commit()\n    db.refresh(db_dataset)\n    return db_dataset\n\n\ndef get_dataset(db: Session, dataset_id: int) -> Optional[Dataset]:\n    \"\"\"Get a dataset by ID.\"\"\"\n    return db.query(Dataset).filter(Dataset.id == dataset_id).first()\n\n\ndef get_dataset_by_name(db: Session, name: str) -> Optional[Dataset]:\n    \"\"\"Get a dataset by name.\"\"\"\n    return db.query(Dataset).filter(Dataset.name == name).first()\n\n\ndef get_datasets(\n    db: Session,\n    skip: int = 0,\n    limit: int = 100,\n    status: Optional[DatasetStatus] = None\n) -> List[Dataset]:\n    \"\"\"Get all datasets with optional filtering.\"\"\"\n    query = db.query(Dataset)\n    if status:\n        query = query.filter(Dataset.status == status)\n    return query.offset(skip).limit(limit).all()\n\n\ndef update_dataset(\n    db: Session,\n    dataset_id: int,\n    dataset_update: DatasetUpdate\n) -> Optional[Dataset]:\n    \"\"\"Update a dataset.\"\"\"\n    db_dataset = get_dataset(db, dataset_id)\n    if not db_dataset:\n        return None\n    \n    update_data = dataset_update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(db_dataset, field, value)\n    \n    db.commit()\n    db.refresh(db_dataset)\n    return db_dataset\n\n\ndef delete_dataset(db: Session, dataset_id: int) -> bool:\n    \"\"\"Delete a dataset.\"\"\"\n    db_dataset = get_dataset(db, dataset_id)\n    if not db_dataset:\n        return False\n    db.delete(db_dataset)\n    db.commit()\n    return True\n\n\n# DataLineage CRUD operations\n\ndef create_lineage(db: Session, lineage: DataLineageCreate) -> DataLineage:\n    \"\"\"Create a new lineage record.\"\"\"\n    db_lineage = DataLineage(\n        source_dataset_id=lineage.source_dataset_id,\n        target_dataset_id=lineage.target_dataset_id,\n        transformation_type=lineage.transformation_type,\n        transformation_details=lineage.transformation_details\n    )\n    db.add(db_lineage)\n    db.commit()\n    db.refresh(db_lineage)\n    return db_lineage\n\n\ndef get_lineage_for_dataset(\n    db: Session,\n    dataset_id: int,\n    direction: str = \"both\"\n) -> List[DataLineage]:\n    \"\"\"Get lineage records for a dataset.\"\"\"\n    if direction == \"upstream\":\n        return db.query(DataLineage).filter(\n            DataLineage.target_dataset_id == dataset_id\n        ).all()\n    elif direction == \"downstream\":\n        return db.query(DataLineage).filter(\n            DataLineage.source_dataset_id == dataset_id\n        ).all()\n    else:\n        return db.query(DataLineage).filter(\n            or_(\n                DataLineage.source_dataset_id == dataset_id,\n                DataLineage.target_dataset_id == dataset_id\n            )\n        ).all()\n\n\n# QuarantinedRecord CRUD operations\n\ndef create_quarantined_record(\n    db: Session,\n    record: QuarantinedRecordCreate\n) -> QuarantinedRecord:\n    \"\"\"Create a new quarantined record entry.\"\"\"\n    db_record = QuarantinedRecord(\n        source_topic=record.source_topic,\n        payload=record.payload,\n        failure_reason=record.failure_reason,\n        storage_path=record.storage_path,\n        original_timestamp=record.original_timestamp,\n        metadata=record.metadata,\n        status=QuarantineStatus.QUARANTINED,\n        quarantined_at=datetime.utcnow()\n    )\n    db.add(db_record)\n    db.commit()\n    db.refresh(db_record)\n    return db_record\n\n\ndef get_quarantined_record(\n    db: Session,\n    record_id: int\n) -> Optional[QuarantinedRecord]:\n    \"\"\"Get a quarantined record by ID.\"\"\"\n    return db.query(QuarantinedRecord).filter(\n        QuarantinedRecord.id == record_id\n    ).first()\n\n\ndef get_quarantined_records(\n    db: Session,\n    skip: int = 0,\n    limit: int = 100,\n    status: Optional[QuarantineStatus] = None,\n    source_topic: Optional[str] = None,\n    start_date: Optional[datetime] = None,\n    end_date: Optional[datetime] = None\n) -> Tuple[List[QuarantinedRecord], int]:\n    \"\"\"Get quarantined records with optional filtering.\n    \n    Returns a tuple of (records, total_count).\n    \"\"\"\n    query = db.query(QuarantinedRecord)\n    \n    # Apply filters\n    filters = []\n    if status:\n        filters.append(QuarantinedRecord.status == status)\n    if source_topic:\n        filters.append(QuarantinedRecord.source_topic == source_topic)\n    if start_date:\n        filters.append(QuarantinedRecord.quarantined_at >= start_date)\n    if end_date:\n        filters.append(QuarantinedRecord.quarantined_at <= end_date)\n    \n    if filters:\n        query = query.filter(and_(*filters))\n    \n    # Get total count before pagination\n    total = query.count()\n    \n    # Apply pagination and ordering\n    records = query.order_by(\n        QuarantinedRecord.quarantined_at.desc()\n    ).offset(skip).limit(limit).all()\n    \n    return records, total\n\n\ndef update_quarantined_record(\n    db: Session,\n    record_id: int,\n    record_update: QuarantinedRecordUpdate\n) -> Optional[QuarantinedRecord]:\n    \"\"\"Update a quarantined record.\"\"\"\n    db_record = get_quarantined_record(db, record_id)\n    if not db_record:\n        return None\n    \n    update_data = record_update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(db_record, field, value)\n    \n    db.commit()\n    db.refresh(db_record)\n    return db_record\n\n\ndef update_quarantined_record_status(\n    db: Session,\n    record_id: int,\n    new_status: QuarantineStatus\n) -> Optional[QuarantinedRecord]:\n    \"\"\"Update the status of a quarantined record.\"\"\"\n    db_record = get_quarantined_record(db, record_id)\n    if not db_record:\n        return None\n    \n    db_record.status = new_status\n    if new_status == QuarantineStatus.PENDING_REPLAY:\n        db_record.replay_attempts = (db_record.replay_attempts or 0) + 1\n        db_record.last_replay_at = datetime.utcnow()\n    \n    db.commit()\n    db.refresh(db_record)\n    return db_record\n\n\ndef delete_quarantined_record(db: Session, record_id: int) -> bool:\n    \"\"\"Delete a quarantined record.\"\"\"\n    db_record = get_quarantined_record(db, record_id)\n    if not db_record:\n        return False\n    db.delete(db_record)\n    db.commit()\n    return True\n\n\ndef get_quarantine_statistics(db: Session) -> dict:\n    \"\"\"Get statistics about quarantined records.\"\"\"\n    total = db.query(QuarantinedRecord).count()\n    by_status = {}\n    for status in QuarantineStatus:\n        count = db.query(QuarantinedRecord).filter(\n            QuarantinedRecord.status == status\n        ).count()\n        by_status[status.value] = count\n    \n    return {\n        \"total\": total,\n        \"by_status\": by_status\n    }\n",
            "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py": "\"\"\"Data quality checks for stream processing with quarantine support.\"\"\"\n\nimport json\nimport uuid\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional, Callable, Tuple\nfrom dataclasses import dataclass\nimport logging\nimport httpx\n\nfrom utilitylake_core.storage import StorageClient\nfrom utilitylake_core.config import get_config\nfrom utilitylake_core.errors import DataQualityError, ValidationError\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass QualityCheckResult:\n    \"\"\"Result of a quality check.\"\"\"\n    passed: bool\n    check_name: str\n    message: str\n    details: Optional[Dict[str, Any]] = None\n\n\n@dataclass\nclass QuarantineResult:\n    \"\"\"Result of quarantining a record.\"\"\"\n    success: bool\n    storage_path: Optional[str] = None\n    catalog_id: Optional[int] = None\n    error: Optional[str] = None\n\n\nclass DataCatalogClient:\n    \"\"\"Client for interacting with the Data Catalog API.\"\"\"\n    \n    def __init__(self, base_url: Optional[str] = None, timeout: int = 30):\n        config = get_config()\n        self.base_url = base_url or config.get(\n            'data_catalog_api', {}\n        ).get('base_url', 'http://localhost:8001')\n        self.timeout = timeout\n    \n    def create_quarantined_record(\n        self,\n        source_topic: str,\n        payload: Dict[str, Any],\n        failure_reason: str,\n        storage_path: Optional[str] = None,\n        original_timestamp: Optional[datetime] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> Optional[int]:\n        \"\"\"Create a quarantined record entry in the data catalog.\"\"\"\n        try:\n            data = {\n                \"source_topic\": source_topic,\n                \"payload\": payload,\n                \"failure_reason\": failure_reason,\n                \"storage_path\": storage_path,\n                \"metadata\": metadata\n            }\n            if original_timestamp:\n                data[\"original_timestamp\"] = original_timestamp.isoformat()\n            \n            with httpx.Client(timeout=self.timeout) as client:\n                response = client.post(\n                    f\"{self.base_url}/api/v1/quarantine/records\",\n                    json=data\n                )\n                response.raise_for_status()\n                result = response.json()\n                return result.get(\"id\")\n        except Exception as e:\n            logger.error(f\"Failed to create quarantine record in catalog: {e}\")\n            return None\n\n\nclass QuarantineManager:\n    \"\"\"Manages quarantining of failed records.\"\"\"\n    \n    def __init__(\n        self,\n        storage_client: Optional[StorageClient] = None,\n        catalog_client: Optional[DataCatalogClient] = None,\n        quarantine_path: Optional[str] = None\n    ):\n        config = get_config()\n        self.storage_client = storage_client or StorageClient()\n        self.catalog_client = catalog_client or DataCatalogClient()\n        self.quarantine_path = quarantine_path or config.get(\n            'storage', {}\n        ).get('quarantine_storage_path', 's3a://utilitylake-quarantine/')\n    \n    def quarantine_record(\n        self,\n        record: Dict[str, Any],\n        source_topic: str,\n        failure_reason: str,\n        original_timestamp: Optional[datetime] = None,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> QuarantineResult:\n        \"\"\"Quarantine a failed record.\n        \n        1. Write the record to quarantine storage\n        2. Log the record in the data catalog\n        \"\"\"\n        # Generate unique path for the quarantined record\n        timestamp = datetime.utcnow()\n        record_id = str(uuid.uuid4())\n        date_partition = timestamp.strftime(\"%Y/%m/%d\")\n        storage_path = f\"{self.quarantine_path}{source_topic}/{date_partition}/{record_id}.json\"\n        \n        # Prepare quarantine data with metadata\n        quarantine_data = {\n            \"record\": record,\n            \"quarantine_metadata\": {\n                \"source_topic\": source_topic,\n                \"failure_reason\": failure_reason,\n                \"quarantined_at\": timestamp.isoformat(),\n                \"original_timestamp\": original_timestamp.isoformat() if original_timestamp else None,\n                \"additional_metadata\": metadata\n            }\n        }\n        \n        try:\n            # Write to quarantine storage\n            self.storage_client.write(\n                path=storage_path,\n                data=json.dumps(quarantine_data, default=str)\n            )\n            logger.info(f\"Record quarantined to storage: {storage_path}\")\n        except Exception as e:\n            error_msg = f\"Failed to write record to quarantine storage: {e}\"\n            logger.error(error_msg)\n            return QuarantineResult(success=False, error=error_msg)\n        \n        # Log to data catalog\n        try:\n            catalog_id = self.catalog_client.create_quarantined_record(\n                source_topic=source_topic,\n                payload=record,\n                failure_reason=failure_reason,\n                storage_path=storage_path,\n                original_timestamp=original_timestamp,\n                metadata=metadata\n            )\n            logger.info(f\"Quarantine record logged in catalog with ID: {catalog_id}\")\n        except Exception as e:\n            logger.warning(f\"Failed to log quarantine record in catalog: {e}\")\n            catalog_id = None\n        \n        return QuarantineResult(\n            success=True,\n            storage_path=storage_path,\n            catalog_id=catalog_id\n        )\n\n\nclass QualityChecker:\n    \"\"\"Performs data quality checks on streaming records.\"\"\"\n    \n    def __init__(\n        self,\n        quarantine_manager: Optional[QuarantineManager] = None,\n        enable_quarantine: bool = True\n    ):\n        self.quarantine_manager = quarantine_manager or QuarantineManager()\n        self.enable_quarantine = enable_quarantine\n        self.checks: List[Callable[[Dict[str, Any]], QualityCheckResult]] = []\n    \n    def add_check(self, check_func: Callable[[Dict[str, Any]], QualityCheckResult]):\n        \"\"\"Add a quality check function.\"\"\"\n        self.checks.append(check_func)\n    \n    def run_checks(\n        self,\n        record: Dict[str, Any],\n        source_topic: str = \"unknown\",\n        original_timestamp: Optional[datetime] = None\n    ) -> Tuple[bool, List[QualityCheckResult]]:\n        \"\"\"Run all quality checks on a record.\n        \n        Returns tuple of (all_passed, results).\n        \"\"\"\n        results = []\n        all_passed = True\n        \n        for check_func in self.checks:\n            try:\n                result = check_func(record)\n                results.append(result)\n                if not result.passed:\n                    all_passed = False\n            except Exception as e:\n                result = QualityCheckResult(\n                    passed=False,\n                    check_name=check_func.__name__,\n                    message=f\"Check failed with exception: {str(e)}\"\n                )\n                results.append(result)\n                all_passed = False\n        \n        return all_passed, results\n    \n    def process_record(\n        self,\n        record: Dict[str, Any],\n        source_topic: str = \"unknown\",\n        original_timestamp: Optional[datetime] = None\n    ) -> Tuple[bool, Optional[QuarantineResult]]:\n        \"\"\"Process a record through quality checks.\n        \n        If checks fail and quarantine is enabled, the record is quarantined.\n        Returns tuple of (passed, quarantine_result).\n        \"\"\"\n        all_passed, results = self.run_checks(\n            record, source_topic, original_timestamp\n        )\n        \n        if all_passed:\n            return True, None\n        \n        # Collect failure reasons\n        failure_reasons = [\n            f\"{r.check_name}: {r.message}\"\n            for r in results\n            if not r.passed\n        ]\n        failure_reason = \"; \".join(failure_reasons)\n        \n        # Quarantine the failed record\n        if self.enable_quarantine:\n            quarantine_result = self.quarantine_manager.quarantine_record(\n                record=record,\n                source_topic=source_topic,\n                failure_reason=failure_reason,\n                original_timestamp=original_timestamp,\n                metadata={\n                    \"check_results\": [\n                        {\n                            \"check_name\": r.check_name,\n                            \"passed\": r.passed,\n                            \"message\": r.message,\n                            \"details\": r.details\n                        }\n                        for r in results\n                    ]\n                }\n            )\n            return False, quarantine_result\n        \n        return False, None\n\n\n# Built-in quality check functions\n\ndef check_not_null(fields: List[str]) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that ensures specified fields are not null.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        missing_fields = [\n            field for field in fields\n            if field not in record or record[field] is None\n        ]\n        if missing_fields:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"not_null_check\",\n                message=f\"Missing or null fields: {missing_fields}\",\n                details={\"missing_fields\": missing_fields}\n            )\n        return QualityCheckResult(\n            passed=True,\n            check_name=\"not_null_check\",\n            message=\"All required fields present\"\n        )\n    return _check\n\n\ndef check_field_type(\n    field_types: Dict[str, type]\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates field types.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        type_errors = []\n        for field, expected_type in field_types.items():\n            if field in record and record[field] is not None:\n                if not isinstance(record[field], expected_type):\n                    type_errors.append({\n                        \"field\": field,\n                        \"expected\": expected_type.__name__,\n                        \"actual\": type(record[field]).__name__\n                    })\n        if type_errors:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"field_type_check\",\n                message=f\"Type validation failed for {len(type_errors)} field(s)\",\n                details={\"type_errors\": type_errors}\n            )\n        return QualityCheckResult(\n            passed=True,\n            check_name=\"field_type_check\",\n            message=\"All field types valid\"\n        )\n    return _check\n\n\ndef check_value_range(\n    field: str,\n    min_value: Optional[float] = None,\n    max_value: Optional[float] = None\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates a numeric field is within range.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        if field not in record or record[field] is None:\n            return QualityCheckResult(\n                passed=True,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} not present, skipping range check\"\n            )\n        \n        value = record[field]\n        try:\n            value = float(value)\n        except (ValueError, TypeError):\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} is not numeric\",\n                details={\"field\": field, \"value\": str(value)}\n            )\n        \n        if min_value is not None and value < min_value:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} value {value} is below minimum {min_value}\",\n                details={\"field\": field, \"value\": value, \"min\": min_value}\n            )\n        \n        if max_value is not None and value > max_value:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"value_range_check\",\n                message=f\"Field {field} value {value} is above maximum {max_value}\",\n                details={\"field\": field, \"value\": value, \"max\": max_value}\n            )\n        \n        return QualityCheckResult(\n            passed=True,\n            check_name=\"value_range_check\",\n            message=f\"Field {field} value {value} is within range\"\n        )\n    return _check\n\n\ndef check_schema_conformance(\n    required_fields: List[str],\n    optional_fields: Optional[List[str]] = None\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates record schema conformance.\"\"\"\n    optional_fields = optional_fields or []\n    all_known_fields = set(required_fields + optional_fields)\n    \n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        missing_required = [\n            field for field in required_fields\n            if field not in record\n        ]\n        unknown_fields = [\n            field for field in record.keys()\n            if field not in all_known_fields\n        ]\n        \n        issues = []\n        if missing_required:\n            issues.append(f\"Missing required fields: {missing_required}\")\n        if unknown_fields:\n            issues.append(f\"Unknown fields: {unknown_fields}\")\n        \n        if issues:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"schema_conformance_check\",\n                message=\"; \".join(issues),\n                details={\n                    \"missing_required\": missing_required,\n                    \"unknown_fields\": unknown_fields\n                }\n            )\n        \n        return QualityCheckResult(\n            passed=True,\n            check_name=\"schema_conformance_check\",\n            message=\"Record conforms to expected schema\"\n        )\n    return _check\n\n\ndef check_timestamp_valid(\n    field: str,\n    max_age_seconds: Optional[int] = None,\n    max_future_seconds: int = 300\n) -> Callable[[Dict[str, Any]], QualityCheckResult]:\n    \"\"\"Create a check that validates timestamp fields.\"\"\"\n    def _check(record: Dict[str, Any]) -> QualityCheckResult:\n        if field not in record or record[field] is None:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"timestamp_valid_check\",\n                message=f\"Timestamp field {field} is missing or null\"\n            )\n        \n        try:\n            if isinstance(record[field], str):\n                ts = datetime.fromisoformat(record[field].replace('Z', '+00:00'))\n            elif isinstance(record[field], (int, float)):\n                ts = datetime.fromtimestamp(record[field])\n            elif isinstance(record[field], datetime):\n                ts = record[field]\n            else:\n                raise ValueError(f\"Unknown timestamp format: {type(record[field])}\")\n        except Exception as e:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"timestamp_valid_check\",\n                message=f\"Invalid timestamp format: {e}\",\n                details={\"field\": field, \"value\": str(record[field])}\n            )\n        \n        now = datetime.utcnow()\n        \n        # Check if timestamp is too far in the future\n        future_delta = (ts.replace(tzinfo=None) - now).total_seconds()\n        if future_delta > max_future_seconds:\n            return QualityCheckResult(\n                passed=False,\n                check_name=\"timestamp_valid_check\",\n                message=f\"Timestamp is {future_delta:.0f}s in the future\",\n                details={\"field\": field, \"future_seconds\": future_delta}\n            )\n        \n        # Check if timestamp is too old\n        if max_age_seconds is not None:\n            age = (now - ts.replace(tzinfo=None)).total_seconds()\n            if age > max_age_seconds:\n                return QualityCheckResult(\n                    passed=False,\n                    check_name=\"timestamp_valid_check\",\n                    message=f\"Timestamp is {age:.0f}s old, max allowed is {max_age_seconds}s\",\n                    details={\"field\": field, \"age_seconds\": age}\n                )\n        \n        return QualityCheckResult(\n            passed=True,\n            check_name=\"timestamp_valid_check\",\n            message=f\"Timestamp {field} is valid\"\n        )\n    return _check\n\n\n# Factory function to create a configured quality checker\n\ndef create_quality_checker(\n    required_fields: Optional[List[str]] = None,\n    field_types: Optional[Dict[str, type]] = None,\n    enable_quarantine: bool = True,\n    quarantine_manager: Optional[QuarantineManager] = None\n) -> QualityChecker:\n    \"\"\"Create a QualityChecker with common checks configured.\"\"\"\n    checker = QualityChecker(\n        quarantine_manager=quarantine_manager,\n        enable_quarantine=enable_quarantine\n    )\n    \n    if required_fields:\n        checker.add_check(check_not_null(required_fields))\n    \n    if field_types:\n        checker.add_check(check_field_type(field_types))\n    \n    return checker\n",
            "UtilityLake_Sentinel/services/observability_api/endpoints.py": "\"\"\"API endpoints for the Observability API service.\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Optional, List\nimport logging\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, status\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\n\n# Health check router\nhealth_router = APIRouter(tags=[\"Health\"])\n\n\nclass HealthStatus(BaseModel):\n    \"\"\"Health status response model.\"\"\"\n    status: str\n    timestamp: datetime\n    version: str = \"1.0.0\"\n    services: dict = {}\n\n\n@health_router.get(\"/health\", response_model=HealthStatus)\nasync def health_check():\n    \"\"\"Check the health of the observability API.\"\"\"\n    return HealthStatus(\n        status=\"healthy\",\n        timestamp=datetime.utcnow(),\n        services={\n            \"api\": \"up\",\n            \"database\": \"up\"\n        }\n    )\n\n\n@health_router.get(\"/health/live\")\nasync def liveness_check():\n    \"\"\"Kubernetes liveness probe endpoint.\"\"\"\n    return {\"status\": \"alive\"}\n\n\n@health_router.get(\"/health/ready\")\nasync def readiness_check():\n    \"\"\"Kubernetes readiness probe endpoint.\"\"\"\n    return {\"status\": \"ready\"}\n\n\n# Metrics router\nmetrics_router = APIRouter(prefix=\"/metrics\", tags=[\"Metrics\"])\n\n\nclass MetricPoint(BaseModel):\n    \"\"\"A single metric data point.\"\"\"\n    timestamp: datetime\n    value: float\n    labels: dict = {}\n\n\nclass MetricSeries(BaseModel):\n    \"\"\"A time series of metric data points.\"\"\"\n    name: str\n    points: List[MetricPoint]\n    unit: Optional[str] = None\n\n\n@metrics_router.get(\"/summary\")\nasync def get_metrics_summary():\n    \"\"\"Get a summary of platform metrics.\"\"\"\n    return {\n        \"ingestion_rate\": 1500.0,\n        \"processing_latency_ms\": 45.2,\n        \"error_rate\": 0.02,\n        \"active_streams\": 12,\n        \"timestamp\": datetime.utcnow().isoformat()\n    }\n\n\n@metrics_router.get(\"/series/{metric_name}\", response_model=MetricSeries)\nasync def get_metric_series(\n    metric_name: str,\n    start_time: Optional[datetime] = None,\n    end_time: Optional[datetime] = None,\n    resolution: str = Query(default=\"1m\", regex=\"^[0-9]+[smhd]$\")\n):\n    \"\"\"Get time series data for a specific metric.\"\"\"\n    if start_time is None:\n        start_time = datetime.utcnow() - timedelta(hours=1)\n    if end_time is None:\n        end_time = datetime.utcnow()\n    \n    # Placeholder - would query actual metrics store\n    return MetricSeries(\n        name=metric_name,\n        points=[\n            MetricPoint(\n                timestamp=start_time + timedelta(minutes=i),\n                value=100.0 + i * 0.5\n            )\n            for i in range(10)\n        ],\n        unit=\"count\"\n    )\n\n\n# Alerts router\nalerts_router = APIRouter(prefix=\"/alerts\", tags=[\"Alerts\"])\n\n\nclass Alert(BaseModel):\n    \"\"\"Alert model.\"\"\"\n    id: str\n    name: str\n    severity: str\n    status: str\n    message: str\n    triggered_at: datetime\n    resolved_at: Optional[datetime] = None\n    labels: dict = {}\n\n\n@alerts_router.get(\"/\", response_model=List[Alert])\nasync def get_alerts(\n    status: Optional[str] = Query(default=None, description=\"Filter by status\"),\n    severity: Optional[str] = Query(default=None, description=\"Filter by severity\")\n):\n    \"\"\"Get active alerts.\"\"\"\n    # Placeholder - would query actual alerting system\n    return [\n        Alert(\n            id=\"alert-001\",\n            name=\"High Error Rate\",\n            severity=\"warning\",\n            status=\"active\",\n            message=\"Error rate exceeded threshold\",\n            triggered_at=datetime.utcnow() - timedelta(minutes=30),\n            labels={\"service\": \"stream_processor\"}\n        )\n    ]\n\n\n@alerts_router.post(\"/{alert_id}/acknowledge\")\nasync def acknowledge_alert(alert_id: str):\n    \"\"\"Acknowledge an alert.\"\"\"\n    return {\"status\": \"acknowledged\", \"alert_id\": alert_id}\n\n\n# Quarantine router\nquarantine_router = APIRouter(prefix=\"/quarantine\", tags=[\"Quarantine\"])\n\n\nclass QuarantineStatus(str):\n    \"\"\"Quarantine status enum values.\"\"\"\n    QUARANTINED = \"quarantined\"\n    PENDING_REPLAY = \"pending_replay\"\n    REPLAYED = \"replayed\"\n    ARCHIVED = \"archived\"\n\n\nclass QuarantinedRecordResponse(BaseModel):\n    \"\"\"Response model for a quarantined record.\"\"\"\n    id: int\n    source_topic: str\n    payload: dict\n    failure_reason: str\n    quarantined_at: datetime\n    status: str\n    storage_path: Optional[str] = None\n    original_timestamp: Optional[datetime] = None\n    replay_attempts: int = 0\n    last_replay_at: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass QuarantinedRecordListResponse(BaseModel):\n    \"\"\"Response model for listing quarantined records.\"\"\"\n    records: List[QuarantinedRecordResponse]\n    total: int\n    page: int\n    page_size: int\n\n\nclass QuarantinedRecordCreate(BaseModel):\n    \"\"\"Request model for creating a quarantined record.\"\"\"\n    source_topic: str\n    payload: dict\n    failure_reason: str\n    storage_path: Optional[str] = None\n    original_timestamp: Optional[datetime] = None\n    metadata: Optional[dict] = None\n\n\nclass ReplayResponse(BaseModel):\n    \"\"\"Response model for replay action.\"\"\"\n    id: int\n    status: str\n    message: str\n    replay_attempts: int\n\n\nclass QuarantineStatistics(BaseModel):\n    \"\"\"Statistics about quarantined records.\"\"\"\n    total: int\n    by_status: dict\n    by_topic: Optional[dict] = None\n\n\n# In-memory storage for demo purposes\n# In production, this would use the Data Catalog database\n_quarantine_store: List[dict] = []\n_quarantine_id_counter = 0\n\n\ndef _get_db_session():\n    \"\"\"Dependency to get database session.\n    \n    In production, this would return an actual SQLAlchemy session.\n    For now, we use in-memory storage.\n    \"\"\"\n    return None\n\n\n@quarantine_router.get(\"/records\", response_model=QuarantinedRecordListResponse)\nasync def get_quarantined_records(\n    status: Optional[str] = Query(\n        default=None,\n        description=\"Filter by status (quarantined, pending_replay, replayed, archived)\"\n    ),\n    source_topic: Optional[str] = Query(\n        default=None,\n        description=\"Filter by source topic\"\n    ),\n    start_date: Optional[datetime] = Query(\n        default=None,\n        description=\"Filter records quarantined after this date\"\n    ),\n    end_date: Optional[datetime] = Query(\n        default=None,\n        description=\"Filter records quarantined before this date\"\n    ),\n    page: int = Query(default=1, ge=1, description=\"Page number\"),\n    page_size: int = Query(default=50, ge=1, le=500, description=\"Records per page\")\n):\n    \"\"\"Get quarantined records with optional filtering.\n    \n    Supports filtering by:\n    - status: quarantined, pending_replay, replayed, archived\n    - source_topic: the Kafka topic the record originated from\n    - date_range: start_date and end_date for quarantined_at timestamp\n    \"\"\"\n    # Filter records\n    filtered_records = _quarantine_store.copy()\n    \n    if status:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"status\") == status\n        ]\n    \n    if source_topic:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"source_topic\") == source_topic\n        ]\n    \n    if start_date:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"quarantined_at\") and r[\"quarantined_at\"] >= start_date\n        ]\n    \n    if end_date:\n        filtered_records = [\n            r for r in filtered_records\n            if r.get(\"quarantined_at\") and r[\"quarantined_at\"] <= end_date\n        ]\n    \n    # Sort by quarantined_at descending\n    filtered_records.sort(\n        key=lambda x: x.get(\"quarantined_at\", datetime.min),\n        reverse=True\n    )\n    \n    # Paginate\n    total = len(filtered_records)\n    start_idx = (page - 1) * page_size\n    end_idx = start_idx + page_size\n    paginated_records = filtered_records[start_idx:end_idx]\n    \n    return QuarantinedRecordListResponse(\n        records=[QuarantinedRecordResponse(**r) for r in paginated_records],\n        total=total,\n        page=page,\n        page_size=page_size\n    )\n\n\n@quarantine_router.get(\"/records/{record_id}\", response_model=QuarantinedRecordResponse)\nasync def get_quarantined_record(record_id: int):\n    \"\"\"Get a specific quarantined record by ID.\"\"\"\n    for record in _quarantine_store:\n        if record.get(\"id\") == record_id:\n            return QuarantinedRecordResponse(**record)\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n\n\n@quarantine_router.post(\"/records\", response_model=QuarantinedRecordResponse, status_code=status.HTTP_201_CREATED)\nasync def create_quarantined_record(record: QuarantinedRecordCreate):\n    \"\"\"Create a new quarantined record entry.\n    \n    This endpoint is typically called by the stream processor when a record\n    fails data quality validation.\n    \"\"\"\n    global _quarantine_id_counter\n    _quarantine_id_counter += 1\n    \n    new_record = {\n        \"id\": _quarantine_id_counter,\n        \"source_topic\": record.source_topic,\n        \"payload\": record.payload,\n        \"failure_reason\": record.failure_reason,\n        \"quarantined_at\": datetime.utcnow(),\n        \"status\": \"quarantined\",\n        \"storage_path\": record.storage_path,\n        \"original_timestamp\": record.original_timestamp,\n        \"replay_attempts\": 0,\n        \"last_replay_at\": None,\n        \"metadata\": record.metadata\n    }\n    \n    _quarantine_store.append(new_record)\n    logger.info(f\"Created quarantine record {new_record['id']} for topic {record.source_topic}\")\n    \n    return QuarantinedRecordResponse(**new_record)\n\n\n@quarantine_router.post(\"/records/{record_id}/replay\", response_model=ReplayResponse)\nasync def replay_quarantined_record(record_id: int):\n    \"\"\"Initiate replay of a quarantined record.\n    \n    This endpoint updates the record's status to 'pending_replay'.\n    The actual replay logic (re-submitting to the stream processor)\n    is handled by a separate background process.\n    \"\"\"\n    for record in _quarantine_store:\n        if record.get(\"id\") == record_id:\n            # Check if record can be replayed\n            current_status = record.get(\"status\")\n            if current_status == \"replayed\":\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=\"Record has already been successfully replayed\"\n                )\n            \n            # Update status to pending_replay\n            record[\"status\"] = \"pending_replay\"\n            record[\"replay_attempts\"] = record.get(\"replay_attempts\", 0) + 1\n            record[\"last_replay_at\"] = datetime.utcnow()\n            \n            logger.info(\n                f\"Initiated replay for quarantine record {record_id}, \"\n                f\"attempt #{record['replay_attempts']}\"\n            )\n            \n            return ReplayResponse(\n                id=record_id,\n                status=\"pending_replay\",\n                message=\"Record queued for replay. Status will be updated upon completion.\",\n                replay_attempts=record[\"replay_attempts\"]\n            )\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n\n\n@quarantine_router.post(\"/records/{record_id}/archive\", response_model=QuarantinedRecordResponse)\nasync def archive_quarantined_record(record_id: int):\n    \"\"\"Archive a quarantined record.\n    \n    Archived records are kept for audit purposes but are no longer\n    considered for replay.\n    \"\"\"\n    for record in _quarantine_store:\n        if record.get(\"id\") == record_id:\n            record[\"status\"] = \"archived\"\n            logger.info(f\"Archived quarantine record {record_id}\")\n            return QuarantinedRecordResponse(**record)\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n\n\n@quarantine_router.get(\"/statistics\", response_model=QuarantineStatistics)\nasync def get_quarantine_statistics():\n    \"\"\"Get statistics about quarantined records.\"\"\"\n    total = len(_quarantine_store)\n    \n    by_status = {}\n    by_topic = {}\n    \n    for record in _quarantine_store:\n        # Count by status\n        status = record.get(\"status\", \"unknown\")\n        by_status[status] = by_status.get(status, 0) + 1\n        \n        # Count by topic\n        topic = record.get(\"source_topic\", \"unknown\")\n        by_topic[topic] = by_topic.get(topic, 0) + 1\n    \n    return QuarantineStatistics(\n        total=total,\n        by_status=by_status,\n        by_topic=by_topic\n    )\n\n\n@quarantine_router.delete(\"/records/{record_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_quarantined_record(record_id: int):\n    \"\"\"Delete a quarantined record.\n    \n    This permanently removes the record from the quarantine.\n    Use with caution - consider archiving instead.\n    \"\"\"\n    global _quarantine_store\n    \n    for i, record in enumerate(_quarantine_store):\n        if record.get(\"id\") == record_id:\n            del _quarantine_store[i]\n            logger.info(f\"Deleted quarantine record {record_id}\")\n            return\n    \n    raise HTTPException(\n        status_code=status.HTTP_404_NOT_FOUND,\n        detail=f\"Quarantined record with ID {record_id} not found\"\n    )\n",
            "UtilityLake_Sentinel/services/observability_api/main.py": "\"\"\"Main entry point for the Observability API service.\"\"\"\n\nimport logging\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom .endpoints import (\n    health_router,\n    metrics_router,\n    alerts_router,\n    quarantine_router\n)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan handler.\"\"\"\n    logger.info(\"Starting Observability API service...\")\n    yield\n    logger.info(\"Shutting down Observability API service...\")\n\n\napp = FastAPI(\n    title=\"UtilityLake Sentinel Observability API\",\n    description=\"API for monitoring and observability of the UtilityLake Sentinel platform\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(health_router)\napp.include_router(metrics_router, prefix=\"/api/v1\")\napp.include_router(alerts_router, prefix=\"/api/v1\")\napp.include_router(quarantine_router, prefix=\"/api/v1\")\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint.\"\"\"\n    return {\n        \"service\": \"UtilityLake Sentinel Observability API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\"\n    }\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8002)\n",
            "UtilityLake_Sentinel/services/data_catalog_api/main.py": "\"\"\"Main entry point for the Data Catalog API service.\"\"\"\n\nimport logging\nfrom contextlib import asynccontextmanager\nfrom typing import List, Optional\nfrom datetime import datetime\n\nfrom fastapi import FastAPI, HTTPException, Depends, Query, status\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker, Session\n\nfrom .models import (\n    Base,\n    DatasetCreate, DatasetUpdate, DatasetResponse, DatasetStatus,\n    DataLineageCreate, DataLineageResponse,\n    QuarantinedRecordCreate, QuarantinedRecordUpdate, QuarantinedRecordResponse,\n    QuarantinedRecordListResponse, QuarantineStatus\n)\nfrom . import crud\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n# Database configuration\nDATABASE_URL = \"sqlite:///./data_catalog.db\"\nengine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False})\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n\ndef get_db():\n    \"\"\"Dependency to get database session.\"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan handler.\"\"\"\n    logger.info(\"Starting Data Catalog API service...\")\n    # Create tables\n    Base.metadata.create_all(bind=engine)\n    logger.info(\"Database tables created/verified\")\n    yield\n    logger.info(\"Shutting down Data Catalog API service...\")\n\n\napp = FastAPI(\n    title=\"UtilityLake Sentinel Data Catalog API\",\n    description=\"API for managing the data catalog of the UtilityLake Sentinel platform\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Root endpoint.\"\"\"\n    return {\n        \"service\": \"UtilityLake Sentinel Data Catalog API\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\"\n    }\n\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"timestamp\": datetime.utcnow().isoformat()}\n\n\n# Dataset endpoints\n\n@app.post(\"/api/v1/datasets\", response_model=DatasetResponse, status_code=status.HTTP_201_CREATED)\nasync def create_dataset(dataset: DatasetCreate, db: Session = Depends(get_db)):\n    \"\"\"Create a new dataset in the catalog.\"\"\"\n    existing = crud.get_dataset_by_name(db, dataset.name)\n    if existing:\n        raise HTTPException(\n            status_code=status.HTTP_409_CONFLICT,\n            detail=f\"Dataset with name '{dataset.name}' already exists\"\n        )\n    return crud.create_dataset(db, dataset)\n\n\n@app.get(\"/api/v1/datasets\", response_model=List[DatasetResponse])\nasync def list_datasets(\n    skip: int = Query(default=0, ge=0),\n    limit: int = Query(default=100, ge=1, le=500),\n    status: Optional[DatasetStatus] = None,\n    db: Session = Depends(get_db)\n):\n    \"\"\"List all datasets with optional filtering.\"\"\"\n    return crud.get_datasets(db, skip=skip, limit=limit, status=status)\n\n\n@app.get(\"/api/v1/datasets/{dataset_id}\", response_model=DatasetResponse)\nasync def get_dataset(dataset_id: int, db: Session = Depends(get_db)):\n    \"\"\"Get a specific dataset by ID.\"\"\"\n    dataset = crud.get_dataset(db, dataset_id)\n    if not dataset:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Dataset with ID {dataset_id} not found\"\n        )\n    return dataset\n\n\n@app.put(\"/api/v1/datasets/{dataset_id}\", response_model=DatasetResponse)\nasync def update_dataset(\n    dataset_id: int,\n    dataset_update: DatasetUpdate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update a dataset.\"\"\"\n    dataset = crud.update_dataset(db, dataset_id, dataset_update)\n    if not dataset:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Dataset with ID {dataset_id} not found\"\n        )\n    return dataset\n\n\n@app.delete(\"/api/v1/datasets/{dataset_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_dataset(dataset_id: int, db: Session = Depends(get_db)):\n    \"\"\"Delete a dataset.\"\"\"\n    if not crud.delete_dataset(db, dataset_id):\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Dataset with ID {dataset_id} not found\"\n        )\n\n\n# Lineage endpoints\n\n@app.post(\"/api/v1/lineage\", response_model=DataLineageResponse, status_code=status.HTTP_201_CREATED)\nasync def create_lineage(lineage: DataLineageCreate, db: Session = Depends(get_db)):\n    \"\"\"Create a new lineage record.\"\"\"\n    return crud.create_lineage(db, lineage)\n\n\n@app.get(\"/api/v1/lineage/{dataset_id}\", response_model=List[DataLineageResponse])\nasync def get_lineage(\n    dataset_id: int,\n    direction: str = Query(default=\"both\", regex=\"^(upstream|downstream|both)$\"),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get lineage for a dataset.\"\"\"\n    return crud.get_lineage_for_dataset(db, dataset_id, direction)\n\n\n# Quarantine endpoints\n\n@app.post(\"/api/v1/quarantine/records\", response_model=QuarantinedRecordResponse, status_code=status.HTTP_201_CREATED)\nasync def create_quarantined_record(\n    record: QuarantinedRecordCreate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Create a new quarantined record entry.\"\"\"\n    return crud.create_quarantined_record(db, record)\n\n\n@app.get(\"/api/v1/quarantine/records\", response_model=QuarantinedRecordListResponse)\nasync def list_quarantined_records(\n    status: Optional[QuarantineStatus] = None,\n    source_topic: Optional[str] = None,\n    start_date: Optional[datetime] = None,\n    end_date: Optional[datetime] = None,\n    page: int = Query(default=1, ge=1),\n    page_size: int = Query(default=50, ge=1, le=500),\n    db: Session = Depends(get_db)\n):\n    \"\"\"List quarantined records with optional filtering.\"\"\"\n    skip = (page - 1) * page_size\n    records, total = crud.get_quarantined_records(\n        db,\n        skip=skip,\n        limit=page_size,\n        status=status,\n        source_topic=source_topic,\n        start_date=start_date,\n        end_date=end_date\n    )\n    return QuarantinedRecordListResponse(\n        records=records,\n        total=total,\n        page=page,\n        page_size=page_size\n    )\n\n\n@app.get(\"/api/v1/quarantine/records/{record_id}\", response_model=QuarantinedRecordResponse)\nasync def get_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Get a specific quarantined record by ID.\"\"\"\n    record = crud.get_quarantined_record(db, record_id)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    return record\n\n\n@app.put(\"/api/v1/quarantine/records/{record_id}\", response_model=QuarantinedRecordResponse)\nasync def update_quarantined_record(\n    record_id: int,\n    record_update: QuarantinedRecordUpdate,\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update a quarantined record.\"\"\"\n    record = crud.update_quarantined_record(db, record_id, record_update)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    return record\n\n\n@app.post(\"/api/v1/quarantine/records/{record_id}/replay\", response_model=QuarantinedRecordResponse)\nasync def replay_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Initiate replay of a quarantined record.\"\"\"\n    record = crud.get_quarantined_record(db, record_id)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    \n    if record.status == QuarantineStatus.REPLAYED:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Record has already been successfully replayed\"\n        )\n    \n    updated_record = crud.update_quarantined_record_status(\n        db, record_id, QuarantineStatus.PENDING_REPLAY\n    )\n    return updated_record\n\n\n@app.post(\"/api/v1/quarantine/records/{record_id}/archive\", response_model=QuarantinedRecordResponse)\nasync def archive_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Archive a quarantined record.\"\"\"\n    record = crud.get_quarantined_record(db, record_id)\n    if not record:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n    \n    updated_record = crud.update_quarantined_record_status(\n        db, record_id, QuarantineStatus.ARCHIVED\n    )\n    return updated_record\n\n\n@app.get(\"/api/v1/quarantine/statistics\")\nasync def get_quarantine_statistics(db: Session = Depends(get_db)):\n    \"\"\"Get statistics about quarantined records.\"\"\"\n    return crud.get_quarantine_statistics(db)\n\n\n@app.delete(\"/api/v1/quarantine/records/{record_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_quarantined_record(record_id: int, db: Session = Depends(get_db)):\n    \"\"\"Delete a quarantined record.\"\"\"\n    if not crud.delete_quarantined_record(db, record_id):\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"Quarantined record with ID {record_id} not found\"\n        )\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\n",
            "UtilityLake_Sentinel/docs/api/openapi.yaml": "openapi: 3.0.3\ninfo:\n  title: UtilityLake Sentinel Platform API\n  description: |\n    Comprehensive API for the UtilityLake Sentinel data platform.\n    This specification covers all platform services including ingestion,\n    data catalog, and observability APIs.\n  version: 1.0.0\n  contact:\n    name: UtilityLake Platform Team\n    email: platform@utilitylake.io\n  license:\n    name: MIT\n    url: https://opensource.org/licenses/MIT\n\nservers:\n  - url: http://localhost:8000\n    description: Ingestion Gateway\n  - url: http://localhost:8001\n    description: Data Catalog API\n  - url: http://localhost:8002\n    description: Observability API\n\ntags:\n  - name: Health\n    description: Health check endpoints\n  - name: Ingestion\n    description: Data ingestion endpoints\n  - name: Datasets\n    description: Dataset catalog management\n  - name: Lineage\n    description: Data lineage tracking\n  - name: Quarantine\n    description: Quarantined records management\n  - name: Metrics\n    description: Platform metrics\n  - name: Alerts\n    description: Alert management\n\npaths:\n  /health:\n    get:\n      tags:\n        - Health\n      summary: Health check\n      description: Check the health status of the service\n      operationId: healthCheck\n      responses:\n        '200':\n          description: Service is healthy\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/HealthStatus'\n\n  /api/v1/ingest:\n    post:\n      tags:\n        - Ingestion\n      summary: Ingest data\n      description: Submit data for ingestion into the platform\n      operationId: ingestData\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/IngestRequest'\n      responses:\n        '202':\n          description: Data accepted for processing\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/IngestResponse'\n        '400':\n          description: Invalid request\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/datasets:\n    get:\n      tags:\n        - Datasets\n      summary: List datasets\n      description: Retrieve a list of all datasets in the catalog\n      operationId: listDatasets\n      parameters:\n        - name: skip\n          in: query\n          schema:\n            type: integer\n            default: 0\n        - name: limit\n          in: query\n          schema:\n            type: integer\n            default: 100\n        - name: status\n          in: query\n          schema:\n            type: string\n            enum: [active, deprecated, archived]\n      responses:\n        '200':\n          description: List of datasets\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  $ref: '#/components/schemas/Dataset'\n    post:\n      tags:\n        - Datasets\n      summary: Create dataset\n      description: Create a new dataset in the catalog\n      operationId: createDataset\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/DatasetCreate'\n      responses:\n        '201':\n          description: Dataset created\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Dataset'\n        '409':\n          description: Dataset already exists\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/datasets/{dataset_id}:\n    get:\n      tags:\n        - Datasets\n      summary: Get dataset\n      description: Retrieve a specific dataset by ID\n      operationId: getDataset\n      parameters:\n        - name: dataset_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Dataset details\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Dataset'\n        '404':\n          description: Dataset not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/records:\n    get:\n      tags:\n        - Quarantine\n      summary: List quarantined records\n      description: |\n        Retrieve quarantined records with optional filtering.\n        Supports filtering by status, source topic, and date range.\n      operationId: listQuarantinedRecords\n      parameters:\n        - name: status\n          in: query\n          description: Filter by quarantine status\n          schema:\n            type: string\n            enum: [quarantined, pending_replay, replayed, archived]\n        - name: source_topic\n          in: query\n          description: Filter by source Kafka topic\n          schema:\n            type: string\n        - name: start_date\n          in: query\n          description: Filter records quarantined after this date\n          schema:\n            type: string\n            format: date-time\n        - name: end_date\n          in: query\n          description: Filter records quarantined before this date\n          schema:\n            type: string\n            format: date-time\n        - name: page\n          in: query\n          description: Page number (1-indexed)\n          schema:\n            type: integer\n            default: 1\n            minimum: 1\n        - name: page_size\n          in: query\n          description: Number of records per page\n          schema:\n            type: integer\n            default: 50\n            minimum: 1\n            maximum: 500\n      responses:\n        '200':\n          description: List of quarantined records\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecordList'\n    post:\n      tags:\n        - Quarantine\n      summary: Create quarantined record\n      description: |\n        Create a new quarantined record entry.\n        Typically called by the stream processor when a record fails validation.\n      operationId: createQuarantinedRecord\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/QuarantinedRecordCreate'\n      responses:\n        '201':\n          description: Quarantined record created\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n\n  /api/v1/quarantine/records/{record_id}:\n    get:\n      tags:\n        - Quarantine\n      summary: Get quarantined record\n      description: Retrieve a specific quarantined record by ID\n      operationId: getQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Quarantined record details\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n    put:\n      tags:\n        - Quarantine\n      summary: Update quarantined record\n      description: Update a quarantined record's metadata\n      operationId: updateQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/QuarantinedRecordUpdate'\n      responses:\n        '200':\n          description: Record updated\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n    delete:\n      tags:\n        - Quarantine\n      summary: Delete quarantined record\n      description: Permanently delete a quarantined record\n      operationId: deleteQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '204':\n          description: Record deleted\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/records/{record_id}/replay:\n    post:\n      tags:\n        - Quarantine\n      summary: Replay quarantined record\n      description: |\n        Initiate replay of a quarantined record.\n        Updates the record's status to 'pending_replay'.\n        The actual replay is handled by a background process.\n      operationId: replayQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Replay initiated\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ReplayResponse'\n        '400':\n          description: Record cannot be replayed\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/records/{record_id}/archive:\n    post:\n      tags:\n        - Quarantine\n      summary: Archive quarantined record\n      description: Archive a quarantined record (no longer eligible for replay)\n      operationId: archiveQuarantinedRecord\n      parameters:\n        - name: record_id\n          in: path\n          required: true\n          schema:\n            type: integer\n      responses:\n        '200':\n          description: Record archived\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantinedRecord'\n        '404':\n          description: Record not found\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n\n  /api/v1/quarantine/statistics:\n    get:\n      tags:\n        - Quarantine\n      summary: Get quarantine statistics\n      description: Get aggregated statistics about quarantined records\n      operationId: getQuarantineStatistics\n      responses:\n        '200':\n          description: Quarantine statistics\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/QuarantineStatistics'\n\n  /api/v1/metrics/summary:\n    get:\n      tags:\n        - Metrics\n      summary: Get metrics summary\n      description: Get a summary of platform metrics\n      operationId: getMetricsSummary\n      responses:\n        '200':\n          description: Metrics summary\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/MetricsSummary'\n\n  /api/v1/alerts:\n    get:\n      tags:\n        - Alerts\n      summary: List alerts\n      description: Get active alerts\n      operationId: listAlerts\n      parameters:\n        - name: status\n          in: query\n          schema:\n            type: string\n        - name: severity\n          in: query\n          schema:\n            type: string\n      responses:\n        '200':\n          description: List of alerts\n          content:\n            application/json:\n              schema:\n                type: array\n                items:\n                  $ref: '#/components/schemas/Alert'\n\ncomponents:\n  schemas:\n    HealthStatus:\n      type: object\n      properties:\n        status:\n          type: string\n          example: healthy\n        timestamp:\n          type: string\n          format: date-time\n        version:\n          type: string\n          example: \"1.0.0\"\n        services:\n          type: object\n          additionalProperties:\n            type: string\n\n    ErrorResponse:\n      type: object\n      properties:\n        detail:\n          type: string\n          example: Resource not found\n\n    IngestRequest:\n      type: object\n      required:\n        - source\n        - data\n      properties:\n        source:\n          type: string\n          example: sensor-network-1\n        data:\n          type: object\n        metadata:\n          type: object\n\n    IngestResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          example: accepted\n        request_id:\n          type: string\n          format: uuid\n        timestamp:\n          type: string\n          format: date-time\n\n    DatasetCreate:\n      type: object\n      required:\n        - name\n        - storage_location\n      properties:\n        name:\n          type: string\n        description:\n          type: string\n        schema_definition:\n          type: object\n        storage_location:\n          type: string\n        format:\n          type: string\n          default: parquet\n        owner:\n          type: string\n        tags:\n          type: array\n          items:\n            type: string\n        metadata:\n          type: object\n\n    Dataset:\n      allOf:\n        - $ref: '#/components/schemas/DatasetCreate'\n        - type: object\n          properties:\n            id:\n              type: integer\n            status:\n              type: string\n              enum: [active, deprecated, archived]\n            created_at:\n              type: string\n              format: date-time\n            updated_at:\n              type: string\n              format: date-time\n\n    QuarantinedRecordCreate:\n      type: object\n      required:\n        - source_topic\n        - payload\n        - failure_reason\n      properties:\n        source_topic:\n          type: string\n          description: The Kafka topic the record originated from\n          example: utility-meter-readings\n        payload:\n          type: object\n          description: The full data of the failed record\n        failure_reason:\n          type: string\n          description: Description of why the record failed validation\n          example: \"Missing required field: meter_id\"\n        storage_path:\n          type: string\n          description: Path where the record is stored in quarantine\n          example: s3a://utilitylake-quarantine/utility-meter-readings/2024/01/15/abc123.json\n        original_timestamp:\n          type: string\n          format: date-time\n          description: Original timestamp from the source record\n        metadata:\n          type: object\n          description: Additional metadata about the failure\n\n    QuarantinedRecordUpdate:\n      type: object\n      properties:\n        status:\n          type: string\n          enum: [quarantined, pending_replay, replayed, archived]\n        metadata:\n          type: object\n\n    QuarantinedRecord:\n      allOf:\n        - $ref: '#/components/schemas/QuarantinedRecordCreate'\n        - type: object\n          properties:\n            id:\n              type: integer\n            status:\n              type: string\n              enum: [quarantined, pending_replay, replayed, archived]\n            quarantined_at:\n              type: string\n              format: date-time\n            replay_attempts:\n              type: integer\n              default: 0\n            last_replay_at:\n              type: string\n              format: date-time\n              nullable: true\n\n    QuarantinedRecordList:\n      type: object\n      properties:\n        records:\n          type: array\n          items:\n            $ref: '#/components/schemas/QuarantinedRecord'\n        total:\n          type: integer\n          description: Total number of records matching the filter\n        page:\n          type: integer\n          description: Current page number\n        page_size:\n          type: integer\n          description: Number of records per page\n\n    ReplayResponse:\n      type: object\n      properties:\n        id:\n          type: integer\n        status:\n          type: string\n          example: pending_replay\n        message:\n          type: string\n          example: Record queued for replay\n        replay_attempts:\n          type: integer\n\n    QuarantineStatistics:\n      type: object\n      properties:\n        total:\n          type: integer\n          description: Total number of quarantined records\n        by_status:\n          type: object\n          additionalProperties:\n            type: integer\n          description: Count of records by status\n        by_topic:\n          type: object\n          additionalProperties:\n            type: integer\n          description: Count of records by source topic\n\n    MetricsSummary:\n      type: object\n      properties:\n        ingestion_rate:\n          type: number\n        processing_latency_ms:\n          type: number\n        error_rate:\n          type: number\n        active_streams:\n          type: integer\n        timestamp:\n          type: string\n          format: date-time\n\n    Alert:\n      type: object\n      properties:\n        id:\n          type: string\n        name:\n          type: string\n        severity:\n          type: string\n          enum: [info, warning, critical]\n        status:\n          type: string\n          enum: [active, acknowledged, resolved]\n        message:\n          type: string\n        triggered_at:\n          type: string\n          format: date-time\n        resolved_at:\n          type: string\n          format: date-time\n          nullable: true\n        labels:\n          type: object\n          additionalProperties:\n            type: string\n",
            "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py": "\"\"\"Tests for the data quarantine flow in stream processing.\"\"\"\n\nimport json\nimport pytest\nfrom datetime import datetime\nfrom unittest.mock import Mock, MagicMock, patch, call\nfrom typing import Dict, Any\n\nimport sys\nimport os\n\n# Add parent paths to allow imports\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..', 'core_lib'))\n\nfrom services.stream_processor.transforms.quality_checks import (\n    QualityChecker,\n    QualityCheckResult,\n    QuarantineManager,\n    QuarantineResult,\n    DataCatalogClient,\n    check_not_null,\n    check_field_type,\n    check_value_range,\n    check_schema_conformance,\n    create_quality_checker\n)\n\n\nclass TestQualityCheckResult:\n    \"\"\"Tests for QualityCheckResult dataclass.\"\"\"\n    \n    def test_passed_result(self):\n        \"\"\"Test creating a passed result.\"\"\"\n        result = QualityCheckResult(\n            passed=True,\n            check_name=\"test_check\",\n            message=\"All good\"\n        )\n        assert result.passed is True\n        assert result.check_name == \"test_check\"\n        assert result.message == \"All good\"\n        assert result.details is None\n    \n    def test_failed_result_with_details(self):\n        \"\"\"Test creating a failed result with details.\"\"\"\n        result = QualityCheckResult(\n            passed=False,\n            check_name=\"validation_check\",\n            message=\"Validation failed\",\n            details={\"field\": \"meter_id\", \"error\": \"missing\"}\n        )\n        assert result.passed is False\n        assert result.details == {\"field\": \"meter_id\", \"error\": \"missing\"}\n\n\nclass TestBuiltInChecks:\n    \"\"\"Tests for built-in quality check functions.\"\"\"\n    \n    def test_check_not_null_passes(self):\n        \"\"\"Test not_null check passes when fields are present.\"\"\"\n        check = check_not_null([\"id\", \"name\"])\n        record = {\"id\": 1, \"name\": \"test\", \"value\": 100}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_not_null_fails_missing_field(self):\n        \"\"\"Test not_null check fails when field is missing.\"\"\"\n        check = check_not_null([\"id\", \"name\", \"required_field\"])\n        record = {\"id\": 1, \"name\": \"test\"}\n        result = check(record)\n        assert result.passed is False\n        assert \"required_field\" in result.message\n    \n    def test_check_not_null_fails_null_value(self):\n        \"\"\"Test not_null check fails when field is null.\"\"\"\n        check = check_not_null([\"id\", \"name\"])\n        record = {\"id\": 1, \"name\": None}\n        result = check(record)\n        assert result.passed is False\n    \n    def test_check_field_type_passes(self):\n        \"\"\"Test field_type check passes with correct types.\"\"\"\n        check = check_field_type({\"id\": int, \"name\": str, \"value\": float})\n        record = {\"id\": 1, \"name\": \"test\", \"value\": 3.14}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_field_type_fails(self):\n        \"\"\"Test field_type check fails with incorrect types.\"\"\"\n        check = check_field_type({\"id\": int, \"name\": str})\n        record = {\"id\": \"not_an_int\", \"name\": \"test\"}\n        result = check(record)\n        assert result.passed is False\n        assert \"type_errors\" in result.details\n    \n    def test_check_value_range_passes(self):\n        \"\"\"Test value_range check passes within range.\"\"\"\n        check = check_value_range(\"temperature\", min_value=0, max_value=100)\n        record = {\"temperature\": 50}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_value_range_fails_below_min(self):\n        \"\"\"Test value_range check fails below minimum.\"\"\"\n        check = check_value_range(\"temperature\", min_value=0, max_value=100)\n        record = {\"temperature\": -10}\n        result = check(record)\n        assert result.passed is False\n        assert \"below minimum\" in result.message\n    \n    def test_check_value_range_fails_above_max(self):\n        \"\"\"Test value_range check fails above maximum.\"\"\"\n        check = check_value_range(\"temperature\", min_value=0, max_value=100)\n        record = {\"temperature\": 150}\n        result = check(record)\n        assert result.passed is False\n        assert \"above maximum\" in result.message\n    \n    def test_check_schema_conformance_passes(self):\n        \"\"\"Test schema_conformance check passes with valid schema.\"\"\"\n        check = check_schema_conformance(\n            required_fields=[\"id\", \"name\"],\n            optional_fields=[\"description\"]\n        )\n        record = {\"id\": 1, \"name\": \"test\", \"description\": \"optional\"}\n        result = check(record)\n        assert result.passed is True\n    \n    def test_check_schema_conformance_fails_missing_required(self):\n        \"\"\"Test schema_conformance check fails with missing required field.\"\"\"\n        check = check_schema_conformance(\n            required_fields=[\"id\", \"name\"],\n            optional_fields=[\"description\"]\n        )\n        record = {\"id\": 1}\n        result = check(record)\n        assert result.passed is False\n        assert \"name\" in result.details[\"missing_required\"]\n\n\nclass TestQuarantineManager:\n    \"\"\"Tests for QuarantineManager class.\"\"\"\n    \n    @pytest.fixture\n    def mock_storage_client(self):\n        \"\"\"Create a mock storage client.\"\"\"\n        client = Mock()\n        client.write = Mock(return_value=None)\n        return client\n    \n    @pytest.fixture\n    def mock_catalog_client(self):\n        \"\"\"Create a mock data catalog client.\"\"\"\n        client = Mock(spec=DataCatalogClient)\n        client.create_quarantined_record = Mock(return_value=123)\n        return client\n    \n    @pytest.fixture\n    def quarantine_manager(self, mock_storage_client, mock_catalog_client):\n        \"\"\"Create a QuarantineManager with mocked dependencies.\"\"\"\n        return QuarantineManager(\n            storage_client=mock_storage_client,\n            catalog_client=mock_catalog_client,\n            quarantine_path=\"s3a://test-quarantine/\"\n        )\n    \n    def test_quarantine_record_success(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test successful quarantining of a record.\"\"\"\n        record = {\"meter_id\": \"M001\", \"reading\": \"invalid\"}\n        source_topic = \"utility-meter-readings\"\n        failure_reason = \"Invalid reading format\"\n        \n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=source_topic,\n            failure_reason=failure_reason\n        )\n        \n        # Verify result\n        assert result.success is True\n        assert result.storage_path is not None\n        assert \"test-quarantine\" in result.storage_path\n        assert source_topic in result.storage_path\n        assert result.catalog_id == 123\n        \n        # Verify storage client was called\n        mock_storage_client.write.assert_called_once()\n        call_args = mock_storage_client.write.call_args\n        assert \"path\" in call_args.kwargs or len(call_args.args) > 0\n        \n        # Verify the data written contains the record\n        written_data = call_args.kwargs.get(\"data\") or call_args.args[1]\n        parsed_data = json.loads(written_data)\n        assert parsed_data[\"record\"] == record\n        assert parsed_data[\"quarantine_metadata\"][\"failure_reason\"] == failure_reason\n        \n        # Verify catalog client was called\n        mock_catalog_client.create_quarantined_record.assert_called_once_with(\n            source_topic=source_topic,\n            payload=record,\n            failure_reason=failure_reason,\n            storage_path=result.storage_path,\n            original_timestamp=None,\n            metadata=None\n        )\n    \n    def test_quarantine_record_with_metadata(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test quarantining a record with additional metadata.\"\"\"\n        record = {\"sensor_id\": \"S001\", \"value\": -999}\n        source_topic = \"sensor-data\"\n        failure_reason = \"Value out of range\"\n        original_timestamp = datetime(2024, 1, 15, 10, 30, 0)\n        metadata = {\"pipeline_stage\": \"validation\", \"attempt\": 1}\n        \n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=source_topic,\n            failure_reason=failure_reason,\n            original_timestamp=original_timestamp,\n            metadata=metadata\n        )\n        \n        assert result.success is True\n        \n        # Verify catalog client received metadata\n        mock_catalog_client.create_quarantined_record.assert_called_once()\n        call_kwargs = mock_catalog_client.create_quarantined_record.call_args.kwargs\n        assert call_kwargs[\"original_timestamp\"] == original_timestamp\n        assert call_kwargs[\"metadata\"] == metadata\n    \n    def test_quarantine_record_storage_failure(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test quarantine fails gracefully when storage write fails.\"\"\"\n        mock_storage_client.write.side_effect = Exception(\"Storage unavailable\")\n        \n        record = {\"id\": 1}\n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=\"test-topic\",\n            failure_reason=\"Test failure\"\n        )\n        \n        assert result.success is False\n        assert \"Storage unavailable\" in result.error\n        \n        # Catalog should not be called if storage fails\n        mock_catalog_client.create_quarantined_record.assert_not_called()\n    \n    def test_quarantine_record_catalog_failure_still_succeeds(self, quarantine_manager, mock_storage_client, mock_catalog_client):\n        \"\"\"Test quarantine succeeds even if catalog logging fails.\"\"\"\n        mock_catalog_client.create_quarantined_record.side_effect = Exception(\"Catalog unavailable\")\n        \n        record = {\"id\": 1}\n        result = quarantine_manager.quarantine_record(\n            record=record,\n            source_topic=\"test-topic\",\n            failure_reason=\"Test failure\"\n        )\n        \n        # Should still succeed - storage write worked\n        assert result.success is True\n        assert result.storage_path is not None\n        assert result.catalog_id is None  # Catalog failed\n\n\nclass TestQualityChecker:\n    \"\"\"Tests for QualityChecker class.\"\"\"\n    \n    @pytest.fixture\n    def mock_quarantine_manager(self):\n        \"\"\"Create a mock quarantine manager.\"\"\"\n        manager = Mock(spec=QuarantineManager)\n        manager.quarantine_record = Mock(return_value=QuarantineResult(\n            success=True,\n            storage_path=\"s3a://quarantine/test/record.json\",\n            catalog_id=456\n        ))\n        return manager\n    \n    @pytest.fixture\n    def quality_checker(self, mock_quarantine_manager):\n        \"\"\"Create a QualityChecker with mocked quarantine manager.\"\"\"\n        checker = QualityChecker(\n            quarantine_manager=mock_quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"id\", \"value\"]))\n        checker.add_check(check_field_type({\"id\": int, \"value\": (int, float)}))\n        return checker\n    \n    def test_process_valid_record(self, quality_checker, mock_quarantine_manager):\n        \"\"\"Test processing a valid record passes all checks.\"\"\"\n        record = {\"id\": 1, \"value\": 100.5}\n        passed, quarantine_result = quality_checker.process_record(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert passed is True\n        assert quarantine_result is None\n        mock_quarantine_manager.quarantine_record.assert_not_called()\n    \n    def test_process_invalid_record_quarantined(self, quality_checker, mock_quarantine_manager):\n        \"\"\"Test processing an invalid record triggers quarantine.\"\"\"\n        # Missing 'value' field\n        record = {\"id\": 1}\n        passed, quarantine_result = quality_checker.process_record(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert passed is False\n        assert quarantine_result is not None\n        assert quarantine_result.success is True\n        \n        # Verify quarantine was called\n        mock_quarantine_manager.quarantine_record.assert_called_once()\n        call_kwargs = mock_quarantine_manager.quarantine_record.call_args.kwargs\n        assert call_kwargs[\"record\"] == record\n        assert call_kwargs[\"source_topic\"] == \"test-topic\"\n        assert \"value\" in call_kwargs[\"failure_reason\"]  # Should mention missing field\n    \n    def test_process_record_with_type_error_quarantined(self, quality_checker, mock_quarantine_manager):\n        \"\"\"Test record with wrong type is quarantined.\"\"\"\n        record = {\"id\": \"not_an_int\", \"value\": 100}\n        passed, quarantine_result = quality_checker.process_record(\n            record=record,\n            source_topic=\"sensor-data\"\n        )\n        \n        assert passed is False\n        mock_quarantine_manager.quarantine_record.assert_called_once()\n    \n    def test_process_record_quarantine_disabled(self, mock_quarantine_manager):\n        \"\"\"Test quarantine is not triggered when disabled.\"\"\"\n        checker = QualityChecker(\n            quarantine_manager=mock_quarantine_manager,\n            enable_quarantine=False\n        )\n        checker.add_check(check_not_null([\"id\"]))\n        \n        record = {}  # Missing required field\n        passed, quarantine_result = checker.process_record(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert passed is False\n        assert quarantine_result is None\n        mock_quarantine_manager.quarantine_record.assert_not_called()\n    \n    def test_run_checks_returns_all_results(self, quality_checker):\n        \"\"\"Test run_checks returns results for all checks.\"\"\"\n        record = {\"id\": 1, \"value\": 100}\n        all_passed, results = quality_checker.run_checks(\n            record=record,\n            source_topic=\"test-topic\"\n        )\n        \n        assert all_passed is True\n        assert len(results) == 2  # Two checks added\n        assert all(r.passed for r in results)\n\n\nclass TestIntegrationQuarantineFlow:\n    \"\"\"Integration tests for the complete quarantine flow.\"\"\"\n    \n    def test_malformed_record_through_pipeline(self):\n        \"\"\"Test that a malformed record is properly quarantined.\n        \n        This test verifies:\n        1. StorageClient.write is called with correct quarantine path and data\n        2. DataCatalogClient.create_quarantined_record is called with correct metadata\n        \"\"\"\n        # Create mocks\n        mock_storage = Mock()\n        mock_storage.write = Mock(return_value=None)\n        \n        mock_catalog = Mock(spec=DataCatalogClient)\n        mock_catalog.create_quarantined_record = Mock(return_value=789)\n        \n        # Create quarantine manager with mocks\n        quarantine_manager = QuarantineManager(\n            storage_client=mock_storage,\n            catalog_client=mock_catalog,\n            quarantine_path=\"s3a://utilitylake-quarantine/\"\n        )\n        \n        # Create quality checker\n        checker = QualityChecker(\n            quarantine_manager=quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"meter_id\", \"reading\", \"timestamp\"]))\n        checker.add_check(check_field_type({\"reading\": (int, float)}))\n        checker.add_check(check_value_range(\"reading\", min_value=0, max_value=10000))\n        \n        # Create a malformed record (missing meter_id, invalid reading type)\n        malformed_record = {\n            \"reading\": \"not_a_number\",\n            \"timestamp\": \"2024-01-15T10:30:00Z\"\n        }\n        source_topic = \"utility-meter-readings\"\n        \n        # Process the malformed record\n        passed, quarantine_result = checker.process_record(\n            record=malformed_record,\n            source_topic=source_topic,\n            original_timestamp=datetime(2024, 1, 15, 10, 30, 0)\n        )\n        \n        # Assertions\n        assert passed is False, \"Malformed record should fail quality checks\"\n        assert quarantine_result is not None, \"Quarantine result should be returned\"\n        assert quarantine_result.success is True, \"Quarantine should succeed\"\n        \n        # Verify StorageClient.write was called correctly\n        mock_storage.write.assert_called_once()\n        storage_call = mock_storage.write.call_args\n        \n        # Check path contains quarantine base path and topic\n        storage_path = storage_call.kwargs.get(\"path\") or storage_call.args[0]\n        assert \"utilitylake-quarantine\" in storage_path, \n            f\"Storage path should contain quarantine path: {storage_path}\"\n        assert source_topic in storage_path, \n            f\"Storage path should contain source topic: {storage_path}\"\n        \n        # Check data contains the original record\n        storage_data = storage_call.kwargs.get(\"data\") or storage_call.args[1]\n        parsed_data = json.loads(storage_data)\n        assert parsed_data[\"record\"] == malformed_record, \n            \"Stored data should contain original record\"\n        assert parsed_data[\"quarantine_metadata\"][\"source_topic\"] == source_topic, \n            \"Stored metadata should contain source topic\"\n        assert \"meter_id\" in parsed_data[\"quarantine_metadata\"][\"failure_reason\"], \n            \"Failure reason should mention missing meter_id\"\n        \n        # Verify DataCatalogClient.create_quarantined_record was called correctly\n        mock_catalog.create_quarantined_record.assert_called_once()\n        catalog_call = mock_catalog.create_quarantined_record.call_args\n        catalog_kwargs = catalog_call.kwargs\n        \n        assert catalog_kwargs[\"source_topic\"] == source_topic, \n            \"Catalog should receive correct source topic\"\n        assert catalog_kwargs[\"payload\"] == malformed_record, \n            \"Catalog should receive original payload\"\n        assert \"meter_id\" in catalog_kwargs[\"failure_reason\"], \n            \"Catalog failure reason should mention missing field\"\n        assert catalog_kwargs[\"storage_path\"] == quarantine_result.storage_path, \n            \"Catalog should receive storage path\"\n    \n    def test_valid_record_not_quarantined(self):\n        \"\"\"Test that a valid record is not quarantined.\"\"\"\n        mock_storage = Mock()\n        mock_catalog = Mock(spec=DataCatalogClient)\n        \n        quarantine_manager = QuarantineManager(\n            storage_client=mock_storage,\n            catalog_client=mock_catalog,\n            quarantine_path=\"s3a://utilitylake-quarantine/\"\n        )\n        \n        checker = QualityChecker(\n            quarantine_manager=quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"meter_id\", \"reading\"]))\n        checker.add_check(check_field_type({\"reading\": (int, float)}))\n        \n        # Valid record\n        valid_record = {\n            \"meter_id\": \"M001\",\n            \"reading\": 1234.5,\n            \"timestamp\": \"2024-01-15T10:30:00Z\"\n        }\n        \n        passed, quarantine_result = checker.process_record(\n            record=valid_record,\n            source_topic=\"utility-meter-readings\"\n        )\n        \n        assert passed is True\n        assert quarantine_result is None\n        mock_storage.write.assert_not_called()\n        mock_catalog.create_quarantined_record.assert_not_called()\n    \n    def test_multiple_validation_failures_captured(self):\n        \"\"\"Test that multiple validation failures are all captured in failure reason.\"\"\"\n        mock_storage = Mock()\n        mock_storage.write = Mock(return_value=None)\n        \n        mock_catalog = Mock(spec=DataCatalogClient)\n        mock_catalog.create_quarantined_record = Mock(return_value=100)\n        \n        quarantine_manager = QuarantineManager(\n            storage_client=mock_storage,\n            catalog_client=mock_catalog,\n            quarantine_path=\"s3a://quarantine/\"\n        )\n        \n        checker = QualityChecker(\n            quarantine_manager=quarantine_manager,\n            enable_quarantine=True\n        )\n        checker.add_check(check_not_null([\"field_a\", \"field_b\"]))\n        checker.add_check(check_field_type({\"field_c\": int}))\n        \n        # Record with multiple issues\n        bad_record = {\n            \"field_c\": \"not_an_int\"  # Missing field_a, field_b, and wrong type for field_c\n        }\n        \n        passed, result = checker.process_record(\n            record=bad_record,\n            source_topic=\"test\"\n        )\n        \n        assert passed is False\n        \n        # Check that failure reason contains all issues\n        catalog_call = mock_catalog.create_quarantined_record.call_args\n        failure_reason = catalog_call.kwargs[\"failure_reason\"]\n        \n        assert \"field_a\" in failure_reason or \"field_b\" in failure_reason, \n            \"Failure reason should mention missing fields\"\n\n\nclass TestCreateQualityChecker:\n    \"\"\"Tests for the create_quality_checker factory function.\"\"\"\n    \n    def test_create_with_required_fields(self):\n        \"\"\"Test creating checker with required fields.\"\"\"\n        checker = create_quality_checker(\n            required_fields=[\"id\", \"name\"],\n            enable_quarantine=False\n        )\n        \n        # Valid record\n        passed, _ = checker.run_checks({\"id\": 1, \"name\": \"test\"})\n        assert passed is True\n        \n        # Invalid record\n        passed, _ = checker.run_checks({\"id\": 1})\n        assert passed is False\n    \n    def test_create_with_field_types(self):\n        \"\"\"Test creating checker with field types.\"\"\"\n        checker = create_quality_checker(\n            field_types={\"count\": int, \"name\": str},\n            enable_quarantine=False\n        )\n        \n        # Valid record\n        passed, _ = checker.run_checks({\"count\": 10, \"name\": \"test\"})\n        assert passed is True\n        \n        # Invalid record\n        passed, _ = checker.run_checks({\"count\": \"ten\", \"name\": \"test\"})\n        assert passed is False\n\n\nif __name__ == \"__main__\":\n    pytest.main([__file__, \"-v\"])\n",
            "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py": "\"\"\"Storage client for UtilityLake Sentinel platform.\"\"\"\n\nimport os\nimport json\nimport logging\nfrom typing import Any, Optional, Union\nfrom pathlib import Path\nfrom abc import ABC, abstractmethod\n\nlogger = logging.getLogger(__name__)\n\n\nclass StorageBackend(ABC):\n    \"\"\"Abstract base class for storage backends.\"\"\"\n    \n    @abstractmethod\n    def read(self, path: str) -> str:\n        \"\"\"Read data from the given path.\"\"\"\n        pass\n    \n    @abstractmethod\n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to the given path.\"\"\"\n        pass\n    \n    @abstractmethod\n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists.\"\"\"\n        pass\n    \n    @abstractmethod\n    def delete(self, path: str) -> bool:\n        \"\"\"Delete data at the given path.\"\"\"\n        pass\n    \n    @abstractmethod\n    def list_files(self, path: str) -> list:\n        \"\"\"List files at the given path.\"\"\"\n        pass\n\n\nclass LocalStorageBackend(StorageBackend):\n    \"\"\"Local filesystem storage backend.\"\"\"\n    \n    def __init__(self, base_path: str = \"/tmp/utilitylake\"):\n        self.base_path = base_path\n        os.makedirs(base_path, exist_ok=True)\n    \n    def _resolve_path(self, path: str) -> str:\n        \"\"\"Resolve a path, handling file:// prefix.\"\"\"\n        if path.startswith(\"file://\"):\n            return path[7:]\n        return path\n    \n    def read(self, path: str) -> str:\n        \"\"\"Read data from a local file.\"\"\"\n        resolved_path = self._resolve_path(path)\n        with open(resolved_path, 'r') as f:\n            return f.read()\n    \n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to a local file.\"\"\"\n        resolved_path = self._resolve_path(path)\n        # Create parent directories if needed\n        parent_dir = os.path.dirname(resolved_path)\n        if parent_dir:\n            os.makedirs(parent_dir, exist_ok=True)\n        with open(resolved_path, 'w') as f:\n            f.write(data)\n        logger.debug(f\"Wrote {len(data)} bytes to {resolved_path}\")\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a local file exists.\"\"\"\n        resolved_path = self._resolve_path(path)\n        return os.path.exists(resolved_path)\n    \n    def delete(self, path: str) -> bool:\n        \"\"\"Delete a local file.\"\"\"\n        resolved_path = self._resolve_path(path)\n        if os.path.exists(resolved_path):\n            os.remove(resolved_path)\n            return True\n        return False\n    \n    def list_files(self, path: str) -> list:\n        \"\"\"List files in a local directory.\"\"\"\n        resolved_path = self._resolve_path(path)\n        if os.path.isdir(resolved_path):\n            return os.listdir(resolved_path)\n        return []\n\n\nclass S3StorageBackend(StorageBackend):\n    \"\"\"S3-compatible storage backend.\n    \n    Note: This is a placeholder implementation.\n    In production, this would use boto3 or similar.\n    \"\"\"\n    \n    def __init__(self, endpoint_url: Optional[str] = None):\n        self.endpoint_url = endpoint_url\n        self._storage: dict = {}  # In-memory mock for testing\n        logger.info(f\"S3 storage backend initialized (mock mode)\")\n    \n    def _normalize_path(self, path: str) -> str:\n        \"\"\"Normalize S3 path, removing s3:// or s3a:// prefix.\"\"\"\n        if path.startswith(\"s3a://\"):\n            return path[6:]\n        if path.startswith(\"s3://\"):\n            return path[5:]\n        return path\n    \n    def read(self, path: str) -> str:\n        \"\"\"Read data from S3.\"\"\"\n        normalized = self._normalize_path(path)\n        if normalized not in self._storage:\n            raise FileNotFoundError(f\"Object not found: {path}\")\n        return self._storage[normalized]\n    \n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to S3.\"\"\"\n        normalized = self._normalize_path(path)\n        self._storage[normalized] = data\n        logger.debug(f\"Wrote {len(data)} bytes to s3://{normalized}\")\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if an S3 object exists.\"\"\"\n        normalized = self._normalize_path(path)\n        return normalized in self._storage\n    \n    def delete(self, path: str) -> bool:\n        \"\"\"Delete an S3 object.\"\"\"\n        normalized = self._normalize_path(path)\n        if normalized in self._storage:\n            del self._storage[normalized]\n            return True\n        return False\n    \n    def list_files(self, path: str) -> list:\n        \"\"\"List objects with a given prefix.\"\"\"\n        normalized = self._normalize_path(path)\n        return [\n            key for key in self._storage.keys()\n            if key.startswith(normalized)\n        ]\n\n\nclass StorageClient:\n    \"\"\"Unified storage client for UtilityLake Sentinel.\n    \n    Automatically selects the appropriate backend based on the path prefix.\n    \"\"\"\n    \n    def __init__(\n        self,\n        default_backend: Optional[StorageBackend] = None,\n        s3_endpoint_url: Optional[str] = None\n    ):\n        self._local_backend = LocalStorageBackend()\n        self._s3_backend = S3StorageBackend(endpoint_url=s3_endpoint_url)\n        self._default_backend = default_backend or self._local_backend\n    \n    def _get_backend(self, path: str) -> StorageBackend:\n        \"\"\"Get the appropriate backend for a path.\"\"\"\n        if path.startswith(\"s3://\") or path.startswith(\"s3a://\"):\n            return self._s3_backend\n        if path.startswith(\"file://\"):\n            return self._local_backend\n        return self._default_backend\n    \n    def read(self, path: str) -> str:\n        \"\"\"Read data from storage.\"\"\"\n        backend = self._get_backend(path)\n        return backend.read(path)\n    \n    def write(self, path: str, data: str) -> None:\n        \"\"\"Write data to storage.\"\"\"\n        backend = self._get_backend(path)\n        backend.write(path, data)\n    \n    def read_json(self, path: str) -> Any:\n        \"\"\"Read and parse JSON data from storage.\"\"\"\n        data = self.read(path)\n        return json.loads(data)\n    \n    def write_json(self, path: str, data: Any, indent: int = 2) -> None:\n        \"\"\"Write data as JSON to storage.\"\"\"\n        json_str = json.dumps(data, indent=indent, default=str)\n        self.write(path, json_str)\n    \n    def exists(self, path: str) -> bool:\n        \"\"\"Check if a path exists in storage.\"\"\"\n        backend = self._get_backend(path)\n        return backend.exists(path)\n    \n    def delete(self, path: str) -> bool:\n        \"\"\"Delete data from storage.\"\"\"\n        backend = self._get_backend(path)\n        return backend.delete(path)\n    \n    def list_files(self, path: str) -> list:\n        \"\"\"List files at a path.\"\"\"\n        backend = self._get_backend(path)\n        return backend.list_files(path)\n"
          },
          "generated_files": [
            "UtilityLake_Sentinel/configs/default.yml",
            "UtilityLake_Sentinel/configs/development.yml",
            "UtilityLake_Sentinel/services/data_catalog_api/models.py",
            "UtilityLake_Sentinel/services/data_catalog_api/crud.py",
            "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py",
            "UtilityLake_Sentinel/services/observability_api/endpoints.py",
            "UtilityLake_Sentinel/services/observability_api/main.py",
            "UtilityLake_Sentinel/services/data_catalog_api/main.py",
            "UtilityLake_Sentinel/docs/api/openapi.yaml",
            "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py",
            "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py"
          ],
          "detailed_results": {
            "software_engineering_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "architectural_coherence_score",
                "dependency_traversal_accuracy",
                "cross_file_reasoning_depth",
                "system_thinking_score",
                "robustness_score",
                "comprehensiveness_score",
                "innovation_score",
                "solution_elegance_score"
              ],
              "individual_scores": {
                "architectural_coherence_score": 0.6957515751575158,
                "dependency_traversal_accuracy": 0.634509242742249,
                "cross_file_reasoning_depth": 0.3238636363636364,
                "system_thinking_score": 0.5381461160580213,
                "robustness_score": 0.40668077388149937,
                "comprehensiveness_score": 0.7046371485792019,
                "innovation_score": 0.37014056831922615,
                "solution_elegance_score": 0.45570356603338663
              },
              "weighted_breakdown": {
                "architectural_coherence_weighted": 0.08696894689468948,
                "dependency_traversal_weighted": 0.07931365534278112,
                "cross_file_reasoning_weighted": 0.04048295454545455,
                "system_thinking_weighted": 0.06726826450725266,
                "robustness_weighted": 0.05083509673518742,
                "comprehensiveness_weighted": 0.08807964357240024,
                "innovation_weighted": 0.04626757103990327,
                "solution_elegance_weighted": 0.05696294575417333
              },
              "total_software_engineering_score": 0.5161790783918421
            },
            "functional_correctness_details": {
              "compilation": {
                "success": false,
                "score": 0.0,
                "execution_time": 0.7128126621246338,
                "errors": [
                  "  File \"UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py\", line 423",
                  "    assert \"utilitylake-quarantine\" in storage_path, ",
                  "                                                     ^",
                  "SyntaxError: invalid syntax",
                  "  File \"UtilityLake_Sentinel/docs/api/openapi.py\", line 275",
                  "    description: Update a quarantined record's metadata",
                  "                                            ^",
                  "SyntaxError: unterminated string literal (detected at line 275)",
                  "  File \"UtilityLake_Sentinel/configs/development.py\", line 3",
                  "    application:",
                  "                ^",
                  "SyntaxError: invalid syntax",
                  "  File \"UtilityLake_Sentinel/configs/default.py\", line 3",
                  "    application:",
                  "                ^",
                  "SyntaxError: invalid syntax"
                ],
                "warnings": [],
                "binary_size": null,
                "files_tested": [
                  "UtilityLake_Sentinel/configs/default.yml",
                  "UtilityLake_Sentinel/configs/development.yml",
                  "UtilityLake_Sentinel/services/data_catalog_api/models.py",
                  "UtilityLake_Sentinel/services/data_catalog_api/crud.py",
                  "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py",
                  "UtilityLake_Sentinel/services/observability_api/endpoints.py",
                  "UtilityLake_Sentinel/services/observability_api/main.py",
                  "UtilityLake_Sentinel/services/data_catalog_api/main.py",
                  "UtilityLake_Sentinel/docs/api/openapi.yaml",
                  "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py",
                  "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py"
                ],
                "scoring_breakdown": {
                  "no_credit": 0.0
                }
              },
              "unit_tests": {
                "test_pass_rate": 0.5,
                "tests_run": 4,
                "tests_passed": 2,
                "tests_failed": 2,
                "test_results": [
                  {
                    "name": "function_signature_preservation",
                    "passed": true,
                    "description": "Public function signatures are preserved"
                  },
                  {
                    "name": "error_handling",
                    "passed": true,
                    "description": "Proper error handling for edge cases"
                  },
                  {
                    "name": "input_validation",
                    "passed": false,
                    "description": "Input validation works correctly"
                  },
                  {
                    "name": "output_correctness",
                    "passed": false,
                    "description": "Functions return expected outputs"
                  }
                ],
                "errors": [],
                "overall_success": false
              },
              "integration": {
                "files_analyzed": 11,
                "multi_file_solution": true,
                "integration_score": 0.7999999999999999,
                "integration_indicators": [
                  "Multi-file solution suggests integration capability",
                  "Found imports in 9 files"
                ],
                "tests_defined": 3
              },
              "incremental_development": {
                "idc_score": 0.31497951619196257,
                "description": "Ability to build incrementally on previous work"
              },
              "overall_breakdown": {
                "compilation_score": 0.0,
                "compilation_weight": 0.3,
                "unit_test_score": 0.5,
                "unit_test_weight": 0.3,
                "integration_score": 0.7999999999999999,
                "integration_weight": 0.2,
                "idc_score": 0.31497951619196257,
                "idc_weight": 0.2,
                "total_functional_score": 0.3729959032383925
              }
            },
            "code_quality_details": {
              "files_analyzed": 11,
              "quality_checks": {
                "UtilityLake_Sentinel/configs/default.yml": {
                  "line_count": 53,
                  "non_empty_lines": 44,
                  "comment_lines": 1,
                  "comment_ratio": 0.022727272727272728,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.7
                },
                "UtilityLake_Sentinel/configs/development.yml": {
                  "line_count": 57,
                  "non_empty_lines": 47,
                  "comment_lines": 1,
                  "comment_ratio": 0.02127659574468085,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 0,
                  "quality_score": 0.7
                },
                "UtilityLake_Sentinel/services/data_catalog_api/models.py": {
                  "line_count": 187,
                  "non_empty_lines": 140,
                  "comment_lines": 3,
                  "comment_ratio": 0.02142857142857143,
                  "function_count": 0,
                  "class_count": 21,
                  "import_count": 14,
                  "quality_score": 0.7
                },
                "UtilityLake_Sentinel/services/data_catalog_api/crud.py": {
                  "line_count": 263,
                  "non_empty_lines": 213,
                  "comment_lines": 6,
                  "comment_ratio": 0.028169014084507043,
                  "function_count": 15,
                  "class_count": 0,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "UtilityLake_Sentinel/services/stream_processor/transforms/quality_checks.py": {
                  "line_count": 485,
                  "non_empty_lines": 419,
                  "comment_lines": 10,
                  "comment_ratio": 0.02386634844868735,
                  "function_count": 20,
                  "class_count": 6,
                  "import_count": 16,
                  "quality_score": 0.7999999999999999
                },
                "UtilityLake_Sentinel/services/observability_api/endpoints.py": {
                  "line_count": 444,
                  "non_empty_lines": 352,
                  "comment_lines": 15,
                  "comment_ratio": 0.04261363636363636,
                  "function_count": 15,
                  "class_count": 10,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "UtilityLake_Sentinel/services/observability_api/main.py": {
                  "line_count": 68,
                  "non_empty_lines": 53,
                  "comment_lines": 3,
                  "comment_ratio": 0.05660377358490566,
                  "function_count": 2,
                  "class_count": 0,
                  "import_count": 10,
                  "quality_score": 0.7999999999999999
                },
                "UtilityLake_Sentinel/services/data_catalog_api/main.py": {
                  "line_count": 294,
                  "non_empty_lines": 239,
                  "comment_lines": 7,
                  "comment_ratio": 0.029288702928870293,
                  "function_count": 19,
                  "class_count": 0,
                  "import_count": 20,
                  "quality_score": 0.7999999999999999
                },
                "UtilityLake_Sentinel/docs/api/openapi.yaml": {
                  "line_count": 688,
                  "non_empty_lines": 660,
                  "comment_lines": 0,
                  "comment_ratio": 0.0,
                  "function_count": 0,
                  "class_count": 0,
                  "import_count": 1,
                  "quality_score": 0.5
                },
                "UtilityLake_Sentinel/services/stream_processor/tests/test_quarantine_flow.py": {
                  "line_count": 564,
                  "non_empty_lines": 465,
                  "comment_lines": 27,
                  "comment_ratio": 0.05806451612903226,
                  "function_count": 31,
                  "class_count": 10,
                  "import_count": 12,
                  "quality_score": 0.6
                },
                "UtilityLake_Sentinel/core_lib/utilitylake_core/storage.py": {
                  "line_count": 205,
                  "non_empty_lines": 164,
                  "comment_lines": 1,
                  "comment_ratio": 0.006097560975609756,
                  "function_count": 28,
                  "class_count": 5,
                  "import_count": 15,
                  "quality_score": 0.7999999999999999
                }
              },
              "security_analysis": {
                "security_score": 0.8,
                "vulnerabilities_found": [],
                "security_level": "medium"
              },
              "overall_quality_score": 0.7490909090909089,
              "issues_found": []
            },
            "longcontext_utilization_details": {
              "task_category": "feature_implementation",
              "metrics_applied": [
                "information_coverage_utilization",
                "multi_session_memory_retention"
              ],
              "individual_scores": {
                "information_coverage_utilization": 0.9372619047619049,
                "multi_session_memory_retention": 0.9192424242424242
              },
              "weighted_breakdown": {
                "information_coverage_utilization_weighted": 0.4686309523809524,
                "multi_session_memory_retention_weighted": 0.4596212121212121
              },
              "total_longcontext_utilization_score": 0.9282521645021645
            }
          },
          "timestamp": "2026-01-14T21:42:25.736667"
        }
      }
    }
  }
}