# üìä LoCoBench Overall Summary

**Evaluation Date:** 2026-01-09 16:12:56
**Framework Version:** LoCoBench v1.0
**Benchmark:** Feature Implementation (best run per provider/difficulty)

## üèÜ Provider Performance by Difficulty

‚≠ê indicates the best score across all providers for that difficulty.

### CLAUDE-DIRECT

<table>
<colgroup><col style="width: 10%"><col style="width: 30%"><col style="width: 10%"><col style="width: 12%"><col style="width: 12%"><col style="width: 10%"><col style="width: 12%"><col style="width: 7%"><col style="width: 17%"></colgroup>
<thead><tr><th>Difficulty</th><th>Model</th><th>Total Score</th><th>Software Engineering</th><th>Functional Correctness</th><th>Code Quality</th><th>Long-Context Util</th><th>Scenarios</th><th>Run</th></tr></thead>
<tbody>
<tr><td>easy</td><td>claude-sonnet-4-5-20250929</td><td>2.750 ‚≠ê</td><td>0.477 ‚≠ê</td><td>0.507 ‚≠ê</td><td>0.765 ‚≠ê</td><td>0.538 ‚≠ê</td><td>25</td><td>claudesonnet4520250929_1cats_easy_20260109_142748_evaluation_results</td></tr>
<tr><td>medium</td><td>claude-sonnet-4-5-20250929</td><td>2.604 ‚≠ê</td><td>0.457 ‚≠ê</td><td>0.465 ‚≠ê</td><td>0.736 ‚≠ê</td><td>0.513 ‚≠ê</td><td>44</td><td>claudesonnet4520250929_1cats_medium_20260109_144631_evaluation_results</td></tr>
<tr><td>hard</td><td>claude-sonnet-4-5-20250929</td><td>2.557 ‚≠ê</td><td>0.451 ‚≠ê</td><td>0.452 ‚≠ê</td><td>0.719 ‚≠ê</td><td>0.515 ‚≠ê</td><td>68</td><td>claudesonnet4520250929_1cats_hard_20260109_152750_evaluation_results</td></tr>
<tr><td>expert</td><td>claude-sonnet-4-5-20250929</td><td>2.449 ‚≠ê</td><td>0.434 ‚≠ê</td><td>0.427 ‚≠ê</td><td>0.701 ‚≠ê</td><td>0.478 ‚≠ê</td><td>99</td><td>claudesonnet4520250929_1cats_expert_20260109_155637_evaluation_results</td></tr>
</tbody></table>

### CLAUDE-PROXY

<table>
<colgroup><col style="width: 10%"><col style="width: 30%"><col style="width: 10%"><col style="width: 12%"><col style="width: 12%"><col style="width: 10%"><col style="width: 12%"><col style="width: 7%"><col style="width: 17%"></colgroup>
<thead><tr><th>Difficulty</th><th>Model</th><th>Total Score</th><th>Software Engineering</th><th>Functional Correctness</th><th>Code Quality</th><th>Long-Context Util</th><th>Scenarios</th><th>Run</th></tr></thead>
<tbody>
<tr><td>easy</td><td>claude-sonnet-4-5-20250929</td><td>2.699</td><td>0.470</td><td>0.502</td><td>0.740</td><td>0.533</td><td>25</td><td>claudesonnet4520250929_1cats_easy_20260108_175947_evaluation_results</td></tr>
<tr><td>medium</td><td>claude-sonnet-4-5-20250929</td><td>2.540</td><td>0.446</td><td>0.460</td><td>0.711</td><td>0.494</td><td>44</td><td>claudesonnet4520250929_1cats_medium_20260108_212633_evaluation_results</td></tr>
<tr><td>hard</td><td>claude-sonnet-4-5-20250929</td><td>2.488</td><td>0.442</td><td>0.437</td><td>0.702</td><td>0.493</td><td>68</td><td>claudesonnet4520250929_1cats_hard_20260108_214601_evaluation_results</td></tr>
<tr><td>expert</td><td>claude-sonnet-4-5-20250929</td><td>2.432</td><td>0.433</td><td>0.424</td><td>0.696</td><td>0.468</td><td>100</td><td>claudesonnet4520250929_1cats_expert_20260108_221907_evaluation_results</td></tr>
</tbody></table>

### QWEN-NOVITA

<table>
<colgroup><col style="width: 10%"><col style="width: 30%"><col style="width: 10%"><col style="width: 12%"><col style="width: 12%"><col style="width: 10%"><col style="width: 12%"><col style="width: 7%"><col style="width: 17%"></colgroup>
<thead><tr><th>Difficulty</th><th>Model</th><th>Total Score</th><th>Software Engineering</th><th>Functional Correctness</th><th>Code Quality</th><th>Long-Context Util</th><th>Scenarios</th><th>Run</th></tr></thead>
<tbody>
<tr><td>easy</td><td>qwen/qwen3-coder-30b-a3b-instruct</td><td>2.300</td><td>0.381</td><td>0.397</td><td>0.718</td><td>0.447</td><td>74</td><td>qwen3coder30ba3binstruct_1cats_easy_20260108_154904_evaluation_results</td></tr>
<tr><td>medium</td><td>qwen/qwen3-coder-30b-a3b-instruct</td><td>2.467</td><td>0.415</td><td>0.436</td><td>0.732</td><td>0.502</td><td>122</td><td>qwen3coder30ba3binstruct_1cats_medium_20260108_160955_evaluation_results</td></tr>
<tr><td>hard</td><td>qwen/qwen3-coder-30b-a3b-instruct</td><td>2.511</td><td>0.424</td><td>0.449</td><td>0.733</td><td>0.513</td><td>146</td><td>qwen3coder30ba3binstruct_1cats_hard_20260108_162651_evaluation_results</td></tr>
<tr><td>expert</td><td>qwen/qwen3-coder-30b-a3b-instruct</td><td>2.407</td><td>0.405</td><td>0.418</td><td>0.727</td><td>0.487</td><td>103</td><td>qwen3coder30ba3binstruct_1cats_expert_20260108_155940_evaluation_results</td></tr>
</tbody></table>

## üí° Summary & Insights

- **Category:** Feature Implementation
- **Selection Rule:** Best run per provider/difficulty by Total Score (from summary MD files)
- **Global Best per Difficulty:**
  - **easy**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.750
  - **medium**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.604
  - **hard**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.557
  - **expert**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.449

## üìñ Evaluation Framework

LoCoBench uses **17 metrics across 4 dimensions**:

- **üèóÔ∏è Software Engineering Excellence (8 metrics):** ACS, DTA, CFRD, STS, RS, CS, IS, SES
- **‚öôÔ∏è Functional Correctness (4 metrics):** Code Compilation, Unit Tests, Integration Tests, IDC
- **üîç Code Quality Assessment (3 metrics):** Security Analysis, Code Quality, Issue Detection
- **üß† Long-Context Utilization (2 metrics):** ICU, MMR

**Scoring:** LoCoBench Score (LCBS) = 40% SE + 30% FC + 20% CQ + 10% LCU

---

*Generated by LoCoBench v1.0 - Comprehensive long-context software development evaluation*
