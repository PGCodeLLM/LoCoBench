# üìä LoCoBench Overall Summary (All Difficulties)

**Evaluation Date:** 2026-01-21 09:29:09
**Framework Version:** LoCoBench v1.0
**Benchmark:** Feature Implementation (alldiff runs only)

## üèÜ Model Performance (All Difficulties)

‚≠ê indicates the best score across all providers (alldiff runs).

### CLAUDE-DIRECT

| Model | Total Score | Grade | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---:|---|---:|---:|---:|---:|---:|---|
| claude-opus-4-5-20251101 | 2.855 | C (Fair) | 0.513 | 0.453 | 0.770 | 0.762 | 100 | [claudeopus4520251101_1cats_alldiff_20260115_180811_evaluation_results](claude-direct/claudeopus4520251101_1cats_alldiff_20260115_180811_evaluation_results_summary.md) |

### CLAUDE-PROXY

| Model | Total Score | Grade | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---:|---|---:|---:|---:|---:|---:|---|
| claude-opus-4-5-20251101 | 2.942 ‚≠ê | C (Fair) | 0.516 | 0.501 | 0.772 | 0.770 | 100 | [claudeopus4520251101_1cats_alldiff_20260115_021130_evaluation_results](claude-proxy/claudeopus4520251101_1cats_alldiff_20260115_021130_evaluation_results_summary.md) |

### QWEN

| Model | Total Score | Grade | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---:|---|---:|---:|---:|---:|---:|---|
| qwen3_coder_30b | 2.775 | C (Fair) | 0.472 | 0.530 | 0.752 | 0.568 | 99 | [qwen3coder30b_1cats_alldiff_20260114_223232_evaluation_results](qwen/qwen3coder30b_1cats_alldiff_20260114_223232_evaluation_results_summary.md) |

### IFLOWROME

| Model | Total Score | Grade | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---:|---|---:|---:|---:|---:|---:|---|
| iflow_rome | 2.725 | C (Fair) | 0.469 | 0.510 | 0.730 | 0.583 | 97 | [iflowrome_1cats_alldiff_20260119_175920_evaluation_results](iflowrome/iflowrome_1cats_alldiff_20260119_175920_evaluation_results_summary.md) |

### GLM4.7

| Model | Total Score | Grade | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---:|---|---:|---:|---:|---:|---:|---|
| z-ai/glm-4.7 | 2.798 | C (Fair) | 0.489 | 0.486 | 0.763 | 0.659 | 93 | [glm4.7_1cats_alldiff_20260120_233102_evaluation_results](glm4.7/glm4.7_1cats_alldiff_20260120_233102_evaluation_results_summary.md) |

### DEEPSEEKV3.2

| Model | Total Score | Grade | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---:|---|---:|---:|---:|---:|---:|---|
| deepseek/deepseek-v3.2 | 2.868 | C (Fair) | 0.495 | 0.489 | 0.799 | 0.692 | 85 | [deepseekv3.2_1cats_alldiff_20260121_092909_evaluation_results](deepseekv3.2/deepseekv3.2_1cats_alldiff_20260121_092909_evaluation_results_summary.md) |

## üí° Summary & Insights

- **Category:** Feature Implementation
- **Selection Rule:** Best alldiff run per provider by Total Score (from summary MD files)
- **Global Best:** claude-opus-4-5-20251101 (claude-proxy) ‚Äî 2.942

## üìñ Evaluation Framework

LoCoBench uses **17 metrics across 4 dimensions**:

- **üèóÔ∏è Software Engineering Excellence (8 metrics):** ACS, DTA, CFRD, STS, RS, CS, IS, SES
- **‚öôÔ∏è Functional Correctness (4 metrics):** Code Compilation, Unit Tests, Integration Tests, IDC
- **üîç Code Quality Assessment (3 metrics):** Security Analysis, Code Quality, Issue Detection
- **üß† Long-Context Utilization (2 metrics):** ICU, MMR

**Scoring:** LoCoBench Score (LCBS) = 40% SE + 30% FC + 20% CQ + 10% LCU

---

*Generated by LoCoBench v1.0 - Comprehensive long-context software development evaluation*
