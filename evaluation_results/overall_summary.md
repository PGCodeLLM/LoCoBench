# üìä LoCoBench Overall Summary

**Evaluation Date:** 2026-01-09 16:02:59
**Framework Version:** LoCoBench v1.0
**Benchmark:** Feature Implementation (best run per provider/difficulty)

## üèÜ Provider Performance by Difficulty

‚≠ê indicates the best score across all providers for that difficulty.

### CLAUDE-DIRECT

| Difficulty | Model | Total Score | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---|---:|---:|---:|---:|---:|---:|---|
| easy | claude-sonnet-4-5-20250929 | 2.750 ‚≠ê | 0.477 | 0.507 | 0.765 | 0.538 | 25 | claudesonnet4520250929_1cats_easy_20260109_142748_evaluation_results |
| medium | claude-sonnet-4-5-20250929 | 2.604 ‚≠ê | 0.457 | 0.465 | 0.736 | 0.513 | 44 | claudesonnet4520250929_1cats_medium_20260109_144631_evaluation_results |
| hard | claude-sonnet-4-5-20250929 | 2.557 ‚≠ê | 0.451 | 0.452 | 0.719 | 0.515 | 68 | claudesonnet4520250929_1cats_hard_20260109_152750_evaluation_results |
| expert | claude-sonnet-4-5-20250929 | 2.449 ‚≠ê | 0.434 | 0.427 | 0.701 | 0.478 | 99 | claudesonnet4520250929_1cats_expert_20260109_155637_evaluation_results |

### CLAUDE-PROXY

| Difficulty | Model | Total Score | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---|---:|---:|---:|---:|---:|---:|---|
| easy | claude-sonnet-4-5-20250929 | 2.699 | 0.470 | 0.502 | 0.740 | 0.533 | 25 | claudesonnet4520250929_1cats_easy_20260108_175947_evaluation_results |
| medium | claude-sonnet-4-5-20250929 | 2.540 | 0.446 | 0.460 | 0.711 | 0.494 | 44 | claudesonnet4520250929_1cats_medium_20260108_212633_evaluation_results |
| hard | claude-sonnet-4-5-20250929 | 2.488 | 0.442 | 0.437 | 0.702 | 0.493 | 68 | claudesonnet4520250929_1cats_hard_20260108_214601_evaluation_results |
| expert | claude-sonnet-4-5-20250929 | 2.432 | 0.433 | 0.424 | 0.696 | 0.468 | 100 | claudesonnet4520250929_1cats_expert_20260108_221907_evaluation_results |

### QWEN-NOVITA

| Difficulty | Model | Total Score | Software Engineering | Functional Correctness | Code Quality | Long-Context Util | Scenarios | Run |
|---|---|---:|---:|---:|---:|---:|---:|---|
| easy | qwen/qwen3-coder-30b-a3b-instruct | 2.300 | 0.381 | 0.397 | 0.718 | 0.447 | 74 | qwen3coder30ba3binstruct_1cats_easy_20260108_154904_evaluation_results |
| medium | qwen/qwen3-coder-30b-a3b-instruct | 2.467 | 0.415 | 0.436 | 0.732 | 0.502 | 122 | qwen3coder30ba3binstruct_1cats_medium_20260108_160955_evaluation_results |
| hard | qwen/qwen3-coder-30b-a3b-instruct | 2.511 | 0.424 | 0.449 | 0.733 | 0.513 | 146 | qwen3coder30ba3binstruct_1cats_hard_20260108_162651_evaluation_results |
| expert | qwen/qwen3-coder-30b-a3b-instruct | 2.407 | 0.405 | 0.418 | 0.727 | 0.487 | 103 | qwen3coder30ba3binstruct_1cats_expert_20260108_155940_evaluation_results |

## üí° Summary & Insights

- **Category:** Feature Implementation
- **Selection Rule:** Best run per provider/difficulty by Total Score (from summary MD files)
- **Global Best per Difficulty:**
  - **easy**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.750
  - **medium**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.604
  - **hard**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.557
  - **expert**: claude-sonnet-4-5-20250929 (claude-direct) ‚Äî 2.449

## üìñ Evaluation Framework

LoCoBench uses **17 metrics across 4 dimensions**:

- **üèóÔ∏è Software Engineering Excellence (8 metrics):** ACS, DTA, CFRD, STS, RS, CS, IS, SES
- **‚öôÔ∏è Functional Correctness (4 metrics):** Code Compilation, Unit Tests, Integration Tests, IDC
- **üîç Code Quality Assessment (3 metrics):** Security Analysis, Code Quality, Issue Detection
- **üß† Long-Context Utilization (2 metrics):** ICU, MMR

**Scoring:** LoCoBench Score (LCBS) = 40% SE + 30% FC + 20% CQ + 10% LCU

---

*Generated by LoCoBench v1.0 - Comprehensive long-context software development evaluation*
